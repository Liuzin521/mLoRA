[2025-12-23 16:07:55,543] m-LoRA: NVIDIA CUDA initialized successfully.
[2025-12-23 16:07:55,543] m-LoRA: Total 8 GPU(s) detected.
[2025-12-23 16:07:55,771] m-LoRA: Pipeline parallelism, rank is 0 and balance is [8, 9, 9, 9].
[2025-12-23 16:07:55,773] m-LoRA: Loading model with precision - bf16
[2025-12-23 16:07:57,219] m-LoRA: Some parameters are on the meta device because they were offloaded to the disk.
[2025-12-23 16:07:57,219] m-LoRA: loading llama compatible model - llama
[2025-12-23 16:07:57,367] m-LoRA: Adapter lora_winogrande_0 without lr_scheduler.
[2025-12-23 16:07:57,367] m-LoRA: Adapter lora_winogrande_1 without lr_scheduler.
[2025-12-23 16:07:57,367] m-LoRA: Adapter lora_winogrande_2 without lr_scheduler.
[2025-12-23 16:07:57,367] m-LoRA: Adapter lora_winogrande_3 without lr_scheduler.
[2025-12-23 16:07:57,367] m-LoRA: Adapter lora_winogrande_4 without lr_scheduler.
[2025-12-23 16:07:57,367] m-LoRA: Adapter lora_winogrande_5 without lr_scheduler.
[2025-12-23 16:07:57,367] m-LoRA: Adapter lora_winogrande_6 without lr_scheduler.
[2025-12-23 16:07:57,367] m-LoRA: Adapter lora_winogrande_7 without lr_scheduler.
[2025-12-23 16:07:57,367] m-LoRA: Adapter lora_winogrande_8 without lr_scheduler.
[2025-12-23 16:07:57,367] m-LoRA: Adapter lora_winogrande_9 without lr_scheduler.
[2025-12-23 16:07:57,367] m-LoRA: Adapter lora_winogrande_10 without lr_scheduler.
[2025-12-23 16:07:57,367] m-LoRA: Adapter lora_winogrande_11 without lr_scheduler.
[2025-12-23 16:07:57,367] m-LoRA: Adapter lora_winogrande_12 without lr_scheduler.
[2025-12-23 16:07:57,367] m-LoRA: Adapter lora_winogrande_13 without lr_scheduler.
[2025-12-23 16:07:57,367] m-LoRA: Adapter lora_winogrande_14 without lr_scheduler.
[2025-12-23 16:07:57,367] m-LoRA: Adapter lora_winogrande_15 without lr_scheduler.
[2025-12-23 16:07:57,368] m-LoRA: Adapter lora_winogrande_16 without lr_scheduler.
[2025-12-23 16:07:57,368] m-LoRA: Adapter lora_winogrande_17 without lr_scheduler.
[2025-12-23 16:07:57,368] m-LoRA: Adapter lora_winogrande_18 without lr_scheduler.
[2025-12-23 16:07:57,368] m-LoRA: Adapter lora_winogrande_19 without lr_scheduler.
[2025-12-23 16:07:57,368] m-LoRA: Adapter lora_winogrande_20 without lr_scheduler.
[2025-12-23 16:07:57,368] m-LoRA: Adapter lora_winogrande_21 without lr_scheduler.
[2025-12-23 16:07:57,368] m-LoRA: Adapter lora_winogrande_22 without lr_scheduler.
[2025-12-23 16:07:57,368] m-LoRA: Adapter lora_winogrande_23 without lr_scheduler.
[2025-12-23 16:07:57,368] m-LoRA: Adapter lora_winogrande_24 without lr_scheduler.
[2025-12-23 16:07:57,368] m-LoRA: Adapter lora_winogrande_25 without lr_scheduler.
[2025-12-23 16:07:57,368] m-LoRA: Adapter lora_winogrande_26 without lr_scheduler.
[2025-12-23 16:07:57,368] m-LoRA: Adapter lora_winogrande_27 without lr_scheduler.
[2025-12-23 16:07:57,368] m-LoRA: Adapter lora_winogrande_28 without lr_scheduler.
[2025-12-23 16:07:57,368] m-LoRA: Adapter lora_winogrande_29 without lr_scheduler.
[2025-12-23 16:07:57,368] m-LoRA: Adapter lora_winogrande_30 without lr_scheduler.
[2025-12-23 16:07:57,368] m-LoRA: Adapter lora_winogrande_31 without lr_scheduler.
[2025-12-23 16:07:57,368] m-LoRA: Adapter lora_winogrande_32 without lr_scheduler.
[2025-12-23 16:07:57,368] m-LoRA: Adapter lora_winogrande_33 without lr_scheduler.
[2025-12-23 16:07:57,368] m-LoRA: Adapter lora_winogrande_34 without lr_scheduler.
[2025-12-23 16:07:57,368] m-LoRA: Adapter lora_winogrande_35 without lr_scheduler.
[2025-12-23 16:07:57,368] m-LoRA: Adapter lora_winogrande_36 without lr_scheduler.
[2025-12-23 16:07:57,368] m-LoRA: Adapter lora_winogrande_37 without lr_scheduler.
[2025-12-23 16:07:57,368] m-LoRA: Adapter lora_winogrande_38 without lr_scheduler.
[2025-12-23 16:07:57,368] m-LoRA: Adapter lora_winogrande_39 without lr_scheduler.
[2025-12-23 16:07:57,368] m-LoRA: Adapter lora_winogrande_40 without lr_scheduler.
[2025-12-23 16:07:57,368] m-LoRA: Adapter lora_winogrande_41 without lr_scheduler.
[2025-12-23 16:07:57,368] m-LoRA: Adapter lora_winogrande_42 without lr_scheduler.
[2025-12-23 16:07:57,368] m-LoRA: Adapter lora_winogrande_43 without lr_scheduler.
[2025-12-23 16:07:57,368] m-LoRA: Adapter lora_winogrande_44 without lr_scheduler.
[2025-12-23 16:07:57,368] m-LoRA: Adapter lora_winogrande_45 without lr_scheduler.
[2025-12-23 16:07:57,368] m-LoRA: Adapter lora_winogrande_46 without lr_scheduler.
[2025-12-23 16:07:57,368] m-LoRA: Adapter lora_winogrande_47 without lr_scheduler.
[2025-12-23 16:07:57,368] m-LoRA: Adapter lora_winogrande_48 without lr_scheduler.
[2025-12-23 16:07:57,368] m-LoRA: Adapter lora_winogrande_49 without lr_scheduler.
[2025-12-23 16:07:57,368] m-LoRA: Adapter lora_winogrande_50 without lr_scheduler.
[2025-12-23 16:07:57,368] m-LoRA: Adapter lora_winogrande_51 without lr_scheduler.
[2025-12-23 16:07:57,368] m-LoRA: Adapter lora_winogrande_52 without lr_scheduler.
[2025-12-23 16:07:57,368] m-LoRA: Adapter lora_winogrande_53 without lr_scheduler.
[2025-12-23 16:07:57,368] m-LoRA: Adapter lora_winogrande_54 without lr_scheduler.
[2025-12-23 16:07:57,368] m-LoRA: Adapter lora_winogrande_55 without lr_scheduler.
[2025-12-23 16:07:57,368] m-LoRA: Adapter lora_winogrande_56 without lr_scheduler.
[2025-12-23 16:07:57,368] m-LoRA: Adapter lora_winogrande_57 without lr_scheduler.
[2025-12-23 16:07:57,368] m-LoRA: Adapter lora_winogrande_58 without lr_scheduler.
[2025-12-23 16:07:57,368] m-LoRA: Adapter lora_winogrande_59 without lr_scheduler.
[2025-12-23 16:07:57,368] m-LoRA: Adapter lora_winogrande_60 without lr_scheduler.
[2025-12-23 16:07:57,369] m-LoRA: Adapter lora_winogrande_61 without lr_scheduler.
[2025-12-23 16:07:57,369] m-LoRA: Adapter lora_winogrande_62 without lr_scheduler.
[2025-12-23 16:07:57,369] m-LoRA: Adapter lora_winogrande_63 without lr_scheduler.
[2025-12-23 16:07:57,369] m-LoRA: Adapter lora_winogrande_64 without lr_scheduler.
[2025-12-23 16:07:57,369] m-LoRA: Adapter lora_winogrande_65 without lr_scheduler.
[2025-12-23 16:07:57,369] m-LoRA: Adapter lora_winogrande_66 without lr_scheduler.
[2025-12-23 16:07:57,369] m-LoRA: Adapter lora_winogrande_67 without lr_scheduler.
[2025-12-23 16:07:57,369] m-LoRA: Adapter lora_winogrande_68 without lr_scheduler.
[2025-12-23 16:07:57,369] m-LoRA: Adapter lora_winogrande_69 without lr_scheduler.
[2025-12-23 16:07:57,369] m-LoRA: Adapter lora_winogrande_70 without lr_scheduler.
[2025-12-23 16:07:57,369] m-LoRA: Adapter lora_winogrande_71 without lr_scheduler.
[2025-12-23 16:07:57,369] m-LoRA: Adapter lora_winogrande_72 without lr_scheduler.
[2025-12-23 16:07:57,369] m-LoRA: Adapter lora_winogrande_73 without lr_scheduler.
[2025-12-23 16:07:57,369] m-LoRA: Adapter lora_winogrande_74 without lr_scheduler.
[2025-12-23 16:07:57,369] m-LoRA: Adapter lora_winogrande_75 without lr_scheduler.
[2025-12-23 16:07:57,369] m-LoRA: Adapter lora_winogrande_76 without lr_scheduler.
[2025-12-23 16:07:57,369] m-LoRA: Adapter lora_winogrande_77 without lr_scheduler.
[2025-12-23 16:07:57,369] m-LoRA: Adapter lora_winogrande_78 without lr_scheduler.
[2025-12-23 16:07:57,369] m-LoRA: Adapter lora_winogrande_79 without lr_scheduler.
[2025-12-23 16:07:57,369] m-LoRA: Adapter lora_winogrande_80 without lr_scheduler.
[2025-12-23 16:07:57,369] m-LoRA: Adapter lora_winogrande_81 without lr_scheduler.
[2025-12-23 16:07:57,369] m-LoRA: Adapter lora_winogrande_82 without lr_scheduler.
[2025-12-23 16:07:57,369] m-LoRA: Adapter lora_winogrande_83 without lr_scheduler.
[2025-12-23 16:07:57,369] m-LoRA: Adapter lora_winogrande_84 without lr_scheduler.
[2025-12-23 16:07:57,369] m-LoRA: Adapter lora_winogrande_85 without lr_scheduler.
[2025-12-23 16:07:57,369] m-LoRA: Adapter lora_winogrande_86 without lr_scheduler.
[2025-12-23 16:07:57,369] m-LoRA: Adapter lora_winogrande_87 without lr_scheduler.
[2025-12-23 16:07:57,369] m-LoRA: Adapter lora_winogrande_88 without lr_scheduler.
[2025-12-23 16:07:57,369] m-LoRA: Adapter lora_winogrande_89 without lr_scheduler.
[2025-12-23 16:07:57,376] m-LoRA: DeviceSwapQueue - input_data_queue start.
[2025-12-23 16:07:57,376] m-LoRA: RANK-0 in device cuda:0 to load module layers from 0 to 8.
[2025-12-23 16:07:57,378] m-LoRA: DeviceSwapQueue - ACTIVATIONS_send start.
[2025-12-23 16:07:57,378] m-LoRA: DeviceSwapQueue - GRADIENTS_send start.
[2025-12-23 16:07:57,379] m-LoRA: DeviceSwapQueue - ACTIVATIONS_recv start.
[2025-12-23 16:07:57,379] m-LoRA: DeviceSwapQueue - GRADIENTS_recv start.
[2025-12-23 16:08:01,345] m-LoRA: Init rpc with rank 0 world_size: 4
[2025-12-23 16:08:01,346] m-LoRA: Init train : task_winogrande_0 task with adapters: ['lora_winogrande_0']
[2025-12-23 16:08:03,312] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:08:03,564] m-LoRA: Adapter lora_winogrande_0 data size: 128
[2025-12-23 16:08:03,570] m-LoRA: Init train : task_winogrande_1 task with adapters: ['lora_winogrande_1']
[2025-12-23 16:08:05,524] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:08:05,786] m-LoRA: Adapter lora_winogrande_1 data size: 128
[2025-12-23 16:08:05,790] m-LoRA: Init train : task_winogrande_2 task with adapters: ['lora_winogrande_2']
[2025-12-23 16:08:07,129] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:08:07,409] m-LoRA: Adapter lora_winogrande_2 data size: 128
[2025-12-23 16:08:07,414] m-LoRA: Init train : task_winogrande_3 task with adapters: ['lora_winogrande_3']
[2025-12-23 16:08:07,478] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:08:07,734] m-LoRA: Adapter lora_winogrande_3 data size: 128
[2025-12-23 16:08:07,739] m-LoRA: Init train : task_winogrande_4 task with adapters: ['lora_winogrande_4']
[2025-12-23 16:08:08,687] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:08:08,945] m-LoRA: Adapter lora_winogrande_4 data size: 128
[2025-12-23 16:08:08,951] m-LoRA: Init train : task_winogrande_5 task with adapters: ['lora_winogrande_5']
[2025-12-23 16:08:09,856] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:08:10,124] m-LoRA: Adapter lora_winogrande_5 data size: 128
[2025-12-23 16:08:10,130] m-LoRA: Init train : task_winogrande_6 task with adapters: ['lora_winogrande_6']
[2025-12-23 16:08:11,156] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:08:11,406] m-LoRA: Adapter lora_winogrande_6 data size: 128
[2025-12-23 16:08:11,410] m-LoRA: Init train : task_winogrande_7 task with adapters: ['lora_winogrande_7']
[2025-12-23 16:08:12,356] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:08:12,633] m-LoRA: Adapter lora_winogrande_7 data size: 128
[2025-12-23 16:08:12,642] m-LoRA: Init train : task_winogrande_8 task with adapters: ['lora_winogrande_8']
[2025-12-23 16:08:13,471] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:08:13,729] m-LoRA: Adapter lora_winogrande_8 data size: 128
[2025-12-23 16:08:13,754] m-LoRA: Init train : task_winogrande_9 task with adapters: ['lora_winogrande_9']
[2025-12-23 16:08:14,766] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:08:15,024] m-LoRA: Adapter lora_winogrande_9 data size: 128
[2025-12-23 16:08:15,029] m-LoRA: Init train : task_winogrande_10 task with adapters: ['lora_winogrande_10']
[2025-12-23 16:08:16,543] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:08:16,799] m-LoRA: Adapter lora_winogrande_10 data size: 128
[2025-12-23 16:08:16,804] m-LoRA: Init train : task_winogrande_11 task with adapters: ['lora_winogrande_11']
[2025-12-23 16:08:18,823] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:08:19,081] m-LoRA: Adapter lora_winogrande_11 data size: 128
[2025-12-23 16:08:19,086] m-LoRA: Init train : task_winogrande_12 task with adapters: ['lora_winogrande_12']
[2025-12-23 16:08:20,872] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:08:21,122] m-LoRA: Adapter lora_winogrande_12 data size: 128
[2025-12-23 16:08:21,126] m-LoRA: Init train : task_winogrande_13 task with adapters: ['lora_winogrande_13']
[2025-12-23 16:08:22,897] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:08:23,143] m-LoRA: Adapter lora_winogrande_13 data size: 128
[2025-12-23 16:08:23,150] m-LoRA: Init train : task_winogrande_14 task with adapters: ['lora_winogrande_14']
[2025-12-23 16:08:24,802] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:08:25,068] m-LoRA: Adapter lora_winogrande_14 data size: 128
[2025-12-23 16:08:25,073] m-LoRA: Init train : task_winogrande_15 task with adapters: ['lora_winogrande_15']
[2025-12-23 16:08:26,814] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:08:27,057] m-LoRA: Adapter lora_winogrande_15 data size: 128
[2025-12-23 16:08:27,061] m-LoRA: Init train : task_winogrande_16 task with adapters: ['lora_winogrande_16']
[2025-12-23 16:08:28,891] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:08:29,145] m-LoRA: Adapter lora_winogrande_16 data size: 128
[2025-12-23 16:08:29,150] m-LoRA: Init train : task_winogrande_17 task with adapters: ['lora_winogrande_17']
[2025-12-23 16:08:30,761] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:08:31,023] m-LoRA: Adapter lora_winogrande_17 data size: 128
[2025-12-23 16:08:31,032] m-LoRA: Init train : task_winogrande_18 task with adapters: ['lora_winogrande_18']
[2025-12-23 16:08:31,140] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:08:31,411] m-LoRA: Adapter lora_winogrande_18 data size: 128
[2025-12-23 16:08:31,416] m-LoRA: Init train : task_winogrande_19 task with adapters: ['lora_winogrande_19']
[2025-12-23 16:08:32,851] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:08:33,115] m-LoRA: Adapter lora_winogrande_19 data size: 128
[2025-12-23 16:08:33,118] m-LoRA: Init train : task_winogrande_20 task with adapters: ['lora_winogrande_20']
[2025-12-23 16:08:34,419] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:08:34,682] m-LoRA: Adapter lora_winogrande_20 data size: 128
[2025-12-23 16:08:34,687] m-LoRA: Init train : task_winogrande_21 task with adapters: ['lora_winogrande_21']
[2025-12-23 16:08:36,401] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:08:36,692] m-LoRA: Adapter lora_winogrande_21 data size: 128
[2025-12-23 16:08:36,700] m-LoRA: Init train : task_winogrande_22 task with adapters: ['lora_winogrande_22']
[2025-12-23 16:08:36,957] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:08:37,208] m-LoRA: Adapter lora_winogrande_22 data size: 128
[2025-12-23 16:08:37,213] m-LoRA: Init train : task_winogrande_23 task with adapters: ['lora_winogrande_23']
[2025-12-23 16:08:38,794] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:08:39,065] m-LoRA: Adapter lora_winogrande_23 data size: 128
[2025-12-23 16:08:39,071] m-LoRA: Init train : task_winogrande_24 task with adapters: ['lora_winogrande_24']
[2025-12-23 16:08:39,185] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:08:39,446] m-LoRA: Adapter lora_winogrande_24 data size: 128
[2025-12-23 16:08:39,451] m-LoRA: Init train : task_winogrande_25 task with adapters: ['lora_winogrande_25']
[2025-12-23 16:08:41,299] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:08:41,562] m-LoRA: Adapter lora_winogrande_25 data size: 128
[2025-12-23 16:08:41,566] m-LoRA: Init train : task_winogrande_26 task with adapters: ['lora_winogrande_26']
[2025-12-23 16:08:43,502] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:08:43,769] m-LoRA: Adapter lora_winogrande_26 data size: 128
[2025-12-23 16:08:43,773] m-LoRA: Init train : task_winogrande_27 task with adapters: ['lora_winogrande_27']
[2025-12-23 16:08:44,830] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:08:45,102] m-LoRA: Adapter lora_winogrande_27 data size: 128
[2025-12-23 16:08:45,107] m-LoRA: Init train : task_winogrande_28 task with adapters: ['lora_winogrande_28']
[2025-12-23 16:08:45,657] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:08:45,935] m-LoRA: Adapter lora_winogrande_28 data size: 128
[2025-12-23 16:08:45,940] m-LoRA: Init train : task_winogrande_29 task with adapters: ['lora_winogrande_29']
[2025-12-23 16:08:47,695] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:08:47,965] m-LoRA: Adapter lora_winogrande_29 data size: 128
[2025-12-23 16:08:47,969] m-LoRA: Init train : task_winogrande_30 task with adapters: ['lora_winogrande_30']
[2025-12-23 16:08:48,651] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:08:48,929] m-LoRA: Adapter lora_winogrande_30 data size: 128
[2025-12-23 16:08:48,935] m-LoRA: Init train : task_winogrande_31 task with adapters: ['lora_winogrande_31']
[2025-12-23 16:08:50,207] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:08:50,486] m-LoRA: Adapter lora_winogrande_31 data size: 128
[2025-12-23 16:08:50,491] m-LoRA: Init train : task_winogrande_32 task with adapters: ['lora_winogrande_32']
[2025-12-23 16:08:52,200] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:08:52,468] m-LoRA: Adapter lora_winogrande_32 data size: 128
[2025-12-23 16:08:52,473] m-LoRA: Init train : task_winogrande_33 task with adapters: ['lora_winogrande_33']
[2025-12-23 16:08:52,750] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:08:53,002] m-LoRA: Adapter lora_winogrande_33 data size: 128
[2025-12-23 16:08:53,007] m-LoRA: Init train : task_winogrande_34 task with adapters: ['lora_winogrande_34']
[2025-12-23 16:08:53,868] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:08:54,132] m-LoRA: Adapter lora_winogrande_34 data size: 128
[2025-12-23 16:08:54,137] m-LoRA: Init train : task_winogrande_35 task with adapters: ['lora_winogrande_35']
[2025-12-23 16:08:55,040] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:08:55,310] m-LoRA: Adapter lora_winogrande_35 data size: 128
[2025-12-23 16:08:55,317] m-LoRA: Init train : task_winogrande_36 task with adapters: ['lora_winogrande_36']
[2025-12-23 16:08:56,910] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:08:57,194] m-LoRA: Adapter lora_winogrande_36 data size: 128
[2025-12-23 16:08:57,200] m-LoRA: Init train : task_winogrande_37 task with adapters: ['lora_winogrande_37']
[2025-12-23 16:08:58,588] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:08:58,857] m-LoRA: Adapter lora_winogrande_37 data size: 128
[2025-12-23 16:08:58,862] m-LoRA: Init train : task_winogrande_38 task with adapters: ['lora_winogrande_38']
[2025-12-23 16:09:00,675] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:09:00,948] m-LoRA: Adapter lora_winogrande_38 data size: 128
[2025-12-23 16:09:00,953] m-LoRA: Init train : task_winogrande_39 task with adapters: ['lora_winogrande_39']
[2025-12-23 16:09:02,514] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:09:02,774] m-LoRA: Adapter lora_winogrande_39 data size: 128
[2025-12-23 16:09:02,779] m-LoRA: Init train : task_winogrande_40 task with adapters: ['lora_winogrande_40']
[2025-12-23 16:09:04,489] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:09:04,752] m-LoRA: Adapter lora_winogrande_40 data size: 128
[2025-12-23 16:09:04,758] m-LoRA: Init train : task_winogrande_41 task with adapters: ['lora_winogrande_41']
[2025-12-23 16:09:06,643] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:09:06,921] m-LoRA: Adapter lora_winogrande_41 data size: 128
[2025-12-23 16:09:06,928] m-LoRA: Init train : task_winogrande_42 task with adapters: ['lora_winogrande_42']
[2025-12-23 16:09:08,585] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:09:08,847] m-LoRA: Adapter lora_winogrande_42 data size: 128
[2025-12-23 16:09:08,852] m-LoRA: Init train : task_winogrande_43 task with adapters: ['lora_winogrande_43']
[2025-12-23 16:09:10,613] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:09:10,870] m-LoRA: Adapter lora_winogrande_43 data size: 128
[2025-12-23 16:09:10,874] m-LoRA: Init train : task_winogrande_44 task with adapters: ['lora_winogrande_44']
[2025-12-23 16:09:12,136] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:09:12,405] m-LoRA: Adapter lora_winogrande_44 data size: 128
[2025-12-23 16:09:12,410] m-LoRA: Init train : task_winogrande_45 task with adapters: ['lora_winogrande_45']
[2025-12-23 16:09:12,638] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:09:12,913] m-LoRA: Adapter lora_winogrande_45 data size: 128
[2025-12-23 16:09:12,925] m-LoRA: Init train : task_winogrande_46 task with adapters: ['lora_winogrande_46']
[2025-12-23 16:09:14,403] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:09:14,656] m-LoRA: Adapter lora_winogrande_46 data size: 128
[2025-12-23 16:09:14,661] m-LoRA: Init train : task_winogrande_47 task with adapters: ['lora_winogrande_47']
[2025-12-23 16:09:16,278] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:09:16,564] m-LoRA: Adapter lora_winogrande_47 data size: 128
[2025-12-23 16:09:16,569] m-LoRA: Init train : task_winogrande_48 task with adapters: ['lora_winogrande_48']
[2025-12-23 16:09:16,679] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:09:16,949] m-LoRA: Adapter lora_winogrande_48 data size: 128
[2025-12-23 16:09:16,954] m-LoRA: Init train : task_winogrande_49 task with adapters: ['lora_winogrande_49']
[2025-12-23 16:09:18,209] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:09:18,473] m-LoRA: Adapter lora_winogrande_49 data size: 128
[2025-12-23 16:09:18,498] m-LoRA: Init train : task_winogrande_50 task with adapters: ['lora_winogrande_50']
[2025-12-23 16:09:20,244] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:09:20,514] m-LoRA: Adapter lora_winogrande_50 data size: 128
[2025-12-23 16:09:20,518] m-LoRA: Init train : task_winogrande_51 task with adapters: ['lora_winogrande_51']
[2025-12-23 16:09:22,263] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:09:22,530] m-LoRA: Adapter lora_winogrande_51 data size: 128
[2025-12-23 16:09:22,535] m-LoRA: Init train : task_winogrande_52 task with adapters: ['lora_winogrande_52']
[2025-12-23 16:09:22,916] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:09:23,170] m-LoRA: Adapter lora_winogrande_52 data size: 128
[2025-12-23 16:09:23,175] m-LoRA: Init train : task_winogrande_53 task with adapters: ['lora_winogrande_53']
[2025-12-23 16:09:24,798] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:09:25,075] m-LoRA: Adapter lora_winogrande_53 data size: 128
[2025-12-23 16:09:25,079] m-LoRA: Init train : task_winogrande_54 task with adapters: ['lora_winogrande_54']
[2025-12-23 16:09:25,306] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:09:25,558] m-LoRA: Adapter lora_winogrande_54 data size: 128
[2025-12-23 16:09:25,564] m-LoRA: Init train : task_winogrande_55 task with adapters: ['lora_winogrande_55']
[2025-12-23 16:09:25,705] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:09:25,959] m-LoRA: Adapter lora_winogrande_55 data size: 128
[2025-12-23 16:09:25,963] m-LoRA: Init train : task_winogrande_56 task with adapters: ['lora_winogrande_56']
[2025-12-23 16:09:27,192] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:09:27,448] m-LoRA: Adapter lora_winogrande_56 data size: 128
[2025-12-23 16:09:27,453] m-LoRA: Init train : task_winogrande_57 task with adapters: ['lora_winogrande_57']
[2025-12-23 16:09:27,671] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:09:27,934] m-LoRA: Adapter lora_winogrande_57 data size: 128
[2025-12-23 16:09:27,939] m-LoRA: Init train : task_winogrande_58 task with adapters: ['lora_winogrande_58']
[2025-12-23 16:09:29,353] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:09:29,622] m-LoRA: Adapter lora_winogrande_58 data size: 128
[2025-12-23 16:09:29,627] m-LoRA: Init train : task_winogrande_59 task with adapters: ['lora_winogrande_59']
[2025-12-23 16:09:31,586] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:09:31,860] m-LoRA: Adapter lora_winogrande_59 data size: 128
[2025-12-23 16:09:31,871] m-LoRA: Init train : task_winogrande_60 task with adapters: ['lora_winogrande_60']
[2025-12-23 16:09:33,122] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:09:33,380] m-LoRA: Adapter lora_winogrande_60 data size: 128
[2025-12-23 16:09:33,384] m-LoRA: Init train : task_winogrande_61 task with adapters: ['lora_winogrande_61']
[2025-12-23 16:09:34,647] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:09:34,925] m-LoRA: Adapter lora_winogrande_61 data size: 128
[2025-12-23 16:09:34,930] m-LoRA: Init train : task_winogrande_62 task with adapters: ['lora_winogrande_62']
[2025-12-23 16:09:35,459] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:09:35,719] m-LoRA: Adapter lora_winogrande_62 data size: 128
[2025-12-23 16:09:35,723] m-LoRA: Init train : task_winogrande_63 task with adapters: ['lora_winogrande_63']
[2025-12-23 16:09:35,931] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:09:36,181] m-LoRA: Adapter lora_winogrande_63 data size: 128
[2025-12-23 16:09:36,187] m-LoRA: Init train : task_winogrande_64 task with adapters: ['lora_winogrande_64']
[2025-12-23 16:09:37,700] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:09:37,956] m-LoRA: Adapter lora_winogrande_64 data size: 128
[2025-12-23 16:09:37,960] m-LoRA: Init train : task_winogrande_65 task with adapters: ['lora_winogrande_65']
[2025-12-23 16:09:38,180] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:09:38,448] m-LoRA: Adapter lora_winogrande_65 data size: 128
[2025-12-23 16:09:38,453] m-LoRA: Init train : task_winogrande_66 task with adapters: ['lora_winogrande_66']
[2025-12-23 16:09:39,891] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:09:40,167] m-LoRA: Adapter lora_winogrande_66 data size: 128
[2025-12-23 16:09:40,172] m-LoRA: Init train : task_winogrande_67 task with adapters: ['lora_winogrande_67']
[2025-12-23 16:09:41,716] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:09:41,975] m-LoRA: Adapter lora_winogrande_67 data size: 128
[2025-12-23 16:09:41,980] m-LoRA: Init train : task_winogrande_68 task with adapters: ['lora_winogrande_68']
[2025-12-23 16:09:43,019] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:09:43,345] m-LoRA: Adapter lora_winogrande_68 data size: 128
[2025-12-23 16:09:43,350] m-LoRA: Init train : task_winogrande_69 task with adapters: ['lora_winogrande_69']
[2025-12-23 16:09:45,275] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:09:45,539] m-LoRA: Adapter lora_winogrande_69 data size: 128
[2025-12-23 16:09:45,545] m-LoRA: Init train : task_winogrande_70 task with adapters: ['lora_winogrande_70']
[2025-12-23 16:09:47,155] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:09:47,415] m-LoRA: Adapter lora_winogrande_70 data size: 128
[2025-12-23 16:09:47,420] m-LoRA: Init train : task_winogrande_71 task with adapters: ['lora_winogrande_71']
[2025-12-23 16:09:49,102] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:09:49,366] m-LoRA: Adapter lora_winogrande_71 data size: 128
[2025-12-23 16:09:49,370] m-LoRA: Init train : task_winogrande_72 task with adapters: ['lora_winogrande_72']
[2025-12-23 16:09:49,564] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:09:49,836] m-LoRA: Adapter lora_winogrande_72 data size: 128
[2025-12-23 16:09:49,842] m-LoRA: Init train : task_winogrande_73 task with adapters: ['lora_winogrande_73']
[2025-12-23 16:09:51,534] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:09:51,809] m-LoRA: Adapter lora_winogrande_73 data size: 128
[2025-12-23 16:09:51,816] m-LoRA: Init train : task_winogrande_74 task with adapters: ['lora_winogrande_74']
[2025-12-23 16:09:52,202] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:09:52,499] m-LoRA: Adapter lora_winogrande_74 data size: 128
[2025-12-23 16:09:52,509] m-LoRA: Init train : task_winogrande_75 task with adapters: ['lora_winogrande_75']
[2025-12-23 16:09:54,089] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:09:54,359] m-LoRA: Adapter lora_winogrande_75 data size: 128
[2025-12-23 16:09:54,367] m-LoRA: Init train : task_winogrande_76 task with adapters: ['lora_winogrande_76']
[2025-12-23 16:09:54,433] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:09:54,693] m-LoRA: Adapter lora_winogrande_76 data size: 128
[2025-12-23 16:09:54,721] m-LoRA: Init train : task_winogrande_77 task with adapters: ['lora_winogrande_77']
[2025-12-23 16:09:56,176] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:09:56,425] m-LoRA: Adapter lora_winogrande_77 data size: 128
[2025-12-23 16:09:56,429] m-LoRA: Init train : task_winogrande_78 task with adapters: ['lora_winogrande_78']
[2025-12-23 16:09:57,358] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:09:57,632] m-LoRA: Adapter lora_winogrande_78 data size: 128
[2025-12-23 16:09:57,639] m-LoRA: Init train : task_winogrande_79 task with adapters: ['lora_winogrande_79']
[2025-12-23 16:09:58,327] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:09:58,601] m-LoRA: Adapter lora_winogrande_79 data size: 128
[2025-12-23 16:09:58,606] m-LoRA: Init train : task_winogrande_80 task with adapters: ['lora_winogrande_80']
[2025-12-23 16:09:59,685] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:09:59,939] m-LoRA: Adapter lora_winogrande_80 data size: 128
[2025-12-23 16:09:59,944] m-LoRA: Init train : task_winogrande_81 task with adapters: ['lora_winogrande_81']
[2025-12-23 16:10:01,002] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:10:01,270] m-LoRA: Adapter lora_winogrande_81 data size: 128
[2025-12-23 16:10:01,300] m-LoRA: Init train : task_winogrande_82 task with adapters: ['lora_winogrande_82']
[2025-12-23 16:10:02,079] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:10:02,321] m-LoRA: Adapter lora_winogrande_82 data size: 128
[2025-12-23 16:10:02,325] m-LoRA: Init train : task_winogrande_83 task with adapters: ['lora_winogrande_83']
[2025-12-23 16:10:03,884] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:10:04,141] m-LoRA: Adapter lora_winogrande_83 data size: 128
[2025-12-23 16:10:04,145] m-LoRA: Init train : task_winogrande_84 task with adapters: ['lora_winogrande_84']
[2025-12-23 16:10:06,124] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:10:06,389] m-LoRA: Adapter lora_winogrande_84 data size: 128
[2025-12-23 16:10:06,396] m-LoRA: Init train : task_winogrande_85 task with adapters: ['lora_winogrande_85']
[2025-12-23 16:10:07,840] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:10:08,095] m-LoRA: Adapter lora_winogrande_85 data size: 128
[2025-12-23 16:10:08,100] m-LoRA: Init train : task_winogrande_86 task with adapters: ['lora_winogrande_86']
[2025-12-23 16:10:08,318] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:10:08,583] m-LoRA: Adapter lora_winogrande_86 data size: 128
[2025-12-23 16:10:08,589] m-LoRA: Init train : task_winogrande_87 task with adapters: ['lora_winogrande_87']
[2025-12-23 16:10:09,939] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:10:10,196] m-LoRA: Adapter lora_winogrande_87 data size: 128
[2025-12-23 16:10:10,201] m-LoRA: Init train : task_winogrande_88 task with adapters: ['lora_winogrande_88']
[2025-12-23 16:10:10,326] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:10:10,596] m-LoRA: Adapter lora_winogrande_88 data size: 128
[2025-12-23 16:10:10,603] m-LoRA: Init train : task_winogrande_89 task with adapters: ['lora_winogrande_89']
[2025-12-23 16:10:11,856] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/winogrande_train_subset_128.json
[2025-12-23 16:10:12,132] m-LoRA: Adapter lora_winogrande_89 data size: 128
[2025-12-23 16:10:12,138] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_0']
[2025-12-23 16:10:12,207] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_1']
[2025-12-23 16:10:12,332] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_2']
[2025-12-23 16:10:12,403] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_3']
[2025-12-23 16:10:12,435] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_4']
[2025-12-23 16:10:12,500] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_5']
[2025-12-23 16:10:12,564] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_6']
[2025-12-23 16:10:12,681] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_7']
[2025-12-23 16:10:12,743] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_8']
[2025-12-23 16:10:12,825] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_9']
[2025-12-23 16:10:12,915] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_10']
[2025-12-23 16:10:12,991] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_11']
[2025-12-23 16:10:13,123] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_12']
[2025-12-23 16:10:13,271] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_13']
[2025-12-23 16:10:13,350] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_14']
[2025-12-23 16:10:13,435] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_15']
[2025-12-23 16:10:13,533] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_16']
[2025-12-23 16:10:13,714] m-LoRA: Adapter lora_winogrande_0 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:10:14,033] m-LoRA: Adapter lora_winogrande_1 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:10:14,054] m-LoRA: Adapter lora_winogrande_2 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:10:14,139] m-LoRA: Adapter lora_winogrande_3 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:10:14,196] m-LoRA: Adapter lora_winogrande_4 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:10:14,242] m-LoRA: Adapter lora_winogrande_5 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:10:14,267] m-LoRA: Adapter lora_winogrande_6 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:10:14,293] m-LoRA: Adapter lora_winogrande_7 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:10:14,311] m-LoRA: Adapter lora_winogrande_8 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:10:14,331] m-LoRA: Adapter lora_winogrande_9 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:10:14,348] m-LoRA: Adapter lora_winogrande_10 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:10:14,367] m-LoRA: Adapter lora_winogrande_11 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:10:14,385] m-LoRA: Adapter lora_winogrande_12 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:10:14,403] m-LoRA: Adapter lora_winogrande_13 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:10:14,426] m-LoRA: Adapter lora_winogrande_14 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:10:14,469] m-LoRA: Adapter lora_winogrande_15 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:10:14,514] m-LoRA: Adapter lora_winogrande_16 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:10:16,435] m-LoRA: Adapter lora_winogrande_0 loss: 2.915083646774292
[2025-12-23 16:10:16,672] m-LoRA: Adapter lora_winogrande_1 loss: 2.952209949493408
[2025-12-23 16:10:17,715] m-LoRA: Adapter lora_winogrande_5 loss: 3.2007369995117188
[2025-12-23 16:10:17,719] m-LoRA: Adapter lora_winogrande_0 epoch: 1/1 iteration: 2/128 step: 2
[2025-12-23 16:10:17,913] m-LoRA: Adapter lora_winogrande_9 loss: 3.1259350776672363
[2025-12-23 16:10:17,915] m-LoRA: Adapter lora_winogrande_1 epoch: 1/1 iteration: 4/128 step: 2
[2025-12-23 16:10:17,998] m-LoRA: Adapter lora_winogrande_2 loss: 2.911566734313965
[2025-12-23 16:10:18,184] m-LoRA: Adapter lora_winogrande_7 loss: 3.187764883041382
[2025-12-23 16:10:18,642] m-LoRA: Adapter lora_winogrande_6 loss: 3.1304714679718018
[2025-12-23 16:10:19,401] m-LoRA: Adapter lora_winogrande_4 loss: 3.1883351802825928
[2025-12-23 16:10:19,408] m-LoRA: Adapter lora_winogrande_5 epoch: 1/1 iteration: 8/128 step: 2
[2025-12-23 16:10:20,128] m-LoRA: Adapter lora_winogrande_3 loss: 3.3053362369537354
[2025-12-23 16:10:20,135] m-LoRA: Adapter lora_winogrande_9 epoch: 1/1 iteration: 2/128 step: 2
[2025-12-23 16:10:20,430] m-LoRA: Adapter lora_winogrande_8 loss: 3.2252354621887207
[2025-12-23 16:10:20,432] m-LoRA: Adapter lora_winogrande_2 epoch: 1/1 iteration: 4/128 step: 2
[2025-12-23 16:10:20,582] m-LoRA: Adapter lora_winogrande_10 loss: 3.008415699005127
[2025-12-23 16:10:20,585] m-LoRA: Adapter lora_winogrande_7 epoch: 1/1 iteration: 4/128 step: 2
[2025-12-23 16:10:20,707] m-LoRA: Adapter lora_winogrande_11 loss: 2.8864665031433105
[2025-12-23 16:10:20,709] m-LoRA: Adapter lora_winogrande_6 epoch: 1/1 iteration: 8/128 step: 2
[2025-12-23 16:10:20,842] m-LoRA: Adapter lora_winogrande_12 loss: 2.9532086849212646
[2025-12-23 16:10:20,850] m-LoRA: Adapter lora_winogrande_13 loss: 3.1391570568084717
[2025-12-23 16:10:21,641] m-LoRA: Adapter lora_winogrande_14 loss: 3.1512300968170166
[2025-12-23 16:10:21,647] m-LoRA: Adapter lora_winogrande_4 epoch: 1/1 iteration: 16/128 step: 2
[2025-12-23 16:10:21,986] m-LoRA: Adapter lora_winogrande_16 loss: 3.117689609527588
[2025-12-23 16:10:21,991] m-LoRA: Adapter lora_winogrande_3 epoch: 1/1 iteration: 16/128 step: 2
[2025-12-23 16:10:22,746] m-LoRA: Adapter lora_winogrande_15 loss: 3.3935999870300293
[2025-12-23 16:10:22,752] m-LoRA: Adapter lora_winogrande_8 epoch: 1/1 iteration: 4/128 step: 2
[2025-12-23 16:10:23,030] m-LoRA: Adapter lora_winogrande_0 loss: 2.6766140460968018
[2025-12-23 16:10:23,032] m-LoRA: Adapter lora_winogrande_10 epoch: 1/1 iteration: 4/128 step: 2
[2025-12-23 16:10:23,152] m-LoRA: Adapter lora_winogrande_1 loss: 2.524561643600464
[2025-12-23 16:10:23,155] m-LoRA: Adapter lora_winogrande_11 epoch: 1/1 iteration: 2/128 step: 2
[2025-12-23 16:10:23,378] m-LoRA: Adapter lora_winogrande_5 loss: 2.961329221725464
[2025-12-23 16:10:23,382] m-LoRA: Adapter lora_winogrande_12 epoch: 1/1 iteration: 2/128 step: 2
[2025-12-23 16:10:23,519] m-LoRA: Adapter lora_winogrande_9 loss: 2.731290578842163
[2025-12-23 16:10:23,521] m-LoRA: Adapter lora_winogrande_13 epoch: 1/1 iteration: 8/128 step: 2
[2025-12-23 16:10:23,677] m-LoRA: Adapter lora_winogrande_2 loss: 3.0125844478607178
[2025-12-23 16:10:23,680] m-LoRA: Adapter lora_winogrande_14 epoch: 1/1 iteration: 16/128 step: 2
[2025-12-23 16:10:23,816] m-LoRA: Adapter lora_winogrande_7 loss: 2.585822343826294
[2025-12-23 16:10:23,818] m-LoRA: Adapter lora_winogrande_16 epoch: 1/1 iteration: 8/128 step: 2
[2025-12-23 16:10:24,111] m-LoRA: Adapter lora_winogrande_6 loss: 2.6725778579711914
[2025-12-23 16:10:25,165] m-LoRA: Adapter lora_winogrande_4 loss: 3.037848711013794
[2025-12-23 16:10:25,172] m-LoRA: Adapter lora_winogrande_15 epoch: 1/1 iteration: 16/128 step: 2
[2025-12-23 16:10:25,928] m-LoRA: Adapter lora_winogrande_3 loss: 2.9185497760772705
[2025-12-23 16:10:25,934] m-LoRA: Adapter lora_winogrande_0 epoch: 1/1 iteration: 4/128 step: 3
[2025-12-23 16:10:26,136] m-LoRA: Adapter lora_winogrande_8 loss: 3.046761989593506
[2025-12-23 16:10:26,139] m-LoRA: Adapter lora_winogrande_1 epoch: 1/1 iteration: 8/128 step: 3
[2025-12-23 16:10:26,271] m-LoRA: Adapter lora_winogrande_10 loss: 2.468813180923462
[2025-12-23 16:10:26,273] m-LoRA: Adapter lora_winogrande_5 epoch: 1/1 iteration: 16/128 step: 3
[2025-12-23 16:10:26,424] m-LoRA: Adapter lora_winogrande_11 loss: 2.727301836013794
[2025-12-23 16:10:26,427] m-LoRA: Adapter lora_winogrande_9 epoch: 1/1 iteration: 4/128 step: 3
[2025-12-23 16:10:26,536] m-LoRA: Adapter lora_winogrande_12 loss: 2.407285451889038
[2025-12-23 16:10:26,539] m-LoRA: Adapter lora_winogrande_2 epoch: 1/1 iteration: 8/128 step: 3
[2025-12-23 16:10:26,841] m-LoRA: Adapter lora_winogrande_7 epoch: 1/1 iteration: 8/128 step: 3
[2025-12-23 16:10:26,882] m-LoRA: Adapter lora_winogrande_13 loss: 3.054563045501709
[2025-12-23 16:10:27,636] m-LoRA: Adapter lora_winogrande_14 loss: 2.641274929046631
[2025-12-23 16:10:27,643] m-LoRA: Adapter lora_winogrande_6 epoch: 1/1 iteration: 16/128 step: 3
[2025-12-23 16:10:27,998] m-LoRA: Adapter lora_winogrande_16 loss: 2.4254744052886963
[2025-12-23 16:10:28,002] m-LoRA: Adapter lora_winogrande_4 epoch: 1/1 iteration: 32/128 step: 3
[2025-12-23 16:10:28,744] m-LoRA: Adapter lora_winogrande_15 loss: 3.16994047164917
[2025-12-23 16:10:28,751] m-LoRA: Adapter lora_winogrande_3 epoch: 1/1 iteration: 32/128 step: 3
[2025-12-23 16:10:28,902] m-LoRA: Adapter lora_winogrande_0 loss: 2.047988176345825
[2025-12-23 16:10:28,904] m-LoRA: Adapter lora_winogrande_8 epoch: 1/1 iteration: 8/128 step: 3
[2025-12-23 16:10:29,014] m-LoRA: Adapter lora_winogrande_1 loss: 1.8955013751983643
[2025-12-23 16:10:29,017] m-LoRA: Adapter lora_winogrande_10 epoch: 1/1 iteration: 8/128 step: 3
[2025-12-23 16:10:29,285] m-LoRA: Adapter lora_winogrande_11 epoch: 1/1 iteration: 4/128 step: 3
[2025-12-23 16:10:29,373] m-LoRA: Adapter lora_winogrande_5 loss: 2.187436103820801
[2025-12-23 16:10:29,376] m-LoRA: Adapter lora_winogrande_12 epoch: 1/1 iteration: 4/128 step: 3
[2025-12-23 16:10:29,398] m-LoRA: Adapter lora_winogrande_9 loss: 2.9405503273010254
[2025-12-23 16:10:29,557] m-LoRA: Adapter lora_winogrande_2 loss: 3.1343705654144287
[2025-12-23 16:10:29,559] m-LoRA: Adapter lora_winogrande_13 epoch: 1/1 iteration: 16/128 step: 3
[2025-12-23 16:10:29,750] m-LoRA: Adapter lora_winogrande_7 loss: 2.1316893100738525
[2025-12-23 16:10:29,752] m-LoRA: Adapter lora_winogrande_14 epoch: 1/1 iteration: 32/128 step: 3
[2025-12-23 16:10:30,119] m-LoRA: Adapter lora_winogrande_6 loss: 2.12766170501709
[2025-12-23 16:10:30,124] m-LoRA: Adapter lora_winogrande_16 epoch: 1/1 iteration: 16/128 step: 3
[2025-12-23 16:10:30,902] m-LoRA: Adapter lora_winogrande_4 loss: 3.078672409057617
[2025-12-23 16:10:30,908] m-LoRA: Adapter lora_winogrande_15 epoch: 1/1 iteration: 32/128 step: 3
[2025-12-23 16:10:31,541] m-LoRA: Adapter lora_winogrande_0 epoch: 1/1 iteration: 6/128 step: 4
[2025-12-23 16:10:31,584] m-LoRA: Adapter lora_winogrande_3 loss: 2.487664222717285
[2025-12-23 16:10:31,779] m-LoRA: Adapter lora_winogrande_8 loss: 3.0659377574920654
[2025-12-23 16:10:31,783] m-LoRA: Adapter lora_winogrande_1 epoch: 1/1 iteration: 12/128 step: 4
[2025-12-23 16:10:31,974] m-LoRA: Adapter lora_winogrande_10 loss: 2.094005584716797
[2025-12-23 16:10:31,976] m-LoRA: Adapter lora_winogrande_5 epoch: 1/1 iteration: 24/128 step: 4
[2025-12-23 16:10:32,104] m-LoRA: Adapter lora_winogrande_11 loss: 2.1854727268218994
[2025-12-23 16:10:32,106] m-LoRA: Adapter lora_winogrande_9 epoch: 1/1 iteration: 6/128 step: 4
[2025-12-23 16:10:32,221] m-LoRA: Adapter lora_winogrande_12 loss: 2.3361663818359375
[2025-12-23 16:10:32,224] m-LoRA: Adapter lora_winogrande_2 epoch: 1/1 iteration: 12/128 step: 4
[2025-12-23 16:10:32,453] m-LoRA: Adapter lora_winogrande_7 epoch: 1/1 iteration: 12/128 step: 4
[2025-12-23 16:10:32,496] m-LoRA: Adapter lora_winogrande_13 loss: 2.9945976734161377
[2025-12-23 16:10:33,157] m-LoRA: Adapter lora_winogrande_6 epoch: 1/1 iteration: 24/128 step: 4
[2025-12-23 16:10:33,219] m-LoRA: Adapter lora_winogrande_14 loss: 2.0278260707855225
[2025-12-23 16:10:33,664] m-LoRA: Adapter lora_winogrande_16 loss: 1.958510160446167
[2025-12-23 16:10:33,669] m-LoRA: Adapter lora_winogrande_4 epoch: 1/1 iteration: 48/128 step: 4
[2025-12-23 16:10:34,325] m-LoRA: Adapter lora_winogrande_15 loss: 3.096778154373169
[2025-12-23 16:10:34,332] m-LoRA: Adapter lora_winogrande_3 epoch: 1/1 iteration: 48/128 step: 4
[2025-12-23 16:10:34,528] m-LoRA: Adapter lora_winogrande_0 loss: 1.8523708581924438
[2025-12-23 16:10:34,530] m-LoRA: Adapter lora_winogrande_8 epoch: 1/1 iteration: 12/128 step: 4
[2025-12-23 16:10:34,661] m-LoRA: Adapter lora_winogrande_1 loss: 1.6944466829299927
[2025-12-23 16:10:34,664] m-LoRA: Adapter lora_winogrande_10 epoch: 1/1 iteration: 12/128 step: 4
[2025-12-23 16:10:34,982] m-LoRA: Adapter lora_winogrande_5 loss: 1.9976158142089844
[2025-12-23 16:10:34,987] m-LoRA: Adapter lora_winogrande_11 epoch: 1/1 iteration: 6/128 step: 4
[2025-12-23 16:10:35,143] m-LoRA: Adapter lora_winogrande_9 loss: 3.1478939056396484
[2025-12-23 16:10:35,145] m-LoRA: Adapter lora_winogrande_12 epoch: 1/1 iteration: 6/128 step: 4
[2025-12-23 16:10:35,289] m-LoRA: Adapter lora_winogrande_2 loss: 2.9566402435302734
[2025-12-23 16:10:35,293] m-LoRA: Adapter lora_winogrande_13 epoch: 1/1 iteration: 24/128 step: 4
[2025-12-23 16:10:35,489] m-LoRA: Adapter lora_winogrande_7 loss: 1.951028823852539
[2025-12-23 16:10:35,491] m-LoRA: Adapter lora_winogrande_14 epoch: 1/1 iteration: 48/128 step: 4
[2025-12-23 16:10:35,812] m-LoRA: Adapter lora_winogrande_6 loss: 2.0083208084106445
[2025-12-23 16:10:35,816] m-LoRA: Adapter lora_winogrande_16 epoch: 1/1 iteration: 24/128 step: 4
[2025-12-23 16:10:36,579] m-LoRA: Adapter lora_winogrande_15 epoch: 1/1 iteration: 48/128 step: 4
[2025-12-23 16:10:36,642] m-LoRA: Adapter lora_winogrande_4 loss: 3.167708158493042
[2025-12-23 16:10:37,403] m-LoRA: Adapter lora_winogrande_3 loss: 2.290189743041992
[2025-12-23 16:10:37,409] m-LoRA: Adapter lora_winogrande_0 epoch: 1/1 iteration: 8/128 step: 5
[2025-12-23 16:10:37,600] m-LoRA: Adapter lora_winogrande_8 loss: 2.983301877975464
[2025-12-23 16:10:37,604] m-LoRA: Adapter lora_winogrande_1 epoch: 1/1 iteration: 16/128 step: 5
[2025-12-23 16:10:37,769] m-LoRA: Adapter lora_winogrande_10 loss: 1.840531349182129
[2025-12-23 16:10:37,772] m-LoRA: Adapter lora_winogrande_5 epoch: 1/1 iteration: 32/128 step: 5
[2025-12-23 16:10:37,875] m-LoRA: Adapter lora_winogrande_11 loss: 1.863631248474121
[2025-12-23 16:10:37,877] m-LoRA: Adapter lora_winogrande_9 epoch: 1/1 iteration: 8/128 step: 5
[2025-12-23 16:10:37,969] m-LoRA: Adapter lora_winogrande_12 loss: 1.9902751445770264
[2025-12-23 16:10:37,971] m-LoRA: Adapter lora_winogrande_2 epoch: 1/1 iteration: 16/128 step: 5
[2025-12-23 16:10:38,352] m-LoRA: Adapter lora_winogrande_13 loss: 2.9960176944732666
[2025-12-23 16:10:38,356] m-LoRA: Adapter lora_winogrande_7 epoch: 1/1 iteration: 16/128 step: 5
[2025-12-23 16:10:39,071] m-LoRA: Adapter lora_winogrande_14 loss: 1.9570034742355347
[2025-12-23 16:10:39,078] m-LoRA: Adapter lora_winogrande_6 epoch: 1/1 iteration: 32/128 step: 5
[2025-12-23 16:10:39,488] m-LoRA: Adapter lora_winogrande_16 loss: 1.6687963008880615
[2025-12-23 16:10:39,493] m-LoRA: Adapter lora_winogrande_4 epoch: 1/1 iteration: 64/128 step: 5
[2025-12-23 16:10:40,268] m-LoRA: Adapter lora_winogrande_15 loss: 3.2007293701171875
[2025-12-23 16:10:40,275] m-LoRA: Adapter lora_winogrande_3 epoch: 1/1 iteration: 64/128 step: 5
[2025-12-23 16:10:40,588] m-LoRA: Adapter lora_winogrande_0 loss: 1.5835658311843872
[2025-12-23 16:10:40,590] m-LoRA: Adapter lora_winogrande_8 epoch: 1/1 iteration: 16/128 step: 5
[2025-12-23 16:10:40,666] m-LoRA: Adapter lora_winogrande_1 loss: 1.2608187198638916
[2025-12-23 16:10:40,670] m-LoRA: Adapter lora_winogrande_10 epoch: 1/1 iteration: 16/128 step: 5
[2025-12-23 16:10:41,009] m-LoRA: Adapter lora_winogrande_5 loss: 1.8221776485443115
[2025-12-23 16:10:41,012] m-LoRA: Adapter lora_winogrande_11 epoch: 1/1 iteration: 8/128 step: 5
[2025-12-23 16:10:41,186] m-LoRA: Adapter lora_winogrande_9 loss: 2.950944423675537
[2025-12-23 16:10:41,188] m-LoRA: Adapter lora_winogrande_12 epoch: 1/1 iteration: 8/128 step: 5
[2025-12-23 16:10:41,349] m-LoRA: Adapter lora_winogrande_2 loss: 2.88952898979187
[2025-12-23 16:10:41,353] m-LoRA: Adapter lora_winogrande_13 epoch: 1/1 iteration: 32/128 step: 5
[2025-12-23 16:10:41,531] m-LoRA: Adapter lora_winogrande_7 loss: 1.7073911428451538
[2025-12-23 16:10:41,534] m-LoRA: Adapter lora_winogrande_14 epoch: 1/1 iteration: 64/128 step: 5
[2025-12-23 16:10:41,806] m-LoRA: Adapter lora_winogrande_6 loss: 1.8616572618484497
[2025-12-23 16:10:41,811] m-LoRA: Adapter lora_winogrande_16 epoch: 1/1 iteration: 32/128 step: 5
[2025-12-23 16:10:42,485] m-LoRA: Adapter lora_winogrande_15 epoch: 1/1 iteration: 64/128 step: 5
[2025-12-23 16:10:42,540] m-LoRA: Adapter lora_winogrande_4 loss: 2.917067766189575
[2025-12-23 16:10:43,385] m-LoRA: Adapter lora_winogrande_3 loss: 2.117100954055786
[2025-12-23 16:10:43,391] m-LoRA: Adapter lora_winogrande_0 epoch: 1/1 iteration: 10/128 step: 6
[2025-12-23 16:10:43,543] m-LoRA: Adapter lora_winogrande_8 loss: 3.073779344558716
[2025-12-23 16:10:43,546] m-LoRA: Adapter lora_winogrande_1 epoch: 1/1 iteration: 20/128 step: 6
[2025-12-23 16:10:43,669] m-LoRA: Adapter lora_winogrande_10 loss: 1.7402005195617676
[2025-12-23 16:10:43,672] m-LoRA: Adapter lora_winogrande_5 epoch: 1/1 iteration: 40/128 step: 6
[2025-12-23 16:10:43,766] m-LoRA: Adapter lora_winogrande_11 loss: 1.8119854927062988
[2025-12-23 16:10:43,768] m-LoRA: Adapter lora_winogrande_9 epoch: 1/1 iteration: 10/128 step: 6
[2025-12-23 16:10:43,856] m-LoRA: Adapter lora_winogrande_12 loss: 1.6116746664047241
[2025-12-23 16:10:43,858] m-LoRA: Adapter lora_winogrande_2 epoch: 1/1 iteration: 20/128 step: 6
[2025-12-23 16:10:44,145] m-LoRA: Adapter lora_winogrande_7 epoch: 1/1 iteration: 20/128 step: 6
[2025-12-23 16:10:44,185] m-LoRA: Adapter lora_winogrande_13 loss: 2.7688560485839844
[2025-12-23 16:10:48,005] m-LoRA: Adapter lora_winogrande_14 loss: 1.749267816543579
[2025-12-23 16:10:48,023] m-LoRA: Adapter lora_winogrande_6 epoch: 1/1 iteration: 40/128 step: 6
[2025-12-23 16:10:48,352] m-LoRA: Adapter lora_winogrande_16 loss: 1.3970284461975098
[2025-12-23 16:10:48,356] m-LoRA: Adapter lora_winogrande_4 epoch: 1/1 iteration: 80/128 step: 6
[2025-12-23 16:10:48,531] m-LoRA: Adapter lora_winogrande_15 loss: 2.9056146144866943
[2025-12-23 16:10:48,538] m-LoRA: Adapter lora_winogrande_3 epoch: 1/1 iteration: 80/128 step: 6
[2025-12-23 16:10:48,728] m-LoRA: Adapter lora_winogrande_0 loss: 1.5516072511672974
[2025-12-23 16:10:48,730] m-LoRA: Adapter lora_winogrande_8 epoch: 1/1 iteration: 20/128 step: 6
[2025-12-23 16:10:48,834] m-LoRA: Adapter lora_winogrande_1 loss: 1.063533902168274
[2025-12-23 16:10:48,837] m-LoRA: Adapter lora_winogrande_10 epoch: 1/1 iteration: 20/128 step: 6
[2025-12-23 16:10:48,996] m-LoRA: Adapter lora_winogrande_5 loss: 1.5413163900375366
[2025-12-23 16:10:49,000] m-LoRA: Adapter lora_winogrande_11 epoch: 1/1 iteration: 10/128 step: 6
[2025-12-23 16:10:49,166] m-LoRA: Adapter lora_winogrande_9 loss: 2.7929558753967285
[2025-12-23 16:10:49,168] m-LoRA: Adapter lora_winogrande_12 epoch: 1/1 iteration: 10/128 step: 6
[2025-12-23 16:10:49,285] m-LoRA: Adapter lora_winogrande_2 loss: 2.8437347412109375
[2025-12-23 16:10:49,288] m-LoRA: Adapter lora_winogrande_13 epoch: 1/1 iteration: 40/128 step: 6
[2025-12-23 16:10:49,358] m-LoRA: Adapter lora_winogrande_7 loss: 1.4907262325286865
[2025-12-23 16:10:49,656] m-LoRA: Adapter lora_winogrande_6 loss: 1.521502137184143
[2025-12-23 16:10:49,659] m-LoRA: Adapter lora_winogrande_14 epoch: 1/1 iteration: 80/128 step: 6
[2025-12-23 16:10:50,411] m-LoRA: Adapter lora_winogrande_16 epoch: 1/1 iteration: 40/128 step: 6
[2025-12-23 16:10:50,473] m-LoRA: Adapter lora_winogrande_4 loss: 2.906853437423706
[2025-12-23 16:10:51,197] m-LoRA: Adapter lora_winogrande_15 epoch: 1/1 iteration: 80/128 step: 6
[2025-12-23 16:10:51,267] m-LoRA: Adapter lora_winogrande_3 loss: 1.919973611831665
[2025-12-23 16:10:51,465] m-LoRA: Adapter lora_winogrande_8 loss: 2.858670473098755
[2025-12-23 16:10:51,468] m-LoRA: Adapter lora_winogrande_0 epoch: 1/1 iteration: 12/128 step: 7
[2025-12-23 16:10:51,631] m-LoRA: Adapter lora_winogrande_10 loss: 1.3872451782226562
[2025-12-23 16:10:51,645] m-LoRA: Adapter lora_winogrande_1 epoch: 1/1 iteration: 24/128 step: 7
[2025-12-23 16:10:51,788] m-LoRA: Adapter lora_winogrande_11 loss: 1.5257424116134644
[2025-12-23 16:10:51,811] m-LoRA: Adapter lora_winogrande_5 epoch: 1/1 iteration: 48/128 step: 7
[2025-12-23 16:10:51,925] m-LoRA: Adapter lora_winogrande_12 loss: 1.3613413572311401
[2025-12-23 16:10:51,928] m-LoRA: Adapter lora_winogrande_9 epoch: 1/1 iteration: 12/128 step: 7
[2025-12-23 16:10:52,179] m-LoRA: Adapter lora_winogrande_2 epoch: 1/1 iteration: 24/128 step: 7
[2025-12-23 16:10:52,217] m-LoRA: Adapter lora_winogrande_13 loss: 2.9166157245635986
[2025-12-23 16:10:52,872] m-LoRA: Adapter lora_winogrande_7 epoch: 1/1 iteration: 24/128 step: 7
[2025-12-23 16:10:52,917] m-LoRA: Adapter lora_winogrande_14 loss: 1.6161656379699707
[2025-12-23 16:10:53,294] m-LoRA: Adapter lora_winogrande_16 loss: 1.0950247049331665
[2025-12-23 16:10:53,298] m-LoRA: Adapter lora_winogrande_6 epoch: 1/1 iteration: 48/128 step: 7
[2025-12-23 16:10:54,689] m-LoRA: Adapter lora_winogrande_15 loss: 2.882551908493042
[2025-12-23 16:10:54,697] m-LoRA: Adapter lora_winogrande_4 epoch: 1/1 iteration: 96/128 step: 7
[2025-12-23 16:10:54,903] m-LoRA: Adapter lora_winogrande_0 loss: 1.1960402727127075
[2025-12-23 16:10:54,905] m-LoRA: Adapter lora_winogrande_3 epoch: 1/1 iteration: 96/128 step: 7
[2025-12-23 16:10:55,138] m-LoRA: Adapter lora_winogrande_1 loss: 0.8452858328819275
[2025-12-23 16:10:55,140] m-LoRA: Adapter lora_winogrande_8 epoch: 1/1 iteration: 24/128 step: 7
[2025-12-23 16:10:55,743] m-LoRA: Adapter lora_winogrande_5 loss: 1.3928955793380737
[2025-12-23 16:10:55,746] m-LoRA: Adapter lora_winogrande_10 epoch: 1/1 iteration: 24/128 step: 7
[2025-12-23 16:10:55,914] m-LoRA: Adapter lora_winogrande_9 loss: 2.8064980506896973
[2025-12-23 16:10:55,917] m-LoRA: Adapter lora_winogrande_11 epoch: 1/1 iteration: 12/128 step: 7
[2025-12-23 16:10:56,134] m-LoRA: Adapter lora_winogrande_2 loss: 2.6864945888519287
[2025-12-23 16:10:56,137] m-LoRA: Adapter lora_winogrande_12 epoch: 1/1 iteration: 12/128 step: 7
[2025-12-23 16:10:56,426] m-LoRA: Adapter lora_winogrande_7 loss: 1.2359509468078613
[2025-12-23 16:10:56,429] m-LoRA: Adapter lora_winogrande_13 epoch: 1/1 iteration: 48/128 step: 7
[2025-12-23 16:10:56,796] m-LoRA: Adapter lora_winogrande_14 epoch: 1/1 iteration: 96/128 step: 7
[2025-12-23 16:10:56,876] m-LoRA: Adapter lora_winogrande_6 loss: 1.348523497581482
[2025-12-23 16:10:57,682] m-LoRA: Adapter lora_winogrande_4 loss: 2.651201009750366
[2025-12-23 16:10:57,689] m-LoRA: Adapter lora_winogrande_16 epoch: 1/1 iteration: 48/128 step: 7
[2025-12-23 16:10:58,280] m-LoRA: Adapter lora_winogrande_15 epoch: 1/1 iteration: 96/128 step: 7
[2025-12-23 16:10:58,414] m-LoRA: Adapter lora_winogrande_3 loss: 1.9061965942382812
[2025-12-23 16:10:58,420] m-LoRA: Adapter lora_winogrande_0 epoch: 1/1 iteration: 14/128 step: 8
[2025-12-23 16:10:58,457] m-LoRA: Adapter lora_winogrande_8 loss: 2.6185216903686523
[2025-12-23 16:10:58,718] m-LoRA: Adapter lora_winogrande_10 loss: 1.2884132862091064
[2025-12-23 16:10:58,721] m-LoRA: Adapter lora_winogrande_1 epoch: 1/1 iteration: 28/128 step: 8
[2025-12-23 16:10:58,827] m-LoRA: Adapter lora_winogrande_11 loss: 1.2479456663131714
[2025-12-23 16:10:58,829] m-LoRA: Adapter lora_winogrande_5 epoch: 1/1 iteration: 56/128 step: 8
[2025-12-23 16:10:58,929] m-LoRA: Adapter lora_winogrande_12 loss: 1.1524267196655273
[2025-12-23 16:10:58,931] m-LoRA: Adapter lora_winogrande_9 epoch: 1/1 iteration: 14/128 step: 8
[2025-12-23 16:10:59,198] m-LoRA: Adapter lora_winogrande_2 epoch: 1/1 iteration: 28/128 step: 8
[2025-12-23 16:10:59,238] m-LoRA: Adapter lora_winogrande_13 loss: 2.682135820388794
[2025-12-23 16:11:01,858] m-LoRA: Adapter lora_winogrande_14 loss: 1.2785130739212036
[2025-12-23 16:11:01,865] m-LoRA: Adapter lora_winogrande_7 epoch: 1/1 iteration: 28/128 step: 8
[2025-12-23 16:11:02,993] m-LoRA: Adapter lora_winogrande_16 loss: 0.8550761938095093
[2025-12-23 16:11:02,998] m-LoRA: Adapter lora_winogrande_6 epoch: 1/1 iteration: 56/128 step: 8
[2025-12-23 16:11:03,252] m-LoRA: Adapter lora_winogrande_15 loss: 2.6898691654205322
[2025-12-23 16:11:03,258] m-LoRA: Adapter lora_winogrande_4 epoch: 1/1 iteration: 112/128 step: 8
[2025-12-23 16:11:03,449] m-LoRA: Adapter lora_winogrande_0 loss: 1.0573583841323853
[2025-12-23 16:11:03,451] m-LoRA: Adapter lora_winogrande_3 epoch: 1/1 iteration: 112/128 step: 8
[2025-12-23 16:11:03,574] m-LoRA: Adapter lora_winogrande_1 loss: 0.7448511123657227
[2025-12-23 16:11:03,577] m-LoRA: Adapter lora_winogrande_8 epoch: 1/1 iteration: 28/128 step: 8
[2025-12-23 16:11:03,735] m-LoRA: Adapter lora_winogrande_5 loss: 1.178006887435913
[2025-12-23 16:11:03,739] m-LoRA: Adapter lora_winogrande_10 epoch: 1/1 iteration: 28/128 step: 8
[2025-12-23 16:11:03,892] m-LoRA: Adapter lora_winogrande_9 loss: 2.746830940246582
[2025-12-23 16:11:03,894] m-LoRA: Adapter lora_winogrande_11 epoch: 1/1 iteration: 14/128 step: 8
[2025-12-23 16:11:03,996] m-LoRA: Adapter lora_winogrande_2 loss: 2.6349291801452637
[2025-12-23 16:11:03,999] m-LoRA: Adapter lora_winogrande_12 epoch: 1/1 iteration: 14/128 step: 8
[2025-12-23 16:11:04,109] m-LoRA: Adapter lora_winogrande_13 epoch: 1/1 iteration: 56/128 step: 8
[2025-12-23 16:11:04,390] m-LoRA: Adapter lora_winogrande_7 loss: 1.0938303470611572
[2025-12-23 16:11:05,032] m-LoRA: Adapter lora_winogrande_6 loss: 1.1450090408325195
[2025-12-23 16:11:05,036] m-LoRA: Adapter lora_winogrande_14 epoch: 1/1 iteration: 112/128 step: 8
[2025-12-23 16:11:05,766] m-LoRA: Adapter lora_winogrande_4 loss: 2.565084218978882
[2025-12-23 16:11:05,773] m-LoRA: Adapter lora_winogrande_16 epoch: 1/1 iteration: 56/128 step: 8
[2025-12-23 16:11:06,417] m-LoRA: Adapter lora_winogrande_15 epoch: 1/1 iteration: 112/128 step: 8
[2025-12-23 16:11:06,578] m-LoRA: Adapter lora_winogrande_3 loss: 1.7251720428466797
[2025-12-23 16:11:06,584] m-LoRA: Adapter lora_winogrande_0 epoch: 1/1 iteration: 16/128 step: 9
[2025-12-23 16:11:06,619] m-LoRA: Adapter lora_winogrande_8 loss: 2.5205042362213135
[2025-12-23 16:11:06,722] m-LoRA: Adapter lora_winogrande_10 loss: 1.054742455482483
[2025-12-23 16:11:06,840] m-LoRA: Adapter lora_winogrande_11 loss: 1.0324351787567139
[2025-12-23 16:11:06,921] m-LoRA: Adapter lora_winogrande_1 epoch: 1/1 iteration: 32/128 step: 9
[2025-12-23 16:11:07,057] m-LoRA: Adapter lora_winogrande_12 loss: 1.0044459104537964
[2025-12-23 16:11:07,059] m-LoRA: Adapter lora_winogrande_5 epoch: 1/1 iteration: 64/128 step: 9
[2025-12-23 16:11:07,143] m-LoRA: Adapter lora_winogrande_9 epoch: 1/1 iteration: 16/128 step: 9
[2025-12-23 16:11:07,385] m-LoRA: Adapter lora_winogrande_13 loss: 2.5879647731781006
[2025-12-23 16:11:07,389] m-LoRA: Adapter lora_winogrande_2 epoch: 1/1 iteration: 32/128 step: 9
[2025-12-23 16:11:08,114] m-LoRA: Adapter lora_winogrande_7 epoch: 1/1 iteration: 32/128 step: 9
[2025-12-23 16:11:08,154] m-LoRA: Adapter lora_winogrande_14 loss: 1.2432103157043457
[2025-12-23 16:11:08,546] m-LoRA: Adapter lora_winogrande_16 loss: 0.7145543694496155
[2025-12-23 16:11:08,550] m-LoRA: Adapter lora_winogrande_6 epoch: 1/1 iteration: 64/128 step: 9
[2025-12-23 16:11:09,245] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_4']
[2025-12-23 16:11:09,585] m-LoRA: Adapter lora_winogrande_15 loss: 2.5674102306365967
[2025-12-23 16:11:09,591] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_17']
[2025-12-23 16:11:10,038] m-LoRA: Adapter lora_winogrande_17 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:11:10,168] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_3']
[2025-12-23 16:11:10,322] m-LoRA: Adapter lora_winogrande_0 loss: 0.8486315608024597
[2025-12-23 16:11:10,334] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_18']
[2025-12-23 16:11:10,429] m-LoRA: Adapter lora_winogrande_18 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:11:10,524] m-LoRA: Adapter lora_winogrande_1 loss: 0.6983880400657654
[2025-12-23 16:11:10,526] m-LoRA: Adapter lora_winogrande_8 epoch: 1/1 iteration: 32/128 step: 9
[2025-12-23 16:11:10,739] m-LoRA: Adapter lora_winogrande_5 loss: 1.038910150527954
[2025-12-23 16:11:10,743] m-LoRA: Adapter lora_winogrande_10 epoch: 1/1 iteration: 32/128 step: 9
[2025-12-23 16:11:10,882] m-LoRA: Adapter lora_winogrande_9 loss: 2.5084285736083984
[2025-12-23 16:11:10,884] m-LoRA: Adapter lora_winogrande_11 epoch: 1/1 iteration: 16/128 step: 9
[2025-12-23 16:11:10,977] m-LoRA: Adapter lora_winogrande_2 loss: 2.3814949989318848
[2025-12-23 16:11:10,979] m-LoRA: Adapter lora_winogrande_12 epoch: 1/1 iteration: 16/128 step: 9
[2025-12-23 16:11:11,088] m-LoRA: Adapter lora_winogrande_7 loss: 0.8238572478294373
[2025-12-23 16:11:11,092] m-LoRA: Adapter lora_winogrande_13 epoch: 1/1 iteration: 64/128 step: 9
[2025-12-23 16:11:11,227] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_14']
[2025-12-23 16:11:11,502] m-LoRA: Adapter lora_winogrande_6 loss: 0.9564619660377502
[2025-12-23 16:11:11,583] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_19']
[2025-12-23 16:11:11,800] m-LoRA: Adapter lora_winogrande_19 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:11:11,916] m-LoRA: Adapter lora_winogrande_17 loss: 3.2912075519561768
[2025-12-23 16:11:11,921] m-LoRA: Adapter lora_winogrande_16 epoch: 1/1 iteration: 64/128 step: 9
[2025-12-23 16:11:12,046] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_15']
[2025-12-23 16:11:12,296] m-LoRA: Adapter lora_winogrande_18 loss: 3.038581371307373
[2025-12-23 16:11:12,298] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_20']
[2025-12-23 16:11:12,436] m-LoRA: Adapter lora_winogrande_20 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:11:12,535] m-LoRA: Adapter lora_winogrande_8 loss: 2.500458240509033
[2025-12-23 16:11:12,539] m-LoRA: Adapter lora_winogrande_0 epoch: 1/1 iteration: 18/128 step: 10
[2025-12-23 16:11:12,653] m-LoRA: Adapter lora_winogrande_10 loss: 0.9762588143348694
[2025-12-23 16:11:12,657] m-LoRA: Adapter lora_winogrande_1 epoch: 1/1 iteration: 36/128 step: 10
[2025-12-23 16:11:12,782] m-LoRA: Adapter lora_winogrande_11 loss: 1.0519142150878906
[2025-12-23 16:11:12,785] m-LoRA: Adapter lora_winogrande_5 epoch: 1/1 iteration: 72/128 step: 10
[2025-12-23 16:11:12,926] m-LoRA: Adapter lora_winogrande_9 epoch: 1/1 iteration: 18/128 step: 10
[2025-12-23 16:11:13,522] m-LoRA: Adapter lora_winogrande_12 loss: 0.7401267886161804
[2025-12-23 16:11:13,525] m-LoRA: Adapter lora_winogrande_2 epoch: 1/1 iteration: 36/128 step: 10
[2025-12-23 16:11:13,761] m-LoRA: Adapter lora_winogrande_7 epoch: 1/1 iteration: 36/128 step: 10
[2025-12-23 16:11:14,153] m-LoRA: Adapter lora_winogrande_13 loss: 2.3536572456359863
[2025-12-23 16:11:14,158] m-LoRA: Adapter lora_winogrande_6 epoch: 1/1 iteration: 72/128 step: 10
[2025-12-23 16:11:14,331] m-LoRA: Adapter lora_winogrande_19 loss: 2.8866970539093018
[2025-12-23 16:11:14,333] m-LoRA: Adapter lora_winogrande_17 epoch: 1/1 iteration: 8/128 step: 2
[2025-12-23 16:11:14,617] m-LoRA: Adapter lora_winogrande_18 epoch: 1/1 iteration: 2/128 step: 2
[2025-12-23 16:11:14,749] m-LoRA: Adapter lora_winogrande_16 loss: 0.6431658267974854
[2025-12-23 16:11:14,753] m-LoRA: Adapter lora_winogrande_8 epoch: 1/1 iteration: 36/128 step: 10
[2025-12-23 16:11:14,940] m-LoRA: Adapter lora_winogrande_20 loss: 2.7077548503875732
[2025-12-23 16:11:14,943] m-LoRA: Adapter lora_winogrande_10 epoch: 1/1 iteration: 36/128 step: 10
[2025-12-23 16:11:15,111] m-LoRA: Adapter lora_winogrande_0 loss: 0.7060794234275818
[2025-12-23 16:11:15,113] m-LoRA: Adapter lora_winogrande_11 epoch: 1/1 iteration: 18/128 step: 10
[2025-12-23 16:11:15,168] m-LoRA: Adapter lora_winogrande_1 loss: 0.6718600392341614
[2025-12-23 16:11:15,414] m-LoRA: Adapter lora_winogrande_5 loss: 0.8215859532356262
[2025-12-23 16:11:15,418] m-LoRA: Adapter lora_winogrande_12 epoch: 1/1 iteration: 18/128 step: 10
[2025-12-23 16:11:15,574] m-LoRA: Adapter lora_winogrande_9 loss: 2.4116928577423096
[2025-12-23 16:11:15,577] m-LoRA: Adapter lora_winogrande_13 epoch: 1/1 iteration: 72/128 step: 10
[2025-12-23 16:11:15,702] m-LoRA: Adapter lora_winogrande_2 loss: 2.386826753616333
[2025-12-23 16:11:15,705] m-LoRA: Adapter lora_winogrande_19 epoch: 1/1 iteration: 4/128 step: 2
[2025-12-23 16:11:15,843] m-LoRA: Adapter lora_winogrande_7 loss: 0.7057346701622009
[2025-12-23 16:11:15,846] m-LoRA: Adapter lora_winogrande_16 epoch: 1/1 iteration: 72/128 step: 10
[2025-12-23 16:11:16,165] m-LoRA: Adapter lora_winogrande_20 epoch: 1/1 iteration: 2/128 step: 2
[2025-12-23 16:11:16,202] m-LoRA: Adapter lora_winogrande_6 loss: 0.8571183085441589
[2025-12-23 16:11:16,645] m-LoRA: Adapter lora_winogrande_17 loss: 2.382672071456909
[2025-12-23 16:11:16,649] m-LoRA: Adapter lora_winogrande_0 epoch: 1/1 iteration: 20/128 step: 11
[2025-12-23 16:11:16,834] m-LoRA: Adapter lora_winogrande_18 loss: 3.024010419845581
[2025-12-23 16:11:16,837] m-LoRA: Adapter lora_winogrande_1 epoch: 1/1 iteration: 40/128 step: 11
[2025-12-23 16:11:16,970] m-LoRA: Adapter lora_winogrande_8 loss: 2.4343464374542236
[2025-12-23 16:11:16,972] m-LoRA: Adapter lora_winogrande_5 epoch: 1/1 iteration: 80/128 step: 11
[2025-12-23 16:11:17,152] m-LoRA: Adapter lora_winogrande_10 loss: 0.8298887610435486
[2025-12-23 16:11:17,154] m-LoRA: Adapter lora_winogrande_9 epoch: 1/1 iteration: 20/128 step: 11
[2025-12-23 16:11:17,272] m-LoRA: Adapter lora_winogrande_11 loss: 0.8707707524299622
[2025-12-23 16:11:17,274] m-LoRA: Adapter lora_winogrande_2 epoch: 1/1 iteration: 40/128 step: 11
[2025-12-23 16:11:17,381] m-LoRA: Adapter lora_winogrande_12 loss: 0.6870941519737244
[2025-12-23 16:11:17,383] m-LoRA: Adapter lora_winogrande_7 epoch: 1/1 iteration: 40/128 step: 11
[2025-12-23 16:11:17,586] m-LoRA: Adapter lora_winogrande_13 loss: 2.3318653106689453
[2025-12-23 16:11:17,589] m-LoRA: Adapter lora_winogrande_6 epoch: 1/1 iteration: 80/128 step: 11
[2025-12-23 16:11:17,795] m-LoRA: Adapter lora_winogrande_19 loss: 2.6082732677459717
[2025-12-23 16:11:17,797] m-LoRA: Adapter lora_winogrande_17 epoch: 1/1 iteration: 16/128 step: 3
[2025-12-23 16:11:18,134] m-LoRA: Adapter lora_winogrande_16 loss: 0.5982068777084351
[2025-12-23 16:11:18,137] m-LoRA: Adapter lora_winogrande_18 epoch: 1/1 iteration: 4/128 step: 3
[2025-12-23 16:11:18,303] m-LoRA: Adapter lora_winogrande_20 loss: 2.850403070449829
[2025-12-23 16:11:18,306] m-LoRA: Adapter lora_winogrande_8 epoch: 1/1 iteration: 40/128 step: 11
[2025-12-23 16:11:18,475] m-LoRA: Adapter lora_winogrande_0 loss: 0.7122440338134766
[2025-12-23 16:11:18,477] m-LoRA: Adapter lora_winogrande_10 epoch: 1/1 iteration: 40/128 step: 11
[2025-12-23 16:11:18,593] m-LoRA: Adapter lora_winogrande_1 loss: 0.5849947929382324
[2025-12-23 16:11:18,595] m-LoRA: Adapter lora_winogrande_11 epoch: 1/1 iteration: 20/128 step: 11
[2025-12-23 16:11:18,811] m-LoRA: Adapter lora_winogrande_5 loss: 0.7723233103752136
[2025-12-23 16:11:18,815] m-LoRA: Adapter lora_winogrande_12 epoch: 1/1 iteration: 20/128 step: 11
[2025-12-23 16:11:18,979] m-LoRA: Adapter lora_winogrande_9 loss: 2.4295432567596436
[2025-12-23 16:11:18,982] m-LoRA: Adapter lora_winogrande_13 epoch: 1/1 iteration: 80/128 step: 11
[2025-12-23 16:11:19,152] m-LoRA: Adapter lora_winogrande_2 loss: 2.1593873500823975
[2025-12-23 16:11:19,155] m-LoRA: Adapter lora_winogrande_19 epoch: 1/1 iteration: 8/128 step: 3
[2025-12-23 16:11:19,316] m-LoRA: Adapter lora_winogrande_7 loss: 0.6773866415023804
[2025-12-23 16:11:19,320] m-LoRA: Adapter lora_winogrande_16 epoch: 1/1 iteration: 80/128 step: 11
[2025-12-23 16:11:19,692] m-LoRA: Adapter lora_winogrande_6 loss: 0.7149693965911865
[2025-12-23 16:11:19,695] m-LoRA: Adapter lora_winogrande_20 epoch: 1/1 iteration: 4/128 step: 3
[2025-12-23 16:11:20,063] m-LoRA: Adapter lora_winogrande_17 loss: 2.0355279445648193
[2025-12-23 16:11:20,066] m-LoRA: Adapter lora_winogrande_0 epoch: 1/1 iteration: 22/128 step: 12
[2025-12-23 16:11:20,261] m-LoRA: Adapter lora_winogrande_18 loss: 3.1448276042938232
[2025-12-23 16:11:20,268] m-LoRA: Adapter lora_winogrande_1 epoch: 1/1 iteration: 44/128 step: 12
[2025-12-23 16:11:20,379] m-LoRA: Adapter lora_winogrande_8 loss: 2.3565008640289307
[2025-12-23 16:11:20,381] m-LoRA: Adapter lora_winogrande_5 epoch: 1/1 iteration: 88/128 step: 12
[2025-12-23 16:11:20,551] m-LoRA: Adapter lora_winogrande_10 loss: 0.6827391386032104
[2025-12-23 16:11:20,553] m-LoRA: Adapter lora_winogrande_9 epoch: 1/1 iteration: 22/128 step: 12
[2025-12-23 16:11:20,682] m-LoRA: Adapter lora_winogrande_11 loss: 0.6858319640159607
[2025-12-23 16:11:20,684] m-LoRA: Adapter lora_winogrande_2 epoch: 1/1 iteration: 44/128 step: 12
[2025-12-23 16:11:20,788] m-LoRA: Adapter lora_winogrande_12 loss: 0.6475631594657898
[2025-12-23 16:11:20,790] m-LoRA: Adapter lora_winogrande_7 epoch: 1/1 iteration: 44/128 step: 12
[2025-12-23 16:11:21,001] m-LoRA: Adapter lora_winogrande_6 epoch: 1/1 iteration: 88/128 step: 12
[2025-12-23 16:11:21,050] m-LoRA: Adapter lora_winogrande_13 loss: 2.255201578140259
[2025-12-23 16:11:21,211] m-LoRA: Adapter lora_winogrande_19 loss: 2.220928192138672
[2025-12-23 16:11:21,689] m-LoRA: Adapter lora_winogrande_16 loss: 0.5627627372741699
[2025-12-23 16:11:21,693] m-LoRA: Adapter lora_winogrande_17 epoch: 1/1 iteration: 24/128 step: 4
[2025-12-23 16:11:21,882] m-LoRA: Adapter lora_winogrande_20 loss: 2.2325775623321533
[2025-12-23 16:11:21,884] m-LoRA: Adapter lora_winogrande_18 epoch: 1/1 iteration: 6/128 step: 4
[2025-12-23 16:11:22,038] m-LoRA: Adapter lora_winogrande_0 loss: 0.6657780408859253
[2025-12-23 16:11:22,074] m-LoRA: Adapter lora_winogrande_8 epoch: 1/1 iteration: 44/128 step: 12
[2025-12-23 16:11:22,208] m-LoRA: Adapter lora_winogrande_1 loss: 0.6340827941894531
[2025-12-23 16:11:22,211] m-LoRA: Adapter lora_winogrande_10 epoch: 1/1 iteration: 44/128 step: 12
[2025-12-23 16:11:22,548] m-LoRA: Adapter lora_winogrande_5 loss: 0.6953257322311401
[2025-12-23 16:11:22,551] m-LoRA: Adapter lora_winogrande_11 epoch: 1/1 iteration: 22/128 step: 12
[2025-12-23 16:11:22,711] m-LoRA: Adapter lora_winogrande_9 loss: 2.3360421657562256
[2025-12-23 16:11:22,734] m-LoRA: Adapter lora_winogrande_12 epoch: 1/1 iteration: 22/128 step: 12
[2025-12-23 16:11:22,845] m-LoRA: Adapter lora_winogrande_2 loss: 2.264256238937378
[2025-12-23 16:11:22,848] m-LoRA: Adapter lora_winogrande_13 epoch: 1/1 iteration: 88/128 step: 12
[2025-12-23 16:11:23,054] m-LoRA: Adapter lora_winogrande_7 loss: 0.5746783018112183
[2025-12-23 16:11:23,061] m-LoRA: Adapter lora_winogrande_19 epoch: 1/1 iteration: 12/128 step: 4
[2025-12-23 16:11:23,444] m-LoRA: Adapter lora_winogrande_6 loss: 0.6283196806907654
[2025-12-23 16:11:23,449] m-LoRA: Adapter lora_winogrande_16 epoch: 1/1 iteration: 88/128 step: 12
[2025-12-23 16:11:23,823] m-LoRA: Adapter lora_winogrande_17 loss: 1.6925255060195923
[2025-12-23 16:11:23,827] m-LoRA: Adapter lora_winogrande_20 epoch: 1/1 iteration: 6/128 step: 4
[2025-12-23 16:11:24,006] m-LoRA: Adapter lora_winogrande_18 loss: 2.8477041721343994
[2025-12-23 16:11:24,008] m-LoRA: Adapter lora_winogrande_0 epoch: 1/1 iteration: 24/128 step: 13
[2025-12-23 16:11:24,174] m-LoRA: Adapter lora_winogrande_8 loss: 2.255558967590332
[2025-12-23 16:11:24,176] m-LoRA: Adapter lora_winogrande_1 epoch: 1/1 iteration: 48/128 step: 13
[2025-12-23 16:11:24,361] m-LoRA: Adapter lora_winogrande_10 loss: 0.631592333316803
[2025-12-23 16:11:24,364] m-LoRA: Adapter lora_winogrande_5 epoch: 1/1 iteration: 96/128 step: 13
[2025-12-23 16:11:24,536] m-LoRA: Adapter lora_winogrande_11 loss: 0.7400645017623901
[2025-12-23 16:11:24,539] m-LoRA: Adapter lora_winogrande_9 epoch: 1/1 iteration: 24/128 step: 13
[2025-12-23 16:11:24,666] m-LoRA: Adapter lora_winogrande_12 loss: 0.6437066793441772
[2025-12-23 16:11:24,669] m-LoRA: Adapter lora_winogrande_2 epoch: 1/1 iteration: 48/128 step: 13
[2025-12-23 16:11:24,855] m-LoRA: Adapter lora_winogrande_7 epoch: 1/1 iteration: 48/128 step: 13
[2025-12-23 16:11:24,898] m-LoRA: Adapter lora_winogrande_13 loss: 2.250338554382324
[2025-12-23 16:11:25,096] m-LoRA: Adapter lora_winogrande_19 loss: 1.7637743949890137
[2025-12-23 16:11:25,100] m-LoRA: Adapter lora_winogrande_6 epoch: 1/1 iteration: 96/128 step: 13
[2025-12-23 16:11:25,407] m-LoRA: Adapter lora_winogrande_17 epoch: 1/1 iteration: 32/128 step: 5
[2025-12-23 16:11:25,505] m-LoRA: Adapter lora_winogrande_16 loss: 0.5985056757926941
[2025-12-23 16:11:25,509] m-LoRA: Adapter lora_winogrande_18 epoch: 1/1 iteration: 8/128 step: 5
[2025-12-23 16:11:25,591] m-LoRA: Adapter lora_winogrande_20 loss: 1.9892113208770752
[2025-12-23 16:11:25,682] m-LoRA: Adapter lora_winogrande_0 loss: 0.6291413903236389
[2025-12-23 16:11:25,685] m-LoRA: Adapter lora_winogrande_8 epoch: 1/1 iteration: 48/128 step: 13
[2025-12-23 16:11:25,875] m-LoRA: Adapter lora_winogrande_1 loss: 0.5791047811508179
[2025-12-23 16:11:25,879] m-LoRA: Adapter lora_winogrande_10 epoch: 1/1 iteration: 48/128 step: 13
[2025-12-23 16:11:26,250] m-LoRA: Adapter lora_winogrande_5 loss: 0.6485344171524048
[2025-12-23 16:11:26,253] m-LoRA: Adapter lora_winogrande_11 epoch: 1/1 iteration: 24/128 step: 13
[2025-12-23 16:11:26,438] m-LoRA: Adapter lora_winogrande_9 loss: 2.2004873752593994
[2025-12-23 16:11:26,443] m-LoRA: Adapter lora_winogrande_12 epoch: 1/1 iteration: 24/128 step: 13
[2025-12-23 16:11:26,554] m-LoRA: Adapter lora_winogrande_2 loss: 2.1949892044067383
[2025-12-23 16:11:26,557] m-LoRA: Adapter lora_winogrande_13 epoch: 1/1 iteration: 96/128 step: 13
[2025-12-23 16:11:26,686] m-LoRA: Adapter lora_winogrande_7 loss: 0.6285263895988464
[2025-12-23 16:11:26,689] m-LoRA: Adapter lora_winogrande_19 epoch: 1/1 iteration: 16/128 step: 5
[2025-12-23 16:11:27,088] m-LoRA: Adapter lora_winogrande_6 loss: 0.615384042263031
[2025-12-23 16:11:27,092] m-LoRA: Adapter lora_winogrande_16 epoch: 1/1 iteration: 96/128 step: 13
[2025-12-23 16:11:27,491] m-LoRA: Adapter lora_winogrande_17 loss: 1.3680521249771118
[2025-12-23 16:11:27,495] m-LoRA: Adapter lora_winogrande_20 epoch: 1/1 iteration: 8/128 step: 5
[2025-12-23 16:11:27,628] m-LoRA: Adapter lora_winogrande_18 loss: 2.831838369369507
[2025-12-23 16:11:27,630] m-LoRA: Adapter lora_winogrande_0 epoch: 1/1 iteration: 26/128 step: 14
[2025-12-23 16:11:28,185] m-LoRA: Adapter lora_winogrande_8 loss: 2.025318145751953
[2025-12-23 16:11:28,188] m-LoRA: Adapter lora_winogrande_1 epoch: 1/1 iteration: 52/128 step: 14
[2025-12-23 16:11:28,302] m-LoRA: Adapter lora_winogrande_10 loss: 0.7218939661979675
[2025-12-23 16:11:28,304] m-LoRA: Adapter lora_winogrande_5 epoch: 1/1 iteration: 104/128 step: 14
[2025-12-23 16:11:28,447] m-LoRA: Adapter lora_winogrande_11 loss: 0.702438235282898
[2025-12-23 16:11:28,449] m-LoRA: Adapter lora_winogrande_9 epoch: 1/1 iteration: 26/128 step: 14
[2025-12-23 16:11:28,533] m-LoRA: Adapter lora_winogrande_12 loss: 0.6167738437652588
[2025-12-23 16:11:28,536] m-LoRA: Adapter lora_winogrande_2 epoch: 1/1 iteration: 52/128 step: 14
[2025-12-23 16:11:28,703] m-LoRA: Adapter lora_winogrande_13 loss: 2.2006144523620605
[2025-12-23 16:11:28,708] m-LoRA: Adapter lora_winogrande_7 epoch: 1/1 iteration: 52/128 step: 14
[2025-12-23 16:11:28,799] m-LoRA: Adapter lora_winogrande_19 loss: 1.6918716430664062
[2025-12-23 16:11:29,169] m-LoRA: Adapter lora_winogrande_16 loss: 0.5662937760353088
[2025-12-23 16:11:29,173] m-LoRA: Adapter lora_winogrande_6 epoch: 1/1 iteration: 104/128 step: 14
[2025-12-23 16:11:29,372] m-LoRA: Adapter lora_winogrande_20 loss: 1.8384960889816284
[2025-12-23 16:11:29,374] m-LoRA: Adapter lora_winogrande_17 epoch: 1/1 iteration: 40/128 step: 6
[2025-12-23 16:11:29,560] m-LoRA: Adapter lora_winogrande_0 loss: 0.6428201198577881
[2025-12-23 16:11:29,563] m-LoRA: Adapter lora_winogrande_18 epoch: 1/1 iteration: 10/128 step: 6
[2025-12-23 16:11:29,682] m-LoRA: Adapter lora_winogrande_1 loss: 0.5823245048522949
[2025-12-23 16:11:29,685] m-LoRA: Adapter lora_winogrande_8 epoch: 1/1 iteration: 52/128 step: 14
[2025-12-23 16:11:29,934] m-LoRA: Adapter lora_winogrande_5 loss: 0.6154170036315918
[2025-12-23 16:11:29,938] m-LoRA: Adapter lora_winogrande_10 epoch: 1/1 iteration: 52/128 step: 14
[2025-12-23 16:11:30,074] m-LoRA: Adapter lora_winogrande_9 loss: 2.246985912322998
[2025-12-23 16:11:30,091] m-LoRA: Adapter lora_winogrande_11 epoch: 1/1 iteration: 26/128 step: 14
[2025-12-23 16:11:30,243] m-LoRA: Adapter lora_winogrande_2 loss: 2.1517446041107178
[2025-12-23 16:11:30,247] m-LoRA: Adapter lora_winogrande_12 epoch: 1/1 iteration: 26/128 step: 14
[2025-12-23 16:11:30,390] m-LoRA: Adapter lora_winogrande_13 epoch: 1/1 iteration: 104/128 step: 14
[2025-12-23 16:11:30,436] m-LoRA: Adapter lora_winogrande_7 loss: 0.6248629093170166
[2025-12-23 16:11:30,840] m-LoRA: Adapter lora_winogrande_6 loss: 0.594936728477478
[2025-12-23 16:11:30,844] m-LoRA: Adapter lora_winogrande_19 epoch: 1/1 iteration: 20/128 step: 6
[2025-12-23 16:11:31,207] m-LoRA: Adapter lora_winogrande_17 loss: 1.0638736486434937
[2025-12-23 16:11:31,211] m-LoRA: Adapter lora_winogrande_16 epoch: 1/1 iteration: 104/128 step: 14
[2025-12-23 16:11:31,433] m-LoRA: Adapter lora_winogrande_18 loss: 2.8475940227508545
[2025-12-23 16:11:31,436] m-LoRA: Adapter lora_winogrande_20 epoch: 1/1 iteration: 10/128 step: 6
[2025-12-23 16:11:31,585] m-LoRA: Adapter lora_winogrande_8 loss: 2.263974905014038
[2025-12-23 16:11:31,587] m-LoRA: Adapter lora_winogrande_0 epoch: 1/1 iteration: 28/128 step: 15
[2025-12-23 16:11:31,722] m-LoRA: Adapter lora_winogrande_10 loss: 0.6913626790046692
[2025-12-23 16:11:31,725] m-LoRA: Adapter lora_winogrande_1 epoch: 1/1 iteration: 56/128 step: 15
[2025-12-23 16:11:31,860] m-LoRA: Adapter lora_winogrande_11 loss: 0.6473667621612549
[2025-12-23 16:11:31,863] m-LoRA: Adapter lora_winogrande_5 epoch: 1/1 iteration: 112/128 step: 15
[2025-12-23 16:11:31,974] m-LoRA: Adapter lora_winogrande_12 loss: 0.6645104885101318
[2025-12-23 16:11:31,976] m-LoRA: Adapter lora_winogrande_9 epoch: 1/1 iteration: 28/128 step: 15
[2025-12-23 16:11:32,306] m-LoRA: Adapter lora_winogrande_2 epoch: 1/1 iteration: 56/128 step: 15
[2025-12-23 16:11:32,357] m-LoRA: Adapter lora_winogrande_13 loss: 2.089440107345581
[2025-12-23 16:11:32,541] m-LoRA: Adapter lora_winogrande_19 loss: 1.4874778985977173
[2025-12-23 16:11:32,544] m-LoRA: Adapter lora_winogrande_7 epoch: 1/1 iteration: 56/128 step: 15
[2025-12-23 16:11:32,948] m-LoRA: Adapter lora_winogrande_16 loss: 0.549272358417511
[2025-12-23 16:11:32,951] m-LoRA: Adapter lora_winogrande_6 epoch: 1/1 iteration: 112/128 step: 15
[2025-12-23 16:11:33,131] m-LoRA: Adapter lora_winogrande_20 loss: 1.5759403705596924
[2025-12-23 16:11:33,134] m-LoRA: Adapter lora_winogrande_17 epoch: 1/1 iteration: 48/128 step: 7
[2025-12-23 16:11:33,311] m-LoRA: Adapter lora_winogrande_0 loss: 0.6099987030029297
[2025-12-23 16:11:33,313] m-LoRA: Adapter lora_winogrande_18 epoch: 1/1 iteration: 12/128 step: 7
[2025-12-23 16:11:33,413] m-LoRA: Adapter lora_winogrande_1 loss: 0.5670961737632751
[2025-12-23 16:11:33,416] m-LoRA: Adapter lora_winogrande_8 epoch: 1/1 iteration: 56/128 step: 15
[2025-12-23 16:11:33,631] m-LoRA: Adapter lora_winogrande_5 loss: 0.6705341935157776
[2025-12-23 16:11:33,636] m-LoRA: Adapter lora_winogrande_10 epoch: 1/1 iteration: 56/128 step: 15
[2025-12-23 16:11:33,793] m-LoRA: Adapter lora_winogrande_9 loss: 2.1426024436950684
[2025-12-23 16:11:33,795] m-LoRA: Adapter lora_winogrande_11 epoch: 1/1 iteration: 28/128 step: 15
[2025-12-23 16:11:33,927] m-LoRA: Adapter lora_winogrande_2 loss: 2.089458703994751
[2025-12-23 16:11:33,931] m-LoRA: Adapter lora_winogrande_12 epoch: 1/1 iteration: 28/128 step: 15
[2025-12-23 16:11:34,140] m-LoRA: Adapter lora_winogrande_7 loss: 0.6858659982681274
[2025-12-23 16:11:34,145] m-LoRA: Adapter lora_winogrande_13 epoch: 1/1 iteration: 112/128 step: 15
[2025-12-23 16:11:34,470] m-LoRA: Adapter lora_winogrande_19 epoch: 1/1 iteration: 24/128 step: 7
[2025-12-23 16:11:34,510] m-LoRA: Adapter lora_winogrande_6 loss: 0.6422737240791321
[2025-12-23 16:11:34,870] m-LoRA: Adapter lora_winogrande_17 loss: 0.8616992831230164
[2025-12-23 16:11:34,874] m-LoRA: Adapter lora_winogrande_16 epoch: 1/1 iteration: 112/128 step: 15
[2025-12-23 16:11:35,083] m-LoRA: Adapter lora_winogrande_18 loss: 2.7845330238342285
[2025-12-23 16:11:35,086] m-LoRA: Adapter lora_winogrande_20 epoch: 1/1 iteration: 12/128 step: 7
[2025-12-23 16:11:35,213] m-LoRA: Adapter lora_winogrande_8 loss: 2.1983470916748047
[2025-12-23 16:11:35,215] m-LoRA: Adapter lora_winogrande_0 epoch: 1/1 iteration: 30/128 step: 16
[2025-12-23 16:11:35,332] m-LoRA: Adapter lora_winogrande_10 loss: 0.5459901690483093
[2025-12-23 16:11:35,334] m-LoRA: Adapter lora_winogrande_1 epoch: 1/1 iteration: 60/128 step: 16
[2025-12-23 16:11:35,439] m-LoRA: Adapter lora_winogrande_11 loss: 0.6056332588195801
[2025-12-23 16:11:35,441] m-LoRA: Adapter lora_winogrande_5 epoch: 1/1 iteration: 120/128 step: 16
[2025-12-23 16:11:35,561] m-LoRA: Adapter lora_winogrande_12 loss: 0.6522483825683594
[2025-12-23 16:11:35,563] m-LoRA: Adapter lora_winogrande_9 epoch: 1/1 iteration: 30/128 step: 16
[2025-12-23 16:11:35,893] m-LoRA: Adapter lora_winogrande_13 loss: 2.1275405883789062
[2025-12-23 16:11:35,898] m-LoRA: Adapter lora_winogrande_2 epoch: 1/1 iteration: 60/128 step: 16
[2025-12-23 16:11:36,162] m-LoRA: Adapter lora_winogrande_19 loss: 1.2629801034927368
[2025-12-23 16:11:36,166] m-LoRA: Adapter lora_winogrande_7 epoch: 1/1 iteration: 60/128 step: 16
[2025-12-23 16:11:36,632] m-LoRA: Adapter lora_winogrande_16 loss: 0.5390259027481079
[2025-12-23 16:11:36,636] m-LoRA: Adapter lora_winogrande_6 epoch: 1/1 iteration: 120/128 step: 16
[2025-12-23 16:11:36,811] m-LoRA: Adapter lora_winogrande_20 loss: 1.2647250890731812
[2025-12-23 16:11:36,813] m-LoRA: Adapter lora_winogrande_17 epoch: 1/1 iteration: 56/128 step: 8
[2025-12-23 16:11:36,953] m-LoRA: Adapter lora_winogrande_0 loss: 0.5752741098403931
[2025-12-23 16:11:36,955] m-LoRA: Adapter lora_winogrande_18 epoch: 1/1 iteration: 14/128 step: 8
[2025-12-23 16:11:37,049] m-LoRA: Adapter lora_winogrande_1 loss: 0.5430575609207153
[2025-12-23 16:11:37,052] m-LoRA: Adapter lora_winogrande_8 epoch: 1/1 iteration: 60/128 step: 16
[2025-12-23 16:11:37,290] m-LoRA: Adapter lora_winogrande_5 loss: 0.6247463226318359
[2025-12-23 16:11:37,294] m-LoRA: Adapter lora_winogrande_10 epoch: 1/1 iteration: 60/128 step: 16
[2025-12-23 16:11:37,502] m-LoRA: Adapter lora_winogrande_9 loss: 2.2144105434417725
[2025-12-23 16:11:37,505] m-LoRA: Adapter lora_winogrande_11 epoch: 1/1 iteration: 30/128 step: 16
[2025-12-23 16:11:37,653] m-LoRA: Adapter lora_winogrande_2 loss: 2.1318299770355225
[2025-12-23 16:11:37,655] m-LoRA: Adapter lora_winogrande_12 epoch: 1/1 iteration: 30/128 step: 16
[2025-12-23 16:11:37,820] m-LoRA: Adapter lora_winogrande_7 loss: 0.5860165357589722
[2025-12-23 16:11:37,823] m-LoRA: Adapter lora_winogrande_13 epoch: 1/1 iteration: 120/128 step: 16
[2025-12-23 16:11:38,171] m-LoRA: Adapter lora_winogrande_6 loss: 0.6298074722290039
[2025-12-23 16:11:38,175] m-LoRA: Adapter lora_winogrande_19 epoch: 1/1 iteration: 28/128 step: 8
[2025-12-23 16:11:38,652] m-LoRA: Adapter lora_winogrande_17 loss: 0.7073395848274231
[2025-12-23 16:11:38,658] m-LoRA: Adapter lora_winogrande_16 epoch: 1/1 iteration: 120/128 step: 16
[2025-12-23 16:11:38,751] m-LoRA: Adapter lora_winogrande_18 loss: 2.568966865539551
[2025-12-23 16:11:38,934] m-LoRA: Adapter lora_winogrande_8 loss: 2.0958614349365234
[2025-12-23 16:11:38,936] m-LoRA: Adapter lora_winogrande_20 epoch: 1/1 iteration: 14/128 step: 8
[2025-12-23 16:11:39,111] m-LoRA: Adapter lora_winogrande_10 loss: 0.5655852556228638
[2025-12-23 16:11:39,115] m-LoRA: Adapter lora_winogrande_0 epoch: 1/1 iteration: 32/128 step: 17
[2025-12-23 16:11:39,269] m-LoRA: Adapter lora_winogrande_11 loss: 0.5547035932540894
[2025-12-23 16:11:39,271] m-LoRA: Adapter lora_winogrande_1 epoch: 1/1 iteration: 64/128 step: 17
[2025-12-23 16:11:39,459] m-LoRA: Adapter lora_winogrande_12 loss: 0.7357140183448792
[2025-12-23 16:11:39,954] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_5']
[2025-12-23 16:11:40,732] m-LoRA: Adapter lora_winogrande_13 loss: 1.93503999710083
[2025-12-23 16:11:40,777] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_21']
[2025-12-23 16:11:40,975] m-LoRA: Adapter lora_winogrande_21 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:11:41,114] m-LoRA: Adapter lora_winogrande_19 loss: 1.0486570596694946
[2025-12-23 16:11:41,116] m-LoRA: Adapter lora_winogrande_2 epoch: 1/1 iteration: 64/128 step: 17
[2025-12-23 16:11:41,226] m-LoRA: Adapter lora_winogrande_16 loss: 0.5457825064659119
[2025-12-23 16:11:41,230] m-LoRA: Adapter lora_winogrande_9 epoch: 1/1 iteration: 32/128 step: 17
[2025-12-23 16:11:41,413] m-LoRA: Adapter lora_winogrande_20 loss: 1.0995903015136719
[2025-12-23 16:11:41,416] m-LoRA: Adapter lora_winogrande_7 epoch: 1/1 iteration: 64/128 step: 17
[2025-12-23 16:11:41,530] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_6']
[2025-12-23 16:11:42,145] m-LoRA: Adapter lora_winogrande_0 loss: 0.6078931093215942
[2025-12-23 16:11:42,148] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_22']
[2025-12-23 16:11:42,277] m-LoRA: Adapter lora_winogrande_22 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:11:42,406] m-LoRA: Adapter lora_winogrande_1 loss: 0.508205235004425
[2025-12-23 16:11:42,409] m-LoRA: Adapter lora_winogrande_17 epoch: 1/1 iteration: 64/128 step: 9
[2025-12-23 16:11:42,690] m-LoRA: Adapter lora_winogrande_21 loss: 3.310769557952881
[2025-12-23 16:11:42,698] m-LoRA: Adapter lora_winogrande_18 epoch: 1/1 iteration: 16/128 step: 9
[2025-12-23 16:11:42,932] m-LoRA: Adapter lora_winogrande_2 loss: 2.10823917388916
[2025-12-23 16:11:42,934] m-LoRA: Adapter lora_winogrande_8 epoch: 1/1 iteration: 64/128 step: 17
[2025-12-23 16:11:43,103] m-LoRA: Adapter lora_winogrande_9 loss: 2.1754841804504395
[2025-12-23 16:11:43,120] m-LoRA: Adapter lora_winogrande_10 epoch: 1/1 iteration: 64/128 step: 17
[2025-12-23 16:11:43,254] m-LoRA: Adapter lora_winogrande_7 loss: 0.6582410931587219
[2025-12-23 16:11:43,258] m-LoRA: Adapter lora_winogrande_11 epoch: 1/1 iteration: 32/128 step: 17
[2025-12-23 16:11:43,391] m-LoRA: Adapter lora_winogrande_12 epoch: 1/1 iteration: 32/128 step: 17
[2025-12-23 16:11:43,468] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_13']
[2025-12-23 16:11:43,698] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_23']
[2025-12-23 16:11:43,744] m-LoRA: Adapter lora_winogrande_23 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:11:43,838] m-LoRA: Adapter lora_winogrande_19 epoch: 1/1 iteration: 32/128 step: 9
[2025-12-23 16:11:43,911] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_16']
[2025-12-23 16:11:44,587] m-LoRA: Adapter lora_winogrande_22 loss: 3.210141897201538
[2025-12-23 16:11:44,621] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_24']
[2025-12-23 16:11:44,823] m-LoRA: Adapter lora_winogrande_24 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:11:44,942] m-LoRA: Adapter lora_winogrande_17 loss: 0.69282066822052
[2025-12-23 16:11:44,945] m-LoRA: Adapter lora_winogrande_20 epoch: 1/1 iteration: 16/128 step: 9
[2025-12-23 16:11:45,080] m-LoRA: Adapter lora_winogrande_18 loss: 2.5404624938964844
[2025-12-23 16:11:45,082] m-LoRA: Adapter lora_winogrande_0 epoch: 1/1 iteration: 34/128 step: 18
[2025-12-23 16:11:45,159] m-LoRA: Adapter lora_winogrande_8 loss: 1.9674673080444336
[2025-12-23 16:11:45,162] m-LoRA: Adapter lora_winogrande_1 epoch: 1/1 iteration: 68/128 step: 18
[2025-12-23 16:11:45,332] m-LoRA: Adapter lora_winogrande_10 loss: 0.545732855796814
[2025-12-23 16:11:45,334] m-LoRA: Adapter lora_winogrande_21 epoch: 1/1 iteration: 16/128 step: 2
[2025-12-23 16:11:45,548] m-LoRA: Adapter lora_winogrande_11 loss: 0.6148937344551086
[2025-12-23 16:11:45,550] m-LoRA: Adapter lora_winogrande_2 epoch: 1/1 iteration: 68/128 step: 18
[2025-12-23 16:11:45,662] m-LoRA: Adapter lora_winogrande_12 loss: 0.533555269241333
[2025-12-23 16:11:45,666] m-LoRA: Adapter lora_winogrande_9 epoch: 1/1 iteration: 34/128 step: 18
[2025-12-23 16:11:45,784] m-LoRA: Adapter lora_winogrande_23 loss: 3.0999906063079834
[2025-12-23 16:11:45,787] m-LoRA: Adapter lora_winogrande_7 epoch: 1/1 iteration: 68/128 step: 18
[2025-12-23 16:11:45,842] m-LoRA: Adapter lora_winogrande_19 loss: 0.8023400902748108
[2025-12-23 16:11:45,908] m-LoRA: Adapter lora_winogrande_24 loss: 3.2246944904327393
[2025-12-23 16:11:46,033] m-LoRA: Adapter lora_winogrande_22 epoch: 1/1 iteration: 16/128 step: 2
[2025-12-23 16:11:46,098] m-LoRA: Adapter lora_winogrande_20 loss: 0.9060649275779724
[2025-12-23 16:11:46,236] m-LoRA: Adapter lora_winogrande_0 loss: 0.6668987274169922
[2025-12-23 16:11:46,367] m-LoRA: Adapter lora_winogrande_17 epoch: 1/1 iteration: 72/128 step: 10
[2025-12-23 16:11:46,578] m-LoRA: Adapter lora_winogrande_1 loss: 0.4773809313774109
[2025-12-23 16:11:46,581] m-LoRA: Adapter lora_winogrande_18 epoch: 1/1 iteration: 18/128 step: 10
[2025-12-23 16:11:46,707] m-LoRA: Adapter lora_winogrande_8 epoch: 1/1 iteration: 68/128 step: 18
[2025-12-23 16:11:47,611] m-LoRA: Adapter lora_winogrande_10 epoch: 1/1 iteration: 68/128 step: 18
[2025-12-23 16:11:47,773] m-LoRA: Adapter lora_winogrande_21 loss: 2.375037431716919
[2025-12-23 16:11:47,779] m-LoRA: Adapter lora_winogrande_11 epoch: 1/1 iteration: 34/128 step: 18
[2025-12-23 16:11:47,933] m-LoRA: Adapter lora_winogrande_2 loss: 2.0502727031707764
[2025-12-23 16:11:47,936] m-LoRA: Adapter lora_winogrande_12 epoch: 1/1 iteration: 34/128 step: 18
[2025-12-23 16:11:48,065] m-LoRA: Adapter lora_winogrande_9 loss: 2.0778589248657227
[2025-12-23 16:11:48,067] m-LoRA: Adapter lora_winogrande_23 epoch: 1/1 iteration: 2/128 step: 2
[2025-12-23 16:11:48,119] m-LoRA: Adapter lora_winogrande_7 loss: 0.5869534611701965
[2025-12-23 16:11:48,578] m-LoRA: Adapter lora_winogrande_22 loss: 2.786761522293091
[2025-12-23 16:11:48,585] m-LoRA: Adapter lora_winogrande_19 epoch: 1/1 iteration: 36/128 step: 10
[2025-12-23 16:11:48,913] m-LoRA: Adapter lora_winogrande_17 loss: 0.6699730753898621
[2025-12-23 16:11:48,916] m-LoRA: Adapter lora_winogrande_24 epoch: 1/1 iteration: 4/128 step: 2
[2025-12-23 16:11:49,060] m-LoRA: Adapter lora_winogrande_18 loss: 2.465125560760498
[2025-12-23 16:11:49,062] m-LoRA: Adapter lora_winogrande_20 epoch: 1/1 iteration: 18/128 step: 10
[2025-12-23 16:11:49,166] m-LoRA: Adapter lora_winogrande_8 loss: 2.041069507598877
[2025-12-23 16:11:49,169] m-LoRA: Adapter lora_winogrande_0 epoch: 1/1 iteration: 36/128 step: 19
[2025-12-23 16:11:49,324] m-LoRA: Adapter lora_winogrande_10 loss: 0.5590350031852722
[2025-12-23 16:11:49,327] m-LoRA: Adapter lora_winogrande_1 epoch: 1/1 iteration: 72/128 step: 19
[2025-12-23 16:11:49,487] m-LoRA: Adapter lora_winogrande_11 loss: 0.5992466807365417
[2025-12-23 16:11:49,497] m-LoRA: Adapter lora_winogrande_21 epoch: 1/1 iteration: 32/128 step: 3
[2025-12-23 16:11:49,767] m-LoRA: Adapter lora_winogrande_12 loss: 0.6640457510948181
[2025-12-23 16:11:49,770] m-LoRA: Adapter lora_winogrande_2 epoch: 1/1 iteration: 72/128 step: 19
[2025-12-23 16:11:49,910] m-LoRA: Adapter lora_winogrande_23 loss: 2.9425787925720215
[2025-12-23 16:11:49,912] m-LoRA: Adapter lora_winogrande_9 epoch: 1/1 iteration: 36/128 step: 19
[2025-12-23 16:11:50,030] m-LoRA: Adapter lora_winogrande_19 loss: 0.7726232409477234
[2025-12-23 16:11:50,033] m-LoRA: Adapter lora_winogrande_7 epoch: 1/1 iteration: 72/128 step: 19
[2025-12-23 16:11:51,278] m-LoRA: Adapter lora_winogrande_24 loss: 2.8084990978240967
[2025-12-23 16:11:51,954] m-LoRA: Adapter lora_winogrande_20 loss: 0.6082396507263184
[2025-12-23 16:11:52,193] m-LoRA: Adapter lora_winogrande_0 loss: 0.7082242369651794
[2025-12-23 16:11:52,566] m-LoRA: Adapter lora_winogrande_1 loss: 0.5565491914749146
[2025-12-23 16:11:52,570] m-LoRA: Adapter lora_winogrande_22 epoch: 1/1 iteration: 32/128 step: 3
[2025-12-23 16:11:52,743] m-LoRA: Adapter lora_winogrande_17 epoch: 1/1 iteration: 80/128 step: 11
[2025-12-23 16:11:52,827] m-LoRA: Adapter lora_winogrande_18 epoch: 1/1 iteration: 20/128 step: 11
[2025-12-23 16:11:53,280] m-LoRA: Adapter lora_winogrande_8 epoch: 1/1 iteration: 72/128 step: 19
[2025-12-23 16:11:53,317] m-LoRA: Adapter lora_winogrande_21 loss: 1.8126368522644043
[2025-12-23 16:11:53,586] m-LoRA: Adapter lora_winogrande_2 loss: 2.0599687099456787
[2025-12-23 16:11:53,589] m-LoRA: Adapter lora_winogrande_10 epoch: 1/1 iteration: 72/128 step: 19
[2025-12-23 16:11:53,717] m-LoRA: Adapter lora_winogrande_9 loss: 1.901870608329773
[2025-12-23 16:11:53,719] m-LoRA: Adapter lora_winogrande_11 epoch: 1/1 iteration: 36/128 step: 19
[2025-12-23 16:11:53,802] m-LoRA: Adapter lora_winogrande_7 loss: 0.5827233195304871
[2025-12-23 16:11:53,804] m-LoRA: Adapter lora_winogrande_12 epoch: 1/1 iteration: 36/128 step: 19
[2025-12-23 16:11:54,490] m-LoRA: Adapter lora_winogrande_22 loss: 2.0470995903015137
[2025-12-23 16:11:54,496] m-LoRA: Adapter lora_winogrande_23 epoch: 1/1 iteration: 4/128 step: 3
[2025-12-23 16:11:54,814] m-LoRA: Adapter lora_winogrande_17 loss: 0.5530337691307068
[2025-12-23 16:11:54,819] m-LoRA: Adapter lora_winogrande_19 epoch: 1/1 iteration: 40/128 step: 11
[2025-12-23 16:11:54,943] m-LoRA: Adapter lora_winogrande_18 loss: 2.248135805130005
[2025-12-23 16:11:54,946] m-LoRA: Adapter lora_winogrande_24 epoch: 1/1 iteration: 8/128 step: 3
[2025-12-23 16:11:55,054] m-LoRA: Adapter lora_winogrande_8 loss: 2.1041929721832275
[2025-12-23 16:11:55,058] m-LoRA: Adapter lora_winogrande_20 epoch: 1/1 iteration: 20/128 step: 11
[2025-12-23 16:11:55,200] m-LoRA: Adapter lora_winogrande_10 loss: 0.60603928565979
[2025-12-23 16:11:55,203] m-LoRA: Adapter lora_winogrande_0 epoch: 1/1 iteration: 38/128 step: 20
[2025-12-23 16:11:55,356] m-LoRA: Adapter lora_winogrande_11 loss: 0.685146689414978
[2025-12-23 16:11:55,358] m-LoRA: Adapter lora_winogrande_1 epoch: 1/1 iteration: 76/128 step: 20
[2025-12-23 16:11:55,569] m-LoRA: Adapter lora_winogrande_12 loss: 0.6090806722640991
[2025-12-23 16:11:55,572] m-LoRA: Adapter lora_winogrande_21 epoch: 1/1 iteration: 48/128 step: 4
[2025-12-23 16:11:55,725] m-LoRA: Adapter lora_winogrande_23 loss: 2.985175609588623
[2025-12-23 16:11:55,727] m-LoRA: Adapter lora_winogrande_2 epoch: 1/1 iteration: 76/128 step: 20
[2025-12-23 16:11:55,846] m-LoRA: Adapter lora_winogrande_9 epoch: 1/1 iteration: 38/128 step: 20
[2025-12-23 16:11:55,943] m-LoRA: Adapter lora_winogrande_7 epoch: 1/1 iteration: 76/128 step: 20
[2025-12-23 16:11:56,041] m-LoRA: Adapter lora_winogrande_22 epoch: 1/1 iteration: 48/128 step: 4
[2025-12-23 16:11:56,232] m-LoRA: Adapter lora_winogrande_19 loss: 0.6919114589691162
[2025-12-23 16:11:56,414] m-LoRA: Adapter lora_winogrande_24 loss: 2.2493984699249268
[2025-12-23 16:11:56,417] m-LoRA: Adapter lora_winogrande_17 epoch: 1/1 iteration: 88/128 step: 12
[2025-12-23 16:11:56,598] m-LoRA: Adapter lora_winogrande_20 loss: 0.8473537564277649
[2025-12-23 16:11:56,601] m-LoRA: Adapter lora_winogrande_18 epoch: 1/1 iteration: 22/128 step: 12
[2025-12-23 16:11:56,783] m-LoRA: Adapter lora_winogrande_0 loss: 0.5062798261642456
[2025-12-23 16:11:56,786] m-LoRA: Adapter lora_winogrande_8 epoch: 1/1 iteration: 76/128 step: 20
[2025-12-23 16:11:56,926] m-LoRA: Adapter lora_winogrande_1 loss: 0.6081206798553467
[2025-12-23 16:11:56,928] m-LoRA: Adapter lora_winogrande_10 epoch: 1/1 iteration: 76/128 step: 20
[2025-12-23 16:11:57,063] m-LoRA: Adapter lora_winogrande_11 epoch: 1/1 iteration: 38/128 step: 20
[2025-12-23 16:11:57,160] m-LoRA: Adapter lora_winogrande_12 epoch: 1/1 iteration: 38/128 step: 20
[2025-12-23 16:11:57,631] m-LoRA: Adapter lora_winogrande_21 loss: 1.7279669046401978
[2025-12-23 16:11:57,638] m-LoRA: Adapter lora_winogrande_23 epoch: 1/1 iteration: 6/128 step: 4
[2025-12-23 16:11:57,866] m-LoRA: Adapter lora_winogrande_2 loss: 2.078413248062134
[2025-12-23 16:11:57,868] m-LoRA: Adapter lora_winogrande_19 epoch: 1/1 iteration: 44/128 step: 12
[2025-12-23 16:11:57,999] m-LoRA: Adapter lora_winogrande_9 loss: 1.9384466409683228
[2025-12-23 16:11:58,001] m-LoRA: Adapter lora_winogrande_24 epoch: 1/1 iteration: 12/128 step: 4
[2025-12-23 16:11:58,129] m-LoRA: Adapter lora_winogrande_7 loss: 0.5055010914802551
[2025-12-23 16:11:58,131] m-LoRA: Adapter lora_winogrande_20 epoch: 1/1 iteration: 22/128 step: 12
[2025-12-23 16:11:58,718] m-LoRA: Adapter lora_winogrande_0 epoch: 1/1 iteration: 40/128 step: 21
[2025-12-23 16:11:58,797] m-LoRA: Adapter lora_winogrande_22 loss: 2.0371243953704834
[2025-12-23 16:11:59,168] m-LoRA: Adapter lora_winogrande_17 loss: 0.6575007438659668
[2025-12-23 16:11:59,171] m-LoRA: Adapter lora_winogrande_1 epoch: 1/1 iteration: 80/128 step: 21
[2025-12-23 16:11:59,335] m-LoRA: Adapter lora_winogrande_18 loss: 2.3173129558563232
[2025-12-23 16:11:59,337] m-LoRA: Adapter lora_winogrande_21 epoch: 1/1 iteration: 64/128 step: 5
[2025-12-23 16:11:59,474] m-LoRA: Adapter lora_winogrande_8 loss: 2.0487329959869385
[2025-12-23 16:11:59,482] m-LoRA: Adapter lora_winogrande_2 epoch: 1/1 iteration: 80/128 step: 21
[2025-12-23 16:11:59,605] m-LoRA: Adapter lora_winogrande_10 loss: 0.5828006863594055
[2025-12-23 16:11:59,609] m-LoRA: Adapter lora_winogrande_9 epoch: 1/1 iteration: 40/128 step: 21
[2025-12-23 16:11:59,719] m-LoRA: Adapter lora_winogrande_11 loss: 0.5489512085914612
[2025-12-23 16:11:59,721] m-LoRA: Adapter lora_winogrande_7 epoch: 1/1 iteration: 80/128 step: 21
[2025-12-23 16:11:59,816] m-LoRA: Adapter lora_winogrande_12 loss: 0.6177862286567688
[2025-12-23 16:11:59,820] m-LoRA: Adapter lora_winogrande_23 loss: 2.72082257270813
[2025-12-23 16:12:00,033] m-LoRA: Adapter lora_winogrande_19 loss: 0.7127159237861633
[2025-12-23 16:12:00,252] m-LoRA: Adapter lora_winogrande_24 loss: 2.0403032302856445
[2025-12-23 16:12:00,438] m-LoRA: Adapter lora_winogrande_20 loss: 0.6130091547966003
[2025-12-23 16:12:00,441] m-LoRA: Adapter lora_winogrande_22 epoch: 1/1 iteration: 64/128 step: 5
[2025-12-23 16:12:00,511] m-LoRA: Adapter lora_winogrande_0 loss: 0.6301032304763794
[2025-12-23 16:12:00,728] m-LoRA: Adapter lora_winogrande_1 loss: 0.5054349899291992
[2025-12-23 16:12:00,731] m-LoRA: Adapter lora_winogrande_17 epoch: 1/1 iteration: 96/128 step: 13
[2025-12-23 16:12:01,584] m-LoRA: Adapter lora_winogrande_21 loss: 1.3906490802764893
[2025-12-23 16:12:01,593] m-LoRA: Adapter lora_winogrande_18 epoch: 1/1 iteration: 24/128 step: 13
[2025-12-23 16:12:01,831] m-LoRA: Adapter lora_winogrande_2 loss: 1.8474143743515015
[2025-12-23 16:12:01,834] m-LoRA: Adapter lora_winogrande_8 epoch: 1/1 iteration: 80/128 step: 21
[2025-12-23 16:12:01,965] m-LoRA: Adapter lora_winogrande_9 loss: 1.8623121976852417
[2025-12-23 16:12:01,967] m-LoRA: Adapter lora_winogrande_10 epoch: 1/1 iteration: 80/128 step: 21
[2025-12-23 16:12:02,070] m-LoRA: Adapter lora_winogrande_7 loss: 0.4990025758743286
[2025-12-23 16:12:02,072] m-LoRA: Adapter lora_winogrande_11 epoch: 1/1 iteration: 40/128 step: 21
[2025-12-23 16:12:02,556] m-LoRA: Adapter lora_winogrande_12 epoch: 1/1 iteration: 40/128 step: 21
[2025-12-23 16:12:02,604] m-LoRA: Adapter lora_winogrande_22 loss: 1.8163079023361206
[2025-12-23 16:12:03,183] m-LoRA: Adapter lora_winogrande_17 loss: 0.5474832653999329
[2025-12-23 16:12:03,187] m-LoRA: Adapter lora_winogrande_23 epoch: 1/1 iteration: 8/128 step: 5
[2025-12-23 16:12:03,311] m-LoRA: Adapter lora_winogrande_18 loss: 2.274461269378662
[2025-12-23 16:12:03,313] m-LoRA: Adapter lora_winogrande_19 epoch: 1/1 iteration: 48/128 step: 13
[2025-12-23 16:12:03,432] m-LoRA: Adapter lora_winogrande_8 loss: 1.9763602018356323
[2025-12-23 16:12:03,436] m-LoRA: Adapter lora_winogrande_24 epoch: 1/1 iteration: 16/128 step: 5
[2025-12-23 16:12:03,621] m-LoRA: Adapter lora_winogrande_10 loss: 0.5946434736251831
[2025-12-23 16:12:03,624] m-LoRA: Adapter lora_winogrande_20 epoch: 1/1 iteration: 24/128 step: 13
[2025-12-23 16:12:03,876] m-LoRA: Adapter lora_winogrande_11 loss: 0.5001645684242249
[2025-12-23 16:12:03,878] m-LoRA: Adapter lora_winogrande_0 epoch: 1/1 iteration: 42/128 step: 22
[2025-12-23 16:12:04,044] m-LoRA: Adapter lora_winogrande_12 loss: 0.5730160474777222
[2025-12-23 16:12:04,046] m-LoRA: Adapter lora_winogrande_1 epoch: 1/1 iteration: 84/128 step: 22
[2025-12-23 16:12:04,199] m-LoRA: Adapter lora_winogrande_23 loss: 3.025662899017334
[2025-12-23 16:12:04,201] m-LoRA: Adapter lora_winogrande_21 epoch: 1/1 iteration: 80/128 step: 6
[2025-12-23 16:12:04,334] m-LoRA: Adapter lora_winogrande_2 epoch: 1/1 iteration: 84/128 step: 22
[2025-12-23 16:12:04,432] m-LoRA: Adapter lora_winogrande_9 epoch: 1/1 iteration: 42/128 step: 22
[2025-12-23 16:12:04,506] m-LoRA: Adapter lora_winogrande_19 loss: 0.6190966367721558
[2025-12-23 16:12:04,508] m-LoRA: Adapter lora_winogrande_7 epoch: 1/1 iteration: 84/128 step: 22
[2025-12-23 16:12:04,619] m-LoRA: Adapter lora_winogrande_22 epoch: 1/1 iteration: 80/128 step: 6
[2025-12-23 16:12:04,758] m-LoRA: Adapter lora_winogrande_24 loss: 1.8824800252914429
[2025-12-23 16:12:04,761] m-LoRA: Adapter lora_winogrande_17 epoch: 1/1 iteration: 104/128 step: 14
[2025-12-23 16:12:04,900] m-LoRA: Adapter lora_winogrande_20 loss: 0.684966504573822
[2025-12-23 16:12:04,901] m-LoRA: Adapter lora_winogrande_18 epoch: 1/1 iteration: 26/128 step: 14
[2025-12-23 16:12:05,002] m-LoRA: Adapter lora_winogrande_0 loss: 0.7046926021575928
[2025-12-23 16:12:05,004] m-LoRA: Adapter lora_winogrande_8 epoch: 1/1 iteration: 84/128 step: 22
[2025-12-23 16:12:05,189] m-LoRA: Adapter lora_winogrande_1 loss: 0.4577142000198364
[2025-12-23 16:12:05,192] m-LoRA: Adapter lora_winogrande_10 epoch: 1/1 iteration: 84/128 step: 22
[2025-12-23 16:12:05,323] m-LoRA: Adapter lora_winogrande_11 epoch: 1/1 iteration: 42/128 step: 22
[2025-12-23 16:12:06,059] m-LoRA: Adapter lora_winogrande_21 loss: 1.204757571220398
[2025-12-23 16:12:06,064] m-LoRA: Adapter lora_winogrande_12 epoch: 1/1 iteration: 42/128 step: 22
[2025-12-23 16:12:06,266] m-LoRA: Adapter lora_winogrande_2 loss: 1.9697139263153076
[2025-12-23 16:12:06,270] m-LoRA: Adapter lora_winogrande_23 epoch: 1/1 iteration: 10/128 step: 6
[2025-12-23 16:12:06,369] m-LoRA: Adapter lora_winogrande_9 loss: 1.967616319656372
[2025-12-23 16:12:06,371] m-LoRA: Adapter lora_winogrande_19 epoch: 1/1 iteration: 52/128 step: 14
[2025-12-23 16:12:06,501] m-LoRA: Adapter lora_winogrande_7 loss: 0.5466861724853516
[2025-12-23 16:12:06,503] m-LoRA: Adapter lora_winogrande_24 epoch: 1/1 iteration: 20/128 step: 6
[2025-12-23 16:12:07,217] m-LoRA: Adapter lora_winogrande_22 loss: 1.6976414918899536
[2025-12-23 16:12:07,224] m-LoRA: Adapter lora_winogrande_20 epoch: 1/1 iteration: 26/128 step: 14
[2025-12-23 16:12:07,544] m-LoRA: Adapter lora_winogrande_0 epoch: 1/1 iteration: 44/128 step: 23
[2025-12-23 16:12:07,574] m-LoRA: Adapter lora_winogrande_17 loss: 0.5539166927337646
[2025-12-23 16:12:07,686] m-LoRA: Adapter lora_winogrande_8 loss: 1.9532099962234497
[2025-12-23 16:12:07,688] m-LoRA: Adapter lora_winogrande_1 epoch: 1/1 iteration: 88/128 step: 23
[2025-12-23 16:12:07,847] m-LoRA: Adapter lora_winogrande_18 loss: 2.213494062423706
[2025-12-23 16:12:07,849] m-LoRA: Adapter lora_winogrande_21 epoch: 1/1 iteration: 96/128 step: 7
[2025-12-23 16:12:08,005] m-LoRA: Adapter lora_winogrande_10 loss: 0.48440995812416077
[2025-12-23 16:12:08,078] m-LoRA: Adapter lora_winogrande_2 epoch: 1/1 iteration: 88/128 step: 23
[2025-12-23 16:12:08,233] m-LoRA: Adapter lora_winogrande_11 loss: 0.584524929523468
[2025-12-23 16:12:08,235] m-LoRA: Adapter lora_winogrande_9 epoch: 1/1 iteration: 44/128 step: 23
[2025-12-23 16:12:08,359] m-LoRA: Adapter lora_winogrande_12 loss: 0.4997676610946655
[2025-12-23 16:12:08,361] m-LoRA: Adapter lora_winogrande_7 epoch: 1/1 iteration: 88/128 step: 23
[2025-12-23 16:12:08,429] m-LoRA: Adapter lora_winogrande_23 loss: 2.7477974891662598
[2025-12-23 16:12:08,439] m-LoRA: Adapter lora_winogrande_19 loss: 0.6561751365661621
[2025-12-23 16:12:08,729] m-LoRA: Adapter lora_winogrande_24 loss: 1.5467177629470825
[2025-12-23 16:12:08,732] m-LoRA: Adapter lora_winogrande_22 epoch: 1/1 iteration: 96/128 step: 7
[2025-12-23 16:12:08,815] m-LoRA: Adapter lora_winogrande_20 loss: 0.6401426196098328
[2025-12-23 16:12:08,932] m-LoRA: Adapter lora_winogrande_0 loss: 0.616765558719635
[2025-12-23 16:12:08,935] m-LoRA: Adapter lora_winogrande_17 epoch: 1/1 iteration: 112/128 step: 15
[2025-12-23 16:12:09,093] m-LoRA: Adapter lora_winogrande_1 loss: 0.481206476688385
[2025-12-23 16:12:09,197] m-LoRA: Adapter lora_winogrande_8 epoch: 1/1 iteration: 88/128 step: 23
[2025-12-23 16:12:09,968] m-LoRA: Adapter lora_winogrande_21 loss: 0.8695183396339417
[2025-12-23 16:12:09,975] m-LoRA: Adapter lora_winogrande_18 epoch: 1/1 iteration: 28/128 step: 15
[2025-12-23 16:12:10,184] m-LoRA: Adapter lora_winogrande_2 loss: 1.8674399852752686
[2025-12-23 16:12:10,186] m-LoRA: Adapter lora_winogrande_10 epoch: 1/1 iteration: 88/128 step: 23
[2025-12-23 16:12:10,289] m-LoRA: Adapter lora_winogrande_9 loss: 1.9069329500198364
[2025-12-23 16:12:10,291] m-LoRA: Adapter lora_winogrande_11 epoch: 1/1 iteration: 44/128 step: 23
[2025-12-23 16:12:10,430] m-LoRA: Adapter lora_winogrande_7 loss: 0.5693780183792114
[2025-12-23 16:12:10,432] m-LoRA: Adapter lora_winogrande_12 epoch: 1/1 iteration: 44/128 step: 23
[2025-12-23 16:12:10,998] m-LoRA: Adapter lora_winogrande_23 epoch: 1/1 iteration: 12/128 step: 7
[2025-12-23 16:12:11,041] m-LoRA: Adapter lora_winogrande_22 loss: 1.4841467142105103
[2025-12-23 16:12:11,456] m-LoRA: Adapter lora_winogrande_19 epoch: 1/1 iteration: 56/128 step: 15
[2025-12-23 16:12:11,499] m-LoRA: Adapter lora_winogrande_17 loss: 0.5561650395393372
[2025-12-23 16:12:11,714] m-LoRA: Adapter lora_winogrande_8 loss: 1.889904499053955
[2025-12-23 16:12:11,717] m-LoRA: Adapter lora_winogrande_24 epoch: 1/1 iteration: 24/128 step: 7
[2025-12-23 16:12:11,858] m-LoRA: Adapter lora_winogrande_18 loss: 2.0595242977142334
[2025-12-23 16:12:11,861] m-LoRA: Adapter lora_winogrande_20 epoch: 1/1 iteration: 28/128 step: 15
[2025-12-23 16:12:12,040] m-LoRA: Adapter lora_winogrande_10 loss: 0.5454659461975098
[2025-12-23 16:12:12,042] m-LoRA: Adapter lora_winogrande_0 epoch: 1/1 iteration: 46/128 step: 24
[2025-12-23 16:12:12,271] m-LoRA: Adapter lora_winogrande_11 loss: 0.46316686272621155
[2025-12-23 16:12:12,273] m-LoRA: Adapter lora_winogrande_1 epoch: 1/1 iteration: 92/128 step: 24
[2025-12-23 16:12:12,442] m-LoRA: Adapter lora_winogrande_12 loss: 0.47426337003707886
[2025-12-23 16:12:12,445] m-LoRA: Adapter lora_winogrande_21 epoch: 1/1 iteration: 112/128 step: 8
[2025-12-23 16:12:12,595] m-LoRA: Adapter lora_winogrande_23 loss: 2.740358591079712
[2025-12-23 16:12:12,597] m-LoRA: Adapter lora_winogrande_2 epoch: 1/1 iteration: 92/128 step: 24
[2025-12-23 16:12:12,706] m-LoRA: Adapter lora_winogrande_9 epoch: 1/1 iteration: 46/128 step: 24
[2025-12-23 16:12:12,785] m-LoRA: Adapter lora_winogrande_7 epoch: 1/1 iteration: 92/128 step: 24
[2025-12-23 16:12:12,933] m-LoRA: Adapter lora_winogrande_19 loss: 0.6176550984382629
[2025-12-23 16:12:12,935] m-LoRA: Adapter lora_winogrande_22 epoch: 1/1 iteration: 112/128 step: 8
[2025-12-23 16:12:13,135] m-LoRA: Adapter lora_winogrande_24 loss: 1.4541758298873901
[2025-12-23 16:12:13,143] m-LoRA: Adapter lora_winogrande_17 epoch: 1/1 iteration: 120/128 step: 16
[2025-12-23 16:12:13,284] m-LoRA: Adapter lora_winogrande_20 loss: 0.6087566614151001
[2025-12-23 16:12:13,286] m-LoRA: Adapter lora_winogrande_8 epoch: 1/1 iteration: 92/128 step: 24
[2025-12-23 16:12:13,378] m-LoRA: Adapter lora_winogrande_0 loss: 0.521776020526886
[2025-12-23 16:12:13,380] m-LoRA: Adapter lora_winogrande_18 epoch: 1/1 iteration: 30/128 step: 16
[2025-12-23 16:12:13,537] m-LoRA: Adapter lora_winogrande_1 loss: 0.5763487815856934
[2025-12-23 16:12:13,539] m-LoRA: Adapter lora_winogrande_10 epoch: 1/1 iteration: 92/128 step: 24
[2025-12-23 16:12:14,230] m-LoRA: Adapter lora_winogrande_11 epoch: 1/1 iteration: 46/128 step: 24
[2025-12-23 16:12:14,256] m-LoRA: Adapter lora_winogrande_21 loss: 0.7632128596305847
[2025-12-23 16:12:14,478] m-LoRA: Adapter lora_winogrande_2 loss: 1.7850583791732788
[2025-12-23 16:12:14,480] m-LoRA: Adapter lora_winogrande_12 epoch: 1/1 iteration: 46/128 step: 24
[2025-12-23 16:12:14,630] m-LoRA: Adapter lora_winogrande_9 loss: 2.0348355770111084
[2025-12-23 16:12:14,632] m-LoRA: Adapter lora_winogrande_23 epoch: 1/1 iteration: 14/128 step: 8
[2025-12-23 16:12:14,783] m-LoRA: Adapter lora_winogrande_7 loss: 0.6499825716018677
[2025-12-23 16:12:14,786] m-LoRA: Adapter lora_winogrande_19 epoch: 1/1 iteration: 60/128 step: 16
[2025-12-23 16:12:15,487] m-LoRA: Adapter lora_winogrande_24 epoch: 1/1 iteration: 28/128 step: 8
[2025-12-23 16:12:15,533] m-LoRA: Adapter lora_winogrande_22 loss: 1.2342108488082886
[2025-12-23 16:12:15,922] m-LoRA: Adapter lora_winogrande_17 loss: 0.5974079370498657
[2025-12-23 16:12:15,926] m-LoRA: Adapter lora_winogrande_20 epoch: 1/1 iteration: 30/128 step: 16
[2025-12-23 16:12:16,120] m-LoRA: Adapter lora_winogrande_8 loss: 1.8565226793289185
[2025-12-23 16:12:16,122] m-LoRA: Adapter lora_winogrande_0 epoch: 1/1 iteration: 48/128 step: 25
[2025-12-23 16:12:16,253] m-LoRA: Adapter lora_winogrande_18 loss: 2.0333261489868164
[2025-12-23 16:12:16,255] m-LoRA: Adapter lora_winogrande_1 epoch: 1/1 iteration: 96/128 step: 25
[2025-12-23 16:12:16,327] m-LoRA: Adapter lora_winogrande_10 loss: 0.5467542409896851
[2025-12-23 16:12:16,427] m-LoRA: Adapter lora_winogrande_11 loss: 0.4910203516483307
[2025-12-23 16:12:17,087] m-LoRA: Adapter lora_winogrande_12 loss: 0.5717766284942627
[2025-12-23 16:12:17,480] m-LoRA: Adapter lora_winogrande_23 loss: 2.565833330154419
[2025-12-23 16:12:18,019] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_21']
[2025-12-23 16:12:18,756] m-LoRA: Adapter lora_winogrande_19 loss: 0.5741894841194153
[2025-12-23 16:12:18,758] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_25']
[2025-12-23 16:12:18,910] m-LoRA: Adapter lora_winogrande_25 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:12:19,042] m-LoRA: Adapter lora_winogrande_24 loss: 1.2067710161209106
[2025-12-23 16:12:19,045] m-LoRA: Adapter lora_winogrande_2 epoch: 1/1 iteration: 96/128 step: 25
[2025-12-23 16:12:19,226] m-LoRA: Adapter lora_winogrande_20 loss: 0.6202043294906616
[2025-12-23 16:12:19,253] m-LoRA: Adapter lora_winogrande_9 epoch: 1/1 iteration: 48/128 step: 25
[2025-12-23 16:12:19,383] m-LoRA: Adapter lora_winogrande_0 loss: 0.45763400197029114
[2025-12-23 16:12:19,385] m-LoRA: Adapter lora_winogrande_7 epoch: 1/1 iteration: 96/128 step: 25
[2025-12-23 16:12:19,442] m-LoRA: Adapter lora_winogrande_1 loss: 0.5246838331222534
[2025-12-23 16:12:19,568] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_22']
[2025-12-23 16:12:20,011] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_26']
[2025-12-23 16:12:20,113] m-LoRA: Adapter lora_winogrande_26 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:12:20,215] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_17']
[2025-12-23 16:12:20,703] m-LoRA: Adapter lora_winogrande_25 loss: 3.386909246444702
[2025-12-23 16:12:20,736] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_27']
[2025-12-23 16:12:20,901] m-LoRA: Adapter lora_winogrande_27 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:12:21,008] m-LoRA: Adapter lora_winogrande_2 loss: 1.8613766431808472
[2025-12-23 16:12:21,010] m-LoRA: Adapter lora_winogrande_8 epoch: 1/1 iteration: 96/128 step: 25
[2025-12-23 16:12:21,123] m-LoRA: Adapter lora_winogrande_9 loss: 1.7616597414016724
[2025-12-23 16:12:21,125] m-LoRA: Adapter lora_winogrande_18 epoch: 1/1 iteration: 32/128 step: 17
[2025-12-23 16:12:21,172] m-LoRA: Adapter lora_winogrande_7 loss: 0.47118160128593445
[2025-12-23 16:12:21,178] m-LoRA: Adapter lora_winogrande_26 loss: 3.101923942565918
[2025-12-23 16:12:21,329] m-LoRA: Adapter lora_winogrande_10 epoch: 1/1 iteration: 96/128 step: 25
[2025-12-23 16:12:21,430] m-LoRA: Adapter lora_winogrande_11 epoch: 1/1 iteration: 48/128 step: 25
[2025-12-23 16:12:21,522] m-LoRA: Adapter lora_winogrande_12 epoch: 1/1 iteration: 48/128 step: 25
[2025-12-23 16:12:21,614] m-LoRA: Adapter lora_winogrande_23 epoch: 1/1 iteration: 16/128 step: 9
[2025-12-23 16:12:21,696] m-LoRA: Adapter lora_winogrande_19 epoch: 1/1 iteration: 64/128 step: 17
[2025-12-23 16:12:21,774] m-LoRA: Adapter lora_winogrande_24 epoch: 1/1 iteration: 32/128 step: 9
[2025-12-23 16:12:21,856] m-LoRA: Adapter lora_winogrande_20 epoch: 1/1 iteration: 32/128 step: 17
[2025-12-23 16:12:22,168] m-LoRA: Adapter lora_winogrande_0 epoch: 1/1 iteration: 50/128 step: 26
[2025-12-23 16:12:22,208] m-LoRA: Adapter lora_winogrande_27 loss: 3.1205012798309326
[2025-12-23 16:12:22,459] m-LoRA: Adapter lora_winogrande_8 loss: 1.771253228187561
[2025-12-23 16:12:22,462] m-LoRA: Adapter lora_winogrande_1 epoch: 1/1 iteration: 100/128 step: 26
[2025-12-23 16:12:22,643] m-LoRA: Adapter lora_winogrande_18 loss: 2.1557867527008057
[2025-12-23 16:12:22,645] m-LoRA: Adapter lora_winogrande_25 epoch: 1/1 iteration: 16/128 step: 2
[2025-12-23 16:12:22,763] m-LoRA: Adapter lora_winogrande_10 loss: 0.4705182611942291
[2025-12-23 16:12:22,765] m-LoRA: Adapter lora_winogrande_2 epoch: 1/1 iteration: 100/128 step: 26
[2025-12-23 16:12:22,887] m-LoRA: Adapter lora_winogrande_11 loss: 0.45758122205734253
[2025-12-23 16:12:22,889] m-LoRA: Adapter lora_winogrande_9 epoch: 1/1 iteration: 50/128 step: 26
[2025-12-23 16:12:23,003] m-LoRA: Adapter lora_winogrande_12 loss: 0.6722206473350525
[2025-12-23 16:12:23,005] m-LoRA: Adapter lora_winogrande_7 epoch: 1/1 iteration: 100/128 step: 26
[2025-12-23 16:12:23,124] m-LoRA: Adapter lora_winogrande_23 loss: 2.583357810974121
[2025-12-23 16:12:23,126] m-LoRA: Adapter lora_winogrande_26 epoch: 1/1 iteration: 4/128 step: 2
[2025-12-23 16:12:23,240] m-LoRA: Adapter lora_winogrande_19 loss: 0.5927296876907349
[2025-12-23 16:12:23,242] m-LoRA: Adapter lora_winogrande_27 epoch: 1/1 iteration: 8/128 step: 2
[2025-12-23 16:12:23,339] m-LoRA: Adapter lora_winogrande_24 loss: 0.9963812828063965
[2025-12-23 16:12:23,494] m-LoRA: Adapter lora_winogrande_20 loss: 0.6102724075317383
[2025-12-23 16:12:23,496] m-LoRA: Adapter lora_winogrande_8 epoch: 1/1 iteration: 100/128 step: 26
[2025-12-23 16:12:23,571] m-LoRA: Adapter lora_winogrande_0 loss: 0.592969536781311
[2025-12-23 16:12:23,574] m-LoRA: Adapter lora_winogrande_18 epoch: 1/1 iteration: 34/128 step: 18
[2025-12-23 16:12:23,811] m-LoRA: Adapter lora_winogrande_1 loss: 0.45474568009376526
[2025-12-23 16:12:23,814] m-LoRA: Adapter lora_winogrande_10 epoch: 1/1 iteration: 100/128 step: 26
[2025-12-23 16:12:24,524] m-LoRA: Adapter lora_winogrande_25 loss: 2.5737767219543457
[2025-12-23 16:12:24,530] m-LoRA: Adapter lora_winogrande_11 epoch: 1/1 iteration: 50/128 step: 26
[2025-12-23 16:12:24,780] m-LoRA: Adapter lora_winogrande_2 loss: 1.786670446395874
[2025-12-23 16:12:24,782] m-LoRA: Adapter lora_winogrande_12 epoch: 1/1 iteration: 50/128 step: 26
[2025-12-23 16:12:24,898] m-LoRA: Adapter lora_winogrande_9 loss: 1.657921314239502
[2025-12-23 16:12:24,900] m-LoRA: Adapter lora_winogrande_23 epoch: 1/1 iteration: 18/128 step: 10
[2025-12-23 16:12:25,055] m-LoRA: Adapter lora_winogrande_7 loss: 0.5171239376068115
[2025-12-23 16:12:25,058] m-LoRA: Adapter lora_winogrande_19 epoch: 1/1 iteration: 68/128 step: 18
[2025-12-23 16:12:25,237] m-LoRA: Adapter lora_winogrande_26 loss: 2.913954019546509
[2025-12-23 16:12:25,240] m-LoRA: Adapter lora_winogrande_24 epoch: 1/1 iteration: 36/128 step: 10
[2025-12-23 16:12:25,522] m-LoRA: Adapter lora_winogrande_27 loss: 3.102962017059326
[2025-12-23 16:12:25,527] m-LoRA: Adapter lora_winogrande_20 epoch: 1/1 iteration: 34/128 step: 18
[2025-12-23 16:12:25,690] m-LoRA: Adapter lora_winogrande_8 loss: 1.695313811302185
[2025-12-23 16:12:25,693] m-LoRA: Adapter lora_winogrande_0 epoch: 1/1 iteration: 52/128 step: 27
[2025-12-23 16:12:25,827] m-LoRA: Adapter lora_winogrande_18 loss: 1.9613423347473145
[2025-12-23 16:12:25,830] m-LoRA: Adapter lora_winogrande_1 epoch: 1/1 iteration: 104/128 step: 27
[2025-12-23 16:12:25,953] m-LoRA: Adapter lora_winogrande_10 loss: 0.5133414268493652
[2025-12-23 16:12:26,130] m-LoRA: Adapter lora_winogrande_11 loss: 0.47735750675201416
[2025-12-23 16:12:26,487] m-LoRA: Adapter lora_winogrande_12 loss: 0.559513509273529
[2025-12-23 16:12:26,489] m-LoRA: Adapter lora_winogrande_25 epoch: 1/1 iteration: 32/128 step: 3
[2025-12-23 16:12:26,642] m-LoRA: Adapter lora_winogrande_23 loss: 2.3383543491363525
[2025-12-23 16:12:26,644] m-LoRA: Adapter lora_winogrande_2 epoch: 1/1 iteration: 104/128 step: 27
[2025-12-23 16:12:26,730] m-LoRA: Adapter lora_winogrande_9 epoch: 1/1 iteration: 52/128 step: 27
[2025-12-23 16:12:26,944] m-LoRA: Adapter lora_winogrande_19 loss: 0.5376281142234802
[2025-12-23 16:12:26,947] m-LoRA: Adapter lora_winogrande_7 epoch: 1/1 iteration: 104/128 step: 27
[2025-12-23 16:12:27,227] m-LoRA: Adapter lora_winogrande_24 loss: 0.8986597657203674
[2025-12-23 16:12:27,230] m-LoRA: Adapter lora_winogrande_26 epoch: 1/1 iteration: 8/128 step: 3
[2025-12-23 16:12:27,392] m-LoRA: Adapter lora_winogrande_20 loss: 0.7099050879478455
[2025-12-23 16:12:27,622] m-LoRA: Adapter lora_winogrande_0 loss: 0.41705673933029175
[2025-12-23 16:12:27,624] m-LoRA: Adapter lora_winogrande_27 epoch: 1/1 iteration: 16/128 step: 3
[2025-12-23 16:12:27,901] m-LoRA: Adapter lora_winogrande_1 loss: 0.47066283226013184
[2025-12-23 16:12:27,904] m-LoRA: Adapter lora_winogrande_8 epoch: 1/1 iteration: 104/128 step: 27
[2025-12-23 16:12:27,992] m-LoRA: Adapter lora_winogrande_18 epoch: 1/1 iteration: 36/128 step: 19
[2025-12-23 16:12:28,061] m-LoRA: Adapter lora_winogrande_10 epoch: 1/1 iteration: 104/128 step: 27
[2025-12-23 16:12:28,760] m-LoRA: Adapter lora_winogrande_25 loss: 2.032346725463867
[2025-12-23 16:12:28,767] m-LoRA: Adapter lora_winogrande_11 epoch: 1/1 iteration: 52/128 step: 27
[2025-12-23 16:12:29,076] m-LoRA: Adapter lora_winogrande_2 loss: 1.5771489143371582
[2025-12-23 16:12:29,078] m-LoRA: Adapter lora_winogrande_12 epoch: 1/1 iteration: 52/128 step: 27
[2025-12-23 16:12:29,242] m-LoRA: Adapter lora_winogrande_9 loss: 1.672314167022705
[2025-12-23 16:12:29,245] m-LoRA: Adapter lora_winogrande_23 epoch: 1/1 iteration: 20/128 step: 11
[2025-12-23 16:12:29,399] m-LoRA: Adapter lora_winogrande_7 loss: 0.6226268410682678
[2025-12-23 16:12:29,401] m-LoRA: Adapter lora_winogrande_19 epoch: 1/1 iteration: 72/128 step: 19
[2025-12-23 16:12:29,534] m-LoRA: Adapter lora_winogrande_26 loss: 2.100938081741333
[2025-12-23 16:12:29,537] m-LoRA: Adapter lora_winogrande_24 epoch: 1/1 iteration: 40/128 step: 11
[2025-12-23 16:12:30,083] m-LoRA: Adapter lora_winogrande_27 loss: 2.4673383235931396
[2025-12-23 16:12:30,087] m-LoRA: Adapter lora_winogrande_20 epoch: 1/1 iteration: 36/128 step: 19
[2025-12-23 16:12:30,282] m-LoRA: Adapter lora_winogrande_0 epoch: 1/1 iteration: 54/128 step: 28
[2025-12-23 16:12:30,299] m-LoRA: Adapter lora_winogrande_8 loss: 1.7211593389511108
[2025-12-23 16:12:30,450] m-LoRA: Adapter lora_winogrande_18 loss: 2.000478982925415
[2025-12-23 16:12:30,452] m-LoRA: Adapter lora_winogrande_1 epoch: 1/1 iteration: 108/128 step: 28
[2025-12-23 16:12:30,732] m-LoRA: Adapter lora_winogrande_10 loss: 0.5375691652297974
[2025-12-23 16:12:30,784] m-LoRA: Adapter lora_winogrande_25 epoch: 1/1 iteration: 48/128 step: 4
[2025-12-23 16:12:30,986] m-LoRA: Adapter lora_winogrande_11 loss: 0.5252037048339844
[2025-12-23 16:12:30,994] m-LoRA: Adapter lora_winogrande_2 epoch: 1/1 iteration: 108/128 step: 28
[2025-12-23 16:12:31,116] m-LoRA: Adapter lora_winogrande_12 loss: 0.48705223202705383
[2025-12-23 16:12:31,119] m-LoRA: Adapter lora_winogrande_9 epoch: 1/1 iteration: 54/128 step: 28
[2025-12-23 16:12:31,233] m-LoRA: Adapter lora_winogrande_23 loss: 2.1946518421173096
[2025-12-23 16:12:31,236] m-LoRA: Adapter lora_winogrande_7 epoch: 1/1 iteration: 108/128 step: 28
[2025-12-23 16:12:31,316] m-LoRA: Adapter lora_winogrande_19 loss: 0.6412581205368042
[2025-12-23 16:12:31,318] m-LoRA: Adapter lora_winogrande_26 epoch: 1/1 iteration: 12/128 step: 4
[2025-12-23 16:12:31,575] m-LoRA: Adapter lora_winogrande_24 loss: 0.6978463530540466
[2025-12-23 16:12:31,578] m-LoRA: Adapter lora_winogrande_27 epoch: 1/1 iteration: 24/128 step: 4
[2025-12-23 16:12:31,778] m-LoRA: Adapter lora_winogrande_20 loss: 0.6981598734855652
[2025-12-23 16:12:31,780] m-LoRA: Adapter lora_winogrande_8 epoch: 1/1 iteration: 108/128 step: 28
[2025-12-23 16:12:31,970] m-LoRA: Adapter lora_winogrande_0 loss: 0.42301419377326965
[2025-12-23 16:12:31,973] m-LoRA: Adapter lora_winogrande_18 epoch: 1/1 iteration: 38/128 step: 20
[2025-12-23 16:12:32,085] m-LoRA: Adapter lora_winogrande_1 loss: 0.42174872756004333
[2025-12-23 16:12:32,088] m-LoRA: Adapter lora_winogrande_10 epoch: 1/1 iteration: 108/128 step: 28
[2025-12-23 16:12:32,611] m-LoRA: Adapter lora_winogrande_11 epoch: 1/1 iteration: 54/128 step: 28
[2025-12-23 16:12:32,735] m-LoRA: Adapter lora_winogrande_25 loss: 2.0951297283172607
[2025-12-23 16:12:32,742] m-LoRA: Adapter lora_winogrande_12 epoch: 1/1 iteration: 54/128 step: 28
[2025-12-23 16:12:32,896] m-LoRA: Adapter lora_winogrande_2 loss: 1.5880601406097412
[2025-12-23 16:12:32,900] m-LoRA: Adapter lora_winogrande_23 epoch: 1/1 iteration: 22/128 step: 12
[2025-12-23 16:12:33,022] m-LoRA: Adapter lora_winogrande_9 loss: 1.6642464399337769
[2025-12-23 16:12:33,024] m-LoRA: Adapter lora_winogrande_19 epoch: 1/1 iteration: 76/128 step: 20
[2025-12-23 16:12:33,079] m-LoRA: Adapter lora_winogrande_7 loss: 0.5842390656471252
[2025-12-23 16:12:33,198] m-LoRA: Adapter lora_winogrande_26 loss: 2.056809902191162
[2025-12-23 16:12:33,200] m-LoRA: Adapter lora_winogrande_24 epoch: 1/1 iteration: 44/128 step: 12
[2025-12-23 16:12:33,475] m-LoRA: Adapter lora_winogrande_20 epoch: 1/1 iteration: 38/128 step: 20
[2025-12-23 16:12:33,515] m-LoRA: Adapter lora_winogrande_27 loss: 2.247128486633301
[2025-12-23 16:12:33,798] m-LoRA: Adapter lora_winogrande_8 loss: 1.6489343643188477
[2025-12-23 16:12:33,801] m-LoRA: Adapter lora_winogrande_0 epoch: 1/1 iteration: 56/128 step: 29
[2025-12-23 16:12:33,922] m-LoRA: Adapter lora_winogrande_18 loss: 1.9519309997558594
[2025-12-23 16:12:33,924] m-LoRA: Adapter lora_winogrande_1 epoch: 1/1 iteration: 112/128 step: 29
[2025-12-23 16:12:33,998] m-LoRA: Adapter lora_winogrande_10 loss: 0.43293166160583496
[2025-12-23 16:12:34,162] m-LoRA: Adapter lora_winogrande_11 loss: 0.4676799178123474
[2025-12-23 16:12:34,165] m-LoRA: Adapter lora_winogrande_25 epoch: 1/1 iteration: 64/128 step: 5
[2025-12-23 16:12:34,326] m-LoRA: Adapter lora_winogrande_12 loss: 0.5078126192092896
[2025-12-23 16:12:34,329] m-LoRA: Adapter lora_winogrande_2 epoch: 1/1 iteration: 112/128 step: 29
[2025-12-23 16:12:34,380] m-LoRA: Adapter lora_winogrande_23 loss: 2.361323833465576
[2025-12-23 16:12:34,516] m-LoRA: Adapter lora_winogrande_19 loss: 0.5005064010620117
[2025-12-23 16:12:34,519] m-LoRA: Adapter lora_winogrande_9 epoch: 1/1 iteration: 56/128 step: 29
[2025-12-23 16:12:34,693] m-LoRA: Adapter lora_winogrande_24 loss: 0.7256422638893127
[2025-12-23 16:12:34,696] m-LoRA: Adapter lora_winogrande_7 epoch: 1/1 iteration: 112/128 step: 29
[2025-12-23 16:12:34,873] m-LoRA: Adapter lora_winogrande_20 loss: 0.5845229625701904
[2025-12-23 16:12:34,875] m-LoRA: Adapter lora_winogrande_26 epoch: 1/1 iteration: 16/128 step: 5
[2025-12-23 16:12:34,928] m-LoRA: Adapter lora_winogrande_0 loss: 0.5138002038002014
[2025-12-23 16:12:35,106] m-LoRA: Adapter lora_winogrande_1 loss: 0.5008102059364319
[2025-12-23 16:12:35,108] m-LoRA: Adapter lora_winogrande_27 epoch: 1/1 iteration: 32/128 step: 5
[2025-12-23 16:12:36,957] m-LoRA: Adapter lora_winogrande_8 epoch: 1/1 iteration: 112/128 step: 29
[2025-12-23 16:12:37,535] m-LoRA: Adapter lora_winogrande_25 loss: 1.78815495967865
[2025-12-23 16:12:37,542] m-LoRA: Adapter lora_winogrande_18 epoch: 1/1 iteration: 40/128 step: 21
[2025-12-23 16:12:37,710] m-LoRA: Adapter lora_winogrande_2 loss: 1.5959224700927734
[2025-12-23 16:12:37,712] m-LoRA: Adapter lora_winogrande_10 epoch: 1/1 iteration: 112/128 step: 29
[2025-12-23 16:12:37,794] m-LoRA: Adapter lora_winogrande_9 loss: 1.6074342727661133
[2025-12-23 16:12:37,796] m-LoRA: Adapter lora_winogrande_11 epoch: 1/1 iteration: 56/128 step: 29
[2025-12-23 16:12:37,898] m-LoRA: Adapter lora_winogrande_7 loss: 0.4292052984237671
[2025-12-23 16:12:37,901] m-LoRA: Adapter lora_winogrande_12 epoch: 1/1 iteration: 56/128 step: 29
[2025-12-23 16:12:37,984] m-LoRA: Adapter lora_winogrande_26 loss: 1.851804256439209
[2025-12-23 16:12:37,985] m-LoRA: Adapter lora_winogrande_23 epoch: 1/1 iteration: 24/128 step: 13
[2025-12-23 16:12:38,066] m-LoRA: Adapter lora_winogrande_27 loss: 2.092306613922119
[2025-12-23 16:12:38,070] m-LoRA: Adapter lora_winogrande_19 epoch: 1/1 iteration: 80/128 step: 21
[2025-12-23 16:12:38,166] m-LoRA: Adapter lora_winogrande_8 loss: 1.571793794631958
[2025-12-23 16:12:38,169] m-LoRA: Adapter lora_winogrande_24 epoch: 1/1 iteration: 48/128 step: 13
[2025-12-23 16:12:38,296] m-LoRA: Adapter lora_winogrande_18 loss: 2.035244941711426
[2025-12-23 16:12:38,298] m-LoRA: Adapter lora_winogrande_20 epoch: 1/1 iteration: 40/128 step: 21
[2025-12-23 16:12:38,387] m-LoRA: Adapter lora_winogrande_0 epoch: 1/1 iteration: 58/128 step: 30
[2025-12-23 16:12:38,462] m-LoRA: Adapter lora_winogrande_1 epoch: 1/1 iteration: 116/128 step: 30
[2025-12-23 16:12:38,727] m-LoRA: Adapter lora_winogrande_10 loss: 0.5078166723251343
[2025-12-23 16:12:38,809] m-LoRA: Adapter lora_winogrande_11 loss: 0.5190110802650452
[2025-12-23 16:12:38,906] m-LoRA: Adapter lora_winogrande_25 epoch: 1/1 iteration: 80/128 step: 6
[2025-12-23 16:12:39,032] m-LoRA: Adapter lora_winogrande_12 loss: 0.4562762379646301
[2025-12-23 16:12:39,034] m-LoRA: Adapter lora_winogrande_2 epoch: 1/1 iteration: 116/128 step: 30
[2025-12-23 16:12:39,151] m-LoRA: Adapter lora_winogrande_23 loss: 2.3282809257507324
[2025-12-23 16:12:39,154] m-LoRA: Adapter lora_winogrande_9 epoch: 1/1 iteration: 58/128 step: 30
[2025-12-23 16:12:39,376] m-LoRA: Adapter lora_winogrande_7 epoch: 1/1 iteration: 116/128 step: 30
[2025-12-23 16:12:39,455] m-LoRA: Adapter lora_winogrande_19 loss: 0.6049967408180237
[2025-12-23 16:12:39,459] m-LoRA: Adapter lora_winogrande_26 epoch: 1/1 iteration: 20/128 step: 6
[2025-12-23 16:12:39,681] m-LoRA: Adapter lora_winogrande_24 loss: 0.61246258020401
[2025-12-23 16:12:39,813] m-LoRA: Adapter lora_winogrande_20 loss: 0.5451308488845825
[2025-12-23 16:12:39,815] m-LoRA: Adapter lora_winogrande_27 epoch: 1/1 iteration: 40/128 step: 6
[2025-12-23 16:12:39,926] m-LoRA: Adapter lora_winogrande_0 loss: 0.5171459913253784
[2025-12-23 16:12:39,928] m-LoRA: Adapter lora_winogrande_8 epoch: 1/1 iteration: 116/128 step: 30
[2025-12-23 16:12:39,995] m-LoRA: Adapter lora_winogrande_18 epoch: 1/1 iteration: 42/128 step: 22
[2025-12-23 16:12:40,133] m-LoRA: Adapter lora_winogrande_1 loss: 0.5778045654296875
[2025-12-23 16:12:40,227] m-LoRA: Adapter lora_winogrande_10 epoch: 1/1 iteration: 116/128 step: 30
[2025-12-23 16:12:40,300] m-LoRA: Adapter lora_winogrande_11 epoch: 1/1 iteration: 58/128 step: 30
[2025-12-23 16:12:40,968] m-LoRA: Adapter lora_winogrande_25 loss: 1.599164366722107
[2025-12-23 16:12:40,974] m-LoRA: Adapter lora_winogrande_12 epoch: 1/1 iteration: 58/128 step: 30
[2025-12-23 16:12:41,187] m-LoRA: Adapter lora_winogrande_2 loss: 1.6356301307678223
[2025-12-23 16:12:41,190] m-LoRA: Adapter lora_winogrande_23 epoch: 1/1 iteration: 26/128 step: 14
[2025-12-23 16:12:41,332] m-LoRA: Adapter lora_winogrande_9 loss: 1.6031060218811035
[2025-12-23 16:12:41,334] m-LoRA: Adapter lora_winogrande_19 epoch: 1/1 iteration: 84/128 step: 22
[2025-12-23 16:12:41,478] m-LoRA: Adapter lora_winogrande_7 loss: 0.541865348815918
[2025-12-23 16:12:41,480] m-LoRA: Adapter lora_winogrande_24 epoch: 1/1 iteration: 52/128 step: 14
[2025-12-23 16:12:41,589] m-LoRA: Adapter lora_winogrande_26 loss: 1.5473871231079102
[2025-12-23 16:12:41,592] m-LoRA: Adapter lora_winogrande_20 epoch: 1/1 iteration: 42/128 step: 22
[2025-12-23 16:12:41,868] m-LoRA: Adapter lora_winogrande_27 loss: 2.06788969039917
[2025-12-23 16:12:41,871] m-LoRA: Adapter lora_winogrande_0 epoch: 1/1 iteration: 60/128 step: 31
[2025-12-23 16:12:42,101] m-LoRA: Adapter lora_winogrande_8 loss: 1.5219144821166992
[2025-12-23 16:12:42,105] m-LoRA: Adapter lora_winogrande_1 epoch: 1/1 iteration: 120/128 step: 31
[2025-12-23 16:12:42,210] m-LoRA: Adapter lora_winogrande_18 loss: 1.9883170127868652
[2025-12-23 16:12:42,491] m-LoRA: Adapter lora_winogrande_10 loss: 0.48988884687423706
[2025-12-23 16:12:42,495] m-LoRA: Adapter lora_winogrande_25 epoch: 1/1 iteration: 96/128 step: 7
[2025-12-23 16:12:42,665] m-LoRA: Adapter lora_winogrande_11 loss: 0.51239413022995
[2025-12-23 16:12:42,667] m-LoRA: Adapter lora_winogrande_2 epoch: 1/1 iteration: 120/128 step: 31
[2025-12-23 16:12:42,785] m-LoRA: Adapter lora_winogrande_12 loss: 0.49263593554496765
[2025-12-23 16:12:42,788] m-LoRA: Adapter lora_winogrande_9 epoch: 1/1 iteration: 60/128 step: 31
[2025-12-23 16:12:42,851] m-LoRA: Adapter lora_winogrande_23 loss: 2.1359779834747314
[2025-12-23 16:12:42,928] m-LoRA: Adapter lora_winogrande_19 loss: 0.5400577783584595
[2025-12-23 16:12:42,931] m-LoRA: Adapter lora_winogrande_7 epoch: 1/1 iteration: 120/128 step: 31
[2025-12-23 16:12:43,169] m-LoRA: Adapter lora_winogrande_24 loss: 0.6620995998382568
[2025-12-23 16:12:43,172] m-LoRA: Adapter lora_winogrande_26 epoch: 1/1 iteration: 24/128 step: 7
[2025-12-23 16:12:43,295] m-LoRA: Adapter lora_winogrande_20 loss: 0.5617135763168335
[2025-12-23 16:12:43,298] m-LoRA: Adapter lora_winogrande_27 epoch: 1/1 iteration: 48/128 step: 7
[2025-12-23 16:12:43,368] m-LoRA: Adapter lora_winogrande_0 loss: 0.5480741858482361
[2025-12-23 16:12:43,604] m-LoRA: Adapter lora_winogrande_1 loss: 0.4970432221889496
[2025-12-23 16:12:43,606] m-LoRA: Adapter lora_winogrande_8 epoch: 1/1 iteration: 120/128 step: 31
[2025-12-23 16:12:44,367] m-LoRA: Adapter lora_winogrande_25 loss: 1.3532320261001587
[2025-12-23 16:12:44,374] m-LoRA: Adapter lora_winogrande_18 epoch: 1/1 iteration: 44/128 step: 23
[2025-12-23 16:12:44,586] m-LoRA: Adapter lora_winogrande_2 loss: 1.5827174186706543
[2025-12-23 16:12:44,588] m-LoRA: Adapter lora_winogrande_10 epoch: 1/1 iteration: 120/128 step: 31
[2025-12-23 16:12:44,705] m-LoRA: Adapter lora_winogrande_9 loss: 1.5652836561203003
[2025-12-23 16:12:44,707] m-LoRA: Adapter lora_winogrande_11 epoch: 1/1 iteration: 60/128 step: 31
[2025-12-23 16:12:44,861] m-LoRA: Adapter lora_winogrande_7 loss: 0.3984456956386566
[2025-12-23 16:12:44,863] m-LoRA: Adapter lora_winogrande_12 epoch: 1/1 iteration: 60/128 step: 31
[2025-12-23 16:12:45,020] m-LoRA: Adapter lora_winogrande_26 loss: 1.3946113586425781
[2025-12-23 16:12:45,023] m-LoRA: Adapter lora_winogrande_23 epoch: 1/1 iteration: 28/128 step: 15
[2025-12-23 16:12:45,226] m-LoRA: Adapter lora_winogrande_27 loss: 2.008039712905884
[2025-12-23 16:12:45,230] m-LoRA: Adapter lora_winogrande_19 epoch: 1/1 iteration: 88/128 step: 23
[2025-12-23 16:12:45,557] m-LoRA: Adapter lora_winogrande_8 loss: 1.462953805923462
[2025-12-23 16:12:45,561] m-LoRA: Adapter lora_winogrande_24 epoch: 1/1 iteration: 56/128 step: 15
[2025-12-23 16:12:45,698] m-LoRA: Adapter lora_winogrande_18 loss: 1.8495928049087524
[2025-12-23 16:12:45,700] m-LoRA: Adapter lora_winogrande_20 epoch: 1/1 iteration: 44/128 step: 23
[2025-12-23 16:12:45,819] m-LoRA: Adapter lora_winogrande_10 loss: 0.5369724035263062
[2025-12-23 16:12:45,823] m-LoRA: Adapter lora_winogrande_0 epoch: 1/1 iteration: 62/128 step: 32
[2025-12-23 16:12:45,968] m-LoRA: Adapter lora_winogrande_11 loss: 0.6464881896972656
[2025-12-23 16:12:45,971] m-LoRA: Adapter lora_winogrande_1 epoch: 1/1 iteration: 124/128 step: 32
[2025-12-23 16:12:46,156] m-LoRA: Adapter lora_winogrande_12 loss: 0.4475599229335785
[2025-12-23 16:12:46,159] m-LoRA: Adapter lora_winogrande_25 epoch: 1/1 iteration: 112/128 step: 8
[2025-12-23 16:12:46,299] m-LoRA: Adapter lora_winogrande_23 loss: 2.3236351013183594
[2025-12-23 16:12:46,301] m-LoRA: Adapter lora_winogrande_2 epoch: 1/1 iteration: 124/128 step: 32
[2025-12-23 16:12:46,431] m-LoRA: Adapter lora_winogrande_19 loss: 0.5014111399650574
[2025-12-23 16:12:46,435] m-LoRA: Adapter lora_winogrande_9 epoch: 1/1 iteration: 62/128 step: 32
[2025-12-23 16:12:46,526] m-LoRA: Adapter lora_winogrande_7 epoch: 1/1 iteration: 124/128 step: 32
[2025-12-23 16:12:46,586] m-LoRA: Adapter lora_winogrande_26 epoch: 1/1 iteration: 28/128 step: 8
[2025-12-23 16:12:46,735] m-LoRA: Adapter lora_winogrande_24 loss: 0.5415006279945374
[2025-12-23 16:12:46,825] m-LoRA: Adapter lora_winogrande_27 epoch: 1/1 iteration: 56/128 step: 8
[2025-12-23 16:12:46,985] m-LoRA: Adapter lora_winogrande_20 loss: 0.5373175740242004
[2025-12-23 16:12:46,988] m-LoRA: Adapter lora_winogrande_8 epoch: 1/1 iteration: 124/128 step: 32
[2025-12-23 16:12:47,175] m-LoRA: Adapter lora_winogrande_0 loss: 0.5667914748191833
[2025-12-23 16:12:47,177] m-LoRA: Adapter lora_winogrande_18 epoch: 1/1 iteration: 46/128 step: 24
[2025-12-23 16:12:47,525] m-LoRA: Adapter lora_winogrande_1 loss: 0.5342510938644409
[2025-12-23 16:12:47,528] m-LoRA: Adapter lora_winogrande_10 epoch: 1/1 iteration: 124/128 step: 32
[2025-12-23 16:12:47,663] m-LoRA: Adapter lora_winogrande_11 epoch: 1/1 iteration: 62/128 step: 32
[2025-12-23 16:12:48,291] m-LoRA: Adapter lora_winogrande_25 loss: 1.2350603342056274
[2025-12-23 16:12:48,299] m-LoRA: Adapter lora_winogrande_12 epoch: 1/1 iteration: 62/128 step: 32
[2025-12-23 16:12:48,547] m-LoRA: Adapter lora_winogrande_2 loss: 1.4756313562393188
[2025-12-23 16:12:48,549] m-LoRA: Adapter lora_winogrande_23 epoch: 1/1 iteration: 30/128 step: 16
[2025-12-23 16:12:48,657] m-LoRA: Adapter lora_winogrande_9 loss: 1.510908603668213
[2025-12-23 16:12:48,660] m-LoRA: Adapter lora_winogrande_19 epoch: 1/1 iteration: 92/128 step: 24
[2025-12-23 16:12:48,782] m-LoRA: Adapter lora_winogrande_7 loss: 0.5283187031745911
[2025-12-23 16:12:48,784] m-LoRA: Adapter lora_winogrande_24 epoch: 1/1 iteration: 60/128 step: 16
[2025-12-23 16:12:48,939] m-LoRA: Adapter lora_winogrande_26 loss: 1.2980561256408691
[2025-12-23 16:12:48,941] m-LoRA: Adapter lora_winogrande_20 epoch: 1/1 iteration: 46/128 step: 24
[2025-12-23 16:12:49,261] m-LoRA: Adapter lora_winogrande_27 loss: 1.828553318977356
[2025-12-23 16:12:49,264] m-LoRA: Adapter lora_winogrande_0 epoch: 1/1 iteration: 64/128 step: 33
[2025-12-23 16:12:49,466] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_1']
[2025-12-23 16:12:50,246] m-LoRA: Adapter lora_winogrande_8 loss: 1.4954829216003418
[2025-12-23 16:12:50,281] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_28']
[2025-12-23 16:12:50,419] m-LoRA: Adapter lora_winogrande_28 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:12:50,525] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_25']
[2025-12-23 16:12:50,967] m-LoRA: Adapter lora_winogrande_18 loss: 1.8018803596496582
[2025-12-23 16:12:50,970] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_29']
[2025-12-23 16:12:51,106] m-LoRA: Adapter lora_winogrande_29 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:12:51,128] m-LoRA: Adapter lora_winogrande_10 loss: 0.46575936675071716
[2025-12-23 16:12:51,133] m-LoRA: Adapter lora_winogrande_11 loss: 0.6118999719619751
[2025-12-23 16:12:51,137] m-LoRA: Adapter lora_winogrande_12 loss: 0.549831211566925
[2025-12-23 16:12:51,140] m-LoRA: Adapter lora_winogrande_23 loss: 2.181602716445923
[2025-12-23 16:12:51,143] m-LoRA: Adapter lora_winogrande_19 loss: 0.5522509813308716
[2025-12-23 16:12:51,312] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_2']
[2025-12-23 16:12:51,656] m-LoRA: Adapter lora_winogrande_24 loss: 0.5793056488037109
[2025-12-23 16:12:51,660] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_30']
[2025-12-23 16:12:51,746] m-LoRA: Adapter lora_winogrande_30 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:12:51,840] m-LoRA: Adapter lora_winogrande_20 loss: 0.6611467599868774
[2025-12-23 16:12:51,842] m-LoRA: Adapter lora_winogrande_9 epoch: 1/1 iteration: 64/128 step: 33
[2025-12-23 16:12:51,921] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_7']
[2025-12-23 16:12:52,159] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_31']
[2025-12-23 16:12:52,249] m-LoRA: Adapter lora_winogrande_31 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:12:52,349] m-LoRA: Adapter lora_winogrande_0 loss: 0.5035586357116699
[2025-12-23 16:12:52,352] m-LoRA: Adapter lora_winogrande_26 epoch: 1/1 iteration: 32/128 step: 9
[2025-12-23 16:12:52,448] m-LoRA: Adapter lora_winogrande_27 epoch: 1/1 iteration: 64/128 step: 9
[2025-12-23 16:12:52,773] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_8']
[2025-12-23 16:12:53,032] m-LoRA: Adapter lora_winogrande_28 loss: 3.1232094764709473
[2025-12-23 16:12:53,035] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_32']
[2025-12-23 16:12:53,165] m-LoRA: Adapter lora_winogrande_32 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:12:53,248] m-LoRA: Adapter lora_winogrande_29 loss: 2.7387654781341553
[2025-12-23 16:12:53,250] m-LoRA: Adapter lora_winogrande_18 epoch: 1/1 iteration: 48/128 step: 25
[2025-12-23 16:12:53,343] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_10']
[2025-12-23 16:12:53,585] m-LoRA: Adapter lora_winogrande_30 loss: 3.2386906147003174
[2025-12-23 16:12:53,589] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_33']
[2025-12-23 16:12:53,759] m-LoRA: Adapter lora_winogrande_33 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:12:53,855] m-LoRA: Adapter lora_winogrande_11 epoch: 1/1 iteration: 64/128 step: 33
[2025-12-23 16:12:53,932] m-LoRA: Adapter lora_winogrande_12 epoch: 1/1 iteration: 64/128 step: 33
[2025-12-23 16:12:54,362] m-LoRA: Adapter lora_winogrande_23 epoch: 1/1 iteration: 32/128 step: 17
[2025-12-23 16:12:54,420] m-LoRA: Adapter lora_winogrande_9 loss: 1.3959194421768188
[2025-12-23 16:12:54,719] m-LoRA: Adapter lora_winogrande_19 epoch: 1/1 iteration: 96/128 step: 25
[2025-12-23 16:12:55,007] m-LoRA: Adapter lora_winogrande_31 loss: 3.1578259468078613
[2025-12-23 16:12:55,289] m-LoRA: Adapter lora_winogrande_26 loss: 1.0965955257415771
[2025-12-23 16:12:55,292] m-LoRA: Adapter lora_winogrande_24 epoch: 1/1 iteration: 64/128 step: 17
[2025-12-23 16:12:55,657] m-LoRA: Adapter lora_winogrande_27 loss: 1.7356672286987305
[2025-12-23 16:12:55,660] m-LoRA: Adapter lora_winogrande_20 epoch: 1/1 iteration: 48/128 step: 25
[2025-12-23 16:12:55,865] m-LoRA: Adapter lora_winogrande_32 loss: 2.733107566833496
[2025-12-23 16:12:55,867] m-LoRA: Adapter lora_winogrande_0 epoch: 1/1 iteration: 66/128 step: 34
[2025-12-23 16:12:55,972] m-LoRA: Adapter lora_winogrande_18 loss: 1.7456753253936768
[2025-12-23 16:12:56,172] m-LoRA: Adapter lora_winogrande_33 loss: 2.97121262550354
[2025-12-23 16:12:56,174] m-LoRA: Adapter lora_winogrande_28 epoch: 1/1 iteration: 8/128 step: 2
[2025-12-23 16:12:56,298] m-LoRA: Adapter lora_winogrande_11 loss: 0.49873995780944824
[2025-12-23 16:12:56,300] m-LoRA: Adapter lora_winogrande_29 epoch: 1/1 iteration: 2/128 step: 2
[2025-12-23 16:12:56,500] m-LoRA: Adapter lora_winogrande_12 loss: 0.5162555575370789
[2025-12-23 16:12:56,502] m-LoRA: Adapter lora_winogrande_30 epoch: 1/1 iteration: 8/128 step: 2
[2025-12-23 16:12:56,642] m-LoRA: Adapter lora_winogrande_23 loss: 1.961377501487732
[2025-12-23 16:12:56,644] m-LoRA: Adapter lora_winogrande_9 epoch: 1/1 iteration: 66/128 step: 34
[2025-12-23 16:12:56,745] m-LoRA: Adapter lora_winogrande_31 epoch: 1/1 iteration: 8/128 step: 2
[2025-12-23 16:12:56,845] m-LoRA: Adapter lora_winogrande_19 loss: 0.5387521982192993
[2025-12-23 16:12:56,848] m-LoRA: Adapter lora_winogrande_26 epoch: 1/1 iteration: 36/128 step: 10
[2025-12-23 16:12:57,026] m-LoRA: Adapter lora_winogrande_24 loss: 0.6026377081871033
[2025-12-23 16:12:57,028] m-LoRA: Adapter lora_winogrande_27 epoch: 1/1 iteration: 72/128 step: 10
[2025-12-23 16:12:57,161] m-LoRA: Adapter lora_winogrande_20 loss: 0.4156714379787445
[2025-12-23 16:12:57,163] m-LoRA: Adapter lora_winogrande_32 epoch: 1/1 iteration: 2/128 step: 2
[2025-12-23 16:12:57,262] m-LoRA: Adapter lora_winogrande_0 loss: 0.5168098211288452
[2025-12-23 16:12:57,264] m-LoRA: Adapter lora_winogrande_18 epoch: 1/1 iteration: 50/128 step: 26
[2025-12-23 16:12:57,765] m-LoRA: Adapter lora_winogrande_28 loss: 3.1257803440093994
[2025-12-23 16:12:57,769] m-LoRA: Adapter lora_winogrande_33 epoch: 1/1 iteration: 2/128 step: 2
[2025-12-23 16:12:57,949] m-LoRA: Adapter lora_winogrande_29 loss: 2.392688035964966
[2025-12-23 16:12:57,951] m-LoRA: Adapter lora_winogrande_11 epoch: 1/1 iteration: 66/128 step: 34
[2025-12-23 16:12:58,239] m-LoRA: Adapter lora_winogrande_30 loss: 2.7142226696014404
[2025-12-23 16:12:58,244] m-LoRA: Adapter lora_winogrande_12 epoch: 1/1 iteration: 66/128 step: 34
[2025-12-23 16:12:58,421] m-LoRA: Adapter lora_winogrande_9 loss: 1.4143797159194946
[2025-12-23 16:12:58,424] m-LoRA: Adapter lora_winogrande_23 epoch: 1/1 iteration: 34/128 step: 18
[2025-12-23 16:12:58,638] m-LoRA: Adapter lora_winogrande_19 epoch: 1/1 iteration: 100/128 step: 26
[2025-12-23 16:12:58,680] m-LoRA: Adapter lora_winogrande_31 loss: 2.3511862754821777
[2025-12-23 16:12:58,874] m-LoRA: Adapter lora_winogrande_26 loss: 0.9847880601882935
[2025-12-23 16:12:58,877] m-LoRA: Adapter lora_winogrande_24 epoch: 1/1 iteration: 68/128 step: 18
[2025-12-23 16:12:59,351] m-LoRA: Adapter lora_winogrande_27 loss: 1.4597817659378052
[2025-12-23 16:12:59,355] m-LoRA: Adapter lora_winogrande_20 epoch: 1/1 iteration: 50/128 step: 26
[2025-12-23 16:12:59,603] m-LoRA: Adapter lora_winogrande_32 loss: 2.8986093997955322
[2025-12-23 16:12:59,605] m-LoRA: Adapter lora_winogrande_0 epoch: 1/1 iteration: 68/128 step: 35
[2025-12-23 16:12:59,782] m-LoRA: Adapter lora_winogrande_18 loss: 1.7133116722106934
[2025-12-23 16:12:59,784] m-LoRA: Adapter lora_winogrande_28 epoch: 1/1 iteration: 16/128 step: 3
[2025-12-23 16:12:59,917] m-LoRA: Adapter lora_winogrande_33 loss: 2.4139363765716553
[2025-12-23 16:12:59,920] m-LoRA: Adapter lora_winogrande_29 epoch: 1/1 iteration: 4/128 step: 3
[2025-12-23 16:13:00,071] m-LoRA: Adapter lora_winogrande_11 loss: 0.5220522284507751
[2025-12-23 16:13:00,073] m-LoRA: Adapter lora_winogrande_30 epoch: 1/1 iteration: 16/128 step: 3
[2025-12-23 16:13:00,216] m-LoRA: Adapter lora_winogrande_12 loss: 0.42637449502944946
[2025-12-23 16:13:00,219] m-LoRA: Adapter lora_winogrande_9 epoch: 1/1 iteration: 68/128 step: 35
[2025-12-23 16:13:00,401] m-LoRA: Adapter lora_winogrande_23 loss: 2.00873064994812
[2025-12-23 16:13:00,403] m-LoRA: Adapter lora_winogrande_31 epoch: 1/1 iteration: 16/128 step: 3
[2025-12-23 16:13:00,537] m-LoRA: Adapter lora_winogrande_19 loss: 0.530863881111145
[2025-12-23 16:13:00,539] m-LoRA: Adapter lora_winogrande_26 epoch: 1/1 iteration: 40/128 step: 11
[2025-12-23 16:13:00,669] m-LoRA: Adapter lora_winogrande_24 loss: 0.5974293947219849
[2025-12-23 16:13:00,671] m-LoRA: Adapter lora_winogrande_27 epoch: 1/1 iteration: 80/128 step: 11
[2025-12-23 16:13:00,866] m-LoRA: Adapter lora_winogrande_20 loss: 0.43715062737464905
[2025-12-23 16:13:00,868] m-LoRA: Adapter lora_winogrande_32 epoch: 1/1 iteration: 4/128 step: 3
[2025-12-23 16:13:00,990] m-LoRA: Adapter lora_winogrande_0 loss: 0.6638867259025574
[2025-12-23 16:13:00,993] m-LoRA: Adapter lora_winogrande_18 epoch: 1/1 iteration: 52/128 step: 27
[2025-12-23 16:13:01,096] m-LoRA: Adapter lora_winogrande_28 loss: 3.1097490787506104
[2025-12-23 16:13:01,100] m-LoRA: Adapter lora_winogrande_33 epoch: 1/1 iteration: 4/128 step: 3
[2025-12-23 16:13:01,188] m-LoRA: Adapter lora_winogrande_29 loss: 2.0931129455566406
[2025-12-23 16:13:01,451] m-LoRA: Adapter lora_winogrande_30 loss: 2.183302879333496
[2025-12-23 16:13:01,455] m-LoRA: Adapter lora_winogrande_11 epoch: 1/1 iteration: 68/128 step: 35
[2025-12-23 16:13:01,620] m-LoRA: Adapter lora_winogrande_9 loss: 1.330441951751709
[2025-12-23 16:13:01,623] m-LoRA: Adapter lora_winogrande_12 epoch: 1/1 iteration: 68/128 step: 35
[2025-12-23 16:13:01,859] m-LoRA: Adapter lora_winogrande_31 loss: 1.8930904865264893
[2025-12-23 16:13:01,864] m-LoRA: Adapter lora_winogrande_23 epoch: 1/1 iteration: 36/128 step: 19
[2025-12-23 16:13:02,026] m-LoRA: Adapter lora_winogrande_26 loss: 0.7100006937980652
[2025-12-23 16:13:02,029] m-LoRA: Adapter lora_winogrande_19 epoch: 1/1 iteration: 104/128 step: 27
[2025-12-23 16:13:02,338] m-LoRA: Adapter lora_winogrande_24 epoch: 1/1 iteration: 72/128 step: 19
[2025-12-23 16:13:02,465] m-LoRA: Adapter lora_winogrande_27 loss: 1.4358307123184204
[2025-12-23 16:13:02,499] m-LoRA: Adapter lora_winogrande_20 epoch: 1/1 iteration: 52/128 step: 27
[2025-12-23 16:13:02,653] m-LoRA: Adapter lora_winogrande_32 loss: 3.059666156768799
[2025-12-23 16:13:02,656] m-LoRA: Adapter lora_winogrande_0 epoch: 1/1 iteration: 70/128 step: 36
[2025-12-23 16:13:02,760] m-LoRA: Adapter lora_winogrande_18 loss: 1.7522941827774048
[2025-12-23 16:13:02,763] m-LoRA: Adapter lora_winogrande_28 epoch: 1/1 iteration: 24/128 step: 4
[2025-12-23 16:13:02,867] m-LoRA: Adapter lora_winogrande_33 loss: 2.106506586074829
[2025-12-23 16:13:02,870] m-LoRA: Adapter lora_winogrande_29 epoch: 1/1 iteration: 6/128 step: 4
[2025-12-23 16:13:02,979] m-LoRA: Adapter lora_winogrande_11 loss: 0.5624257326126099
[2025-12-23 16:13:02,982] m-LoRA: Adapter lora_winogrande_30 epoch: 1/1 iteration: 24/128 step: 4
[2025-12-23 16:13:03,131] m-LoRA: Adapter lora_winogrande_12 loss: 0.47376900911331177
[2025-12-23 16:13:03,134] m-LoRA: Adapter lora_winogrande_9 epoch: 1/1 iteration: 70/128 step: 36
[2025-12-23 16:13:03,251] m-LoRA: Adapter lora_winogrande_23 loss: 2.139070749282837
[2025-12-23 16:13:03,254] m-LoRA: Adapter lora_winogrande_31 epoch: 1/1 iteration: 24/128 step: 4
[2025-12-23 16:13:03,445] m-LoRA: Adapter lora_winogrande_19 loss: 0.5216314196586609
[2025-12-23 16:13:03,448] m-LoRA: Adapter lora_winogrande_26 epoch: 1/1 iteration: 44/128 step: 12
[2025-12-23 16:13:03,609] m-LoRA: Adapter lora_winogrande_24 loss: 0.6478608250617981
[2025-12-23 16:13:03,612] m-LoRA: Adapter lora_winogrande_27 epoch: 1/1 iteration: 88/128 step: 12
[2025-12-23 16:13:03,737] m-LoRA: Adapter lora_winogrande_20 loss: 0.5566975474357605
[2025-12-23 16:13:03,739] m-LoRA: Adapter lora_winogrande_32 epoch: 1/1 iteration: 6/128 step: 4
[2025-12-23 16:13:03,792] m-LoRA: Adapter lora_winogrande_0 loss: 0.4574984610080719
[2025-12-23 16:13:04,030] m-LoRA: Adapter lora_winogrande_28 loss: 3.019169807434082
[2025-12-23 16:13:04,035] m-LoRA: Adapter lora_winogrande_18 epoch: 1/1 iteration: 54/128 step: 28
[2025-12-23 16:13:04,201] m-LoRA: Adapter lora_winogrande_29 loss: 1.6726958751678467
[2025-12-23 16:13:04,204] m-LoRA: Adapter lora_winogrande_33 epoch: 1/1 iteration: 6/128 step: 4
[2025-12-23 16:13:04,597] m-LoRA: Adapter lora_winogrande_30 loss: 1.979112982749939
[2025-12-23 16:13:04,600] m-LoRA: Adapter lora_winogrande_11 epoch: 1/1 iteration: 70/128 step: 36
[2025-12-23 16:13:04,760] m-LoRA: Adapter lora_winogrande_9 loss: 1.3718571662902832
[2025-12-23 16:13:04,762] m-LoRA: Adapter lora_winogrande_12 epoch: 1/1 iteration: 70/128 step: 36
[2025-12-23 16:13:04,998] m-LoRA: Adapter lora_winogrande_23 epoch: 1/1 iteration: 38/128 step: 20
[2025-12-23 16:13:05,036] m-LoRA: Adapter lora_winogrande_31 loss: 1.64490807056427
[2025-12-23 16:13:05,197] m-LoRA: Adapter lora_winogrande_26 loss: 0.728714108467102
[2025-12-23 16:13:05,199] m-LoRA: Adapter lora_winogrande_19 epoch: 1/1 iteration: 108/128 step: 28
[2025-12-23 16:13:05,530] m-LoRA: Adapter lora_winogrande_27 loss: 1.3460596799850464
[2025-12-23 16:13:05,533] m-LoRA: Adapter lora_winogrande_24 epoch: 1/1 iteration: 76/128 step: 20
[2025-12-23 16:13:05,670] m-LoRA: Adapter lora_winogrande_32 loss: 2.6788077354431152
[2025-12-23 16:13:05,673] m-LoRA: Adapter lora_winogrande_20 epoch: 1/1 iteration: 54/128 step: 28
[2025-12-23 16:13:05,846] m-LoRA: Adapter lora_winogrande_18 loss: 1.7396314144134521
[2025-12-23 16:13:05,848] m-LoRA: Adapter lora_winogrande_0 epoch: 1/1 iteration: 72/128 step: 37
[2025-12-23 16:13:05,993] m-LoRA: Adapter lora_winogrande_33 loss: 2.101323366165161
[2025-12-23 16:13:05,995] m-LoRA: Adapter lora_winogrande_28 epoch: 1/1 iteration: 32/128 step: 5
[2025-12-23 16:13:06,123] m-LoRA: Adapter lora_winogrande_11 loss: 0.5007253289222717
[2025-12-23 16:13:06,126] m-LoRA: Adapter lora_winogrande_29 epoch: 1/1 iteration: 8/128 step: 5
[2025-12-23 16:13:06,290] m-LoRA: Adapter lora_winogrande_12 loss: 0.6542925238609314
[2025-12-23 16:13:06,293] m-LoRA: Adapter lora_winogrande_30 epoch: 1/1 iteration: 32/128 step: 5
[2025-12-23 16:13:06,447] m-LoRA: Adapter lora_winogrande_23 loss: 1.9489291906356812
[2025-12-23 16:13:06,450] m-LoRA: Adapter lora_winogrande_9 epoch: 1/1 iteration: 72/128 step: 37
[2025-12-23 16:13:06,604] m-LoRA: Adapter lora_winogrande_19 loss: 0.4609893560409546
[2025-12-23 16:13:06,606] m-LoRA: Adapter lora_winogrande_31 epoch: 1/1 iteration: 32/128 step: 5
[2025-12-23 16:13:06,779] m-LoRA: Adapter lora_winogrande_24 loss: 0.5722483396530151
[2025-12-23 16:13:06,783] m-LoRA: Adapter lora_winogrande_26 epoch: 1/1 iteration: 48/128 step: 13
[2025-12-23 16:13:06,908] m-LoRA: Adapter lora_winogrande_20 loss: 0.5450713634490967
[2025-12-23 16:13:06,910] m-LoRA: Adapter lora_winogrande_27 epoch: 1/1 iteration: 96/128 step: 13
[2025-12-23 16:13:07,042] m-LoRA: Adapter lora_winogrande_0 loss: 0.4826093018054962
[2025-12-23 16:13:07,045] m-LoRA: Adapter lora_winogrande_32 epoch: 1/1 iteration: 8/128 step: 5
[2025-12-23 16:13:07,151] m-LoRA: Adapter lora_winogrande_18 epoch: 1/1 iteration: 56/128 step: 29
[2025-12-23 16:13:07,336] m-LoRA: Adapter lora_winogrande_28 loss: 2.8968706130981445
[2025-12-23 16:13:07,344] m-LoRA: Adapter lora_winogrande_33 epoch: 1/1 iteration: 8/128 step: 5
[2025-12-23 16:13:07,488] m-LoRA: Adapter lora_winogrande_29 loss: 1.2207469940185547
[2025-12-23 16:13:07,491] m-LoRA: Adapter lora_winogrande_11 epoch: 1/1 iteration: 72/128 step: 37
[2025-12-23 16:13:07,771] m-LoRA: Adapter lora_winogrande_30 loss: 1.828791856765747
[2025-12-23 16:13:07,774] m-LoRA: Adapter lora_winogrande_12 epoch: 1/1 iteration: 72/128 step: 37
[2025-12-23 16:13:07,902] m-LoRA: Adapter lora_winogrande_9 loss: 1.3697937726974487
[2025-12-23 16:13:07,904] m-LoRA: Adapter lora_winogrande_23 epoch: 1/1 iteration: 40/128 step: 21
[2025-12-23 16:13:08,543] m-LoRA: Adapter lora_winogrande_31 loss: 1.336724042892456
[2025-12-23 16:13:08,547] m-LoRA: Adapter lora_winogrande_19 epoch: 1/1 iteration: 112/128 step: 29
[2025-12-23 16:13:08,713] m-LoRA: Adapter lora_winogrande_26 loss: 0.6538037657737732
[2025-12-23 16:13:08,716] m-LoRA: Adapter lora_winogrande_24 epoch: 1/1 iteration: 80/128 step: 21
[2025-12-23 16:13:08,928] m-LoRA: Adapter lora_winogrande_27 loss: 1.2585062980651855
[2025-12-23 16:13:08,940] m-LoRA: Adapter lora_winogrande_20 epoch: 1/1 iteration: 56/128 step: 29
[2025-12-23 16:13:09,119] m-LoRA: Adapter lora_winogrande_32 loss: 3.0422322750091553
[2025-12-23 16:13:09,121] m-LoRA: Adapter lora_winogrande_0 epoch: 1/1 iteration: 74/128 step: 38
[2025-12-23 16:13:09,247] m-LoRA: Adapter lora_winogrande_18 loss: 1.6382465362548828
[2025-12-23 16:13:09,249] m-LoRA: Adapter lora_winogrande_28 epoch: 1/1 iteration: 40/128 step: 6
[2025-12-23 16:13:09,399] m-LoRA: Adapter lora_winogrande_33 loss: 1.659303069114685
[2025-12-23 16:13:09,402] m-LoRA: Adapter lora_winogrande_29 epoch: 1/1 iteration: 10/128 step: 6
[2025-12-23 16:13:09,536] m-LoRA: Adapter lora_winogrande_11 loss: 0.4468579888343811
[2025-12-23 16:13:09,538] m-LoRA: Adapter lora_winogrande_30 epoch: 1/1 iteration: 40/128 step: 6
[2025-12-23 16:13:09,717] m-LoRA: Adapter lora_winogrande_12 loss: 0.43652406334877014
[2025-12-23 16:13:09,719] m-LoRA: Adapter lora_winogrande_9 epoch: 1/1 iteration: 74/128 step: 38
[2025-12-23 16:13:09,837] m-LoRA: Adapter lora_winogrande_23 loss: 2.0634350776672363
[2025-12-23 16:13:09,839] m-LoRA: Adapter lora_winogrande_31 epoch: 1/1 iteration: 40/128 step: 6
[2025-12-23 16:13:09,962] m-LoRA: Adapter lora_winogrande_19 loss: 0.5166645646095276
[2025-12-23 16:13:09,964] m-LoRA: Adapter lora_winogrande_26 epoch: 1/1 iteration: 52/128 step: 14
[2025-12-23 16:13:10,102] m-LoRA: Adapter lora_winogrande_24 loss: 0.58359295129776
[2025-12-23 16:13:10,105] m-LoRA: Adapter lora_winogrande_27 epoch: 1/1 iteration: 104/128 step: 14
[2025-12-23 16:13:10,178] m-LoRA: Adapter lora_winogrande_20 loss: 0.5901350975036621
[2025-12-23 16:13:10,183] m-LoRA: Adapter lora_winogrande_0 loss: 0.4519745111465454
[2025-12-23 16:13:10,623] m-LoRA: Adapter lora_winogrande_28 loss: 2.8484485149383545
[2025-12-23 16:13:10,628] m-LoRA: Adapter lora_winogrande_32 epoch: 1/1 iteration: 10/128 step: 6
[2025-12-23 16:13:10,755] m-LoRA: Adapter lora_winogrande_29 loss: 0.9603787064552307
[2025-12-23 16:13:10,757] m-LoRA: Adapter lora_winogrande_18 epoch: 1/1 iteration: 58/128 step: 30
[2025-12-23 16:13:11,196] m-LoRA: Adapter lora_winogrande_30 loss: 1.7828624248504639
[2025-12-23 16:13:11,199] m-LoRA: Adapter lora_winogrande_33 epoch: 1/1 iteration: 10/128 step: 6
[2025-12-23 16:13:11,355] m-LoRA: Adapter lora_winogrande_9 loss: 1.2944515943527222
[2025-12-23 16:13:11,357] m-LoRA: Adapter lora_winogrande_11 epoch: 1/1 iteration: 74/128 step: 38
[2025-12-23 16:13:11,623] m-LoRA: Adapter lora_winogrande_31 loss: 0.9997386932373047
[2025-12-23 16:13:11,627] m-LoRA: Adapter lora_winogrande_12 epoch: 1/1 iteration: 74/128 step: 38
[2025-12-23 16:13:11,773] m-LoRA: Adapter lora_winogrande_26 loss: 0.7071846127510071
[2025-12-23 16:13:11,776] m-LoRA: Adapter lora_winogrande_23 epoch: 1/1 iteration: 42/128 step: 22
[2025-12-23 16:13:12,155] m-LoRA: Adapter lora_winogrande_27 loss: 1.0878326892852783
[2025-12-23 16:13:12,160] m-LoRA: Adapter lora_winogrande_19 epoch: 1/1 iteration: 116/128 step: 30
[2025-12-23 16:13:12,328] m-LoRA: Adapter lora_winogrande_32 loss: 2.9875664710998535
[2025-12-23 16:13:12,331] m-LoRA: Adapter lora_winogrande_24 epoch: 1/1 iteration: 84/128 step: 22
[2025-12-23 16:13:12,455] m-LoRA: Adapter lora_winogrande_18 loss: 1.5803883075714111
[2025-12-23 16:13:12,457] m-LoRA: Adapter lora_winogrande_20 epoch: 1/1 iteration: 58/128 step: 30
[2025-12-23 16:13:12,595] m-LoRA: Adapter lora_winogrande_33 loss: 1.4864219427108765
[2025-12-23 16:13:12,597] m-LoRA: Adapter lora_winogrande_0 epoch: 1/1 iteration: 76/128 step: 39
[2025-12-23 16:13:12,724] m-LoRA: Adapter lora_winogrande_11 loss: 0.5336998105049133
[2025-12-23 16:13:12,726] m-LoRA: Adapter lora_winogrande_28 epoch: 1/1 iteration: 48/128 step: 7
[2025-12-23 16:13:12,865] m-LoRA: Adapter lora_winogrande_12 loss: 0.6208942532539368
[2025-12-23 16:13:12,877] m-LoRA: Adapter lora_winogrande_29 epoch: 1/1 iteration: 12/128 step: 7
[2025-12-23 16:13:13,000] m-LoRA: Adapter lora_winogrande_23 loss: 1.951166033744812
[2025-12-23 16:13:13,002] m-LoRA: Adapter lora_winogrande_30 epoch: 1/1 iteration: 48/128 step: 7
[2025-12-23 16:13:13,125] m-LoRA: Adapter lora_winogrande_19 loss: 0.5508173704147339
[2025-12-23 16:13:13,128] m-LoRA: Adapter lora_winogrande_9 epoch: 1/1 iteration: 76/128 step: 39
[2025-12-23 16:13:13,277] m-LoRA: Adapter lora_winogrande_24 loss: 0.5709472298622131
[2025-12-23 16:13:13,279] m-LoRA: Adapter lora_winogrande_31 epoch: 1/1 iteration: 48/128 step: 7
[2025-12-23 16:13:13,445] m-LoRA: Adapter lora_winogrande_20 loss: 0.6260958313941956
[2025-12-23 16:13:13,447] m-LoRA: Adapter lora_winogrande_26 epoch: 1/1 iteration: 56/128 step: 15
[2025-12-23 16:13:13,588] m-LoRA: Adapter lora_winogrande_0 loss: 0.4509487748146057
[2025-12-23 16:13:13,590] m-LoRA: Adapter lora_winogrande_27 epoch: 1/1 iteration: 112/128 step: 15
[2025-12-23 16:13:13,703] m-LoRA: Adapter lora_winogrande_32 epoch: 1/1 iteration: 12/128 step: 7
[2025-12-23 16:13:13,783] m-LoRA: Adapter lora_winogrande_18 epoch: 1/1 iteration: 60/128 step: 31
[2025-12-23 16:13:13,982] m-LoRA: Adapter lora_winogrande_28 loss: 2.6588380336761475
[2025-12-23 16:13:13,986] m-LoRA: Adapter lora_winogrande_33 epoch: 1/1 iteration: 12/128 step: 7
[2025-12-23 16:13:14,150] m-LoRA: Adapter lora_winogrande_29 loss: 0.7845768928527832
[2025-12-23 16:13:14,156] m-LoRA: Adapter lora_winogrande_11 epoch: 1/1 iteration: 76/128 step: 39
[2025-12-23 16:13:14,469] m-LoRA: Adapter lora_winogrande_30 loss: 1.445054292678833
[2025-12-23 16:13:14,473] m-LoRA: Adapter lora_winogrande_12 epoch: 1/1 iteration: 76/128 step: 39
[2025-12-23 16:13:14,661] m-LoRA: Adapter lora_winogrande_9 loss: 1.1676281690597534
[2025-12-23 16:13:14,663] m-LoRA: Adapter lora_winogrande_23 epoch: 1/1 iteration: 44/128 step: 23
[2025-12-23 16:13:14,926] m-LoRA: Adapter lora_winogrande_31 loss: 0.8730817437171936
[2025-12-23 16:13:14,930] m-LoRA: Adapter lora_winogrande_19 epoch: 1/1 iteration: 120/128 step: 31
[2025-12-23 16:13:15,134] m-LoRA: Adapter lora_winogrande_26 loss: 0.7281092405319214
[2025-12-23 16:13:15,137] m-LoRA: Adapter lora_winogrande_24 epoch: 1/1 iteration: 88/128 step: 23
[2025-12-23 16:13:15,582] m-LoRA: Adapter lora_winogrande_27 loss: 0.9717900156974792
[2025-12-23 16:13:15,587] m-LoRA: Adapter lora_winogrande_20 epoch: 1/1 iteration: 60/128 step: 31
[2025-12-23 16:13:15,751] m-LoRA: Adapter lora_winogrande_32 loss: 2.545182943344116
[2025-12-23 16:13:15,757] m-LoRA: Adapter lora_winogrande_0 epoch: 1/1 iteration: 78/128 step: 40
[2025-12-23 16:13:15,888] m-LoRA: Adapter lora_winogrande_18 loss: 1.495411992073059
[2025-12-23 16:13:15,890] m-LoRA: Adapter lora_winogrande_28 epoch: 1/1 iteration: 56/128 step: 8
[2025-12-23 16:13:16,095] m-LoRA: Adapter lora_winogrande_33 loss: 1.1344362497329712
[2025-12-23 16:13:16,097] m-LoRA: Adapter lora_winogrande_29 epoch: 1/1 iteration: 14/128 step: 8
[2025-12-23 16:13:16,226] m-LoRA: Adapter lora_winogrande_11 loss: 0.5209059119224548
[2025-12-23 16:13:16,229] m-LoRA: Adapter lora_winogrande_30 epoch: 1/1 iteration: 56/128 step: 8
[2025-12-23 16:13:16,401] m-LoRA: Adapter lora_winogrande_12 loss: 0.48147282004356384
[2025-12-23 16:13:16,404] m-LoRA: Adapter lora_winogrande_9 epoch: 1/1 iteration: 78/128 step: 40
[2025-12-23 16:13:16,568] m-LoRA: Adapter lora_winogrande_23 loss: 1.9381500482559204
[2025-12-23 16:13:16,570] m-LoRA: Adapter lora_winogrande_31 epoch: 1/1 iteration: 56/128 step: 8
[2025-12-23 16:13:16,718] m-LoRA: Adapter lora_winogrande_19 loss: 0.5130541920661926
[2025-12-23 16:13:16,720] m-LoRA: Adapter lora_winogrande_26 epoch: 1/1 iteration: 60/128 step: 16
[2025-12-23 16:13:16,855] m-LoRA: Adapter lora_winogrande_24 loss: 0.5883084535598755
[2025-12-23 16:13:16,858] m-LoRA: Adapter lora_winogrande_27 epoch: 1/1 iteration: 120/128 step: 16
[2025-12-23 16:13:16,994] m-LoRA: Adapter lora_winogrande_20 loss: 0.4779578447341919
[2025-12-23 16:13:16,996] m-LoRA: Adapter lora_winogrande_32 epoch: 1/1 iteration: 14/128 step: 8
[2025-12-23 16:13:17,129] m-LoRA: Adapter lora_winogrande_0 loss: 0.3981582224369049
[2025-12-23 16:13:17,131] m-LoRA: Adapter lora_winogrande_18 epoch: 1/1 iteration: 62/128 step: 32
[2025-12-23 16:13:17,272] m-LoRA: Adapter lora_winogrande_28 loss: 2.514860153198242
[2025-12-23 16:13:17,277] m-LoRA: Adapter lora_winogrande_33 epoch: 1/1 iteration: 14/128 step: 8
[2025-12-23 16:13:17,401] m-LoRA: Adapter lora_winogrande_29 loss: 0.7467790842056274
[2025-12-23 16:13:17,403] m-LoRA: Adapter lora_winogrande_11 epoch: 1/1 iteration: 78/128 step: 40
[2025-12-23 16:13:17,602] m-LoRA: Adapter lora_winogrande_12 epoch: 1/1 iteration: 78/128 step: 40
[2025-12-23 16:13:17,636] m-LoRA: Adapter lora_winogrande_30 loss: 1.1815640926361084
[2025-12-23 16:13:17,765] m-LoRA: Adapter lora_winogrande_9 loss: 1.0297962427139282
[2025-12-23 16:13:17,767] m-LoRA: Adapter lora_winogrande_23 epoch: 1/1 iteration: 46/128 step: 24
[2025-12-23 16:13:18,083] m-LoRA: Adapter lora_winogrande_31 loss: 0.7381009459495544
[2025-12-23 16:13:18,088] m-LoRA: Adapter lora_winogrande_19 epoch: 1/1 iteration: 124/128 step: 32
[2025-12-23 16:13:18,251] m-LoRA: Adapter lora_winogrande_26 loss: 0.6189804077148438
[2025-12-23 16:13:18,255] m-LoRA: Adapter lora_winogrande_24 epoch: 1/1 iteration: 92/128 step: 24
[2025-12-23 16:13:18,631] m-LoRA: Adapter lora_winogrande_27 loss: 0.8875174522399902
[2025-12-23 16:13:18,635] m-LoRA: Adapter lora_winogrande_20 epoch: 1/1 iteration: 62/128 step: 32
[2025-12-23 16:13:18,793] m-LoRA: Adapter lora_winogrande_32 loss: 2.515526294708252
[2025-12-23 16:13:18,795] m-LoRA: Adapter lora_winogrande_0 epoch: 1/1 iteration: 80/128 step: 41
[2025-12-23 16:13:18,908] m-LoRA: Adapter lora_winogrande_18 loss: 1.4500714540481567
[2025-12-23 16:13:19,084] m-LoRA: Adapter lora_winogrande_28 epoch: 1/1 iteration: 64/128 step: 9
[2025-12-23 16:13:19,427] m-LoRA: Adapter lora_winogrande_33 loss: 0.9063705801963806
[2025-12-23 16:13:19,429] m-LoRA: Adapter lora_winogrande_29 epoch: 1/1 iteration: 16/128 step: 9
[2025-12-23 16:13:19,563] m-LoRA: Adapter lora_winogrande_11 loss: 0.6119361519813538
[2025-12-23 16:13:19,565] m-LoRA: Adapter lora_winogrande_30 epoch: 1/1 iteration: 64/128 step: 9
[2025-12-23 16:13:19,696] m-LoRA: Adapter lora_winogrande_12 loss: 0.4950747787952423
[2025-12-23 16:13:19,699] m-LoRA: Adapter lora_winogrande_9 epoch: 1/1 iteration: 80/128 step: 41
[2025-12-23 16:13:19,860] m-LoRA: Adapter lora_winogrande_23 loss: 1.8121975660324097
[2025-12-23 16:13:19,863] m-LoRA: Adapter lora_winogrande_31 epoch: 1/1 iteration: 64/128 step: 9
[2025-12-23 16:13:19,984] m-LoRA: Adapter lora_winogrande_19 loss: 0.4495161473751068
[2025-12-23 16:13:19,988] m-LoRA: Adapter lora_winogrande_26 epoch: 1/1 iteration: 64/128 step: 17
[2025-12-23 16:13:20,114] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_27']
[2025-12-23 16:13:20,401] m-LoRA: Adapter lora_winogrande_24 loss: 0.553241491317749
[2025-12-23 16:13:20,403] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_34']
[2025-12-23 16:13:20,504] m-LoRA: Adapter lora_winogrande_34 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:13:20,650] m-LoRA: Adapter lora_winogrande_20 loss: 0.4802955985069275
[2025-12-23 16:13:20,656] m-LoRA: Adapter lora_winogrande_32 epoch: 1/1 iteration: 16/128 step: 9
[2025-12-23 16:13:20,774] m-LoRA: Adapter lora_winogrande_0 loss: 0.4622734785079956
[2025-12-23 16:13:20,777] m-LoRA: Adapter lora_winogrande_18 epoch: 1/1 iteration: 64/128 step: 33
[2025-12-23 16:13:20,896] m-LoRA: Adapter lora_winogrande_28 loss: 2.4208250045776367
[2025-12-23 16:13:20,901] m-LoRA: Adapter lora_winogrande_33 epoch: 1/1 iteration: 16/128 step: 9
[2025-12-23 16:13:21,097] m-LoRA: Adapter lora_winogrande_29 loss: 0.6420512199401855
[2025-12-23 16:13:21,100] m-LoRA: Adapter lora_winogrande_11 epoch: 1/1 iteration: 80/128 step: 41
[2025-12-23 16:13:21,255] m-LoRA: Adapter lora_winogrande_30 loss: 1.0099619626998901
[2025-12-23 16:13:21,259] m-LoRA: Adapter lora_winogrande_12 epoch: 1/1 iteration: 80/128 step: 41
[2025-12-23 16:13:21,429] m-LoRA: Adapter lora_winogrande_9 loss: 1.1026991605758667
[2025-12-23 16:13:21,431] m-LoRA: Adapter lora_winogrande_23 epoch: 1/1 iteration: 48/128 step: 25
[2025-12-23 16:13:21,576] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_19']
[2025-12-23 16:13:22,268] m-LoRA: Adapter lora_winogrande_31 loss: 0.6720065474510193
[2025-12-23 16:13:22,272] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_35']
[2025-12-23 16:13:22,394] m-LoRA: Adapter lora_winogrande_35 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:13:22,520] m-LoRA: Adapter lora_winogrande_26 loss: 0.6034764647483826
[2025-12-23 16:13:22,523] m-LoRA: Adapter lora_winogrande_24 epoch: 1/1 iteration: 96/128 step: 25
[2025-12-23 16:13:22,664] m-LoRA: Adapter lora_winogrande_34 loss: 2.8148581981658936
[2025-12-23 16:13:22,667] m-LoRA: Adapter lora_winogrande_20 epoch: 1/1 iteration: 64/128 step: 33
[2025-12-23 16:13:22,840] m-LoRA: Adapter lora_winogrande_32 loss: 2.5834219455718994
[2025-12-23 16:13:22,842] m-LoRA: Adapter lora_winogrande_0 epoch: 1/1 iteration: 82/128 step: 42
[2025-12-23 16:13:22,966] m-LoRA: Adapter lora_winogrande_18 loss: 1.5089200735092163
[2025-12-23 16:13:22,969] m-LoRA: Adapter lora_winogrande_28 epoch: 1/1 iteration: 72/128 step: 10
[2025-12-23 16:13:23,063] m-LoRA: Adapter lora_winogrande_33 loss: 0.826124370098114
[2025-12-23 16:13:23,065] m-LoRA: Adapter lora_winogrande_29 epoch: 1/1 iteration: 18/128 step: 10
[2025-12-23 16:13:23,161] m-LoRA: Adapter lora_winogrande_11 loss: 0.5128663182258606
[2025-12-23 16:13:23,164] m-LoRA: Adapter lora_winogrande_30 epoch: 1/1 iteration: 72/128 step: 10
[2025-12-23 16:13:23,266] m-LoRA: Adapter lora_winogrande_12 loss: 0.4776126444339752
[2025-12-23 16:13:23,268] m-LoRA: Adapter lora_winogrande_9 epoch: 1/1 iteration: 82/128 step: 42
[2025-12-23 16:13:23,381] m-LoRA: Adapter lora_winogrande_23 loss: 1.7168164253234863
[2025-12-23 16:13:23,384] m-LoRA: Adapter lora_winogrande_31 epoch: 1/1 iteration: 72/128 step: 10
[2025-12-23 16:13:23,883] m-LoRA: Adapter lora_winogrande_26 epoch: 1/1 iteration: 68/128 step: 18
[2025-12-23 16:13:24,003] m-LoRA: Adapter lora_winogrande_35 loss: 3.3448944091796875
[2025-12-23 16:13:24,009] m-LoRA: Adapter lora_winogrande_34 epoch: 1/1 iteration: 2/128 step: 2
[2025-12-23 16:13:24,033] m-LoRA: Adapter lora_winogrande_24 loss: 0.5271477103233337
[2025-12-23 16:13:24,208] m-LoRA: Adapter lora_winogrande_20 loss: 0.6267613768577576
[2025-12-23 16:13:24,211] m-LoRA: Adapter lora_winogrande_32 epoch: 1/1 iteration: 18/128 step: 10
[2025-12-23 16:13:24,298] m-LoRA: Adapter lora_winogrande_0 loss: 0.6013582944869995
[2025-12-23 16:13:24,300] m-LoRA: Adapter lora_winogrande_18 epoch: 1/1 iteration: 66/128 step: 34
[2025-12-23 16:13:24,580] m-LoRA: Adapter lora_winogrande_28 loss: 2.3568546772003174
[2025-12-23 16:13:24,585] m-LoRA: Adapter lora_winogrande_33 epoch: 1/1 iteration: 18/128 step: 10
[2025-12-23 16:13:24,775] m-LoRA: Adapter lora_winogrande_29 loss: 0.7558944225311279
[2025-12-23 16:13:24,823] m-LoRA: Adapter lora_winogrande_11 epoch: 1/1 iteration: 82/128 step: 42
[2025-12-23 16:13:25,110] m-LoRA: Adapter lora_winogrande_30 loss: 0.9344543218612671
[2025-12-23 16:13:25,113] m-LoRA: Adapter lora_winogrande_12 epoch: 1/1 iteration: 82/128 step: 42
[2025-12-23 16:13:25,253] m-LoRA: Adapter lora_winogrande_9 loss: 1.0259513854980469
[2025-12-23 16:13:25,256] m-LoRA: Adapter lora_winogrande_23 epoch: 1/1 iteration: 50/128 step: 26
[2025-12-23 16:13:25,499] m-LoRA: Adapter lora_winogrande_31 loss: 0.663849949836731
[2025-12-23 16:13:25,503] m-LoRA: Adapter lora_winogrande_35 epoch: 1/1 iteration: 16/128 step: 2
[2025-12-23 16:13:25,683] m-LoRA: Adapter lora_winogrande_26 loss: 0.6054477691650391
[2025-12-23 16:13:25,685] m-LoRA: Adapter lora_winogrande_24 epoch: 1/1 iteration: 100/128 step: 26
[2025-12-23 16:13:25,779] m-LoRA: Adapter lora_winogrande_34 loss: 2.4567646980285645
[2025-12-23 16:13:25,781] m-LoRA: Adapter lora_winogrande_20 epoch: 1/1 iteration: 66/128 step: 34
[2025-12-23 16:13:25,878] m-LoRA: Adapter lora_winogrande_32 loss: 2.575129270553589
[2025-12-23 16:13:25,883] m-LoRA: Adapter lora_winogrande_0 epoch: 1/1 iteration: 84/128 step: 43
[2025-12-23 16:13:25,984] m-LoRA: Adapter lora_winogrande_18 loss: 1.386106252670288
[2025-12-23 16:13:25,985] m-LoRA: Adapter lora_winogrande_28 epoch: 1/1 iteration: 80/128 step: 11
[2025-12-23 16:13:26,117] m-LoRA: Adapter lora_winogrande_33 loss: 0.6064514517784119
[2025-12-23 16:13:26,119] m-LoRA: Adapter lora_winogrande_29 epoch: 1/1 iteration: 20/128 step: 11
[2025-12-23 16:13:26,166] m-LoRA: Adapter lora_winogrande_11 loss: 0.5252136588096619
[2025-12-23 16:13:26,308] m-LoRA: Adapter lora_winogrande_12 loss: 0.37762513756752014
[2025-12-23 16:13:26,310] m-LoRA: Adapter lora_winogrande_30 epoch: 1/1 iteration: 80/128 step: 11
[2025-12-23 16:13:26,379] m-LoRA: Adapter lora_winogrande_23 loss: 1.7347527742385864
[2025-12-23 16:13:27,064] m-LoRA: Adapter lora_winogrande_35 loss: 3.179779529571533
[2025-12-23 16:13:27,070] m-LoRA: Adapter lora_winogrande_9 epoch: 1/1 iteration: 84/128 step: 43
[2025-12-23 16:13:27,289] m-LoRA: Adapter lora_winogrande_24 loss: 0.5006816387176514
[2025-12-23 16:13:27,292] m-LoRA: Adapter lora_winogrande_31 epoch: 1/1 iteration: 80/128 step: 11
[2025-12-23 16:13:27,410] m-LoRA: Adapter lora_winogrande_20 loss: 0.5140597224235535
[2025-12-23 16:13:27,412] m-LoRA: Adapter lora_winogrande_26 epoch: 1/1 iteration: 72/128 step: 19
[2025-12-23 16:13:27,524] m-LoRA: Adapter lora_winogrande_0 loss: 0.4073696732521057
[2025-12-23 16:13:27,527] m-LoRA: Adapter lora_winogrande_34 epoch: 1/1 iteration: 4/128 step: 3
[2025-12-23 16:13:27,750] m-LoRA: Adapter lora_winogrande_28 loss: 2.1370720863342285
[2025-12-23 16:13:27,754] m-LoRA: Adapter lora_winogrande_32 epoch: 1/1 iteration: 20/128 step: 11
[2025-12-23 16:13:27,908] m-LoRA: Adapter lora_winogrande_29 loss: 0.6792411208152771
[2025-12-23 16:13:27,911] m-LoRA: Adapter lora_winogrande_18 epoch: 1/1 iteration: 68/128 step: 35
[2025-12-23 16:13:28,302] m-LoRA: Adapter lora_winogrande_30 loss: 0.7590069770812988
[2025-12-23 16:13:28,305] m-LoRA: Adapter lora_winogrande_33 epoch: 1/1 iteration: 20/128 step: 11
[2025-12-23 16:13:28,449] m-LoRA: Adapter lora_winogrande_9 loss: 0.9824830293655396
[2025-12-23 16:13:28,451] m-LoRA: Adapter lora_winogrande_11 epoch: 1/1 iteration: 84/128 step: 43
[2025-12-23 16:13:28,834] m-LoRA: Adapter lora_winogrande_31 loss: 0.6158180832862854
[2025-12-23 16:13:28,837] m-LoRA: Adapter lora_winogrande_12 epoch: 1/1 iteration: 84/128 step: 43
[2025-12-23 16:13:28,993] m-LoRA: Adapter lora_winogrande_26 loss: 0.7083459496498108
[2025-12-23 16:13:28,996] m-LoRA: Adapter lora_winogrande_23 epoch: 1/1 iteration: 52/128 step: 27
[2025-12-23 16:13:29,138] m-LoRA: Adapter lora_winogrande_34 loss: 2.218327283859253
[2025-12-23 16:13:29,140] m-LoRA: Adapter lora_winogrande_35 epoch: 1/1 iteration: 32/128 step: 3
[2025-12-23 16:13:29,266] m-LoRA: Adapter lora_winogrande_32 loss: 2.4540281295776367
[2025-12-23 16:13:29,269] m-LoRA: Adapter lora_winogrande_24 epoch: 1/1 iteration: 104/128 step: 27
[2025-12-23 16:13:29,371] m-LoRA: Adapter lora_winogrande_20 epoch: 1/1 iteration: 68/128 step: 35
[2025-12-23 16:13:29,444] m-LoRA: Adapter lora_winogrande_0 epoch: 1/1 iteration: 86/128 step: 44
[2025-12-23 16:13:29,888] m-LoRA: Adapter lora_winogrande_18 loss: 1.1521309614181519
[2025-12-23 16:13:30,318] m-LoRA: Adapter lora_winogrande_33 loss: 0.7436910271644592
[2025-12-23 16:13:30,320] m-LoRA: Adapter lora_winogrande_28 epoch: 1/1 iteration: 88/128 step: 12
[2025-12-23 16:13:30,571] m-LoRA: Adapter lora_winogrande_11 loss: 0.452083557844162
[2025-12-23 16:13:30,573] m-LoRA: Adapter lora_winogrande_29 epoch: 1/1 iteration: 22/128 step: 12
[2025-12-23 16:13:30,714] m-LoRA: Adapter lora_winogrande_12 loss: 0.4941408336162567
[2025-12-23 16:13:30,716] m-LoRA: Adapter lora_winogrande_30 epoch: 1/1 iteration: 88/128 step: 12
[2025-12-23 16:13:30,833] m-LoRA: Adapter lora_winogrande_23 loss: 1.8254953622817993
[2025-12-23 16:13:30,836] m-LoRA: Adapter lora_winogrande_9 epoch: 1/1 iteration: 86/128 step: 44
[2025-12-23 16:13:30,942] m-LoRA: Adapter lora_winogrande_31 epoch: 1/1 iteration: 88/128 step: 12
[2025-12-23 16:13:31,023] m-LoRA: Adapter lora_winogrande_26 epoch: 1/1 iteration: 76/128 step: 20
[2025-12-23 16:13:31,461] m-LoRA: Adapter lora_winogrande_34 epoch: 1/1 iteration: 6/128 step: 4
[2025-12-23 16:13:31,503] m-LoRA: Adapter lora_winogrande_35 loss: 3.0489754676818848
[2025-12-23 16:13:31,680] m-LoRA: Adapter lora_winogrande_24 loss: 0.5210267901420593
[2025-12-23 16:13:31,682] m-LoRA: Adapter lora_winogrande_32 epoch: 1/1 iteration: 22/128 step: 12
[2025-12-23 16:13:31,806] m-LoRA: Adapter lora_winogrande_20 loss: 0.570074200630188
[2025-12-23 16:13:31,808] m-LoRA: Adapter lora_winogrande_18 epoch: 1/1 iteration: 70/128 step: 36
[2025-12-23 16:13:31,903] m-LoRA: Adapter lora_winogrande_0 loss: 0.36568981409072876
[2025-12-23 16:13:31,905] m-LoRA: Adapter lora_winogrande_33 epoch: 1/1 iteration: 22/128 step: 12
[2025-12-23 16:13:32,136] m-LoRA: Adapter lora_winogrande_28 loss: 2.1795718669891357
[2025-12-23 16:13:32,140] m-LoRA: Adapter lora_winogrande_11 epoch: 1/1 iteration: 86/128 step: 44
[2025-12-23 16:13:32,238] m-LoRA: Adapter lora_winogrande_29 loss: 0.6346455216407776
[2025-12-23 16:13:32,240] m-LoRA: Adapter lora_winogrande_12 epoch: 1/1 iteration: 86/128 step: 44
[2025-12-23 16:13:32,622] m-LoRA: Adapter lora_winogrande_30 loss: 0.7216352224349976
[2025-12-23 16:13:32,626] m-LoRA: Adapter lora_winogrande_23 epoch: 1/1 iteration: 54/128 step: 28
[2025-12-23 16:13:32,669] m-LoRA: Adapter lora_winogrande_9 loss: 1.0256555080413818
[2025-12-23 16:13:33,078] m-LoRA: Adapter lora_winogrande_31 loss: 0.5388367772102356
[2025-12-23 16:13:33,082] m-LoRA: Adapter lora_winogrande_35 epoch: 1/1 iteration: 48/128 step: 4
[2025-12-23 16:13:33,308] m-LoRA: Adapter lora_winogrande_26 loss: 0.608144223690033
[2025-12-23 16:13:33,311] m-LoRA: Adapter lora_winogrande_24 epoch: 1/1 iteration: 108/128 step: 28
[2025-12-23 16:13:33,464] m-LoRA: Adapter lora_winogrande_34 loss: 1.8435124158859253
[2025-12-23 16:13:33,467] m-LoRA: Adapter lora_winogrande_20 epoch: 1/1 iteration: 70/128 step: 36
[2025-12-23 16:13:33,611] m-LoRA: Adapter lora_winogrande_32 loss: 2.366187334060669
[2025-12-23 16:13:33,623] m-LoRA: Adapter lora_winogrande_0 epoch: 1/1 iteration: 88/128 step: 45
[2025-12-23 16:13:33,726] m-LoRA: Adapter lora_winogrande_18 loss: 1.3156176805496216
[2025-12-23 16:13:33,728] m-LoRA: Adapter lora_winogrande_28 epoch: 1/1 iteration: 96/128 step: 13
[2025-12-23 16:13:33,839] m-LoRA: Adapter lora_winogrande_33 loss: 0.6344612240791321
[2025-12-23 16:13:33,841] m-LoRA: Adapter lora_winogrande_29 epoch: 1/1 iteration: 24/128 step: 13
[2025-12-23 16:13:33,948] m-LoRA: Adapter lora_winogrande_11 loss: 0.5703127384185791
[2025-12-23 16:13:33,951] m-LoRA: Adapter lora_winogrande_30 epoch: 1/1 iteration: 96/128 step: 13
[2025-12-23 16:13:34,028] m-LoRA: Adapter lora_winogrande_12 loss: 0.5299953818321228
[2025-12-23 16:13:34,032] m-LoRA: Adapter lora_winogrande_23 loss: 1.4608967304229736
[2025-12-23 16:13:34,649] m-LoRA: Adapter lora_winogrande_9 epoch: 1/1 iteration: 88/128 step: 45
[2025-12-23 16:13:34,711] m-LoRA: Adapter lora_winogrande_35 loss: 2.978085994720459
[2025-12-23 16:13:34,844] m-LoRA: Adapter lora_winogrande_24 loss: 0.46558380126953125
[2025-12-23 16:13:34,864] m-LoRA: Adapter lora_winogrande_31 epoch: 1/1 iteration: 96/128 step: 13
[2025-12-23 16:13:35,019] m-LoRA: Adapter lora_winogrande_20 loss: 0.5240678787231445
[2025-12-23 16:13:35,021] m-LoRA: Adapter lora_winogrande_26 epoch: 1/1 iteration: 80/128 step: 21
[2025-12-23 16:13:35,149] m-LoRA: Adapter lora_winogrande_0 loss: 0.4915078580379486
[2025-12-23 16:13:35,151] m-LoRA: Adapter lora_winogrande_34 epoch: 1/1 iteration: 8/128 step: 5
[2025-12-23 16:13:35,343] m-LoRA: Adapter lora_winogrande_28 loss: 2.283376932144165
[2025-12-23 16:13:35,347] m-LoRA: Adapter lora_winogrande_32 epoch: 1/1 iteration: 24/128 step: 13
[2025-12-23 16:13:35,466] m-LoRA: Adapter lora_winogrande_29 loss: 0.5519440770149231
[2025-12-23 16:13:35,468] m-LoRA: Adapter lora_winogrande_18 epoch: 1/1 iteration: 72/128 step: 37
[2025-12-23 16:13:35,833] m-LoRA: Adapter lora_winogrande_30 loss: 0.6652361750602722
[2025-12-23 16:13:35,847] m-LoRA: Adapter lora_winogrande_33 epoch: 1/1 iteration: 24/128 step: 13
[2025-12-23 16:13:35,986] m-LoRA: Adapter lora_winogrande_9 loss: 0.8968369364738464
[2025-12-23 16:13:35,988] m-LoRA: Adapter lora_winogrande_11 epoch: 1/1 iteration: 88/128 step: 45
[2025-12-23 16:13:36,412] m-LoRA: Adapter lora_winogrande_31 loss: 0.5816271305084229
[2025-12-23 16:13:36,416] m-LoRA: Adapter lora_winogrande_12 epoch: 1/1 iteration: 88/128 step: 45
[2025-12-23 16:13:36,605] m-LoRA: Adapter lora_winogrande_26 loss: 0.5759490132331848
[2025-12-23 16:13:36,607] m-LoRA: Adapter lora_winogrande_23 epoch: 1/1 iteration: 56/128 step: 29
[2025-12-23 16:13:36,729] m-LoRA: Adapter lora_winogrande_34 loss: 1.5883839130401611
[2025-12-23 16:13:36,731] m-LoRA: Adapter lora_winogrande_35 epoch: 1/1 iteration: 64/128 step: 5
[2025-12-23 16:13:36,909] m-LoRA: Adapter lora_winogrande_32 loss: 2.408982753753662
[2025-12-23 16:13:36,911] m-LoRA: Adapter lora_winogrande_24 epoch: 1/1 iteration: 112/128 step: 29
[2025-12-23 16:13:37,051] m-LoRA: Adapter lora_winogrande_18 loss: 1.3079884052276611
[2025-12-23 16:13:37,054] m-LoRA: Adapter lora_winogrande_20 epoch: 1/1 iteration: 72/128 step: 37
[2025-12-23 16:13:37,178] m-LoRA: Adapter lora_winogrande_33 loss: 0.6773396134376526
[2025-12-23 16:13:37,181] m-LoRA: Adapter lora_winogrande_0 epoch: 1/1 iteration: 90/128 step: 46
[2025-12-23 16:13:37,289] m-LoRA: Adapter lora_winogrande_11 loss: 0.45476675033569336
[2025-12-23 16:13:37,291] m-LoRA: Adapter lora_winogrande_28 epoch: 1/1 iteration: 104/128 step: 14
[2025-12-23 16:13:37,413] m-LoRA: Adapter lora_winogrande_12 loss: 0.5872346758842468
[2025-12-23 16:13:37,415] m-LoRA: Adapter lora_winogrande_29 epoch: 1/1 iteration: 26/128 step: 14
[2025-12-23 16:13:37,533] m-LoRA: Adapter lora_winogrande_23 loss: 1.5020904541015625
[2025-12-23 16:13:37,535] m-LoRA: Adapter lora_winogrande_30 epoch: 1/1 iteration: 104/128 step: 14
[2025-12-23 16:13:37,620] m-LoRA: Adapter lora_winogrande_9 epoch: 1/1 iteration: 90/128 step: 46
[2025-12-23 16:13:37,697] m-LoRA: Adapter lora_winogrande_31 epoch: 1/1 iteration: 104/128 step: 14
[2025-12-23 16:13:38,380] m-LoRA: Adapter lora_winogrande_26 epoch: 1/1 iteration: 84/128 step: 22
[2025-12-23 16:13:38,427] m-LoRA: Adapter lora_winogrande_35 loss: 2.912529945373535
[2025-12-23 16:13:38,601] m-LoRA: Adapter lora_winogrande_24 loss: 0.582010805606842
[2025-12-23 16:13:38,605] m-LoRA: Adapter lora_winogrande_34 epoch: 1/1 iteration: 10/128 step: 6
[2025-12-23 16:13:38,699] m-LoRA: Adapter lora_winogrande_20 loss: 0.5269253253936768
[2025-12-23 16:13:38,701] m-LoRA: Adapter lora_winogrande_32 epoch: 1/1 iteration: 26/128 step: 14
[2025-12-23 16:13:38,805] m-LoRA: Adapter lora_winogrande_0 loss: 0.44366464018821716
[2025-12-23 16:13:38,808] m-LoRA: Adapter lora_winogrande_18 epoch: 1/1 iteration: 74/128 step: 38
[2025-12-23 16:13:39,122] m-LoRA: Adapter lora_winogrande_28 loss: 2.181265115737915
[2025-12-23 16:13:39,126] m-LoRA: Adapter lora_winogrande_33 epoch: 1/1 iteration: 26/128 step: 14
[2025-12-23 16:13:39,271] m-LoRA: Adapter lora_winogrande_29 loss: 0.5778886079788208
[2025-12-23 16:13:39,273] m-LoRA: Adapter lora_winogrande_11 epoch: 1/1 iteration: 90/128 step: 46
[2025-12-23 16:13:39,646] m-LoRA: Adapter lora_winogrande_30 loss: 0.6454674601554871
[2025-12-23 16:13:39,649] m-LoRA: Adapter lora_winogrande_12 epoch: 1/1 iteration: 90/128 step: 46
[2025-12-23 16:13:39,813] m-LoRA: Adapter lora_winogrande_9 loss: 0.7706726789474487
[2025-12-23 16:13:39,816] m-LoRA: Adapter lora_winogrande_23 epoch: 1/1 iteration: 58/128 step: 30
[2025-12-23 16:13:40,092] m-LoRA: Adapter lora_winogrande_31 loss: 0.5907813310623169
[2025-12-23 16:13:40,095] m-LoRA: Adapter lora_winogrande_35 epoch: 1/1 iteration: 80/128 step: 6
[2025-12-23 16:13:40,287] m-LoRA: Adapter lora_winogrande_26 loss: 0.5869709849357605
[2025-12-23 16:13:40,290] m-LoRA: Adapter lora_winogrande_24 epoch: 1/1 iteration: 116/128 step: 30
[2025-12-23 16:13:40,518] m-LoRA: Adapter lora_winogrande_34 loss: 1.2877497673034668
[2025-12-23 16:13:40,521] m-LoRA: Adapter lora_winogrande_20 epoch: 1/1 iteration: 74/128 step: 38
[2025-12-23 16:13:40,662] m-LoRA: Adapter lora_winogrande_32 loss: 2.3372955322265625
[2025-12-23 16:13:40,664] m-LoRA: Adapter lora_winogrande_0 epoch: 1/1 iteration: 92/128 step: 47
[2025-12-23 16:13:40,837] m-LoRA: Adapter lora_winogrande_18 loss: 1.0531840324401855
[2025-12-23 16:13:40,839] m-LoRA: Adapter lora_winogrande_28 epoch: 1/1 iteration: 112/128 step: 15
[2025-12-23 16:13:40,986] m-LoRA: Adapter lora_winogrande_33 loss: 0.7323794960975647
[2025-12-23 16:13:40,988] m-LoRA: Adapter lora_winogrande_29 epoch: 1/1 iteration: 28/128 step: 15
[2025-12-23 16:13:41,141] m-LoRA: Adapter lora_winogrande_11 loss: 0.4234614968299866
[2025-12-23 16:13:41,144] m-LoRA: Adapter lora_winogrande_30 epoch: 1/1 iteration: 112/128 step: 15
[2025-12-23 16:13:41,200] m-LoRA: Adapter lora_winogrande_12 loss: 0.6237439513206482
[2025-12-23 16:13:41,204] m-LoRA: Adapter lora_winogrande_23 loss: 1.5575263500213623
[2025-12-23 16:13:42,141] m-LoRA: Adapter lora_winogrande_35 loss: 2.8056180477142334
[2025-12-23 16:13:42,148] m-LoRA: Adapter lora_winogrande_9 epoch: 1/1 iteration: 92/128 step: 47
[2025-12-23 16:13:42,433] m-LoRA: Adapter lora_winogrande_24 loss: 0.4956396818161011
[2025-12-23 16:13:42,435] m-LoRA: Adapter lora_winogrande_31 epoch: 1/1 iteration: 112/128 step: 15
[2025-12-23 16:13:42,550] m-LoRA: Adapter lora_winogrande_20 loss: 0.6151358485221863
[2025-12-23 16:13:42,552] m-LoRA: Adapter lora_winogrande_26 epoch: 1/1 iteration: 88/128 step: 23
[2025-12-23 16:13:42,717] m-LoRA: Adapter lora_winogrande_0 loss: 0.414493203163147
[2025-12-23 16:13:42,719] m-LoRA: Adapter lora_winogrande_34 epoch: 1/1 iteration: 12/128 step: 7
[2025-12-23 16:13:42,841] m-LoRA: Adapter lora_winogrande_28 loss: 2.159970760345459
[2025-12-23 16:13:42,845] m-LoRA: Adapter lora_winogrande_32 epoch: 1/1 iteration: 28/128 step: 15
[2025-12-23 16:13:43,008] m-LoRA: Adapter lora_winogrande_29 loss: 0.5059369206428528
[2025-12-23 16:13:43,010] m-LoRA: Adapter lora_winogrande_18 epoch: 1/1 iteration: 76/128 step: 39
[2025-12-23 16:13:43,116] m-LoRA: Adapter lora_winogrande_30 loss: 0.6560914516448975
[2025-12-23 16:13:43,120] m-LoRA: Adapter lora_winogrande_12 epoch: 1/1 iteration: 92/128 step: 47
[2025-12-23 16:13:43,275] m-LoRA: Adapter lora_winogrande_33 epoch: 1/1 iteration: 28/128 step: 15
[2025-12-23 16:13:43,357] m-LoRA: Adapter lora_winogrande_9 loss: 0.8502756953239441
[2025-12-23 16:13:43,359] m-LoRA: Adapter lora_winogrande_23 epoch: 1/1 iteration: 60/128 step: 31
[2025-12-23 16:13:43,461] m-LoRA: Adapter lora_winogrande_11 epoch: 1/1 iteration: 92/128 step: 47
[2025-12-23 16:13:43,797] m-LoRA: Adapter lora_winogrande_31 loss: 0.5366029739379883
[2025-12-23 16:13:43,801] m-LoRA: Adapter lora_winogrande_35 epoch: 1/1 iteration: 96/128 step: 7
[2025-12-23 16:13:43,977] m-LoRA: Adapter lora_winogrande_26 loss: 0.5825480818748474
[2025-12-23 16:13:43,980] m-LoRA: Adapter lora_winogrande_24 epoch: 1/1 iteration: 120/128 step: 31
[2025-12-23 16:13:44,127] m-LoRA: Adapter lora_winogrande_34 loss: 1.2214853763580322
[2025-12-23 16:13:44,140] m-LoRA: Adapter lora_winogrande_20 epoch: 1/1 iteration: 76/128 step: 39
[2025-12-23 16:13:44,288] m-LoRA: Adapter lora_winogrande_32 loss: 2.2000138759613037
[2025-12-23 16:13:44,291] m-LoRA: Adapter lora_winogrande_0 epoch: 1/1 iteration: 94/128 step: 48
[2025-12-23 16:13:44,410] m-LoRA: Adapter lora_winogrande_18 loss: 1.0623822212219238
[2025-12-23 16:13:44,413] m-LoRA: Adapter lora_winogrande_28 epoch: 1/1 iteration: 120/128 step: 16
[2025-12-23 16:13:44,574] m-LoRA: Adapter lora_winogrande_12 loss: 0.5240907073020935
[2025-12-23 16:13:44,577] m-LoRA: Adapter lora_winogrande_29 epoch: 1/1 iteration: 30/128 step: 16
[2025-12-23 16:13:44,692] m-LoRA: Adapter lora_winogrande_33 loss: 0.6880069375038147
[2025-12-23 16:13:44,695] m-LoRA: Adapter lora_winogrande_30 epoch: 1/1 iteration: 120/128 step: 16
[2025-12-23 16:13:44,841] m-LoRA: Adapter lora_winogrande_23 loss: 1.603948712348938
[2025-12-23 16:13:44,843] m-LoRA: Adapter lora_winogrande_9 epoch: 1/1 iteration: 94/128 step: 48
[2025-12-23 16:13:44,983] m-LoRA: Adapter lora_winogrande_11 loss: 0.499441534280777
[2025-12-23 16:13:44,985] m-LoRA: Adapter lora_winogrande_31 epoch: 1/1 iteration: 120/128 step: 16
[2025-12-23 16:13:45,059] m-LoRA: Adapter lora_winogrande_26 epoch: 1/1 iteration: 92/128 step: 24
[2025-12-23 16:13:45,766] m-LoRA: Adapter lora_winogrande_34 epoch: 1/1 iteration: 14/128 step: 8
[2025-12-23 16:13:45,816] m-LoRA: Adapter lora_winogrande_35 loss: 2.6679770946502686
[2025-12-23 16:13:46,056] m-LoRA: Adapter lora_winogrande_24 loss: 0.4657600224018097
[2025-12-23 16:13:46,059] m-LoRA: Adapter lora_winogrande_32 epoch: 1/1 iteration: 30/128 step: 16
[2025-12-23 16:13:46,195] m-LoRA: Adapter lora_winogrande_20 loss: 0.6449683904647827
[2025-12-23 16:13:46,198] m-LoRA: Adapter lora_winogrande_18 epoch: 1/1 iteration: 78/128 step: 40
[2025-12-23 16:13:46,284] m-LoRA: Adapter lora_winogrande_0 loss: 0.6222277879714966
[2025-12-23 16:13:46,286] m-LoRA: Adapter lora_winogrande_12 epoch: 1/1 iteration: 94/128 step: 48
[2025-12-23 16:13:46,517] m-LoRA: Adapter lora_winogrande_28 loss: 2.104133367538452
[2025-12-23 16:13:46,522] m-LoRA: Adapter lora_winogrande_33 epoch: 1/1 iteration: 30/128 step: 16
[2025-12-23 16:13:46,681] m-LoRA: Adapter lora_winogrande_29 loss: 0.5712831020355225
[2025-12-23 16:13:46,684] m-LoRA: Adapter lora_winogrande_23 epoch: 1/1 iteration: 62/128 step: 32
[2025-12-23 16:13:47,024] m-LoRA: Adapter lora_winogrande_30 loss: 0.6190193891525269
[2025-12-23 16:13:47,027] m-LoRA: Adapter lora_winogrande_11 epoch: 1/1 iteration: 94/128 step: 48
[2025-12-23 16:13:47,113] m-LoRA: Adapter lora_winogrande_9 loss: 0.7744486927986145
[2025-12-23 16:13:47,472] m-LoRA: Adapter lora_winogrande_31 loss: 0.5038058757781982
[2025-12-23 16:13:47,477] m-LoRA: Adapter lora_winogrande_35 epoch: 1/1 iteration: 112/128 step: 8
[2025-12-23 16:13:47,675] m-LoRA: Adapter lora_winogrande_26 loss: 0.6193186044692993
[2025-12-23 16:13:47,678] m-LoRA: Adapter lora_winogrande_24 epoch: 1/1 iteration: 124/128 step: 32
[2025-12-23 16:13:47,796] m-LoRA: Adapter lora_winogrande_34 loss: 0.9774035215377808
[2025-12-23 16:13:47,798] m-LoRA: Adapter lora_winogrande_20 epoch: 1/1 iteration: 78/128 step: 40
[2025-12-23 16:13:47,901] m-LoRA: Adapter lora_winogrande_32 loss: 2.175527572631836
[2025-12-23 16:13:47,903] m-LoRA: Adapter lora_winogrande_0 epoch: 1/1 iteration: 96/128 step: 49
[2025-12-23 16:13:47,997] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_28']
[2025-12-23 16:13:48,375] m-LoRA: Adapter lora_winogrande_18 loss: 1.0079947710037231
[2025-12-23 16:13:48,405] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_36']
[2025-12-23 16:13:48,521] m-LoRA: Adapter lora_winogrande_36 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:13:48,676] m-LoRA: Adapter lora_winogrande_12 loss: 0.5318153500556946
[2025-12-23 16:13:48,683] m-LoRA: Adapter lora_winogrande_29 epoch: 1/1 iteration: 32/128 step: 17
[2025-12-23 16:13:48,743] m-LoRA: Adapter lora_winogrande_33 loss: 0.516895592212677
[2025-12-23 16:13:48,749] m-LoRA: Adapter lora_winogrande_23 loss: 1.5945920944213867
[2025-12-23 16:13:48,752] m-LoRA: Adapter lora_winogrande_11 loss: 0.5567285418510437
[2025-12-23 16:13:49,169] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_30']
[2025-12-23 16:13:49,491] m-LoRA: Adapter lora_winogrande_35 loss: 2.4020493030548096
[2025-12-23 16:13:49,498] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_37']
[2025-12-23 16:13:49,653] m-LoRA: Adapter lora_winogrande_37 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:13:49,756] m-LoRA: Adapter lora_winogrande_24 loss: 0.5128429532051086
[2025-12-23 16:13:49,759] m-LoRA: Adapter lora_winogrande_9 epoch: 1/1 iteration: 96/128 step: 49
[2025-12-23 16:13:49,847] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_31']
[2025-12-23 16:13:50,643] m-LoRA: Adapter lora_winogrande_20 loss: 0.5220203995704651
[2025-12-23 16:13:50,645] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_38']
[2025-12-23 16:13:50,769] m-LoRA: Adapter lora_winogrande_38 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:13:50,868] m-LoRA: Adapter lora_winogrande_0 loss: 0.5550826787948608
[2025-12-23 16:13:50,870] m-LoRA: Adapter lora_winogrande_26 epoch: 1/1 iteration: 96/128 step: 25
[2025-12-23 16:13:50,984] m-LoRA: Adapter lora_winogrande_36 loss: 3.1146554946899414
[2025-12-23 16:13:50,991] m-LoRA: Adapter lora_winogrande_34 epoch: 1/1 iteration: 16/128 step: 9
[2025-12-23 16:13:51,164] m-LoRA: Adapter lora_winogrande_29 loss: 0.5282683968544006
[2025-12-23 16:13:51,166] m-LoRA: Adapter lora_winogrande_32 epoch: 1/1 iteration: 32/128 step: 17
[2025-12-23 16:13:51,269] m-LoRA: Adapter lora_winogrande_18 epoch: 1/1 iteration: 80/128 step: 41
[2025-12-23 16:13:51,340] m-LoRA: Adapter lora_winogrande_12 epoch: 1/1 iteration: 96/128 step: 49
[2025-12-23 16:13:51,410] m-LoRA: Adapter lora_winogrande_33 epoch: 1/1 iteration: 32/128 step: 17
[2025-12-23 16:13:51,482] m-LoRA: Adapter lora_winogrande_23 epoch: 1/1 iteration: 64/128 step: 33
[2025-12-23 16:13:51,603] m-LoRA: Adapter lora_winogrande_11 epoch: 1/1 iteration: 96/128 step: 49
[2025-12-23 16:13:51,716] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_35']
[2025-12-23 16:13:52,001] m-LoRA: Adapter lora_winogrande_37 loss: 2.8250412940979004
[2025-12-23 16:13:52,021] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_39']
[2025-12-23 16:13:52,208] m-LoRA: Adapter lora_winogrande_39 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:13:52,312] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_24']
[2025-12-23 16:13:52,560] m-LoRA: Adapter lora_winogrande_9 loss: 0.7879544496536255
[2025-12-23 16:13:52,563] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_40']
[2025-12-23 16:13:52,689] m-LoRA: Adapter lora_winogrande_40 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:13:52,834] m-LoRA: Adapter lora_winogrande_26 loss: 0.49884283542633057
[2025-12-23 16:13:52,837] m-LoRA: Adapter lora_winogrande_20 epoch: 1/1 iteration: 80/128 step: 41
[2025-12-23 16:13:52,972] m-LoRA: Adapter lora_winogrande_38 loss: 2.854234218597412
[2025-12-23 16:13:52,974] m-LoRA: Adapter lora_winogrande_0 epoch: 1/1 iteration: 98/128 step: 50
[2025-12-23 16:13:53,139] m-LoRA: Adapter lora_winogrande_34 loss: 0.7937384843826294
[2025-12-23 16:13:53,141] m-LoRA: Adapter lora_winogrande_36 epoch: 1/1 iteration: 16/128 step: 2
[2025-12-23 16:13:53,297] m-LoRA: Adapter lora_winogrande_32 loss: 1.9245381355285645
[2025-12-23 16:13:53,299] m-LoRA: Adapter lora_winogrande_29 epoch: 1/1 iteration: 34/128 step: 18
[2025-12-23 16:13:53,446] m-LoRA: Adapter lora_winogrande_18 loss: 1.0936611890792847
[2025-12-23 16:13:53,449] m-LoRA: Adapter lora_winogrande_37 epoch: 1/1 iteration: 8/128 step: 2
[2025-12-23 16:13:53,566] m-LoRA: Adapter lora_winogrande_12 loss: 0.5706178545951843
[2025-12-23 16:13:53,568] m-LoRA: Adapter lora_winogrande_9 epoch: 1/1 iteration: 98/128 step: 50
[2025-12-23 16:13:53,686] m-LoRA: Adapter lora_winogrande_23 loss: 1.4619807004928589
[2025-12-23 16:13:53,688] m-LoRA: Adapter lora_winogrande_26 epoch: 1/1 iteration: 100/128 step: 26
[2025-12-23 16:13:53,835] m-LoRA: Adapter lora_winogrande_33 loss: 0.5458815693855286
[2025-12-23 16:13:53,837] m-LoRA: Adapter lora_winogrande_38 epoch: 1/1 iteration: 2/128 step: 2
[2025-12-23 16:13:53,929] m-LoRA: Adapter lora_winogrande_11 loss: 0.5346011519432068
[2025-12-23 16:13:53,932] m-LoRA: Adapter lora_winogrande_34 epoch: 1/1 iteration: 18/128 step: 10
[2025-12-23 16:13:54,026] m-LoRA: Adapter lora_winogrande_39 loss: 3.3227460384368896
[2025-12-23 16:13:54,030] m-LoRA: Adapter lora_winogrande_32 epoch: 1/1 iteration: 34/128 step: 18
[2025-12-23 16:13:54,553] m-LoRA: Adapter lora_winogrande_18 epoch: 1/1 iteration: 82/128 step: 42
[2025-12-23 16:13:54,606] m-LoRA: Adapter lora_winogrande_40 loss: 3.3047850131988525
[2025-12-23 16:13:54,661] m-LoRA: Adapter lora_winogrande_20 loss: 0.4785745143890381
[2025-12-23 16:13:54,663] m-LoRA: Adapter lora_winogrande_12 epoch: 1/1 iteration: 98/128 step: 50
[2025-12-23 16:13:54,795] m-LoRA: Adapter lora_winogrande_0 loss: 0.45617324113845825
[2025-12-23 16:13:54,797] m-LoRA: Adapter lora_winogrande_23 epoch: 1/1 iteration: 66/128 step: 34
[2025-12-23 16:13:55,522] m-LoRA: Adapter lora_winogrande_36 loss: 2.590667486190796
[2025-12-23 16:13:55,529] m-LoRA: Adapter lora_winogrande_33 epoch: 1/1 iteration: 34/128 step: 18
[2025-12-23 16:13:55,710] m-LoRA: Adapter lora_winogrande_29 loss: 0.6084345579147339
[2025-12-23 16:13:55,713] m-LoRA: Adapter lora_winogrande_11 epoch: 1/1 iteration: 98/128 step: 50
[2025-12-23 16:13:55,919] m-LoRA: Adapter lora_winogrande_37 loss: 3.2117605209350586
[2025-12-23 16:13:55,923] m-LoRA: Adapter lora_winogrande_39 epoch: 1/1 iteration: 4/128 step: 2
[2025-12-23 16:13:56,101] m-LoRA: Adapter lora_winogrande_9 loss: 0.8070643544197083
[2025-12-23 16:13:56,103] m-LoRA: Adapter lora_winogrande_40 epoch: 1/1 iteration: 16/128 step: 2
[2025-12-23 16:13:56,269] m-LoRA: Adapter lora_winogrande_26 loss: 0.5410398840904236
[2025-12-23 16:13:56,271] m-LoRA: Adapter lora_winogrande_20 epoch: 1/1 iteration: 82/128 step: 42
[2025-12-23 16:13:56,479] m-LoRA: Adapter lora_winogrande_38 loss: 2.288283586502075
[2025-12-23 16:13:56,482] m-LoRA: Adapter lora_winogrande_0 epoch: 1/1 iteration: 100/128 step: 51
[2025-12-23 16:13:56,535] m-LoRA: Adapter lora_winogrande_34 loss: 0.7303233742713928
[2025-12-23 16:13:56,539] m-LoRA: Adapter lora_winogrande_32 loss: 2.1152517795562744
[2025-12-23 16:13:56,614] m-LoRA: Adapter lora_winogrande_18 loss: 0.9588177800178528
[2025-12-23 16:13:56,709] m-LoRA: Adapter lora_winogrande_12 loss: 0.5477204322814941
[2025-12-23 16:13:56,885] m-LoRA: Adapter lora_winogrande_23 loss: 1.5112226009368896
[2025-12-23 16:13:56,888] m-LoRA: Adapter lora_winogrande_36 epoch: 1/1 iteration: 32/128 step: 3
[2025-12-23 16:13:57,061] m-LoRA: Adapter lora_winogrande_33 loss: 0.544867217540741
[2025-12-23 16:13:57,063] m-LoRA: Adapter lora_winogrande_29 epoch: 1/1 iteration: 36/128 step: 19
[2025-12-23 16:13:57,113] m-LoRA: Adapter lora_winogrande_11 loss: 0.5420183539390564
[2025-12-23 16:13:57,261] m-LoRA: Adapter lora_winogrande_39 loss: 2.182229518890381
[2025-12-23 16:13:57,264] m-LoRA: Adapter lora_winogrande_37 epoch: 1/1 iteration: 16/128 step: 3
[2025-12-23 16:13:57,395] m-LoRA: Adapter lora_winogrande_9 epoch: 1/1 iteration: 100/128 step: 51
[2025-12-23 16:13:58,089] m-LoRA: Adapter lora_winogrande_40 loss: 2.694190502166748
[2025-12-23 16:13:58,095] m-LoRA: Adapter lora_winogrande_26 epoch: 1/1 iteration: 104/128 step: 27
[2025-12-23 16:13:58,263] m-LoRA: Adapter lora_winogrande_20 loss: 0.48183366656303406
[2025-12-23 16:13:58,270] m-LoRA: Adapter lora_winogrande_38 epoch: 1/1 iteration: 4/128 step: 3
[2025-12-23 16:13:58,361] m-LoRA: Adapter lora_winogrande_0 loss: 0.46707749366760254
[2025-12-23 16:13:58,363] m-LoRA: Adapter lora_winogrande_34 epoch: 1/1 iteration: 20/128 step: 11
[2025-12-23 16:13:58,884] m-LoRA: Adapter lora_winogrande_36 loss: 2.1183364391326904
[2025-12-23 16:13:58,891] m-LoRA: Adapter lora_winogrande_32 epoch: 1/1 iteration: 36/128 step: 19
[2025-12-23 16:13:59,111] m-LoRA: Adapter lora_winogrande_29 loss: 0.6344731450080872
[2025-12-23 16:13:59,113] m-LoRA: Adapter lora_winogrande_18 epoch: 1/1 iteration: 84/128 step: 43
[2025-12-23 16:13:59,335] m-LoRA: Adapter lora_winogrande_12 epoch: 1/1 iteration: 100/128 step: 51
[2025-12-23 16:13:59,373] m-LoRA: Adapter lora_winogrande_37 loss: 2.7854909896850586
[2025-12-23 16:13:59,528] m-LoRA: Adapter lora_winogrande_9 loss: 0.8266670107841492
[2025-12-23 16:13:59,530] m-LoRA: Adapter lora_winogrande_23 epoch: 1/1 iteration: 68/128 step: 35
[2025-12-23 16:13:59,705] m-LoRA: Adapter lora_winogrande_26 loss: 0.5112014412879944
[2025-12-23 16:13:59,708] m-LoRA: Adapter lora_winogrande_33 epoch: 1/1 iteration: 36/128 step: 19
[2025-12-23 16:13:59,850] m-LoRA: Adapter lora_winogrande_38 loss: 1.9715313911437988
[2025-12-23 16:13:59,853] m-LoRA: Adapter lora_winogrande_11 epoch: 1/1 iteration: 100/128 step: 51
[2025-12-23 16:14:00,000] m-LoRA: Adapter lora_winogrande_34 loss: 0.6969340443611145
[2025-12-23 16:14:00,003] m-LoRA: Adapter lora_winogrande_39 epoch: 1/1 iteration: 8/128 step: 3
[2025-12-23 16:14:00,119] m-LoRA: Adapter lora_winogrande_40 epoch: 1/1 iteration: 32/128 step: 3
[2025-12-23 16:14:00,274] m-LoRA: Adapter lora_winogrande_32 loss: 1.8816266059875488
[2025-12-23 16:14:00,277] m-LoRA: Adapter lora_winogrande_20 epoch: 1/1 iteration: 84/128 step: 43
[2025-12-23 16:14:00,393] m-LoRA: Adapter lora_winogrande_18 loss: 1.029639482498169
[2025-12-23 16:14:00,404] m-LoRA: Adapter lora_winogrande_0 epoch: 1/1 iteration: 102/128 step: 52
[2025-12-23 16:14:00,574] m-LoRA: Adapter lora_winogrande_12 loss: 0.4607551395893097
[2025-12-23 16:14:00,577] m-LoRA: Adapter lora_winogrande_36 epoch: 1/1 iteration: 48/128 step: 4
[2025-12-23 16:14:00,754] m-LoRA: Adapter lora_winogrande_23 loss: 1.4139012098312378
[2025-12-23 16:14:00,758] m-LoRA: Adapter lora_winogrande_29 epoch: 1/1 iteration: 38/128 step: 20
[2025-12-23 16:14:00,883] m-LoRA: Adapter lora_winogrande_33 loss: 0.6057571172714233
[2025-12-23 16:14:00,885] m-LoRA: Adapter lora_winogrande_37 epoch: 1/1 iteration: 24/128 step: 4
[2025-12-23 16:14:01,042] m-LoRA: Adapter lora_winogrande_11 loss: 0.4346054792404175
[2025-12-23 16:14:01,044] m-LoRA: Adapter lora_winogrande_9 epoch: 1/1 iteration: 102/128 step: 52
[2025-12-23 16:14:01,167] m-LoRA: Adapter lora_winogrande_26 epoch: 1/1 iteration: 108/128 step: 28
[2025-12-23 16:14:01,305] m-LoRA: Adapter lora_winogrande_39 loss: 1.8045165538787842
[2025-12-23 16:14:01,307] m-LoRA: Adapter lora_winogrande_38 epoch: 1/1 iteration: 6/128 step: 4
[2025-12-23 16:14:01,447] m-LoRA: Adapter lora_winogrande_34 epoch: 1/1 iteration: 22/128 step: 12
[2025-12-23 16:14:02,045] m-LoRA: Adapter lora_winogrande_32 epoch: 1/1 iteration: 38/128 step: 20
[2025-12-23 16:14:02,169] m-LoRA: Adapter lora_winogrande_40 loss: 2.1526126861572266
[2025-12-23 16:14:02,176] m-LoRA: Adapter lora_winogrande_18 epoch: 1/1 iteration: 86/128 step: 44
[2025-12-23 16:14:02,377] m-LoRA: Adapter lora_winogrande_20 loss: 0.48023688793182373
[2025-12-23 16:14:02,379] m-LoRA: Adapter lora_winogrande_12 epoch: 1/1 iteration: 102/128 step: 52
[2025-12-23 16:14:02,427] m-LoRA: Adapter lora_winogrande_0 loss: 0.5691600441932678
[2025-12-23 16:14:02,899] m-LoRA: Adapter lora_winogrande_36 loss: 1.9866864681243896
[2025-12-23 16:14:02,906] m-LoRA: Adapter lora_winogrande_23 epoch: 1/1 iteration: 70/128 step: 36
[2025-12-23 16:14:03,151] m-LoRA: Adapter lora_winogrande_29 loss: 0.5669435262680054
[2025-12-23 16:14:03,153] m-LoRA: Adapter lora_winogrande_33 epoch: 1/1 iteration: 38/128 step: 20
[2025-12-23 16:14:03,356] m-LoRA: Adapter lora_winogrande_37 loss: 2.3740074634552
[2025-12-23 16:14:03,361] m-LoRA: Adapter lora_winogrande_11 epoch: 1/1 iteration: 102/128 step: 52
[2025-12-23 16:14:03,532] m-LoRA: Adapter lora_winogrande_9 loss: 0.7172003984451294
[2025-12-23 16:14:03,535] m-LoRA: Adapter lora_winogrande_39 epoch: 1/1 iteration: 12/128 step: 4
[2025-12-23 16:14:03,689] m-LoRA: Adapter lora_winogrande_26 loss: 0.5546918511390686
[2025-12-23 16:14:03,691] m-LoRA: Adapter lora_winogrande_40 epoch: 1/1 iteration: 48/128 step: 4
[2025-12-23 16:14:03,851] m-LoRA: Adapter lora_winogrande_38 loss: 1.714629888534546
[2025-12-23 16:14:03,853] m-LoRA: Adapter lora_winogrande_20 epoch: 1/1 iteration: 86/128 step: 44
[2025-12-23 16:14:03,972] m-LoRA: Adapter lora_winogrande_34 loss: 0.7266560792922974
[2025-12-23 16:14:03,974] m-LoRA: Adapter lora_winogrande_0 epoch: 1/1 iteration: 104/128 step: 53
[2025-12-23 16:14:04,038] m-LoRA: Adapter lora_winogrande_32 loss: 1.9747638702392578
[2025-12-23 16:14:04,053] m-LoRA: Adapter lora_winogrande_18 loss: 0.886273205280304
[2025-12-23 16:14:04,056] m-LoRA: Adapter lora_winogrande_12 loss: 0.4830506443977356
[2025-12-23 16:14:04,158] m-LoRA: Adapter lora_winogrande_23 loss: 1.2978723049163818
[2025-12-23 16:14:04,245] m-LoRA: Adapter lora_winogrande_33 loss: 0.5285094380378723
[2025-12-23 16:14:04,441] m-LoRA: Adapter lora_winogrande_11 loss: 0.4590970575809479
[2025-12-23 16:14:04,443] m-LoRA: Adapter lora_winogrande_36 epoch: 1/1 iteration: 64/128 step: 5
[2025-12-23 16:14:04,587] m-LoRA: Adapter lora_winogrande_29 epoch: 1/1 iteration: 40/128 step: 21
[2025-12-23 16:14:04,769] m-LoRA: Adapter lora_winogrande_39 loss: 1.5675615072250366
[2025-12-23 16:14:04,772] m-LoRA: Adapter lora_winogrande_37 epoch: 1/1 iteration: 32/128 step: 5
[2025-12-23 16:14:05,489] m-LoRA: Adapter lora_winogrande_9 epoch: 1/1 iteration: 104/128 step: 53
[2025-12-23 16:14:05,601] m-LoRA: Adapter lora_winogrande_40 loss: 1.9835678339004517
[2025-12-23 16:14:05,608] m-LoRA: Adapter lora_winogrande_26 epoch: 1/1 iteration: 112/128 step: 29
[2025-12-23 16:14:05,887] m-LoRA: Adapter lora_winogrande_20 loss: 0.5227535367012024
[2025-12-23 16:14:05,889] m-LoRA: Adapter lora_winogrande_38 epoch: 1/1 iteration: 8/128 step: 5
[2025-12-23 16:14:05,928] m-LoRA: Adapter lora_winogrande_0 loss: 0.515830397605896
[2025-12-23 16:14:06,365] m-LoRA: Adapter lora_winogrande_36 loss: 1.7958122491836548
[2025-12-23 16:14:06,372] m-LoRA: Adapter lora_winogrande_34 epoch: 1/1 iteration: 24/128 step: 13
[2025-12-23 16:14:06,519] m-LoRA: Adapter lora_winogrande_29 loss: 0.3746381998062134
[2025-12-23 16:14:06,521] m-LoRA: Adapter lora_winogrande_32 epoch: 1/1 iteration: 40/128 step: 21
[2025-12-23 16:14:06,818] m-LoRA: Adapter lora_winogrande_37 loss: 2.1765031814575195
[2025-12-23 16:14:06,821] m-LoRA: Adapter lora_winogrande_18 epoch: 1/1 iteration: 88/128 step: 45
[2025-12-23 16:14:06,950] m-LoRA: Adapter lora_winogrande_9 loss: 0.7502247095108032
[2025-12-23 16:14:06,952] m-LoRA: Adapter lora_winogrande_12 epoch: 1/1 iteration: 104/128 step: 53
[2025-12-23 16:14:07,099] m-LoRA: Adapter lora_winogrande_26 loss: 0.48130562901496887
[2025-12-23 16:14:07,102] m-LoRA: Adapter lora_winogrande_23 epoch: 1/1 iteration: 72/128 step: 37
[2025-12-23 16:14:07,271] m-LoRA: Adapter lora_winogrande_38 loss: 1.2760510444641113
[2025-12-23 16:14:07,273] m-LoRA: Adapter lora_winogrande_33 epoch: 1/1 iteration: 40/128 step: 21
[2025-12-23 16:14:07,399] m-LoRA: Adapter lora_winogrande_34 loss: 0.6970991492271423
[2025-12-23 16:14:07,402] m-LoRA: Adapter lora_winogrande_11 epoch: 1/1 iteration: 104/128 step: 53
[2025-12-23 16:14:07,543] m-LoRA: Adapter lora_winogrande_32 loss: 1.8166354894638062
[2025-12-23 16:14:07,545] m-LoRA: Adapter lora_winogrande_39 epoch: 1/1 iteration: 16/128 step: 5
[2025-12-23 16:14:07,674] m-LoRA: Adapter lora_winogrande_18 loss: 0.7267336845397949
[2025-12-23 16:14:07,677] m-LoRA: Adapter lora_winogrande_0 epoch: 1/1 iteration: 106/128 step: 54
[2025-12-23 16:14:07,825] m-LoRA: Adapter lora_winogrande_12 loss: 0.45429161190986633
[2025-12-23 16:14:07,827] m-LoRA: Adapter lora_winogrande_40 epoch: 1/1 iteration: 64/128 step: 5
[2025-12-23 16:14:07,972] m-LoRA: Adapter lora_winogrande_20 epoch: 1/1 iteration: 88/128 step: 45
[2025-12-23 16:14:08,083] m-LoRA: Adapter lora_winogrande_36 epoch: 1/1 iteration: 80/128 step: 6
[2025-12-23 16:14:08,197] m-LoRA: Adapter lora_winogrande_23 loss: 1.2427555322647095
[2025-12-23 16:14:08,200] m-LoRA: Adapter lora_winogrande_29 epoch: 1/1 iteration: 42/128 step: 22
[2025-12-23 16:14:08,335] m-LoRA: Adapter lora_winogrande_33 loss: 0.5312796831130981
[2025-12-23 16:14:08,338] m-LoRA: Adapter lora_winogrande_37 epoch: 1/1 iteration: 40/128 step: 6
[2025-12-23 16:14:08,481] m-LoRA: Adapter lora_winogrande_11 loss: 0.5202140808105469
[2025-12-23 16:14:08,483] m-LoRA: Adapter lora_winogrande_9 epoch: 1/1 iteration: 106/128 step: 54
[2025-12-23 16:14:08,598] m-LoRA: Adapter lora_winogrande_26 epoch: 1/1 iteration: 116/128 step: 30
[2025-12-23 16:14:08,729] m-LoRA: Adapter lora_winogrande_39 loss: 1.1948312520980835
[2025-12-23 16:14:08,733] m-LoRA: Adapter lora_winogrande_38 epoch: 1/1 iteration: 10/128 step: 6
[2025-12-23 16:14:08,969] m-LoRA: Adapter lora_winogrande_0 loss: 0.4576690196990967
[2025-12-23 16:14:08,971] m-LoRA: Adapter lora_winogrande_34 epoch: 1/1 iteration: 26/128 step: 14
[2025-12-23 16:14:09,080] m-LoRA: Adapter lora_winogrande_32 epoch: 1/1 iteration: 42/128 step: 22
[2025-12-23 16:14:09,643] m-LoRA: Adapter lora_winogrande_18 epoch: 1/1 iteration: 90/128 step: 46
[2025-12-23 16:14:09,686] m-LoRA: Adapter lora_winogrande_40 loss: 1.799406886100769
[2025-12-23 16:14:09,752] m-LoRA: Adapter lora_winogrande_20 loss: 0.45627492666244507
[2025-12-23 16:14:09,753] m-LoRA: Adapter lora_winogrande_12 epoch: 1/1 iteration: 106/128 step: 54
[2025-12-23 16:14:10,443] m-LoRA: Adapter lora_winogrande_36 loss: 1.5393160581588745
[2025-12-23 16:14:10,517] m-LoRA: Adapter lora_winogrande_23 epoch: 1/1 iteration: 74/128 step: 38
[2025-12-23 16:14:10,661] m-LoRA: Adapter lora_winogrande_29 loss: 0.5290834903717041
[2025-12-23 16:14:10,675] m-LoRA: Adapter lora_winogrande_33 epoch: 1/1 iteration: 42/128 step: 22
[2025-12-23 16:14:10,931] m-LoRA: Adapter lora_winogrande_37 loss: 1.995301604270935
[2025-12-23 16:14:10,936] m-LoRA: Adapter lora_winogrande_11 epoch: 1/1 iteration: 106/128 step: 54
[2025-12-23 16:14:11,080] m-LoRA: Adapter lora_winogrande_9 loss: 0.7071729898452759
[2025-12-23 16:14:11,082] m-LoRA: Adapter lora_winogrande_39 epoch: 1/1 iteration: 20/128 step: 6
[2025-12-23 16:14:11,210] m-LoRA: Adapter lora_winogrande_26 loss: 0.5177300572395325
[2025-12-23 16:14:11,214] m-LoRA: Adapter lora_winogrande_0 epoch: 1/1 iteration: 108/128 step: 55
[2025-12-23 16:14:11,369] m-LoRA: Adapter lora_winogrande_38 loss: 1.0299923419952393
[2025-12-23 16:14:11,374] m-LoRA: Adapter lora_winogrande_40 epoch: 1/1 iteration: 80/128 step: 6
[2025-12-23 16:14:11,529] m-LoRA: Adapter lora_winogrande_34 loss: 0.735765814781189
[2025-12-23 16:14:11,531] m-LoRA: Adapter lora_winogrande_20 epoch: 1/1 iteration: 90/128 step: 46
[2025-12-23 16:14:11,582] m-LoRA: Adapter lora_winogrande_32 loss: 1.9522747993469238
[2025-12-23 16:14:11,595] m-LoRA: Adapter lora_winogrande_18 loss: 0.7672128677368164
[2025-12-23 16:14:11,615] m-LoRA: Adapter lora_winogrande_12 loss: 0.49259424209594727
[2025-12-23 16:14:11,717] m-LoRA: Adapter lora_winogrande_23 loss: 1.236557960510254
[2025-12-23 16:14:11,824] m-LoRA: Adapter lora_winogrande_33 loss: 0.48323363065719604
[2025-12-23 16:14:12,029] m-LoRA: Adapter lora_winogrande_11 loss: 0.45155778527259827
[2025-12-23 16:14:12,031] m-LoRA: Adapter lora_winogrande_36 epoch: 1/1 iteration: 96/128 step: 7
[2025-12-23 16:14:12,244] m-LoRA: Adapter lora_winogrande_39 loss: 1.0002654790878296
[2025-12-23 16:14:12,247] m-LoRA: Adapter lora_winogrande_29 epoch: 1/1 iteration: 44/128 step: 23
[2025-12-23 16:14:12,378] m-LoRA: Adapter lora_winogrande_0 loss: 0.41765546798706055
[2025-12-23 16:14:12,380] m-LoRA: Adapter lora_winogrande_37 epoch: 1/1 iteration: 48/128 step: 7
[2025-12-23 16:14:12,489] m-LoRA: Adapter lora_winogrande_9 epoch: 1/1 iteration: 108/128 step: 55
[2025-12-23 16:14:12,561] m-LoRA: Adapter lora_winogrande_26 epoch: 1/1 iteration: 120/128 step: 31
[2025-12-23 16:14:13,265] m-LoRA: Adapter lora_winogrande_40 loss: 1.6264057159423828
[2025-12-23 16:14:13,272] m-LoRA: Adapter lora_winogrande_38 epoch: 1/1 iteration: 12/128 step: 7
[2025-12-23 16:14:13,419] m-LoRA: Adapter lora_winogrande_20 loss: 0.43225499987602234
[2025-12-23 16:14:13,421] m-LoRA: Adapter lora_winogrande_34 epoch: 1/1 iteration: 28/128 step: 15
[2025-12-23 16:14:14,006] m-LoRA: Adapter lora_winogrande_36 loss: 1.3738677501678467
[2025-12-23 16:14:14,013] m-LoRA: Adapter lora_winogrande_32 epoch: 1/1 iteration: 44/128 step: 23
[2025-12-23 16:14:14,207] m-LoRA: Adapter lora_winogrande_29 loss: 0.7206927537918091
[2025-12-23 16:14:14,210] m-LoRA: Adapter lora_winogrande_18 epoch: 1/1 iteration: 92/128 step: 47
[2025-12-23 16:14:14,427] m-LoRA: Adapter lora_winogrande_37 loss: 1.855027198791504
[2025-12-23 16:14:14,432] m-LoRA: Adapter lora_winogrande_12 epoch: 1/1 iteration: 108/128 step: 55
[2025-12-23 16:14:14,623] m-LoRA: Adapter lora_winogrande_9 loss: 0.8165841698646545
[2025-12-23 16:14:14,625] m-LoRA: Adapter lora_winogrande_23 epoch: 1/1 iteration: 76/128 step: 39
[2025-12-23 16:14:14,769] m-LoRA: Adapter lora_winogrande_26 loss: 0.5754430890083313
[2025-12-23 16:14:14,772] m-LoRA: Adapter lora_winogrande_33 epoch: 1/1 iteration: 44/128 step: 23
[2025-12-23 16:14:14,980] m-LoRA: Adapter lora_winogrande_38 loss: 0.8143896460533142
[2025-12-23 16:14:14,983] m-LoRA: Adapter lora_winogrande_11 epoch: 1/1 iteration: 108/128 step: 55
[2025-12-23 16:14:15,098] m-LoRA: Adapter lora_winogrande_34 loss: 0.6057517528533936
[2025-12-23 16:14:15,100] m-LoRA: Adapter lora_winogrande_39 epoch: 1/1 iteration: 24/128 step: 7
[2025-12-23 16:14:15,203] m-LoRA: Adapter lora_winogrande_32 loss: 1.8790309429168701
[2025-12-23 16:14:15,205] m-LoRA: Adapter lora_winogrande_0 epoch: 1/1 iteration: 110/128 step: 56
[2025-12-23 16:14:15,352] m-LoRA: Adapter lora_winogrande_18 loss: 0.8262109756469727
[2025-12-23 16:14:15,355] m-LoRA: Adapter lora_winogrande_40 epoch: 1/1 iteration: 96/128 step: 7
[2025-12-23 16:14:15,478] m-LoRA: Adapter lora_winogrande_20 epoch: 1/1 iteration: 92/128 step: 47
[2025-12-23 16:14:15,618] m-LoRA: Adapter lora_winogrande_12 loss: 0.4923613369464874
[2025-12-23 16:14:15,620] m-LoRA: Adapter lora_winogrande_36 epoch: 1/1 iteration: 112/128 step: 8
[2025-12-23 16:14:15,769] m-LoRA: Adapter lora_winogrande_23 loss: 1.2031588554382324
[2025-12-23 16:14:15,771] m-LoRA: Adapter lora_winogrande_29 epoch: 1/1 iteration: 46/128 step: 24
[2025-12-23 16:14:15,908] m-LoRA: Adapter lora_winogrande_33 loss: 0.5691958665847778
[2025-12-23 16:14:15,910] m-LoRA: Adapter lora_winogrande_37 epoch: 1/1 iteration: 56/128 step: 8
[2025-12-23 16:14:16,017] m-LoRA: Adapter lora_winogrande_11 loss: 0.5944380164146423
[2025-12-23 16:14:16,019] m-LoRA: Adapter lora_winogrande_9 epoch: 1/1 iteration: 110/128 step: 56
[2025-12-23 16:14:16,127] m-LoRA: Adapter lora_winogrande_26 epoch: 1/1 iteration: 124/128 step: 32
[2025-12-23 16:14:16,292] m-LoRA: Adapter lora_winogrande_39 loss: 0.6563158631324768
[2025-12-23 16:14:16,295] m-LoRA: Adapter lora_winogrande_38 epoch: 1/1 iteration: 14/128 step: 8
[2025-12-23 16:14:16,460] m-LoRA: Adapter lora_winogrande_0 loss: 0.48995620012283325
[2025-12-23 16:14:16,461] m-LoRA: Adapter lora_winogrande_34 epoch: 1/1 iteration: 30/128 step: 16
[2025-12-23 16:14:16,523] m-LoRA: Adapter lora_winogrande_32 epoch: 1/1 iteration: 46/128 step: 24
[2025-12-23 16:14:16,598] m-LoRA: Adapter lora_winogrande_18 epoch: 1/1 iteration: 94/128 step: 48
[2025-12-23 16:14:17,293] m-LoRA: Adapter lora_winogrande_40 loss: 1.3620595932006836
[2025-12-23 16:14:17,300] m-LoRA: Adapter lora_winogrande_12 epoch: 1/1 iteration: 110/128 step: 56
[2025-12-23 16:14:17,477] m-LoRA: Adapter lora_winogrande_20 loss: 0.6052244305610657
[2025-12-23 16:14:17,478] m-LoRA: Adapter lora_winogrande_23 epoch: 1/1 iteration: 78/128 step: 40
[2025-12-23 16:14:18,061] m-LoRA: Adapter lora_winogrande_36 loss: 1.147626519203186
[2025-12-23 16:14:18,067] m-LoRA: Adapter lora_winogrande_33 epoch: 1/1 iteration: 46/128 step: 24
[2025-12-23 16:14:18,342] m-LoRA: Adapter lora_winogrande_29 loss: 0.5681063532829285
[2025-12-23 16:14:18,344] m-LoRA: Adapter lora_winogrande_11 epoch: 1/1 iteration: 110/128 step: 56
[2025-12-23 16:14:18,521] m-LoRA: Adapter lora_winogrande_37 loss: 1.8543890714645386
[2025-12-23 16:14:18,525] m-LoRA: Adapter lora_winogrande_39 epoch: 1/1 iteration: 28/128 step: 8
[2025-12-23 16:14:18,680] m-LoRA: Adapter lora_winogrande_9 loss: 0.7410351634025574
[2025-12-23 16:14:18,682] m-LoRA: Adapter lora_winogrande_0 epoch: 1/1 iteration: 112/128 step: 57
[2025-12-23 16:14:18,869] m-LoRA: Adapter lora_winogrande_38 loss: 0.6580881476402283
[2025-12-23 16:14:18,872] m-LoRA: Adapter lora_winogrande_40 epoch: 1/1 iteration: 112/128 step: 8
[2025-12-23 16:14:18,985] m-LoRA: Adapter lora_winogrande_26 loss: 0.5128253102302551
[2025-12-23 16:14:18,988] m-LoRA: Adapter lora_winogrande_20 epoch: 1/1 iteration: 94/128 step: 48
[2025-12-23 16:14:19,129] m-LoRA: Adapter lora_winogrande_34 loss: 0.580511748790741
[2025-12-23 16:14:19,135] m-LoRA: Adapter lora_winogrande_32 loss: 1.8446578979492188
[2025-12-23 16:14:19,138] m-LoRA: Adapter lora_winogrande_18 loss: 0.7547240257263184
[2025-12-23 16:14:19,259] m-LoRA: Adapter lora_winogrande_12 loss: 0.46883803606033325
[2025-12-23 16:14:19,338] m-LoRA: Adapter lora_winogrande_23 loss: 1.2157011032104492
[2025-12-23 16:14:19,411] m-LoRA: Adapter lora_winogrande_33 loss: 0.6547747254371643
[2025-12-23 16:14:19,499] m-LoRA: Adapter lora_winogrande_11 loss: 0.5898789167404175
[2025-12-23 16:14:19,755] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_36']
[2025-12-23 16:14:20,441] m-LoRA: Adapter lora_winogrande_39 loss: 0.7465206384658813
[2025-12-23 16:14:20,444] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_41']
[2025-12-23 16:14:20,545] m-LoRA: Adapter lora_winogrande_41 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:14:20,778] m-LoRA: Adapter lora_winogrande_0 loss: 0.49900123476982117
[2025-12-23 16:14:20,781] m-LoRA: Adapter lora_winogrande_29 epoch: 1/1 iteration: 48/128 step: 25
[2025-12-23 16:14:20,904] m-LoRA: Adapter lora_winogrande_40 loss: 1.222955346107483
[2025-12-23 16:14:20,910] m-LoRA: Adapter lora_winogrande_37 epoch: 1/1 iteration: 64/128 step: 9
[2025-12-23 16:14:21,102] m-LoRA: Adapter lora_winogrande_20 loss: 0.5441519618034363
[2025-12-23 16:14:21,104] m-LoRA: Adapter lora_winogrande_9 epoch: 1/1 iteration: 112/128 step: 57
[2025-12-23 16:14:21,247] m-LoRA: Adapter lora_winogrande_41 loss: 2.975064992904663
[2025-12-23 16:14:21,249] m-LoRA: Adapter lora_winogrande_38 epoch: 1/1 iteration: 16/128 step: 9
[2025-12-23 16:14:21,328] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_26']
[2025-12-23 16:14:21,758] m-LoRA: Adapter lora_winogrande_29 loss: 0.5330671072006226
[2025-12-23 16:14:21,768] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_42']
[2025-12-23 16:14:21,848] m-LoRA: Adapter lora_winogrande_42 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:14:21,936] m-LoRA: Adapter lora_winogrande_37 loss: 1.7015527486801147
[2025-12-23 16:14:21,939] m-LoRA: Adapter lora_winogrande_34 epoch: 1/1 iteration: 32/128 step: 17
[2025-12-23 16:14:22,071] m-LoRA: Adapter lora_winogrande_32 epoch: 1/1 iteration: 48/128 step: 25
[2025-12-23 16:14:22,176] m-LoRA: Adapter lora_winogrande_18 epoch: 1/1 iteration: 96/128 step: 49
[2025-12-23 16:14:22,244] m-LoRA: Adapter lora_winogrande_12 epoch: 1/1 iteration: 112/128 step: 57
[2025-12-23 16:14:22,320] m-LoRA: Adapter lora_winogrande_23 epoch: 1/1 iteration: 80/128 step: 41
[2025-12-23 16:14:22,391] m-LoRA: Adapter lora_winogrande_33 epoch: 1/1 iteration: 48/128 step: 25
[2025-12-23 16:14:22,477] m-LoRA: Adapter lora_winogrande_11 epoch: 1/1 iteration: 112/128 step: 57
[2025-12-23 16:14:22,577] m-LoRA: Adapter lora_winogrande_39 epoch: 1/1 iteration: 32/128 step: 9
[2025-12-23 16:14:22,660] m-LoRA: Adapter lora_winogrande_0 epoch: 1/1 iteration: 114/128 step: 58
[2025-12-23 16:14:22,901] m-LoRA: Adapter lora_winogrande_9 loss: 0.6435588002204895
[2025-12-23 16:14:23,074] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_40']
[2025-12-23 16:14:23,584] m-LoRA: Adapter lora_winogrande_38 loss: 0.6065083742141724
[2025-12-23 16:14:23,587] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_43']
[2025-12-23 16:14:23,680] m-LoRA: Adapter lora_winogrande_43 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:14:23,808] m-LoRA: Adapter lora_winogrande_42 loss: 2.850125789642334
[2025-12-23 16:14:23,810] m-LoRA: Adapter lora_winogrande_20 epoch: 1/1 iteration: 96/128 step: 49
[2025-12-23 16:14:23,939] m-LoRA: Adapter lora_winogrande_18 loss: 0.7657004594802856
[2025-12-23 16:14:23,942] m-LoRA: Adapter lora_winogrande_41 epoch: 1/1 iteration: 4/128 step: 2
[2025-12-23 16:14:24,092] m-LoRA: Adapter lora_winogrande_34 loss: 0.6811781525611877
[2025-12-23 16:14:24,095] m-LoRA: Adapter lora_winogrande_29 epoch: 1/1 iteration: 50/128 step: 26
[2025-12-23 16:14:24,223] m-LoRA: Adapter lora_winogrande_32 loss: 1.730068564414978
[2025-12-23 16:14:24,225] m-LoRA: Adapter lora_winogrande_37 epoch: 1/1 iteration: 72/128 step: 10
[2025-12-23 16:14:24,365] m-LoRA: Adapter lora_winogrande_12 loss: 0.4349798262119293
[2025-12-23 16:14:24,368] m-LoRA: Adapter lora_winogrande_9 epoch: 1/1 iteration: 114/128 step: 58
[2025-12-23 16:14:24,474] m-LoRA: Adapter lora_winogrande_23 loss: 1.2031008005142212
[2025-12-23 16:14:24,477] m-LoRA: Adapter lora_winogrande_38 epoch: 1/1 iteration: 18/128 step: 10
[2025-12-23 16:14:24,632] m-LoRA: Adapter lora_winogrande_33 loss: 0.5170782804489136
[2025-12-23 16:14:24,634] m-LoRA: Adapter lora_winogrande_42 epoch: 1/1 iteration: 2/128 step: 2
[2025-12-23 16:14:24,741] m-LoRA: Adapter lora_winogrande_11 loss: 0.4841160178184509
[2025-12-23 16:14:24,743] m-LoRA: Adapter lora_winogrande_18 epoch: 1/1 iteration: 98/128 step: 50
[2025-12-23 16:14:24,838] m-LoRA: Adapter lora_winogrande_39 loss: 0.7330938577651978
[2025-12-23 16:14:24,841] m-LoRA: Adapter lora_winogrande_34 epoch: 1/1 iteration: 34/128 step: 18
[2025-12-23 16:14:24,947] m-LoRA: Adapter lora_winogrande_0 loss: 0.5839385390281677
[2025-12-23 16:14:24,949] m-LoRA: Adapter lora_winogrande_32 epoch: 1/1 iteration: 50/128 step: 26
[2025-12-23 16:14:25,506] m-LoRA: Adapter lora_winogrande_12 epoch: 1/1 iteration: 114/128 step: 58
[2025-12-23 16:14:25,621] m-LoRA: Adapter lora_winogrande_43 loss: 3.339824676513672
[2025-12-23 16:14:25,628] m-LoRA: Adapter lora_winogrande_23 epoch: 1/1 iteration: 82/128 step: 42
[2025-12-23 16:14:25,673] m-LoRA: Adapter lora_winogrande_20 loss: 0.424448162317276
[2025-12-23 16:14:25,882] m-LoRA: Adapter lora_winogrande_41 loss: 2.620728015899658
[2025-12-23 16:14:25,885] m-LoRA: Adapter lora_winogrande_33 epoch: 1/1 iteration: 50/128 step: 26
[2025-12-23 16:14:26,024] m-LoRA: Adapter lora_winogrande_29 loss: 0.5334228277206421
[2025-12-23 16:14:26,026] m-LoRA: Adapter lora_winogrande_11 epoch: 1/1 iteration: 114/128 step: 58
[2025-12-23 16:14:26,275] m-LoRA: Adapter lora_winogrande_37 loss: 1.492347002029419
[2025-12-23 16:14:26,279] m-LoRA: Adapter lora_winogrande_39 epoch: 1/1 iteration: 36/128 step: 10
[2025-12-23 16:14:26,454] m-LoRA: Adapter lora_winogrande_9 loss: 0.6369677782058716
[2025-12-23 16:14:26,456] m-LoRA: Adapter lora_winogrande_0 epoch: 1/1 iteration: 116/128 step: 59
[2025-12-23 16:14:26,502] m-LoRA: Adapter lora_winogrande_38 loss: 0.6479367613792419
[2025-12-23 16:14:26,506] m-LoRA: Adapter lora_winogrande_42 loss: 2.3959200382232666
[2025-12-23 16:14:26,548] m-LoRA: Adapter lora_winogrande_18 loss: 0.8686848282814026
[2025-12-23 16:14:26,674] m-LoRA: Adapter lora_winogrande_34 loss: 0.5904648303985596
[2025-12-23 16:14:26,754] m-LoRA: Adapter lora_winogrande_32 loss: 1.6608003377914429
[2025-12-23 16:14:26,839] m-LoRA: Adapter lora_winogrande_12 loss: 0.548672080039978
[2025-12-23 16:14:26,945] m-LoRA: Adapter lora_winogrande_23 loss: 0.9783226847648621
[2025-12-23 16:14:27,107] m-LoRA: Adapter lora_winogrande_33 loss: 0.631380021572113
[2025-12-23 16:14:27,110] m-LoRA: Adapter lora_winogrande_43 epoch: 1/1 iteration: 16/128 step: 2
[2025-12-23 16:14:27,274] m-LoRA: Adapter lora_winogrande_11 loss: 0.490219384431839
[2025-12-23 16:14:27,276] m-LoRA: Adapter lora_winogrande_20 epoch: 1/1 iteration: 98/128 step: 50
[2025-12-23 16:14:27,426] m-LoRA: Adapter lora_winogrande_39 loss: 0.6029534339904785
[2025-12-23 16:14:27,428] m-LoRA: Adapter lora_winogrande_41 epoch: 1/1 iteration: 8/128 step: 3
[2025-12-23 16:14:27,569] m-LoRA: Adapter lora_winogrande_0 loss: 0.562379777431488
[2025-12-23 16:14:27,571] m-LoRA: Adapter lora_winogrande_29 epoch: 1/1 iteration: 52/128 step: 27
[2025-12-23 16:14:27,676] m-LoRA: Adapter lora_winogrande_37 epoch: 1/1 iteration: 80/128 step: 11
[2025-12-23 16:14:28,417] m-LoRA: Adapter lora_winogrande_43 loss: 3.2990520000457764
[2025-12-23 16:14:28,423] m-LoRA: Adapter lora_winogrande_9 epoch: 1/1 iteration: 116/128 step: 59
[2025-12-23 16:14:28,627] m-LoRA: Adapter lora_winogrande_20 loss: 0.5206903219223022
[2025-12-23 16:14:28,629] m-LoRA: Adapter lora_winogrande_38 epoch: 1/1 iteration: 20/128 step: 11
[2025-12-23 16:14:28,767] m-LoRA: Adapter lora_winogrande_41 loss: 2.1900012493133545
[2025-12-23 16:14:28,769] m-LoRA: Adapter lora_winogrande_42 epoch: 1/1 iteration: 4/128 step: 3
[2025-12-23 16:14:28,891] m-LoRA: Adapter lora_winogrande_29 loss: 0.5779740214347839
[2025-12-23 16:14:28,893] m-LoRA: Adapter lora_winogrande_18 epoch: 1/1 iteration: 100/128 step: 51
[2025-12-23 16:14:29,081] m-LoRA: Adapter lora_winogrande_37 loss: 1.4628938436508179
[2025-12-23 16:14:29,086] m-LoRA: Adapter lora_winogrande_34 epoch: 1/1 iteration: 36/128 step: 19
[2025-12-23 16:14:29,231] m-LoRA: Adapter lora_winogrande_9 loss: 0.8372047543525696
[2025-12-23 16:14:29,310] m-LoRA: Adapter lora_winogrande_32 epoch: 1/1 iteration: 52/128 step: 27
[2025-12-23 16:14:29,441] m-LoRA: Adapter lora_winogrande_23 epoch: 1/1 iteration: 84/128 step: 43
[2025-12-23 16:14:29,570] m-LoRA: Adapter lora_winogrande_38 loss: 0.4823783040046692
[2025-12-23 16:14:29,572] m-LoRA: Adapter lora_winogrande_12 epoch: 1/1 iteration: 116/128 step: 59
[2025-12-23 16:14:29,700] m-LoRA: Adapter lora_winogrande_42 loss: 2.4495062828063965
[2025-12-23 16:14:29,702] m-LoRA: Adapter lora_winogrande_11 epoch: 1/1 iteration: 116/128 step: 59
[2025-12-23 16:14:29,820] m-LoRA: Adapter lora_winogrande_33 epoch: 1/1 iteration: 52/128 step: 27
[2025-12-23 16:14:29,924] m-LoRA: Adapter lora_winogrande_18 loss: 0.797631561756134
[2025-12-23 16:14:29,926] m-LoRA: Adapter lora_winogrande_39 epoch: 1/1 iteration: 40/128 step: 11
[2025-12-23 16:14:30,040] m-LoRA: Adapter lora_winogrande_34 loss: 0.6653615236282349
[2025-12-23 16:14:30,042] m-LoRA: Adapter lora_winogrande_0 epoch: 1/1 iteration: 118/128 step: 60
[2025-12-23 16:14:30,150] m-LoRA: Adapter lora_winogrande_43 epoch: 1/1 iteration: 32/128 step: 3
[2025-12-23 16:14:30,292] m-LoRA: Adapter lora_winogrande_32 loss: 1.6475402116775513
[2025-12-23 16:14:30,295] m-LoRA: Adapter lora_winogrande_20 epoch: 1/1 iteration: 100/128 step: 51
[2025-12-23 16:14:30,431] m-LoRA: Adapter lora_winogrande_23 loss: 0.9370675086975098
[2025-12-23 16:14:30,433] m-LoRA: Adapter lora_winogrande_41 epoch: 1/1 iteration: 12/128 step: 4
[2025-12-23 16:14:30,556] m-LoRA: Adapter lora_winogrande_12 loss: 0.5212422609329224
[2025-12-23 16:14:30,559] m-LoRA: Adapter lora_winogrande_29 epoch: 1/1 iteration: 54/128 step: 28
[2025-12-23 16:14:30,693] m-LoRA: Adapter lora_winogrande_11 loss: 0.5272571444511414
[2025-12-23 16:14:30,695] m-LoRA: Adapter lora_winogrande_37 epoch: 1/1 iteration: 88/128 step: 12
[2025-12-23 16:14:30,826] m-LoRA: Adapter lora_winogrande_33 loss: 0.5743237733840942
[2025-12-23 16:14:30,828] m-LoRA: Adapter lora_winogrande_9 epoch: 1/1 iteration: 118/128 step: 60
[2025-12-23 16:14:30,940] m-LoRA: Adapter lora_winogrande_38 epoch: 1/1 iteration: 22/128 step: 12
[2025-12-23 16:14:31,037] m-LoRA: Adapter lora_winogrande_39 loss: 0.5961073040962219
[2025-12-23 16:14:31,040] m-LoRA: Adapter lora_winogrande_42 epoch: 1/1 iteration: 6/128 step: 4
[2025-12-23 16:14:31,205] m-LoRA: Adapter lora_winogrande_0 loss: 0.506719172000885
[2025-12-23 16:14:31,209] m-LoRA: Adapter lora_winogrande_18 epoch: 1/1 iteration: 102/128 step: 52
[2025-12-23 16:14:31,299] m-LoRA: Adapter lora_winogrande_34 epoch: 1/1 iteration: 38/128 step: 20
[2025-12-23 16:14:31,374] m-LoRA: Adapter lora_winogrande_32 epoch: 1/1 iteration: 54/128 step: 28
[2025-12-23 16:14:31,458] m-LoRA: Adapter lora_winogrande_23 epoch: 1/1 iteration: 86/128 step: 44
[2025-12-23 16:14:31,982] m-LoRA: Adapter lora_winogrande_43 loss: 3.0800232887268066
[2025-12-23 16:14:31,988] m-LoRA: Adapter lora_winogrande_12 epoch: 1/1 iteration: 118/128 step: 60
[2025-12-23 16:14:32,227] m-LoRA: Adapter lora_winogrande_20 loss: 0.6523345112800598
[2025-12-23 16:14:32,229] m-LoRA: Adapter lora_winogrande_11 epoch: 1/1 iteration: 118/128 step: 60
[2025-12-23 16:14:32,348] m-LoRA: Adapter lora_winogrande_41 loss: 1.9540597200393677
[2025-12-23 16:14:32,351] m-LoRA: Adapter lora_winogrande_33 epoch: 1/1 iteration: 54/128 step: 28
[2025-12-23 16:14:32,475] m-LoRA: Adapter lora_winogrande_29 loss: 0.4325162172317505
[2025-12-23 16:14:32,477] m-LoRA: Adapter lora_winogrande_39 epoch: 1/1 iteration: 44/128 step: 12
[2025-12-23 16:14:32,636] m-LoRA: Adapter lora_winogrande_37 loss: 1.3221652507781982
[2025-12-23 16:14:32,640] m-LoRA: Adapter lora_winogrande_0 epoch: 1/1 iteration: 120/128 step: 61
[2025-12-23 16:14:32,681] m-LoRA: Adapter lora_winogrande_9 loss: 0.7666529417037964
[2025-12-23 16:14:32,732] m-LoRA: Adapter lora_winogrande_38 loss: 0.510180652141571
[2025-12-23 16:14:32,873] m-LoRA: Adapter lora_winogrande_42 loss: 2.060049057006836
[2025-12-23 16:14:33,005] m-LoRA: Adapter lora_winogrande_18 loss: 0.8319283723831177
[2025-12-23 16:14:33,095] m-LoRA: Adapter lora_winogrande_34 loss: 0.5177940726280212
[2025-12-23 16:14:33,194] m-LoRA: Adapter lora_winogrande_32 loss: 1.6912776231765747
[2025-12-23 16:14:33,363] m-LoRA: Adapter lora_winogrande_23 loss: 0.9024000763893127
[2025-12-23 16:14:33,365] m-LoRA: Adapter lora_winogrande_43 epoch: 1/1 iteration: 48/128 step: 4
[2025-12-23 16:14:33,540] m-LoRA: Adapter lora_winogrande_12 loss: 0.4312431216239929
[2025-12-23 16:14:33,542] m-LoRA: Adapter lora_winogrande_20 epoch: 1/1 iteration: 102/128 step: 52
[2025-12-23 16:14:33,665] m-LoRA: Adapter lora_winogrande_11 loss: 0.5615063905715942
[2025-12-23 16:14:33,668] m-LoRA: Adapter lora_winogrande_41 epoch: 1/1 iteration: 16/128 step: 5
[2025-12-23 16:14:33,782] m-LoRA: Adapter lora_winogrande_33 loss: 0.41506922245025635
[2025-12-23 16:14:33,784] m-LoRA: Adapter lora_winogrande_29 epoch: 1/1 iteration: 56/128 step: 29
[2025-12-23 16:14:33,889] m-LoRA: Adapter lora_winogrande_39 loss: 0.6423096060752869
[2025-12-23 16:14:33,892] m-LoRA: Adapter lora_winogrande_37 epoch: 1/1 iteration: 96/128 step: 13
[2025-12-23 16:14:33,958] m-LoRA: Adapter lora_winogrande_0 loss: 0.550023078918457
[2025-12-23 16:14:34,688] m-LoRA: Adapter lora_winogrande_43 loss: 3.165243148803711
[2025-12-23 16:14:34,694] m-LoRA: Adapter lora_winogrande_9 epoch: 1/1 iteration: 120/128 step: 61
[2025-12-23 16:14:34,864] m-LoRA: Adapter lora_winogrande_20 loss: 0.44553619623184204
[2025-12-23 16:14:34,866] m-LoRA: Adapter lora_winogrande_38 epoch: 1/1 iteration: 24/128 step: 13
[2025-12-23 16:14:35,009] m-LoRA: Adapter lora_winogrande_41 loss: 1.755505084991455
[2025-12-23 16:14:35,011] m-LoRA: Adapter lora_winogrande_42 epoch: 1/1 iteration: 8/128 step: 5
[2025-12-23 16:14:35,136] m-LoRA: Adapter lora_winogrande_29 loss: 0.4631253182888031
[2025-12-23 16:14:35,138] m-LoRA: Adapter lora_winogrande_18 epoch: 1/1 iteration: 104/128 step: 53
[2025-12-23 16:14:35,339] m-LoRA: Adapter lora_winogrande_37 loss: 1.1981061697006226
[2025-12-23 16:14:35,342] m-LoRA: Adapter lora_winogrande_34 epoch: 1/1 iteration: 40/128 step: 21
[2025-12-23 16:14:35,498] m-LoRA: Adapter lora_winogrande_9 loss: 0.6160172820091248
[2025-12-23 16:14:35,500] m-LoRA: Adapter lora_winogrande_0 epoch: 1/1 iteration: 122/128 step: 62
[2025-12-23 16:14:35,683] m-LoRA: Adapter lora_winogrande_32 epoch: 1/1 iteration: 56/128 step: 29
[2025-12-23 16:14:35,803] m-LoRA: Adapter lora_winogrande_38 loss: 0.5686720609664917
[2025-12-23 16:14:35,806] m-LoRA: Adapter lora_winogrande_11 epoch: 1/1 iteration: 120/128 step: 61
[2025-12-23 16:14:35,933] m-LoRA: Adapter lora_winogrande_42 loss: 1.7011709213256836
[2025-12-23 16:14:35,935] m-LoRA: Adapter lora_winogrande_33 epoch: 1/1 iteration: 56/128 step: 29
[2025-12-23 16:14:36,059] m-LoRA: Adapter lora_winogrande_23 epoch: 1/1 iteration: 88/128 step: 45
[2025-12-23 16:14:36,152] m-LoRA: Adapter lora_winogrande_18 loss: 0.7798640131950378
[2025-12-23 16:14:36,154] m-LoRA: Adapter lora_winogrande_12 epoch: 1/1 iteration: 120/128 step: 61
[2025-12-23 16:14:36,275] m-LoRA: Adapter lora_winogrande_34 loss: 0.501335084438324
[2025-12-23 16:14:36,278] m-LoRA: Adapter lora_winogrande_39 epoch: 1/1 iteration: 48/128 step: 13
[2025-12-23 16:14:36,414] m-LoRA: Adapter lora_winogrande_43 epoch: 1/1 iteration: 64/128 step: 5
[2025-12-23 16:14:36,561] m-LoRA: Adapter lora_winogrande_0 loss: 0.5916987061500549
[2025-12-23 16:14:36,563] m-LoRA: Adapter lora_winogrande_20 epoch: 1/1 iteration: 104/128 step: 53
[2025-12-23 16:14:36,709] m-LoRA: Adapter lora_winogrande_32 loss: 1.5662132501602173
[2025-12-23 16:14:36,711] m-LoRA: Adapter lora_winogrande_41 epoch: 1/1 iteration: 20/128 step: 6
[2025-12-23 16:14:36,854] m-LoRA: Adapter lora_winogrande_11 loss: 0.4319317936897278
[2025-12-23 16:14:36,857] m-LoRA: Adapter lora_winogrande_29 epoch: 1/1 iteration: 58/128 step: 30
[2025-12-23 16:14:37,000] m-LoRA: Adapter lora_winogrande_33 loss: 0.5169689655303955
[2025-12-23 16:14:37,002] m-LoRA: Adapter lora_winogrande_37 epoch: 1/1 iteration: 104/128 step: 14
[2025-12-23 16:14:37,144] m-LoRA: Adapter lora_winogrande_23 loss: 0.8233984708786011
[2025-12-23 16:14:37,147] m-LoRA: Adapter lora_winogrande_9 epoch: 1/1 iteration: 122/128 step: 62
[2025-12-23 16:14:37,262] m-LoRA: Adapter lora_winogrande_12 loss: 0.3683706820011139
[2025-12-23 16:14:37,264] m-LoRA: Adapter lora_winogrande_38 epoch: 1/1 iteration: 26/128 step: 14
[2025-12-23 16:14:37,456] m-LoRA: Adapter lora_winogrande_39 loss: 0.6284953355789185
[2025-12-23 16:14:37,458] m-LoRA: Adapter lora_winogrande_42 epoch: 1/1 iteration: 10/128 step: 6
[2025-12-23 16:14:37,571] m-LoRA: Adapter lora_winogrande_18 epoch: 1/1 iteration: 106/128 step: 54
[2025-12-23 16:14:37,661] m-LoRA: Adapter lora_winogrande_34 epoch: 1/1 iteration: 42/128 step: 22
[2025-12-23 16:14:38,049] m-LoRA: Adapter lora_winogrande_0 epoch: 1/1 iteration: 124/128 step: 63
[2025-12-23 16:14:38,142] m-LoRA: Adapter lora_winogrande_43 loss: 2.9189953804016113
[2025-12-23 16:14:38,149] m-LoRA: Adapter lora_winogrande_32 epoch: 1/1 iteration: 58/128 step: 30
[2025-12-23 16:14:38,190] m-LoRA: Adapter lora_winogrande_20 loss: 0.5093987584114075
[2025-12-23 16:14:38,419] m-LoRA: Adapter lora_winogrande_41 loss: 1.381136178970337
[2025-12-23 16:14:38,422] m-LoRA: Adapter lora_winogrande_11 epoch: 1/1 iteration: 122/128 step: 62
[2025-12-23 16:14:38,562] m-LoRA: Adapter lora_winogrande_29 loss: 0.4928969442844391
[2025-12-23 16:14:38,564] m-LoRA: Adapter lora_winogrande_33 epoch: 1/1 iteration: 58/128 step: 30
[2025-12-23 16:14:39,122] m-LoRA: Adapter lora_winogrande_37 loss: 1.1034350395202637
[2025-12-23 16:14:39,126] m-LoRA: Adapter lora_winogrande_23 epoch: 1/1 iteration: 90/128 step: 46
[2025-12-23 16:14:39,349] m-LoRA: Adapter lora_winogrande_9 loss: 0.6409487128257751
[2025-12-23 16:14:39,351] m-LoRA: Adapter lora_winogrande_12 epoch: 1/1 iteration: 122/128 step: 62
[2025-12-23 16:14:39,532] m-LoRA: Adapter lora_winogrande_38 loss: 0.5561249256134033
[2025-12-23 16:14:39,534] m-LoRA: Adapter lora_winogrande_39 epoch: 1/1 iteration: 52/128 step: 14
[2025-12-23 16:14:39,708] m-LoRA: Adapter lora_winogrande_42 loss: 1.6211388111114502
[2025-12-23 16:14:39,711] m-LoRA: Adapter lora_winogrande_43 epoch: 1/1 iteration: 80/128 step: 6
[2025-12-23 16:14:39,878] m-LoRA: Adapter lora_winogrande_18 loss: 0.697323739528656
[2025-12-23 16:14:39,880] m-LoRA: Adapter lora_winogrande_20 epoch: 1/1 iteration: 106/128 step: 54
[2025-12-23 16:14:40,092] m-LoRA: Adapter lora_winogrande_34 loss: 0.43178504705429077
[2025-12-23 16:14:40,095] m-LoRA: Adapter lora_winogrande_41 epoch: 1/1 iteration: 24/128 step: 7
[2025-12-23 16:14:40,215] m-LoRA: Adapter lora_winogrande_0 loss: 0.5557746887207031
[2025-12-23 16:14:40,217] m-LoRA: Adapter lora_winogrande_29 epoch: 1/1 iteration: 60/128 step: 31
[2025-12-23 16:14:40,385] m-LoRA: Adapter lora_winogrande_32 loss: 1.5817149877548218
[2025-12-23 16:14:40,387] m-LoRA: Adapter lora_winogrande_37 epoch: 1/1 iteration: 112/128 step: 15
[2025-12-23 16:14:40,548] m-LoRA: Adapter lora_winogrande_11 loss: 0.4991907477378845
[2025-12-23 16:14:40,550] m-LoRA: Adapter lora_winogrande_9 epoch: 1/1 iteration: 124/128 step: 63
[2025-12-23 16:14:40,680] m-LoRA: Adapter lora_winogrande_33 loss: 0.6621715426445007
[2025-12-23 16:14:40,682] m-LoRA: Adapter lora_winogrande_38 epoch: 1/1 iteration: 28/128 step: 15
[2025-12-23 16:14:40,823] m-LoRA: Adapter lora_winogrande_23 loss: 0.9032714366912842
[2025-12-23 16:14:40,825] m-LoRA: Adapter lora_winogrande_42 epoch: 1/1 iteration: 12/128 step: 7
[2025-12-23 16:14:41,020] m-LoRA: Adapter lora_winogrande_12 loss: 0.545613169670105
[2025-12-23 16:14:41,022] m-LoRA: Adapter lora_winogrande_18 epoch: 1/1 iteration: 108/128 step: 55
[2025-12-23 16:14:41,150] m-LoRA: Adapter lora_winogrande_39 loss: 0.6013711094856262
[2025-12-23 16:14:41,152] m-LoRA: Adapter lora_winogrande_34 epoch: 1/1 iteration: 44/128 step: 23
[2025-12-23 16:14:41,658] m-LoRA: Adapter lora_winogrande_43 loss: 2.816258668899536
[2025-12-23 16:14:41,664] m-LoRA: Adapter lora_winogrande_0 epoch: 1/1 iteration: 126/128 step: 64
[2025-12-23 16:14:41,872] m-LoRA: Adapter lora_winogrande_20 loss: 0.5491145253181458
[2025-12-23 16:14:41,894] m-LoRA: Adapter lora_winogrande_32 epoch: 1/1 iteration: 60/128 step: 31
[2025-12-23 16:14:42,026] m-LoRA: Adapter lora_winogrande_41 loss: 1.133203387260437
[2025-12-23 16:14:42,028] m-LoRA: Adapter lora_winogrande_11 epoch: 1/1 iteration: 124/128 step: 63
[2025-12-23 16:14:42,175] m-LoRA: Adapter lora_winogrande_29 loss: 0.5379457473754883
[2025-12-23 16:14:42,177] m-LoRA: Adapter lora_winogrande_33 epoch: 1/1 iteration: 60/128 step: 31
[2025-12-23 16:14:42,370] m-LoRA: Adapter lora_winogrande_37 loss: 1.0099185705184937
[2025-12-23 16:14:42,374] m-LoRA: Adapter lora_winogrande_23 epoch: 1/1 iteration: 92/128 step: 47
[2025-12-23 16:14:42,534] m-LoRA: Adapter lora_winogrande_9 loss: 0.7774561047554016
[2025-12-23 16:14:42,536] m-LoRA: Adapter lora_winogrande_12 epoch: 1/1 iteration: 124/128 step: 63
[2025-12-23 16:14:42,698] m-LoRA: Adapter lora_winogrande_38 loss: 0.5438343286514282
[2025-12-23 16:14:42,700] m-LoRA: Adapter lora_winogrande_39 epoch: 1/1 iteration: 56/128 step: 15
[2025-12-23 16:14:42,754] m-LoRA: Adapter lora_winogrande_42 loss: 1.3644471168518066
[2025-12-23 16:14:42,758] m-LoRA: Adapter lora_winogrande_18 loss: 0.6541520953178406
[2025-12-23 16:14:42,841] m-LoRA: Adapter lora_winogrande_34 loss: 0.5440152883529663
[2025-12-23 16:14:42,953] m-LoRA: Adapter lora_winogrande_0 loss: 0.4252980053424835
[2025-12-23 16:14:43,139] m-LoRA: Adapter lora_winogrande_32 loss: 1.7036035060882568
[2025-12-23 16:14:43,141] m-LoRA: Adapter lora_winogrande_43 epoch: 1/1 iteration: 96/128 step: 7
[2025-12-23 16:14:43,299] m-LoRA: Adapter lora_winogrande_11 loss: 0.46316394209861755
[2025-12-23 16:14:43,301] m-LoRA: Adapter lora_winogrande_20 epoch: 1/1 iteration: 108/128 step: 55
[2025-12-23 16:14:43,431] m-LoRA: Adapter lora_winogrande_33 loss: 0.5720087289810181
[2025-12-23 16:14:43,433] m-LoRA: Adapter lora_winogrande_41 epoch: 1/1 iteration: 28/128 step: 8
[2025-12-23 16:14:43,568] m-LoRA: Adapter lora_winogrande_23 loss: 0.8237243890762329
[2025-12-23 16:14:43,571] m-LoRA: Adapter lora_winogrande_29 epoch: 1/1 iteration: 62/128 step: 32
[2025-12-23 16:14:43,621] m-LoRA: Adapter lora_winogrande_12 loss: 0.41392841935157776
[2025-12-23 16:14:43,918] m-LoRA: Adapter lora_winogrande_39 loss: 0.4860450029373169
[2025-12-23 16:14:43,932] m-LoRA: Adapter lora_winogrande_37 epoch: 1/1 iteration: 120/128 step: 16
[2025-12-23 16:14:44,092] m-LoRA: Adapter lora_winogrande_9 epoch: 1/1 iteration: 126/128 step: 64
[2025-12-23 16:14:44,689] m-LoRA: Adapter lora_winogrande_43 loss: 2.6480872631073
[2025-12-23 16:14:44,696] m-LoRA: Adapter lora_winogrande_38 epoch: 1/1 iteration: 30/128 step: 16
[2025-12-23 16:14:44,928] m-LoRA: Adapter lora_winogrande_20 loss: 0.4649398922920227
[2025-12-23 16:14:44,930] m-LoRA: Adapter lora_winogrande_42 epoch: 1/1 iteration: 14/128 step: 8
[2025-12-23 16:14:45,033] m-LoRA: Adapter lora_winogrande_41 loss: 0.9043397903442383
[2025-12-23 16:14:45,036] m-LoRA: Adapter lora_winogrande_18 epoch: 1/1 iteration: 110/128 step: 56
[2025-12-23 16:14:45,128] m-LoRA: Adapter lora_winogrande_29 loss: 0.3691088557243347
[2025-12-23 16:14:45,130] m-LoRA: Adapter lora_winogrande_34 epoch: 1/1 iteration: 46/128 step: 24
[2025-12-23 16:14:45,306] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_0']
[2025-12-23 16:14:45,668] m-LoRA: Adapter lora_winogrande_37 loss: 0.9464111328125
[2025-12-23 16:14:45,671] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_44']
[2025-12-23 16:14:45,812] m-LoRA: Adapter lora_winogrande_44 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:14:45,918] m-LoRA: Adapter lora_winogrande_9 loss: 0.6135628819465637
[2025-12-23 16:14:45,920] m-LoRA: Adapter lora_winogrande_32 epoch: 1/1 iteration: 62/128 step: 32
[2025-12-23 16:14:46,014] m-LoRA: Adapter lora_winogrande_38 loss: 0.6617115139961243
[2025-12-23 16:14:46,016] m-LoRA: Adapter lora_winogrande_11 epoch: 1/1 iteration: 126/128 step: 64
[2025-12-23 16:14:46,150] m-LoRA: Adapter lora_winogrande_42 loss: 1.1299858093261719
[2025-12-23 16:14:46,152] m-LoRA: Adapter lora_winogrande_33 epoch: 1/1 iteration: 62/128 step: 32
[2025-12-23 16:14:46,266] m-LoRA: Adapter lora_winogrande_18 loss: 0.7047942280769348
[2025-12-23 16:14:46,269] m-LoRA: Adapter lora_winogrande_23 epoch: 1/1 iteration: 94/128 step: 48
[2025-12-23 16:14:46,393] m-LoRA: Adapter lora_winogrande_34 loss: 0.6170726418495178
[2025-12-23 16:14:46,395] m-LoRA: Adapter lora_winogrande_12 epoch: 1/1 iteration: 126/128 step: 64
[2025-12-23 16:14:46,522] m-LoRA: Adapter lora_winogrande_39 epoch: 1/1 iteration: 60/128 step: 16
[2025-12-23 16:14:46,623] m-LoRA: Adapter lora_winogrande_43 epoch: 1/1 iteration: 112/128 step: 8
[2025-12-23 16:14:46,778] m-LoRA: Adapter lora_winogrande_20 epoch: 1/1 iteration: 110/128 step: 56
[2025-12-23 16:14:46,865] m-LoRA: Adapter lora_winogrande_44 loss: 3.0884344577789307
[2025-12-23 16:14:46,868] m-LoRA: Adapter lora_winogrande_41 epoch: 1/1 iteration: 32/128 step: 9
[2025-12-23 16:14:47,055] m-LoRA: Adapter lora_winogrande_32 loss: 1.3654587268829346
[2025-12-23 16:14:47,057] m-LoRA: Adapter lora_winogrande_29 epoch: 1/1 iteration: 64/128 step: 33
[2025-12-23 16:14:47,205] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_37']
[2025-12-23 16:14:47,398] m-LoRA: Adapter lora_winogrande_11 loss: 0.4783649146556854
[2025-12-23 16:14:47,418] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_45']
[2025-12-23 16:14:47,590] m-LoRA: Adapter lora_winogrande_45 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:14:47,753] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_9']
[2025-12-23 16:14:47,990] m-LoRA: Adapter lora_winogrande_33 loss: 0.44398418068885803
[2025-12-23 16:14:47,992] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_46']
[2025-12-23 16:14:48,088] m-LoRA: Adapter lora_winogrande_46 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:14:48,210] m-LoRA: Adapter lora_winogrande_23 loss: 0.751723051071167
[2025-12-23 16:14:48,212] m-LoRA: Adapter lora_winogrande_38 epoch: 1/1 iteration: 32/128 step: 17
[2025-12-23 16:14:48,312] m-LoRA: Adapter lora_winogrande_12 loss: 0.5910012722015381
[2025-12-23 16:14:48,314] m-LoRA: Adapter lora_winogrande_42 epoch: 1/1 iteration: 16/128 step: 9
[2025-12-23 16:14:48,507] m-LoRA: Adapter lora_winogrande_39 loss: 0.49185910820961
[2025-12-23 16:14:48,548] m-LoRA: Adapter lora_winogrande_18 epoch: 1/1 iteration: 112/128 step: 57
[2025-12-23 16:14:48,724] m-LoRA: Adapter lora_winogrande_43 loss: 2.5187408924102783
[2025-12-23 16:14:48,731] m-LoRA: Adapter lora_winogrande_34 epoch: 1/1 iteration: 48/128 step: 25
[2025-12-23 16:14:48,891] m-LoRA: Adapter lora_winogrande_20 loss: 0.4933146834373474
[2025-12-23 16:14:48,893] m-LoRA: Adapter lora_winogrande_44 epoch: 1/1 iteration: 4/128 step: 2
[2025-12-23 16:14:49,039] m-LoRA: Adapter lora_winogrande_41 loss: 0.7423532009124756
[2025-12-23 16:14:49,042] m-LoRA: Adapter lora_winogrande_32 epoch: 1/1 iteration: 64/128 step: 33
[2025-12-23 16:14:49,131] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_11']
[2025-12-23 16:14:49,815] m-LoRA: Adapter lora_winogrande_29 loss: 0.511345624923706
[2025-12-23 16:14:49,882] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_47']
[2025-12-23 16:14:50,099] m-LoRA: Adapter lora_winogrande_47 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:14:50,227] m-LoRA: Adapter lora_winogrande_45 loss: 3.3506484031677246
[2025-12-23 16:14:50,234] m-LoRA: Adapter lora_winogrande_33 epoch: 1/1 iteration: 64/128 step: 33
[2025-12-23 16:14:50,372] m-LoRA: Adapter lora_winogrande_23 epoch: 1/1 iteration: 96/128 step: 49
[2025-12-23 16:14:50,620] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_12']
[2025-12-23 16:14:51,095] m-LoRA: Adapter lora_winogrande_46 loss: 3.1170763969421387
[2025-12-23 16:14:51,101] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_48']
[2025-12-23 16:14:51,273] m-LoRA: Adapter lora_winogrande_48 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:14:51,352] m-LoRA: Adapter lora_winogrande_38 loss: 0.5499716997146606
[2025-12-23 16:14:51,354] m-LoRA: Adapter lora_winogrande_39 epoch: 1/1 iteration: 64/128 step: 17
[2025-12-23 16:14:51,426] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_43']
[2025-12-23 16:14:51,717] m-LoRA: Adapter lora_winogrande_42 loss: 0.8561293482780457
[2025-12-23 16:14:51,785] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_49']
[2025-12-23 16:14:51,848] m-LoRA: Adapter lora_winogrande_49 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:14:51,920] m-LoRA: Adapter lora_winogrande_18 loss: 0.6826631426811218
[2025-12-23 16:14:51,922] m-LoRA: Adapter lora_winogrande_20 epoch: 1/1 iteration: 112/128 step: 57
[2025-12-23 16:14:52,068] m-LoRA: Adapter lora_winogrande_34 loss: 0.5005553960800171
[2025-12-23 16:14:52,070] m-LoRA: Adapter lora_winogrande_41 epoch: 1/1 iteration: 36/128 step: 10
[2025-12-23 16:14:52,170] m-LoRA: Adapter lora_winogrande_44 loss: 3.0479795932769775
[2025-12-23 16:14:52,174] m-LoRA: Adapter lora_winogrande_29 epoch: 1/1 iteration: 66/128 step: 34
[2025-12-23 16:14:52,341] m-LoRA: Adapter lora_winogrande_32 loss: 1.3983882665634155
[2025-12-23 16:14:52,343] m-LoRA: Adapter lora_winogrande_45 epoch: 1/1 iteration: 16/128 step: 2
[2025-12-23 16:14:52,403] m-LoRA: Adapter lora_winogrande_47 loss: 3.0144946575164795
[2025-12-23 16:14:52,410] m-LoRA: Adapter lora_winogrande_33 loss: 0.4749184548854828
[2025-12-23 16:14:52,413] m-LoRA: Adapter lora_winogrande_23 loss: 0.7745971083641052
[2025-12-23 16:14:52,546] m-LoRA: Adapter lora_winogrande_48 loss: 2.8379180431365967
[2025-12-23 16:14:52,843] m-LoRA: Adapter lora_winogrande_39 loss: 0.5953344702720642
[2025-12-23 16:14:52,846] m-LoRA: Adapter lora_winogrande_46 epoch: 1/1 iteration: 16/128 step: 2
[2025-12-23 16:14:53,035] m-LoRA: Adapter lora_winogrande_49 loss: 3.102393865585327
[2025-12-23 16:14:53,037] m-LoRA: Adapter lora_winogrande_38 epoch: 1/1 iteration: 34/128 step: 18
[2025-12-23 16:14:53,176] m-LoRA: Adapter lora_winogrande_20 loss: 0.4159907102584839
[2025-12-23 16:14:53,178] m-LoRA: Adapter lora_winogrande_42 epoch: 1/1 iteration: 18/128 step: 10
[2025-12-23 16:14:53,310] m-LoRA: Adapter lora_winogrande_41 loss: 0.6966525316238403
[2025-12-23 16:14:53,314] m-LoRA: Adapter lora_winogrande_18 epoch: 1/1 iteration: 114/128 step: 58
[2025-12-23 16:14:53,434] m-LoRA: Adapter lora_winogrande_29 loss: 0.5665163397789001
[2025-12-23 16:14:53,437] m-LoRA: Adapter lora_winogrande_34 epoch: 1/1 iteration: 50/128 step: 26
[2025-12-23 16:14:54,001] m-LoRA: Adapter lora_winogrande_44 epoch: 1/1 iteration: 8/128 step: 3
[2025-12-23 16:14:54,044] m-LoRA: Adapter lora_winogrande_45 loss: 2.3978898525238037
[2025-12-23 16:14:55,045] m-LoRA: Adapter lora_winogrande_46 loss: 2.860356330871582
[2025-12-23 16:14:55,052] m-LoRA: Adapter lora_winogrande_32 epoch: 1/1 iteration: 66/128 step: 34
[2025-12-23 16:14:55,185] m-LoRA: Adapter lora_winogrande_38 loss: 0.6024680137634277
[2025-12-23 16:14:55,188] m-LoRA: Adapter lora_winogrande_47 epoch: 1/1 iteration: 16/128 step: 2
[2025-12-23 16:14:55,367] m-LoRA: Adapter lora_winogrande_42 loss: 0.8267485499382019
[2025-12-23 16:14:55,369] m-LoRA: Adapter lora_winogrande_33 epoch: 1/1 iteration: 66/128 step: 34
[2025-12-23 16:14:55,453] m-LoRA: Adapter lora_winogrande_18 loss: 0.6854373812675476
[2025-12-23 16:14:55,455] m-LoRA: Adapter lora_winogrande_23 epoch: 1/1 iteration: 98/128 step: 50
[2025-12-23 16:14:55,589] m-LoRA: Adapter lora_winogrande_34 loss: 0.4560021460056305
[2025-12-23 16:14:55,591] m-LoRA: Adapter lora_winogrande_48 epoch: 1/1 iteration: 2/128 step: 2
[2025-12-23 16:14:55,907] m-LoRA: Adapter lora_winogrande_44 loss: 3.0652294158935547
[2025-12-23 16:14:55,910] m-LoRA: Adapter lora_winogrande_39 epoch: 1/1 iteration: 68/128 step: 18
[2025-12-23 16:14:56,154] m-LoRA: Adapter lora_winogrande_32 loss: 1.2469404935836792
[2025-12-23 16:14:56,156] m-LoRA: Adapter lora_winogrande_49 epoch: 1/1 iteration: 4/128 step: 2
[2025-12-23 16:14:56,280] m-LoRA: Adapter lora_winogrande_20 epoch: 1/1 iteration: 114/128 step: 58
[2025-12-23 16:14:56,380] m-LoRA: Adapter lora_winogrande_41 epoch: 1/1 iteration: 40/128 step: 11
[2025-12-23 16:14:56,473] m-LoRA: Adapter lora_winogrande_29 epoch: 1/1 iteration: 68/128 step: 35
[2025-12-23 16:14:56,557] m-LoRA: Adapter lora_winogrande_45 epoch: 1/1 iteration: 32/128 step: 3
[2025-12-23 16:14:56,906] m-LoRA: Adapter lora_winogrande_46 epoch: 1/1 iteration: 32/128 step: 3
[2025-12-23 16:14:57,042] m-LoRA: Adapter lora_winogrande_47 loss: 2.123004913330078
[2025-12-23 16:14:57,049] m-LoRA: Adapter lora_winogrande_38 epoch: 1/1 iteration: 36/128 step: 19
[2025-12-23 16:14:57,231] m-LoRA: Adapter lora_winogrande_33 loss: 0.6107739806175232
[2025-12-23 16:14:57,233] m-LoRA: Adapter lora_winogrande_42 epoch: 1/1 iteration: 20/128 step: 11
[2025-12-23 16:14:57,340] m-LoRA: Adapter lora_winogrande_23 loss: 0.862808883190155
[2025-12-23 16:14:57,342] m-LoRA: Adapter lora_winogrande_18 epoch: 1/1 iteration: 116/128 step: 59
[2025-12-23 16:14:57,368] m-LoRA: Adapter lora_winogrande_48 loss: 3.0517709255218506
[2025-12-23 16:14:57,510] m-LoRA: Adapter lora_winogrande_39 loss: 0.5145811438560486
[2025-12-23 16:14:57,513] m-LoRA: Adapter lora_winogrande_34 epoch: 1/1 iteration: 52/128 step: 27
[2025-12-23 16:14:57,689] m-LoRA: Adapter lora_winogrande_49 loss: 2.846086025238037
[2025-12-23 16:14:57,693] m-LoRA: Adapter lora_winogrande_44 epoch: 1/1 iteration: 12/128 step: 4
[2025-12-23 16:14:57,854] m-LoRA: Adapter lora_winogrande_20 loss: 0.45084792375564575
[2025-12-23 16:14:57,856] m-LoRA: Adapter lora_winogrande_32 epoch: 1/1 iteration: 68/128 step: 35
[2025-12-23 16:14:57,924] m-LoRA: Adapter lora_winogrande_41 loss: 0.81874680519104
[2025-12-23 16:14:57,987] m-LoRA: Adapter lora_winogrande_29 loss: 0.4889601469039917
[2025-12-23 16:14:58,777] m-LoRA: Adapter lora_winogrande_47 epoch: 1/1 iteration: 32/128 step: 3
[2025-12-23 16:14:58,846] m-LoRA: Adapter lora_winogrande_45 loss: 1.8649295568466187
[2025-12-23 16:14:59,505] m-LoRA: Adapter lora_winogrande_46 loss: 2.049365997314453
[2025-12-23 16:14:59,512] m-LoRA: Adapter lora_winogrande_33 epoch: 1/1 iteration: 68/128 step: 35
[2025-12-23 16:14:59,698] m-LoRA: Adapter lora_winogrande_38 loss: 0.6334381103515625
[2025-12-23 16:14:59,727] m-LoRA: Adapter lora_winogrande_23 epoch: 1/1 iteration: 100/128 step: 51
[2025-12-23 16:14:59,854] m-LoRA: Adapter lora_winogrande_42 loss: 0.8931922316551208
[2025-12-23 16:14:59,856] m-LoRA: Adapter lora_winogrande_48 epoch: 1/1 iteration: 4/128 step: 3
[2025-12-23 16:14:59,923] m-LoRA: Adapter lora_winogrande_18 loss: 0.7061395645141602
[2025-12-23 16:14:59,925] m-LoRA: Adapter lora_winogrande_39 epoch: 1/1 iteration: 72/128 step: 19
[2025-12-23 16:15:00,028] m-LoRA: Adapter lora_winogrande_34 loss: 0.5893649458885193
[2025-12-23 16:15:00,030] m-LoRA: Adapter lora_winogrande_49 epoch: 1/1 iteration: 8/128 step: 3
[2025-12-23 16:15:00,143] m-LoRA: Adapter lora_winogrande_44 loss: 2.785951614379883
[2025-12-23 16:15:00,145] m-LoRA: Adapter lora_winogrande_20 epoch: 1/1 iteration: 116/128 step: 59
[2025-12-23 16:15:00,259] m-LoRA: Adapter lora_winogrande_32 loss: 1.3072259426116943
[2025-12-23 16:15:00,261] m-LoRA: Adapter lora_winogrande_41 epoch: 1/1 iteration: 44/128 step: 12
[2025-12-23 16:15:00,806] m-LoRA: Adapter lora_winogrande_29 epoch: 1/1 iteration: 70/128 step: 36
[2025-12-23 16:15:00,957] m-LoRA: Adapter lora_winogrande_47 loss: 1.9951080083847046
[2025-12-23 16:15:00,963] m-LoRA: Adapter lora_winogrande_45 epoch: 1/1 iteration: 48/128 step: 4
[2025-12-23 16:15:01,199] m-LoRA: Adapter lora_winogrande_33 loss: 0.48996803164482117
[2025-12-23 16:15:01,202] m-LoRA: Adapter lora_winogrande_46 epoch: 1/1 iteration: 48/128 step: 4
[2025-12-23 16:15:01,301] m-LoRA: Adapter lora_winogrande_23 loss: 0.7329288125038147
[2025-12-23 16:15:01,310] m-LoRA: Adapter lora_winogrande_38 epoch: 1/1 iteration: 38/128 step: 20
[2025-12-23 16:15:01,407] m-LoRA: Adapter lora_winogrande_48 loss: 2.743870258331299
[2025-12-23 16:15:01,409] m-LoRA: Adapter lora_winogrande_42 epoch: 1/1 iteration: 22/128 step: 12
[2025-12-23 16:15:01,455] m-LoRA: Adapter lora_winogrande_39 loss: 0.5245227217674255
[2025-12-23 16:15:01,580] m-LoRA: Adapter lora_winogrande_49 loss: 2.4142611026763916
[2025-12-23 16:15:01,583] m-LoRA: Adapter lora_winogrande_18 epoch: 1/1 iteration: 118/128 step: 60
[2025-12-23 16:15:01,697] m-LoRA: Adapter lora_winogrande_20 loss: 0.526326596736908
[2025-12-23 16:15:01,700] m-LoRA: Adapter lora_winogrande_34 epoch: 1/1 iteration: 54/128 step: 28
[2025-12-23 16:15:01,835] m-LoRA: Adapter lora_winogrande_41 loss: 0.6849318742752075
[2025-12-23 16:15:01,838] m-LoRA: Adapter lora_winogrande_44 epoch: 1/1 iteration: 16/128 step: 5
[2025-12-23 16:15:02,030] m-LoRA: Adapter lora_winogrande_29 loss: 0.4477984607219696
[2025-12-23 16:15:02,032] m-LoRA: Adapter lora_winogrande_32 epoch: 1/1 iteration: 70/128 step: 36
[2025-12-23 16:15:02,881] m-LoRA: Adapter lora_winogrande_45 loss: 1.692331314086914
[2025-12-23 16:15:02,889] m-LoRA: Adapter lora_winogrande_47 epoch: 1/1 iteration: 48/128 step: 4
[2025-12-23 16:15:03,574] m-LoRA: Adapter lora_winogrande_46 loss: 1.8192906379699707
[2025-12-23 16:15:03,581] m-LoRA: Adapter lora_winogrande_33 epoch: 1/1 iteration: 70/128 step: 36
[2025-12-23 16:15:03,857] m-LoRA: Adapter lora_winogrande_38 loss: 0.6443923115730286
[2025-12-23 16:15:03,859] m-LoRA: Adapter lora_winogrande_23 epoch: 1/1 iteration: 102/128 step: 52
[2025-12-23 16:15:03,964] m-LoRA: Adapter lora_winogrande_42 loss: 0.6602017283439636
[2025-12-23 16:15:03,966] m-LoRA: Adapter lora_winogrande_48 epoch: 1/1 iteration: 6/128 step: 4
[2025-12-23 16:15:04,065] m-LoRA: Adapter lora_winogrande_18 loss: 0.6207404136657715
[2025-12-23 16:15:04,071] m-LoRA: Adapter lora_winogrande_39 epoch: 1/1 iteration: 76/128 step: 20
[2025-12-23 16:15:04,175] m-LoRA: Adapter lora_winogrande_34 loss: 0.4229206442832947
[2025-12-23 16:15:04,177] m-LoRA: Adapter lora_winogrande_49 epoch: 1/1 iteration: 12/128 step: 4
[2025-12-23 16:15:04,267] m-LoRA: Adapter lora_winogrande_44 loss: 3.0178613662719727
[2025-12-23 16:15:04,269] m-LoRA: Adapter lora_winogrande_20 epoch: 1/1 iteration: 118/128 step: 60
[2025-12-23 16:15:04,370] m-LoRA: Adapter lora_winogrande_32 loss: 1.3675307035446167
[2025-12-23 16:15:04,373] m-LoRA: Adapter lora_winogrande_41 epoch: 1/1 iteration: 48/128 step: 13
[2025-12-23 16:15:04,887] m-LoRA: Adapter lora_winogrande_29 epoch: 1/1 iteration: 72/128 step: 37
[2025-12-23 16:15:04,953] m-LoRA: Adapter lora_winogrande_47 loss: 1.6866618394851685
[2025-12-23 16:15:05,198] m-LoRA: Adapter lora_winogrande_33 loss: 0.49008798599243164
[2025-12-23 16:15:05,201] m-LoRA: Adapter lora_winogrande_45 epoch: 1/1 iteration: 64/128 step: 5
[2025-12-23 16:15:05,361] m-LoRA: Adapter lora_winogrande_23 loss: 0.7284972071647644
[2025-12-23 16:15:05,363] m-LoRA: Adapter lora_winogrande_46 epoch: 1/1 iteration: 64/128 step: 5
[2025-12-23 16:15:05,510] m-LoRA: Adapter lora_winogrande_48 loss: 2.7545695304870605
[2025-12-23 16:15:05,513] m-LoRA: Adapter lora_winogrande_38 epoch: 1/1 iteration: 40/128 step: 21
[2025-12-23 16:15:05,679] m-LoRA: Adapter lora_winogrande_39 loss: 0.5733953714370728
[2025-12-23 16:15:05,683] m-LoRA: Adapter lora_winogrande_42 epoch: 1/1 iteration: 24/128 step: 13
[2025-12-23 16:15:05,846] m-LoRA: Adapter lora_winogrande_49 loss: 2.2412259578704834
[2025-12-23 16:15:05,849] m-LoRA: Adapter lora_winogrande_18 epoch: 1/1 iteration: 120/128 step: 61
[2025-12-23 16:15:06,001] m-LoRA: Adapter lora_winogrande_20 loss: 0.56473308801651
[2025-12-23 16:15:06,003] m-LoRA: Adapter lora_winogrande_34 epoch: 1/1 iteration: 56/128 step: 29
[2025-12-23 16:15:06,127] m-LoRA: Adapter lora_winogrande_41 loss: 0.6917676329612732
[2025-12-23 16:15:06,131] m-LoRA: Adapter lora_winogrande_44 epoch: 1/1 iteration: 20/128 step: 6
[2025-12-23 16:15:06,268] m-LoRA: Adapter lora_winogrande_29 loss: 0.5345270037651062
[2025-12-23 16:15:06,270] m-LoRA: Adapter lora_winogrande_32 epoch: 1/1 iteration: 72/128 step: 37
[2025-12-23 16:15:07,028] m-LoRA: Adapter lora_winogrande_45 loss: 1.3195103406906128
[2025-12-23 16:15:07,034] m-LoRA: Adapter lora_winogrande_47 epoch: 1/1 iteration: 64/128 step: 5
[2025-12-23 16:15:07,726] m-LoRA: Adapter lora_winogrande_46 loss: 1.7957372665405273
[2025-12-23 16:15:07,733] m-LoRA: Adapter lora_winogrande_33 epoch: 1/1 iteration: 72/128 step: 37
[2025-12-23 16:15:07,876] m-LoRA: Adapter lora_winogrande_38 loss: 0.6455057263374329
[2025-12-23 16:15:07,878] m-LoRA: Adapter lora_winogrande_23 epoch: 1/1 iteration: 104/128 step: 53
[2025-12-23 16:15:08,073] m-LoRA: Adapter lora_winogrande_42 loss: 0.6692050099372864
[2025-12-23 16:15:08,075] m-LoRA: Adapter lora_winogrande_48 epoch: 1/1 iteration: 8/128 step: 5
[2025-12-23 16:15:08,179] m-LoRA: Adapter lora_winogrande_18 loss: 0.8334447145462036
[2025-12-23 16:15:08,181] m-LoRA: Adapter lora_winogrande_39 epoch: 1/1 iteration: 80/128 step: 21
[2025-12-23 16:15:08,332] m-LoRA: Adapter lora_winogrande_34 loss: 0.5478973388671875
[2025-12-23 16:15:08,334] m-LoRA: Adapter lora_winogrande_49 epoch: 1/1 iteration: 16/128 step: 5
[2025-12-23 16:15:08,456] m-LoRA: Adapter lora_winogrande_44 loss: 2.98590350151062
[2025-12-23 16:15:08,460] m-LoRA: Adapter lora_winogrande_20 epoch: 1/1 iteration: 120/128 step: 61
[2025-12-23 16:15:08,569] m-LoRA: Adapter lora_winogrande_32 loss: 1.2881262302398682
[2025-12-23 16:15:08,572] m-LoRA: Adapter lora_winogrande_41 epoch: 1/1 iteration: 52/128 step: 14
[2025-12-23 16:15:09,242] m-LoRA: Adapter lora_winogrande_47 loss: 1.3232641220092773
[2025-12-23 16:15:09,249] m-LoRA: Adapter lora_winogrande_29 epoch: 1/1 iteration: 74/128 step: 38
[2025-12-23 16:15:09,443] m-LoRA: Adapter lora_winogrande_33 loss: 0.43050605058670044
[2025-12-23 16:15:09,446] m-LoRA: Adapter lora_winogrande_45 epoch: 1/1 iteration: 80/128 step: 6
[2025-12-23 16:15:09,607] m-LoRA: Adapter lora_winogrande_23 loss: 0.7854069471359253
[2025-12-23 16:15:09,609] m-LoRA: Adapter lora_winogrande_46 epoch: 1/1 iteration: 80/128 step: 6
[2025-12-23 16:15:09,778] m-LoRA: Adapter lora_winogrande_48 loss: 2.734525442123413
[2025-12-23 16:15:09,781] m-LoRA: Adapter lora_winogrande_38 epoch: 1/1 iteration: 42/128 step: 22
[2025-12-23 16:15:09,914] m-LoRA: Adapter lora_winogrande_39 loss: 0.4565623104572296
[2025-12-23 16:15:09,918] m-LoRA: Adapter lora_winogrande_42 epoch: 1/1 iteration: 26/128 step: 14
[2025-12-23 16:15:10,067] m-LoRA: Adapter lora_winogrande_49 loss: 2.095362901687622
[2025-12-23 16:15:10,070] m-LoRA: Adapter lora_winogrande_18 epoch: 1/1 iteration: 122/128 step: 62
[2025-12-23 16:15:10,192] m-LoRA: Adapter lora_winogrande_20 loss: 0.4555302858352661
[2025-12-23 16:15:10,194] m-LoRA: Adapter lora_winogrande_34 epoch: 1/1 iteration: 58/128 step: 30
[2025-12-23 16:15:10,321] m-LoRA: Adapter lora_winogrande_41 loss: 0.5587989091873169
[2025-12-23 16:15:10,324] m-LoRA: Adapter lora_winogrande_44 epoch: 1/1 iteration: 24/128 step: 7
[2025-12-23 16:15:10,435] m-LoRA: Adapter lora_winogrande_29 loss: 0.4601573646068573
[2025-12-23 16:15:10,437] m-LoRA: Adapter lora_winogrande_32 epoch: 1/1 iteration: 74/128 step: 38
[2025-12-23 16:15:11,240] m-LoRA: Adapter lora_winogrande_45 loss: 1.057651400566101
[2025-12-23 16:15:11,247] m-LoRA: Adapter lora_winogrande_47 epoch: 1/1 iteration: 80/128 step: 6
[2025-12-23 16:15:11,964] m-LoRA: Adapter lora_winogrande_46 loss: 1.6074050664901733
[2025-12-23 16:15:11,971] m-LoRA: Adapter lora_winogrande_33 epoch: 1/1 iteration: 74/128 step: 38
[2025-12-23 16:15:12,113] m-LoRA: Adapter lora_winogrande_38 loss: 0.5652065873146057
[2025-12-23 16:15:12,115] m-LoRA: Adapter lora_winogrande_23 epoch: 1/1 iteration: 106/128 step: 54
[2025-12-23 16:15:12,273] m-LoRA: Adapter lora_winogrande_42 loss: 0.6515459418296814
[2025-12-23 16:15:12,275] m-LoRA: Adapter lora_winogrande_48 epoch: 1/1 iteration: 10/128 step: 6
[2025-12-23 16:15:12,432] m-LoRA: Adapter lora_winogrande_18 loss: 0.6588277816772461
[2025-12-23 16:15:12,434] m-LoRA: Adapter lora_winogrande_39 epoch: 1/1 iteration: 84/128 step: 22
[2025-12-23 16:15:12,538] m-LoRA: Adapter lora_winogrande_34 loss: 0.5026350617408752
[2025-12-23 16:15:12,540] m-LoRA: Adapter lora_winogrande_49 epoch: 1/1 iteration: 20/128 step: 6
[2025-12-23 16:15:12,703] m-LoRA: Adapter lora_winogrande_44 loss: 2.6882317066192627
[2025-12-23 16:15:12,706] m-LoRA: Adapter lora_winogrande_20 epoch: 1/1 iteration: 122/128 step: 62
[2025-12-23 16:15:12,854] m-LoRA: Adapter lora_winogrande_32 loss: 1.15554940700531
[2025-12-23 16:15:12,856] m-LoRA: Adapter lora_winogrande_41 epoch: 1/1 iteration: 56/128 step: 15
[2025-12-23 16:15:13,556] m-LoRA: Adapter lora_winogrande_29 epoch: 1/1 iteration: 76/128 step: 39
[2025-12-23 16:15:13,707] m-LoRA: Adapter lora_winogrande_47 loss: 1.0343772172927856
[2025-12-23 16:15:13,713] m-LoRA: Adapter lora_winogrande_45 epoch: 1/1 iteration: 96/128 step: 7
[2025-12-23 16:15:13,779] m-LoRA: Adapter lora_winogrande_33 loss: 0.46466711163520813
[2025-12-23 16:15:13,948] m-LoRA: Adapter lora_winogrande_23 loss: 0.7315776944160461
[2025-12-23 16:15:14,117] m-LoRA: Adapter lora_winogrande_48 loss: 2.6379122734069824
[2025-12-23 16:15:14,460] m-LoRA: Adapter lora_winogrande_39 loss: 0.48526230454444885
[2025-12-23 16:15:14,462] m-LoRA: Adapter lora_winogrande_46 epoch: 1/1 iteration: 96/128 step: 7
[2025-12-23 16:15:14,597] m-LoRA: Adapter lora_winogrande_49 loss: 1.9733800888061523
[2025-12-23 16:15:14,599] m-LoRA: Adapter lora_winogrande_38 epoch: 1/1 iteration: 44/128 step: 23
[2025-12-23 16:15:14,691] m-LoRA: Adapter lora_winogrande_20 loss: 0.44623446464538574
[2025-12-23 16:15:14,693] m-LoRA: Adapter lora_winogrande_42 epoch: 1/1 iteration: 28/128 step: 15
[2025-12-23 16:15:14,757] m-LoRA: Adapter lora_winogrande_34 epoch: 1/1 iteration: 60/128 step: 31
[2025-12-23 16:15:14,811] m-LoRA: Adapter lora_winogrande_18 epoch: 1/1 iteration: 124/128 step: 63
[2025-12-23 16:15:15,054] m-LoRA: Adapter lora_winogrande_41 loss: 0.5394848585128784
[2025-12-23 16:15:15,139] m-LoRA: Adapter lora_winogrande_29 loss: 0.5175754427909851
[2025-12-23 16:15:15,141] m-LoRA: Adapter lora_winogrande_44 epoch: 1/1 iteration: 28/128 step: 8
[2025-12-23 16:15:15,212] m-LoRA: Adapter lora_winogrande_32 epoch: 1/1 iteration: 76/128 step: 39
[2025-12-23 16:15:16,402] m-LoRA: Adapter lora_winogrande_47 epoch: 1/1 iteration: 96/128 step: 7
[2025-12-23 16:15:16,492] m-LoRA: Adapter lora_winogrande_45 loss: 0.9102526307106018
[2025-12-23 16:15:17,219] m-LoRA: Adapter lora_winogrande_46 loss: 1.3684704303741455
[2025-12-23 16:15:17,226] m-LoRA: Adapter lora_winogrande_33 epoch: 1/1 iteration: 76/128 step: 39
[2025-12-23 16:15:17,346] m-LoRA: Adapter lora_winogrande_38 loss: 0.47239917516708374
[2025-12-23 16:15:17,348] m-LoRA: Adapter lora_winogrande_23 epoch: 1/1 iteration: 108/128 step: 55
[2025-12-23 16:15:17,414] m-LoRA: Adapter lora_winogrande_42 loss: 0.6105809807777405
[2025-12-23 16:15:17,416] m-LoRA: Adapter lora_winogrande_48 epoch: 1/1 iteration: 12/128 step: 7
[2025-12-23 16:15:17,524] m-LoRA: Adapter lora_winogrande_34 loss: 0.5340292453765869
[2025-12-23 16:15:17,526] m-LoRA: Adapter lora_winogrande_39 epoch: 1/1 iteration: 88/128 step: 23
[2025-12-23 16:15:17,612] m-LoRA: Adapter lora_winogrande_18 loss: 0.6691756844520569
[2025-12-23 16:15:17,614] m-LoRA: Adapter lora_winogrande_49 epoch: 1/1 iteration: 24/128 step: 7
[2025-12-23 16:15:17,727] m-LoRA: Adapter lora_winogrande_44 loss: 2.545786142349243
[2025-12-23 16:15:17,731] m-LoRA: Adapter lora_winogrande_20 epoch: 1/1 iteration: 124/128 step: 63
[2025-12-23 16:15:17,820] m-LoRA: Adapter lora_winogrande_32 loss: 1.1398108005523682
[2025-12-23 16:15:17,822] m-LoRA: Adapter lora_winogrande_41 epoch: 1/1 iteration: 60/128 step: 16
[2025-12-23 16:15:18,549] m-LoRA: Adapter lora_winogrande_47 loss: 0.8831230998039246
[2025-12-23 16:15:18,555] m-LoRA: Adapter lora_winogrande_29 epoch: 1/1 iteration: 78/128 step: 40
[2025-12-23 16:15:18,712] m-LoRA: Adapter lora_winogrande_33 loss: 0.5355520844459534
[2025-12-23 16:15:18,731] m-LoRA: Adapter lora_winogrande_45 epoch: 1/1 iteration: 112/128 step: 8
[2025-12-23 16:15:18,873] m-LoRA: Adapter lora_winogrande_23 loss: 0.6590304970741272
[2025-12-23 16:15:18,876] m-LoRA: Adapter lora_winogrande_46 epoch: 1/1 iteration: 112/128 step: 8
[2025-12-23 16:15:19,024] m-LoRA: Adapter lora_winogrande_48 loss: 2.7526967525482178
[2025-12-23 16:15:19,026] m-LoRA: Adapter lora_winogrande_38 epoch: 1/1 iteration: 46/128 step: 24
[2025-12-23 16:15:19,170] m-LoRA: Adapter lora_winogrande_39 loss: 0.4372096061706543
[2025-12-23 16:15:19,172] m-LoRA: Adapter lora_winogrande_42 epoch: 1/1 iteration: 30/128 step: 16
[2025-12-23 16:15:19,321] m-LoRA: Adapter lora_winogrande_49 loss: 1.9616683721542358
[2025-12-23 16:15:19,323] m-LoRA: Adapter lora_winogrande_34 epoch: 1/1 iteration: 62/128 step: 32
[2025-12-23 16:15:19,456] m-LoRA: Adapter lora_winogrande_20 loss: 0.3913581669330597
[2025-12-23 16:15:19,458] m-LoRA: Adapter lora_winogrande_18 epoch: 1/1 iteration: 126/128 step: 64
[2025-12-23 16:15:19,627] m-LoRA: Adapter lora_winogrande_41 loss: 0.5845061540603638
[2025-12-23 16:15:19,630] m-LoRA: Adapter lora_winogrande_44 epoch: 1/1 iteration: 32/128 step: 9
[2025-12-23 16:15:19,776] m-LoRA: Adapter lora_winogrande_29 loss: 0.5298393368721008
[2025-12-23 16:15:19,779] m-LoRA: Adapter lora_winogrande_32 epoch: 1/1 iteration: 78/128 step: 40
[2025-12-23 16:15:20,702] m-LoRA: Adapter lora_winogrande_45 loss: 0.7882204651832581
[2025-12-23 16:15:20,708] m-LoRA: Adapter lora_winogrande_47 epoch: 1/1 iteration: 112/128 step: 8
[2025-12-23 16:15:21,321] m-LoRA: Adapter lora_winogrande_46 loss: 1.082688570022583
[2025-12-23 16:15:21,328] m-LoRA: Adapter lora_winogrande_33 epoch: 1/1 iteration: 78/128 step: 40
[2025-12-23 16:15:21,602] m-LoRA: Adapter lora_winogrande_38 loss: 0.398239403963089
[2025-12-23 16:15:21,605] m-LoRA: Adapter lora_winogrande_23 epoch: 1/1 iteration: 110/128 step: 56
[2025-12-23 16:15:21,686] m-LoRA: Adapter lora_winogrande_42 loss: 0.5304184556007385
[2025-12-23 16:15:21,688] m-LoRA: Adapter lora_winogrande_48 epoch: 1/1 iteration: 14/128 step: 8
[2025-12-23 16:15:21,780] m-LoRA: Adapter lora_winogrande_34 loss: 0.44859933853149414
[2025-12-23 16:15:21,782] m-LoRA: Adapter lora_winogrande_39 epoch: 1/1 iteration: 92/128 step: 24
[2025-12-23 16:15:21,911] m-LoRA: Adapter lora_winogrande_18 loss: 0.7076081037521362
[2025-12-23 16:15:21,913] m-LoRA: Adapter lora_winogrande_49 epoch: 1/1 iteration: 28/128 step: 8
[2025-12-23 16:15:22,023] m-LoRA: Adapter lora_winogrande_44 loss: 2.3865134716033936
[2025-12-23 16:15:22,027] m-LoRA: Adapter lora_winogrande_20 epoch: 1/1 iteration: 126/128 step: 64
[2025-12-23 16:15:22,159] m-LoRA: Adapter lora_winogrande_32 loss: 0.9750695824623108
[2025-12-23 16:15:22,161] m-LoRA: Adapter lora_winogrande_41 epoch: 1/1 iteration: 64/128 step: 17
[2025-12-23 16:15:22,722] m-LoRA: Adapter lora_winogrande_47 loss: 0.7488331198692322
[2025-12-23 16:15:22,728] m-LoRA: Adapter lora_winogrande_29 epoch: 1/1 iteration: 80/128 step: 41
[2025-12-23 16:15:22,883] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_45']
[2025-12-23 16:15:23,617] m-LoRA: Adapter lora_winogrande_33 loss: 0.5424472689628601
[2025-12-23 16:15:23,619] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_50']
[2025-12-23 16:15:23,850] m-LoRA: Adapter lora_winogrande_50 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:15:23,956] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_46']
[2025-12-23 16:15:24,253] m-LoRA: Adapter lora_winogrande_23 loss: 0.7847049236297607
[2025-12-23 16:15:24,255] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_51']
[2025-12-23 16:15:24,415] m-LoRA: Adapter lora_winogrande_51 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:15:24,511] m-LoRA: Adapter lora_winogrande_48 loss: 2.7149507999420166
[2025-12-23 16:15:24,513] m-LoRA: Adapter lora_winogrande_38 epoch: 1/1 iteration: 48/128 step: 25
[2025-12-23 16:15:24,648] m-LoRA: Adapter lora_winogrande_39 loss: 0.5578661561012268
[2025-12-23 16:15:24,651] m-LoRA: Adapter lora_winogrande_42 epoch: 1/1 iteration: 32/128 step: 17
[2025-12-23 16:15:24,781] m-LoRA: Adapter lora_winogrande_49 loss: 1.7502466440200806
[2025-12-23 16:15:24,784] m-LoRA: Adapter lora_winogrande_34 epoch: 1/1 iteration: 64/128 step: 33
[2025-12-23 16:15:24,907] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_18']
[2025-12-23 16:15:25,218] m-LoRA: Adapter lora_winogrande_20 loss: 0.528709352016449
[2025-12-23 16:15:25,255] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_52']
[2025-12-23 16:15:25,358] m-LoRA: Adapter lora_winogrande_52 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:15:25,490] m-LoRA: Adapter lora_winogrande_41 loss: 0.6321088075637817
[2025-12-23 16:15:25,492] m-LoRA: Adapter lora_winogrande_44 epoch: 1/1 iteration: 36/128 step: 10
[2025-12-23 16:15:25,624] m-LoRA: Adapter lora_winogrande_29 loss: 0.39125749468803406
[2025-12-23 16:15:25,627] m-LoRA: Adapter lora_winogrande_32 epoch: 1/1 iteration: 80/128 step: 41
[2025-12-23 16:15:25,752] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_47']
[2025-12-23 16:15:26,303] m-LoRA: Adapter lora_winogrande_50 loss: 3.2077865600585938
[2025-12-23 16:15:26,306] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_53']
[2025-12-23 16:15:26,451] m-LoRA: Adapter lora_winogrande_53 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:15:26,622] m-LoRA: Adapter lora_winogrande_51 loss: 3.2171378135681152
[2025-12-23 16:15:26,624] m-LoRA: Adapter lora_winogrande_33 epoch: 1/1 iteration: 80/128 step: 41
[2025-12-23 16:15:26,792] m-LoRA: Adapter lora_winogrande_38 loss: 0.470755934715271
[2025-12-23 16:15:26,794] m-LoRA: Adapter lora_winogrande_23 epoch: 1/1 iteration: 112/128 step: 57
[2025-12-23 16:15:26,992] m-LoRA: Adapter lora_winogrande_34 loss: 0.6224057078361511
[2025-12-23 16:15:27,008] m-LoRA: Adapter lora_winogrande_48 epoch: 1/1 iteration: 16/128 step: 9
[2025-12-23 16:15:27,139] m-LoRA: Adapter lora_winogrande_42 loss: 0.6452882885932922
[2025-12-23 16:15:27,141] m-LoRA: Adapter lora_winogrande_39 epoch: 1/1 iteration: 96/128 step: 25
[2025-12-23 16:15:27,263] m-LoRA: Adapter lora_winogrande_52 loss: 3.323207378387451
[2025-12-23 16:15:27,270] m-LoRA: Adapter lora_winogrande_49 epoch: 1/1 iteration: 32/128 step: 9
[2025-12-23 16:15:27,427] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_20']
[2025-12-23 16:15:27,900] m-LoRA: Adapter lora_winogrande_32 loss: 0.9986304640769958
[2025-12-23 16:15:27,902] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_54']
[2025-12-23 16:15:28,069] m-LoRA: Adapter lora_winogrande_54 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:15:28,170] m-LoRA: Adapter lora_winogrande_44 loss: 2.300947427749634
[2025-12-23 16:15:28,172] m-LoRA: Adapter lora_winogrande_41 epoch: 1/1 iteration: 68/128 step: 18
[2025-12-23 16:15:28,293] m-LoRA: Adapter lora_winogrande_53 loss: 2.9719033241271973
[2025-12-23 16:15:28,295] m-LoRA: Adapter lora_winogrande_29 epoch: 1/1 iteration: 82/128 step: 42
[2025-12-23 16:15:28,475] m-LoRA: Adapter lora_winogrande_33 loss: 0.47562798857688904
[2025-12-23 16:15:28,478] m-LoRA: Adapter lora_winogrande_50 epoch: 1/1 iteration: 8/128 step: 2
[2025-12-23 16:15:28,618] m-LoRA: Adapter lora_winogrande_23 loss: 0.6918171048164368
[2025-12-23 16:15:28,621] m-LoRA: Adapter lora_winogrande_51 epoch: 1/1 iteration: 4/128 step: 2
[2025-12-23 16:15:28,737] m-LoRA: Adapter lora_winogrande_48 loss: 2.526989221572876
[2025-12-23 16:15:28,739] m-LoRA: Adapter lora_winogrande_38 epoch: 1/1 iteration: 50/128 step: 26
[2025-12-23 16:15:28,894] m-LoRA: Adapter lora_winogrande_39 loss: 0.49314406514167786
[2025-12-23 16:15:28,897] m-LoRA: Adapter lora_winogrande_34 epoch: 1/1 iteration: 66/128 step: 34
[2025-12-23 16:15:29,059] m-LoRA: Adapter lora_winogrande_49 loss: 1.657528042793274
[2025-12-23 16:15:29,062] m-LoRA: Adapter lora_winogrande_42 epoch: 1/1 iteration: 34/128 step: 18
[2025-12-23 16:15:29,237] m-LoRA: Adapter lora_winogrande_54 loss: 3.1991119384765625
[2025-12-23 16:15:29,239] m-LoRA: Adapter lora_winogrande_52 epoch: 1/1 iteration: 16/128 step: 2
[2025-12-23 16:15:29,354] m-LoRA: Adapter lora_winogrande_41 loss: 0.5440477728843689
[2025-12-23 16:15:29,358] m-LoRA: Adapter lora_winogrande_32 epoch: 1/1 iteration: 82/128 step: 42
[2025-12-23 16:15:29,516] m-LoRA: Adapter lora_winogrande_29 loss: 0.45036181807518005
[2025-12-23 16:15:29,519] m-LoRA: Adapter lora_winogrande_44 epoch: 1/1 iteration: 40/128 step: 11
[2025-12-23 16:15:29,715] m-LoRA: Adapter lora_winogrande_50 loss: 2.59816837310791
[2025-12-23 16:15:29,722] m-LoRA: Adapter lora_winogrande_53 epoch: 1/1 iteration: 2/128 step: 2
[2025-12-23 16:15:29,904] m-LoRA: Adapter lora_winogrande_51 loss: 2.533735752105713
[2025-12-23 16:15:29,906] m-LoRA: Adapter lora_winogrande_33 epoch: 1/1 iteration: 82/128 step: 42
[2025-12-23 16:15:30,022] m-LoRA: Adapter lora_winogrande_38 loss: 0.645379900932312
[2025-12-23 16:15:30,025] m-LoRA: Adapter lora_winogrande_23 epoch: 1/1 iteration: 114/128 step: 58
[2025-12-23 16:15:30,147] m-LoRA: Adapter lora_winogrande_34 loss: 0.592400848865509
[2025-12-23 16:15:30,149] m-LoRA: Adapter lora_winogrande_48 epoch: 1/1 iteration: 18/128 step: 10
[2025-12-23 16:15:30,237] m-LoRA: Adapter lora_winogrande_42 loss: 0.6651336550712585
[2025-12-23 16:15:30,239] m-LoRA: Adapter lora_winogrande_39 epoch: 1/1 iteration: 100/128 step: 26
[2025-12-23 16:15:30,782] m-LoRA: Adapter lora_winogrande_52 loss: 3.107405185699463
[2025-12-23 16:15:30,789] m-LoRA: Adapter lora_winogrande_49 epoch: 1/1 iteration: 36/128 step: 10
[2025-12-23 16:15:31,039] m-LoRA: Adapter lora_winogrande_32 loss: 0.9281956553459167
[2025-12-23 16:15:31,042] m-LoRA: Adapter lora_winogrande_54 epoch: 1/1 iteration: 4/128 step: 2
[2025-12-23 16:15:31,174] m-LoRA: Adapter lora_winogrande_44 loss: 2.375565528869629
[2025-12-23 16:15:31,176] m-LoRA: Adapter lora_winogrande_41 epoch: 1/1 iteration: 72/128 step: 19
[2025-12-23 16:15:31,315] m-LoRA: Adapter lora_winogrande_53 loss: 3.18194580078125
[2025-12-23 16:15:31,317] m-LoRA: Adapter lora_winogrande_29 epoch: 1/1 iteration: 84/128 step: 43
[2025-12-23 16:15:31,454] m-LoRA: Adapter lora_winogrande_33 loss: 0.5046075582504272
[2025-12-23 16:15:31,456] m-LoRA: Adapter lora_winogrande_50 epoch: 1/1 iteration: 16/128 step: 3
[2025-12-23 16:15:31,627] m-LoRA: Adapter lora_winogrande_23 loss: 0.7457115054130554
[2025-12-23 16:15:31,629] m-LoRA: Adapter lora_winogrande_51 epoch: 1/1 iteration: 8/128 step: 3
[2025-12-23 16:15:31,797] m-LoRA: Adapter lora_winogrande_48 loss: 2.647902250289917
[2025-12-23 16:15:31,799] m-LoRA: Adapter lora_winogrande_38 epoch: 1/1 iteration: 52/128 step: 27
[2025-12-23 16:15:31,909] m-LoRA: Adapter lora_winogrande_39 loss: 0.6009162664413452
[2025-12-23 16:15:31,912] m-LoRA: Adapter lora_winogrande_34 epoch: 1/1 iteration: 68/128 step: 35
[2025-12-23 16:15:32,084] m-LoRA: Adapter lora_winogrande_49 loss: 1.5500900745391846
[2025-12-23 16:15:32,087] m-LoRA: Adapter lora_winogrande_42 epoch: 1/1 iteration: 36/128 step: 19
[2025-12-23 16:15:32,264] m-LoRA: Adapter lora_winogrande_54 loss: 2.588330030441284
[2025-12-23 16:15:32,266] m-LoRA: Adapter lora_winogrande_52 epoch: 1/1 iteration: 32/128 step: 3
[2025-12-23 16:15:32,388] m-LoRA: Adapter lora_winogrande_41 loss: 0.625028133392334
[2025-12-23 16:15:32,391] m-LoRA: Adapter lora_winogrande_32 epoch: 1/1 iteration: 84/128 step: 43
[2025-12-23 16:15:32,458] m-LoRA: Adapter lora_winogrande_29 loss: 0.3781266510486603
[2025-12-23 16:15:32,693] m-LoRA: Adapter lora_winogrande_50 loss: 2.029917001724243
[2025-12-23 16:15:32,697] m-LoRA: Adapter lora_winogrande_44 epoch: 1/1 iteration: 44/128 step: 12
[2025-12-23 16:15:32,893] m-LoRA: Adapter lora_winogrande_51 loss: 2.0202269554138184
[2025-12-23 16:15:32,896] m-LoRA: Adapter lora_winogrande_53 epoch: 1/1 iteration: 4/128 step: 3
[2025-12-23 16:15:33,019] m-LoRA: Adapter lora_winogrande_38 loss: 0.5082932710647583
[2025-12-23 16:15:33,022] m-LoRA: Adapter lora_winogrande_33 epoch: 1/1 iteration: 84/128 step: 43
[2025-12-23 16:15:33,184] m-LoRA: Adapter lora_winogrande_34 loss: 0.5359494686126709
[2025-12-23 16:15:33,186] m-LoRA: Adapter lora_winogrande_23 epoch: 1/1 iteration: 116/128 step: 59
[2025-12-23 16:15:33,315] m-LoRA: Adapter lora_winogrande_42 loss: 0.5020403265953064
[2025-12-23 16:15:33,317] m-LoRA: Adapter lora_winogrande_48 epoch: 1/1 iteration: 20/128 step: 11
[2025-12-23 16:15:33,985] m-LoRA: Adapter lora_winogrande_52 loss: 3.081883192062378
[2025-12-23 16:15:33,998] m-LoRA: Adapter lora_winogrande_39 epoch: 1/1 iteration: 104/128 step: 27
[2025-12-23 16:15:34,209] m-LoRA: Adapter lora_winogrande_32 loss: 0.9883365035057068
[2025-12-23 16:15:34,211] m-LoRA: Adapter lora_winogrande_49 epoch: 1/1 iteration: 40/128 step: 11
[2025-12-23 16:15:34,377] m-LoRA: Adapter lora_winogrande_44 loss: 2.1784331798553467
[2025-12-23 16:15:34,379] m-LoRA: Adapter lora_winogrande_54 epoch: 1/1 iteration: 8/128 step: 3
[2025-12-23 16:15:34,552] m-LoRA: Adapter lora_winogrande_53 loss: 3.0247795581817627
[2025-12-23 16:15:34,554] m-LoRA: Adapter lora_winogrande_41 epoch: 1/1 iteration: 76/128 step: 20
[2025-12-23 16:15:34,684] m-LoRA: Adapter lora_winogrande_33 loss: 0.6109855771064758
[2025-12-23 16:15:34,686] m-LoRA: Adapter lora_winogrande_29 epoch: 1/1 iteration: 86/128 step: 44
[2025-12-23 16:15:34,809] m-LoRA: Adapter lora_winogrande_23 loss: 0.7569029927253723
[2025-12-23 16:15:34,812] m-LoRA: Adapter lora_winogrande_50 epoch: 1/1 iteration: 24/128 step: 4
[2025-12-23 16:15:34,946] m-LoRA: Adapter lora_winogrande_48 loss: 2.5083627700805664
[2025-12-23 16:15:34,948] m-LoRA: Adapter lora_winogrande_38 epoch: 1/1 iteration: 54/128 step: 28
[2025-12-23 16:15:35,104] m-LoRA: Adapter lora_winogrande_51 epoch: 1/1 iteration: 12/128 step: 4
[2025-12-23 16:15:35,263] m-LoRA: Adapter lora_winogrande_39 loss: 0.5414674878120422
[2025-12-23 16:15:35,266] m-LoRA: Adapter lora_winogrande_42 epoch: 1/1 iteration: 38/128 step: 20
[2025-12-23 16:15:35,486] m-LoRA: Adapter lora_winogrande_49 loss: 1.4140201807022095
[2025-12-23 16:15:35,488] m-LoRA: Adapter lora_winogrande_34 epoch: 1/1 iteration: 70/128 step: 36
[2025-12-23 16:15:35,679] m-LoRA: Adapter lora_winogrande_54 loss: 2.291269063949585
[2025-12-23 16:15:35,682] m-LoRA: Adapter lora_winogrande_52 epoch: 1/1 iteration: 48/128 step: 4
[2025-12-23 16:15:35,894] m-LoRA: Adapter lora_winogrande_41 loss: 0.5044738054275513
[2025-12-23 16:15:35,896] m-LoRA: Adapter lora_winogrande_32 epoch: 1/1 iteration: 86/128 step: 44
[2025-12-23 16:15:36,047] m-LoRA: Adapter lora_winogrande_29 loss: 0.4776330292224884
[2025-12-23 16:15:36,049] m-LoRA: Adapter lora_winogrande_44 epoch: 1/1 iteration: 48/128 step: 13
[2025-12-23 16:15:36,169] m-LoRA: Adapter lora_winogrande_53 epoch: 1/1 iteration: 6/128 step: 4
[2025-12-23 16:15:36,374] m-LoRA: Adapter lora_winogrande_50 loss: 1.760511040687561
[2025-12-23 16:15:36,379] m-LoRA: Adapter lora_winogrande_33 epoch: 1/1 iteration: 86/128 step: 44
[2025-12-23 16:15:36,565] m-LoRA: Adapter lora_winogrande_38 loss: 0.47431206703186035
[2025-12-23 16:15:36,567] m-LoRA: Adapter lora_winogrande_23 epoch: 1/1 iteration: 118/128 step: 60
[2025-12-23 16:15:36,707] m-LoRA: Adapter lora_winogrande_51 loss: 1.7341817617416382
[2025-12-23 16:15:36,711] m-LoRA: Adapter lora_winogrande_48 epoch: 1/1 iteration: 22/128 step: 12
[2025-12-23 16:15:36,798] m-LoRA: Adapter lora_winogrande_42 loss: 0.5855807662010193
[2025-12-23 16:15:36,800] m-LoRA: Adapter lora_winogrande_39 epoch: 1/1 iteration: 108/128 step: 28
[2025-12-23 16:15:36,893] m-LoRA: Adapter lora_winogrande_34 loss: 0.47952303290367126
[2025-12-23 16:15:36,895] m-LoRA: Adapter lora_winogrande_49 epoch: 1/1 iteration: 44/128 step: 12
[2025-12-23 16:15:37,557] m-LoRA: Adapter lora_winogrande_52 loss: 3.1625120639801025
[2025-12-23 16:15:37,564] m-LoRA: Adapter lora_winogrande_54 epoch: 1/1 iteration: 12/128 step: 4
[2025-12-23 16:15:37,791] m-LoRA: Adapter lora_winogrande_32 loss: 0.739817202091217
[2025-12-23 16:15:37,793] m-LoRA: Adapter lora_winogrande_41 epoch: 1/1 iteration: 80/128 step: 21
[2025-12-23 16:15:37,961] m-LoRA: Adapter lora_winogrande_44 loss: 2.2868106365203857
[2025-12-23 16:15:37,963] m-LoRA: Adapter lora_winogrande_29 epoch: 1/1 iteration: 88/128 step: 45
[2025-12-23 16:15:38,115] m-LoRA: Adapter lora_winogrande_53 loss: 2.9901931285858154
[2025-12-23 16:15:38,118] m-LoRA: Adapter lora_winogrande_50 epoch: 1/1 iteration: 32/128 step: 5
[2025-12-23 16:15:38,253] m-LoRA: Adapter lora_winogrande_33 loss: 0.47007930278778076
[2025-12-23 16:15:38,255] m-LoRA: Adapter lora_winogrande_38 epoch: 1/1 iteration: 56/128 step: 29
[2025-12-23 16:15:38,412] m-LoRA: Adapter lora_winogrande_23 loss: 0.6161783337593079
[2025-12-23 16:15:38,470] m-LoRA: Adapter lora_winogrande_51 epoch: 1/1 iteration: 16/128 step: 5
[2025-12-23 16:15:38,630] m-LoRA: Adapter lora_winogrande_48 loss: 2.2215421199798584
[2025-12-23 16:15:38,632] m-LoRA: Adapter lora_winogrande_42 epoch: 1/1 iteration: 40/128 step: 21
[2025-12-23 16:15:38,796] m-LoRA: Adapter lora_winogrande_39 loss: 0.48076629638671875
[2025-12-23 16:15:38,802] m-LoRA: Adapter lora_winogrande_34 epoch: 1/1 iteration: 72/128 step: 37
[2025-12-23 16:15:38,856] m-LoRA: Adapter lora_winogrande_49 loss: 1.3624382019042969
[2025-12-23 16:15:38,871] m-LoRA: Adapter lora_winogrande_54 loss: 2.0004546642303467
[2025-12-23 16:15:39,069] m-LoRA: Adapter lora_winogrande_41 loss: 0.53130042552948
[2025-12-23 16:15:39,071] m-LoRA: Adapter lora_winogrande_52 epoch: 1/1 iteration: 64/128 step: 5
[2025-12-23 16:15:39,241] m-LoRA: Adapter lora_winogrande_29 loss: 0.3104933202266693
[2025-12-23 16:15:39,243] m-LoRA: Adapter lora_winogrande_32 epoch: 1/1 iteration: 88/128 step: 45
[2025-12-23 16:15:39,498] m-LoRA: Adapter lora_winogrande_50 loss: 1.5182819366455078
[2025-12-23 16:15:39,504] m-LoRA: Adapter lora_winogrande_44 epoch: 1/1 iteration: 52/128 step: 14
[2025-12-23 16:15:39,658] m-LoRA: Adapter lora_winogrande_38 loss: 0.6037876009941101
[2025-12-23 16:15:39,660] m-LoRA: Adapter lora_winogrande_53 epoch: 1/1 iteration: 8/128 step: 5
[2025-12-23 16:15:39,787] m-LoRA: Adapter lora_winogrande_51 loss: 1.539252758026123
[2025-12-23 16:15:39,790] m-LoRA: Adapter lora_winogrande_33 epoch: 1/1 iteration: 88/128 step: 45
[2025-12-23 16:15:39,891] m-LoRA: Adapter lora_winogrande_42 loss: 0.5690425038337708
[2025-12-23 16:15:39,893] m-LoRA: Adapter lora_winogrande_23 epoch: 1/1 iteration: 120/128 step: 61
[2025-12-23 16:15:39,987] m-LoRA: Adapter lora_winogrande_34 loss: 0.4889148771762848
[2025-12-23 16:15:39,989] m-LoRA: Adapter lora_winogrande_48 epoch: 1/1 iteration: 24/128 step: 13
[2025-12-23 16:15:40,701] m-LoRA: Adapter lora_winogrande_52 loss: 2.9839060306549072
[2025-12-23 16:15:40,708] m-LoRA: Adapter lora_winogrande_39 epoch: 1/1 iteration: 112/128 step: 29
[2025-12-23 16:15:40,903] m-LoRA: Adapter lora_winogrande_32 loss: 0.7708908915519714
[2025-12-23 16:15:40,906] m-LoRA: Adapter lora_winogrande_49 epoch: 1/1 iteration: 48/128 step: 13
[2025-12-23 16:15:41,063] m-LoRA: Adapter lora_winogrande_44 loss: 2.1527576446533203
[2025-12-23 16:15:41,066] m-LoRA: Adapter lora_winogrande_54 epoch: 1/1 iteration: 16/128 step: 5
[2025-12-23 16:15:41,252] m-LoRA: Adapter lora_winogrande_53 loss: 2.8162271976470947
[2025-12-23 16:15:41,255] m-LoRA: Adapter lora_winogrande_41 epoch: 1/1 iteration: 84/128 step: 22
[2025-12-23 16:15:41,382] m-LoRA: Adapter lora_winogrande_33 loss: 0.47239792346954346
[2025-12-23 16:15:41,384] m-LoRA: Adapter lora_winogrande_29 epoch: 1/1 iteration: 90/128 step: 46
[2025-12-23 16:15:41,501] m-LoRA: Adapter lora_winogrande_23 loss: 0.7069428563117981
[2025-12-23 16:15:41,503] m-LoRA: Adapter lora_winogrande_50 epoch: 1/1 iteration: 40/128 step: 6
[2025-12-23 16:15:41,709] m-LoRA: Adapter lora_winogrande_48 loss: 2.368741512298584
[2025-12-23 16:15:41,711] m-LoRA: Adapter lora_winogrande_38 epoch: 1/1 iteration: 58/128 step: 30
[2025-12-23 16:15:41,835] m-LoRA: Adapter lora_winogrande_51 epoch: 1/1 iteration: 20/128 step: 6
[2025-12-23 16:15:41,988] m-LoRA: Adapter lora_winogrande_39 loss: 0.4810878038406372
[2025-12-23 16:15:41,990] m-LoRA: Adapter lora_winogrande_42 epoch: 1/1 iteration: 42/128 step: 22
[2025-12-23 16:15:42,150] m-LoRA: Adapter lora_winogrande_49 loss: 1.1146438121795654
[2025-12-23 16:15:42,153] m-LoRA: Adapter lora_winogrande_34 epoch: 1/1 iteration: 74/128 step: 38
[2025-12-23 16:15:42,317] m-LoRA: Adapter lora_winogrande_52 epoch: 1/1 iteration: 80/128 step: 6
[2025-12-23 16:15:42,431] m-LoRA: Adapter lora_winogrande_54 loss: 1.746516466140747
[2025-12-23 16:15:42,434] m-LoRA: Adapter lora_winogrande_32 epoch: 1/1 iteration: 90/128 step: 46
[2025-12-23 16:15:42,540] m-LoRA: Adapter lora_winogrande_44 epoch: 1/1 iteration: 56/128 step: 15
[2025-12-23 16:15:42,572] m-LoRA: Adapter lora_winogrande_41 loss: 0.4623248279094696
[2025-12-23 16:15:42,680] m-LoRA: Adapter lora_winogrande_29 loss: 0.577139675617218
[2025-12-23 16:15:42,682] m-LoRA: Adapter lora_winogrande_53 epoch: 1/1 iteration: 10/128 step: 6
[2025-12-23 16:15:43,080] m-LoRA: Adapter lora_winogrande_50 loss: 1.2332210540771484
[2025-12-23 16:15:43,084] m-LoRA: Adapter lora_winogrande_33 epoch: 1/1 iteration: 90/128 step: 46
[2025-12-23 16:15:43,240] m-LoRA: Adapter lora_winogrande_38 loss: 0.6114943623542786
[2025-12-23 16:15:43,242] m-LoRA: Adapter lora_winogrande_23 epoch: 1/1 iteration: 122/128 step: 62
[2025-12-23 16:15:43,372] m-LoRA: Adapter lora_winogrande_51 loss: 1.1719387769699097
[2025-12-23 16:15:43,375] m-LoRA: Adapter lora_winogrande_48 epoch: 1/1 iteration: 26/128 step: 14
[2025-12-23 16:15:43,519] m-LoRA: Adapter lora_winogrande_42 loss: 0.601654589176178
[2025-12-23 16:15:43,521] m-LoRA: Adapter lora_winogrande_39 epoch: 1/1 iteration: 116/128 step: 30
[2025-12-23 16:15:43,683] m-LoRA: Adapter lora_winogrande_34 loss: 0.4127699136734009
[2025-12-23 16:15:43,685] m-LoRA: Adapter lora_winogrande_49 epoch: 1/1 iteration: 52/128 step: 14
[2025-12-23 16:15:44,286] m-LoRA: Adapter lora_winogrande_52 loss: 2.790353775024414
[2025-12-23 16:15:44,293] m-LoRA: Adapter lora_winogrande_54 epoch: 1/1 iteration: 20/128 step: 6
[2025-12-23 16:15:44,491] m-LoRA: Adapter lora_winogrande_32 loss: 0.9227628707885742
[2025-12-23 16:15:44,494] m-LoRA: Adapter lora_winogrande_41 epoch: 1/1 iteration: 88/128 step: 23
[2025-12-23 16:15:44,639] m-LoRA: Adapter lora_winogrande_44 loss: 2.1630401611328125
[2025-12-23 16:15:44,642] m-LoRA: Adapter lora_winogrande_29 epoch: 1/1 iteration: 92/128 step: 47
[2025-12-23 16:15:44,785] m-LoRA: Adapter lora_winogrande_53 loss: 2.8314061164855957
[2025-12-23 16:15:44,787] m-LoRA: Adapter lora_winogrande_50 epoch: 1/1 iteration: 48/128 step: 7
[2025-12-23 16:15:44,933] m-LoRA: Adapter lora_winogrande_33 loss: 0.40270376205444336
[2025-12-23 16:15:44,936] m-LoRA: Adapter lora_winogrande_38 epoch: 1/1 iteration: 60/128 step: 31
[2025-12-23 16:15:45,056] m-LoRA: Adapter lora_winogrande_23 loss: 0.781957745552063
[2025-12-23 16:15:45,058] m-LoRA: Adapter lora_winogrande_51 epoch: 1/1 iteration: 24/128 step: 7
[2025-12-23 16:15:45,260] m-LoRA: Adapter lora_winogrande_48 loss: 2.064624547958374
[2025-12-23 16:15:45,269] m-LoRA: Adapter lora_winogrande_42 epoch: 1/1 iteration: 44/128 step: 23
[2025-12-23 16:15:45,405] m-LoRA: Adapter lora_winogrande_39 loss: 0.5157122611999512
[2025-12-23 16:15:45,409] m-LoRA: Adapter lora_winogrande_34 epoch: 1/1 iteration: 76/128 step: 39
[2025-12-23 16:15:45,492] m-LoRA: Adapter lora_winogrande_49 loss: 1.0302866697311401
[2025-12-23 16:15:45,498] m-LoRA: Adapter lora_winogrande_54 loss: 1.6193677186965942
[2025-12-23 16:15:45,608] m-LoRA: Adapter lora_winogrande_41 loss: 0.5268021821975708
[2025-12-23 16:15:45,792] m-LoRA: Adapter lora_winogrande_29 loss: 0.47984030842781067
[2025-12-23 16:15:45,794] m-LoRA: Adapter lora_winogrande_52 epoch: 1/1 iteration: 96/128 step: 7
[2025-12-23 16:15:46,177] m-LoRA: Adapter lora_winogrande_50 loss: 0.9818994402885437
[2025-12-23 16:15:46,180] m-LoRA: Adapter lora_winogrande_32 epoch: 1/1 iteration: 92/128 step: 47
[2025-12-23 16:15:46,366] m-LoRA: Adapter lora_winogrande_38 loss: 0.4321935176849365
[2025-12-23 16:15:46,368] m-LoRA: Adapter lora_winogrande_44 epoch: 1/1 iteration: 60/128 step: 16
[2025-12-23 16:15:46,484] m-LoRA: Adapter lora_winogrande_51 loss: 0.9767193794250488
[2025-12-23 16:15:46,488] m-LoRA: Adapter lora_winogrande_53 epoch: 1/1 iteration: 12/128 step: 7
[2025-12-23 16:15:46,625] m-LoRA: Adapter lora_winogrande_42 loss: 0.556194007396698
[2025-12-23 16:15:46,627] m-LoRA: Adapter lora_winogrande_33 epoch: 1/1 iteration: 92/128 step: 47
[2025-12-23 16:15:46,718] m-LoRA: Adapter lora_winogrande_34 loss: 0.52775639295578
[2025-12-23 16:15:46,720] m-LoRA: Adapter lora_winogrande_23 epoch: 1/1 iteration: 124/128 step: 63
[2025-12-23 16:15:47,414] m-LoRA: Adapter lora_winogrande_52 loss: 2.6518118381500244
[2025-12-23 16:15:47,421] m-LoRA: Adapter lora_winogrande_48 epoch: 1/1 iteration: 28/128 step: 15
[2025-12-23 16:15:47,641] m-LoRA: Adapter lora_winogrande_32 loss: 0.7505557537078857
[2025-12-23 16:15:47,643] m-LoRA: Adapter lora_winogrande_39 epoch: 1/1 iteration: 120/128 step: 31
[2025-12-23 16:15:47,744] m-LoRA: Adapter lora_winogrande_44 loss: 1.951827883720398
[2025-12-23 16:15:47,747] m-LoRA: Adapter lora_winogrande_49 epoch: 1/1 iteration: 56/128 step: 15
[2025-12-23 16:15:47,899] m-LoRA: Adapter lora_winogrande_53 loss: 2.6863677501678467
[2025-12-23 16:15:47,902] m-LoRA: Adapter lora_winogrande_54 epoch: 1/1 iteration: 24/128 step: 7
[2025-12-23 16:15:48,014] m-LoRA: Adapter lora_winogrande_33 loss: 0.5400880575180054
[2025-12-23 16:15:48,016] m-LoRA: Adapter lora_winogrande_41 epoch: 1/1 iteration: 92/128 step: 24
[2025-12-23 16:15:48,112] m-LoRA: Adapter lora_winogrande_23 loss: 0.7057040333747864
[2025-12-23 16:15:48,114] m-LoRA: Adapter lora_winogrande_29 epoch: 1/1 iteration: 94/128 step: 48
[2025-12-23 16:15:48,227] m-LoRA: Adapter lora_winogrande_50 epoch: 1/1 iteration: 56/128 step: 8
[2025-12-23 16:15:48,301] m-LoRA: Adapter lora_winogrande_38 epoch: 1/1 iteration: 62/128 step: 32
[2025-12-23 16:15:48,382] m-LoRA: Adapter lora_winogrande_51 epoch: 1/1 iteration: 28/128 step: 8
[2025-12-23 16:15:48,451] m-LoRA: Adapter lora_winogrande_42 epoch: 1/1 iteration: 46/128 step: 24
[2025-12-23 16:15:48,566] m-LoRA: Adapter lora_winogrande_48 loss: 2.132192850112915
[2025-12-23 16:15:48,568] m-LoRA: Adapter lora_winogrande_34 epoch: 1/1 iteration: 78/128 step: 40
[2025-12-23 16:15:48,874] m-LoRA: Adapter lora_winogrande_39 loss: 0.4655669331550598
[2025-12-23 16:15:48,878] m-LoRA: Adapter lora_winogrande_52 epoch: 1/1 iteration: 112/128 step: 8
[2025-12-23 16:15:49,063] m-LoRA: Adapter lora_winogrande_49 loss: 1.0112464427947998
[2025-12-23 16:15:49,066] m-LoRA: Adapter lora_winogrande_32 epoch: 1/1 iteration: 94/128 step: 48
[2025-12-23 16:15:49,247] m-LoRA: Adapter lora_winogrande_54 loss: 1.3479341268539429
[2025-12-23 16:15:49,249] m-LoRA: Adapter lora_winogrande_44 epoch: 1/1 iteration: 64/128 step: 17
[2025-12-23 16:15:49,436] m-LoRA: Adapter lora_winogrande_41 loss: 0.5350252985954285
[2025-12-23 16:15:49,440] m-LoRA: Adapter lora_winogrande_53 epoch: 1/1 iteration: 14/128 step: 8
[2025-12-23 16:15:49,570] m-LoRA: Adapter lora_winogrande_29 loss: 0.42633503675460815
[2025-12-23 16:15:49,572] m-LoRA: Adapter lora_winogrande_33 epoch: 1/1 iteration: 94/128 step: 48
[2025-12-23 16:15:49,836] m-LoRA: Adapter lora_winogrande_23 epoch: 1/1 iteration: 126/128 step: 64
[2025-12-23 16:15:49,874] m-LoRA: Adapter lora_winogrande_50 loss: 0.8280200958251953
[2025-12-23 16:15:50,033] m-LoRA: Adapter lora_winogrande_38 loss: 0.3692990839481354
[2025-12-23 16:15:50,035] m-LoRA: Adapter lora_winogrande_48 epoch: 1/1 iteration: 30/128 step: 16
[2025-12-23 16:15:50,194] m-LoRA: Adapter lora_winogrande_51 loss: 0.8484141826629639
[2025-12-23 16:15:50,196] m-LoRA: Adapter lora_winogrande_39 epoch: 1/1 iteration: 124/128 step: 32
[2025-12-23 16:15:50,326] m-LoRA: Adapter lora_winogrande_42 loss: 0.5255598425865173
[2025-12-23 16:15:50,328] m-LoRA: Adapter lora_winogrande_49 epoch: 1/1 iteration: 60/128 step: 16
[2025-12-23 16:15:50,403] m-LoRA: Adapter lora_winogrande_34 loss: 0.35568657517433167
[2025-12-23 16:15:50,405] m-LoRA: Adapter lora_winogrande_54 epoch: 1/1 iteration: 28/128 step: 8
[2025-12-23 16:15:51,104] m-LoRA: Adapter lora_winogrande_52 loss: 2.4997363090515137
[2025-12-23 16:15:51,111] m-LoRA: Adapter lora_winogrande_41 epoch: 1/1 iteration: 96/128 step: 25
[2025-12-23 16:15:51,263] m-LoRA: Adapter lora_winogrande_32 loss: 0.7423038482666016
[2025-12-23 16:15:51,265] m-LoRA: Adapter lora_winogrande_29 epoch: 1/1 iteration: 96/128 step: 49
[2025-12-23 16:15:51,423] m-LoRA: Adapter lora_winogrande_44 loss: 2.0549476146698
[2025-12-23 16:15:51,425] m-LoRA: Adapter lora_winogrande_50 epoch: 1/1 iteration: 64/128 step: 9
[2025-12-23 16:15:51,583] m-LoRA: Adapter lora_winogrande_53 loss: 2.4756884574890137
[2025-12-23 16:15:51,586] m-LoRA: Adapter lora_winogrande_38 epoch: 1/1 iteration: 64/128 step: 33
[2025-12-23 16:15:51,714] m-LoRA: Adapter lora_winogrande_33 loss: 0.3620416522026062
[2025-12-23 16:15:51,716] m-LoRA: Adapter lora_winogrande_51 epoch: 1/1 iteration: 32/128 step: 9
[2025-12-23 16:15:51,852] m-LoRA: Adapter lora_winogrande_23 loss: 0.6454876065254211
[2025-12-23 16:15:51,854] m-LoRA: Adapter lora_winogrande_42 epoch: 1/1 iteration: 48/128 step: 25
[2025-12-23 16:15:52,052] m-LoRA: Adapter lora_winogrande_48 loss: 2.0905957221984863
[2025-12-23 16:15:52,054] m-LoRA: Adapter lora_winogrande_34 epoch: 1/1 iteration: 80/128 step: 41
[2025-12-23 16:15:52,156] m-LoRA: Adapter lora_winogrande_39 loss: 0.3621267080307007
[2025-12-23 16:15:52,375] m-LoRA: Adapter lora_winogrande_49 loss: 0.8269734382629395
[2025-12-23 16:15:52,620] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_52']
[2025-12-23 16:15:53,015] m-LoRA: Adapter lora_winogrande_54 loss: 1.1195389032363892
[2025-12-23 16:15:53,018] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_55']
[2025-12-23 16:15:53,187] m-LoRA: Adapter lora_winogrande_55 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:15:53,324] m-LoRA: Adapter lora_winogrande_41 loss: 0.5342969298362732
[2025-12-23 16:15:53,328] m-LoRA: Adapter lora_winogrande_32 epoch: 1/1 iteration: 96/128 step: 49
[2025-12-23 16:15:53,468] m-LoRA: Adapter lora_winogrande_29 loss: 0.5140122175216675
[2025-12-23 16:15:53,471] m-LoRA: Adapter lora_winogrande_44 epoch: 1/1 iteration: 68/128 step: 18
[2025-12-23 16:15:53,562] m-LoRA: Adapter lora_winogrande_50 loss: 0.7281606197357178
[2025-12-23 16:15:53,566] m-LoRA: Adapter lora_winogrande_53 epoch: 1/1 iteration: 16/128 step: 9
[2025-12-23 16:15:53,676] m-LoRA: Adapter lora_winogrande_38 loss: 0.46398815512657166
[2025-12-23 16:15:53,678] m-LoRA: Adapter lora_winogrande_33 epoch: 1/1 iteration: 96/128 step: 49
[2025-12-23 16:15:53,787] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_23']
[2025-12-23 16:15:54,017] m-LoRA: Adapter lora_winogrande_51 loss: 0.7083279490470886
[2025-12-23 16:15:54,020] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_56']
[2025-12-23 16:15:54,104] m-LoRA: Adapter lora_winogrande_56 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:15:54,198] m-LoRA: Adapter lora_winogrande_42 loss: 0.6320223808288574
[2025-12-23 16:15:54,200] m-LoRA: Adapter lora_winogrande_48 epoch: 1/1 iteration: 32/128 step: 17
[2025-12-23 16:15:54,481] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_39']
[2025-12-23 16:15:55,143] m-LoRA: Adapter lora_winogrande_34 loss: 0.4790085554122925
[2025-12-23 16:15:55,145] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_57']
[2025-12-23 16:15:55,298] m-LoRA: Adapter lora_winogrande_57 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:15:55,425] m-LoRA: Adapter lora_winogrande_55 loss: 3.1331634521484375
[2025-12-23 16:15:55,431] m-LoRA: Adapter lora_winogrande_49 epoch: 1/1 iteration: 64/128 step: 17
[2025-12-23 16:15:55,573] m-LoRA: Adapter lora_winogrande_32 loss: 0.7798281908035278
[2025-12-23 16:15:55,575] m-LoRA: Adapter lora_winogrande_54 epoch: 1/1 iteration: 32/128 step: 9
[2025-12-23 16:15:55,717] m-LoRA: Adapter lora_winogrande_44 loss: 2.11142897605896
[2025-12-23 16:15:55,720] m-LoRA: Adapter lora_winogrande_41 epoch: 1/1 iteration: 100/128 step: 26
[2025-12-23 16:15:55,834] m-LoRA: Adapter lora_winogrande_53 loss: 2.4135470390319824
[2025-12-23 16:15:55,836] m-LoRA: Adapter lora_winogrande_29 epoch: 1/1 iteration: 98/128 step: 50
[2025-12-23 16:15:55,942] m-LoRA: Adapter lora_winogrande_33 loss: 0.48733893036842346
[2025-12-23 16:15:55,945] m-LoRA: Adapter lora_winogrande_50 epoch: 1/1 iteration: 72/128 step: 10
[2025-12-23 16:15:56,046] m-LoRA: Adapter lora_winogrande_56 loss: 3.192887306213379
[2025-12-23 16:15:56,048] m-LoRA: Adapter lora_winogrande_38 epoch: 1/1 iteration: 66/128 step: 34
[2025-12-23 16:15:56,164] m-LoRA: Adapter lora_winogrande_48 loss: 2.1138076782226562
[2025-12-23 16:15:56,166] m-LoRA: Adapter lora_winogrande_51 epoch: 1/1 iteration: 36/128 step: 10
[2025-12-23 16:15:56,268] m-LoRA: Adapter lora_winogrande_42 epoch: 1/1 iteration: 50/128 step: 26
[2025-12-23 16:15:56,358] m-LoRA: Adapter lora_winogrande_34 epoch: 1/1 iteration: 82/128 step: 42
[2025-12-23 16:15:57,650] m-LoRA: Adapter lora_winogrande_57 loss: 3.1795740127563477
[2025-12-23 16:15:57,656] m-LoRA: Adapter lora_winogrande_55 epoch: 1/1 iteration: 16/128 step: 2
[2025-12-23 16:15:57,839] m-LoRA: Adapter lora_winogrande_49 loss: 0.7922806739807129
[2025-12-23 16:15:57,842] m-LoRA: Adapter lora_winogrande_32 epoch: 1/1 iteration: 98/128 step: 50
[2025-12-23 16:15:57,940] m-LoRA: Adapter lora_winogrande_54 loss: 0.9592316746711731
[2025-12-23 16:15:57,943] m-LoRA: Adapter lora_winogrande_44 epoch: 1/1 iteration: 72/128 step: 19
[2025-12-23 16:15:58,115] m-LoRA: Adapter lora_winogrande_41 loss: 0.47772449254989624
[2025-12-23 16:15:58,117] m-LoRA: Adapter lora_winogrande_53 epoch: 1/1 iteration: 18/128 step: 10
[2025-12-23 16:15:58,221] m-LoRA: Adapter lora_winogrande_29 loss: 0.3822339177131653
[2025-12-23 16:15:58,223] m-LoRA: Adapter lora_winogrande_33 epoch: 1/1 iteration: 98/128 step: 50
[2025-12-23 16:15:58,467] m-LoRA: Adapter lora_winogrande_50 loss: 0.6249099373817444
[2025-12-23 16:15:58,471] m-LoRA: Adapter lora_winogrande_56 epoch: 1/1 iteration: 4/128 step: 2
[2025-12-23 16:15:58,665] m-LoRA: Adapter lora_winogrande_38 loss: 0.44292542338371277
[2025-12-23 16:15:58,667] m-LoRA: Adapter lora_winogrande_48 epoch: 1/1 iteration: 34/128 step: 18
[2025-12-23 16:15:58,774] m-LoRA: Adapter lora_winogrande_51 loss: 0.7614012956619263
[2025-12-23 16:15:58,869] m-LoRA: Adapter lora_winogrande_42 loss: 0.49013450741767883
[2025-12-23 16:15:58,951] m-LoRA: Adapter lora_winogrande_34 loss: 0.525664210319519
[2025-12-23 16:15:59,769] m-LoRA: Adapter lora_winogrande_55 loss: 2.957336664199829
[2025-12-23 16:15:59,776] m-LoRA: Adapter lora_winogrande_57 epoch: 1/1 iteration: 16/128 step: 2
[2025-12-23 16:15:59,977] m-LoRA: Adapter lora_winogrande_32 loss: 0.9041496515274048
[2025-12-23 16:15:59,979] m-LoRA: Adapter lora_winogrande_49 epoch: 1/1 iteration: 68/128 step: 18
[2025-12-23 16:16:00,120] m-LoRA: Adapter lora_winogrande_44 loss: 1.9439897537231445
[2025-12-23 16:16:00,123] m-LoRA: Adapter lora_winogrande_54 epoch: 1/1 iteration: 36/128 step: 10
[2025-12-23 16:16:00,270] m-LoRA: Adapter lora_winogrande_53 loss: 2.488919258117676
[2025-12-23 16:16:00,273] m-LoRA: Adapter lora_winogrande_41 epoch: 1/1 iteration: 104/128 step: 27
[2025-12-23 16:16:00,404] m-LoRA: Adapter lora_winogrande_33 loss: 0.4157445430755615
[2025-12-23 16:16:00,407] m-LoRA: Adapter lora_winogrande_29 epoch: 1/1 iteration: 100/128 step: 51
[2025-12-23 16:16:00,533] m-LoRA: Adapter lora_winogrande_56 loss: 2.9454257488250732
[2025-12-23 16:16:00,537] m-LoRA: Adapter lora_winogrande_50 epoch: 1/1 iteration: 80/128 step: 11
[2025-12-23 16:16:00,682] m-LoRA: Adapter lora_winogrande_48 loss: 2.052872657775879
[2025-12-23 16:16:00,684] m-LoRA: Adapter lora_winogrande_38 epoch: 1/1 iteration: 68/128 step: 35
[2025-12-23 16:16:00,797] m-LoRA: Adapter lora_winogrande_51 epoch: 1/1 iteration: 40/128 step: 11
[2025-12-23 16:16:00,865] m-LoRA: Adapter lora_winogrande_42 epoch: 1/1 iteration: 52/128 step: 27
[2025-12-23 16:16:00,920] m-LoRA: Adapter lora_winogrande_34 epoch: 1/1 iteration: 84/128 step: 43
[2025-12-23 16:16:01,604] m-LoRA: Adapter lora_winogrande_55 epoch: 1/1 iteration: 32/128 step: 3
[2025-12-23 16:16:01,676] m-LoRA: Adapter lora_winogrande_57 loss: 2.76985502243042
[2025-12-23 16:16:01,874] m-LoRA: Adapter lora_winogrande_49 loss: 0.7586306929588318
[2025-12-23 16:16:01,876] m-LoRA: Adapter lora_winogrande_32 epoch: 1/1 iteration: 100/128 step: 51
[2025-12-23 16:16:02,040] m-LoRA: Adapter lora_winogrande_54 loss: 0.7709932923316956
[2025-12-23 16:16:02,042] m-LoRA: Adapter lora_winogrande_44 epoch: 1/1 iteration: 76/128 step: 20
[2025-12-23 16:16:02,194] m-LoRA: Adapter lora_winogrande_41 loss: 0.4463047385215759
[2025-12-23 16:16:02,196] m-LoRA: Adapter lora_winogrande_53 epoch: 1/1 iteration: 20/128 step: 11
[2025-12-23 16:16:02,315] m-LoRA: Adapter lora_winogrande_29 loss: 0.463042676448822
[2025-12-23 16:16:02,317] m-LoRA: Adapter lora_winogrande_33 epoch: 1/1 iteration: 100/128 step: 51
[2025-12-23 16:16:02,671] m-LoRA: Adapter lora_winogrande_50 loss: 0.6220587491989136
[2025-12-23 16:16:02,675] m-LoRA: Adapter lora_winogrande_56 epoch: 1/1 iteration: 8/128 step: 3
[2025-12-23 16:16:02,837] m-LoRA: Adapter lora_winogrande_38 loss: 0.47248131036758423
[2025-12-23 16:16:02,839] m-LoRA: Adapter lora_winogrande_48 epoch: 1/1 iteration: 36/128 step: 19
[2025-12-23 16:16:02,992] m-LoRA: Adapter lora_winogrande_51 loss: 0.6338808536529541
[2025-12-23 16:16:03,160] m-LoRA: Adapter lora_winogrande_42 loss: 0.6102079749107361
[2025-12-23 16:16:03,163] m-LoRA: Adapter lora_winogrande_57 epoch: 1/1 iteration: 32/128 step: 3
[2025-12-23 16:16:03,230] m-LoRA: Adapter lora_winogrande_34 loss: 0.5497140288352966
[2025-12-23 16:16:03,884] m-LoRA: Adapter lora_winogrande_55 loss: 2.4216408729553223
[2025-12-23 16:16:03,891] m-LoRA: Adapter lora_winogrande_49 epoch: 1/1 iteration: 72/128 step: 19
[2025-12-23 16:16:04,089] m-LoRA: Adapter lora_winogrande_32 loss: 0.7823843955993652
[2025-12-23 16:16:04,098] m-LoRA: Adapter lora_winogrande_54 epoch: 1/1 iteration: 40/128 step: 11
[2025-12-23 16:16:04,248] m-LoRA: Adapter lora_winogrande_44 loss: 1.9215822219848633
[2025-12-23 16:16:04,250] m-LoRA: Adapter lora_winogrande_41 epoch: 1/1 iteration: 108/128 step: 28
[2025-12-23 16:16:04,414] m-LoRA: Adapter lora_winogrande_53 loss: 2.22275447845459
[2025-12-23 16:16:04,416] m-LoRA: Adapter lora_winogrande_29 epoch: 1/1 iteration: 102/128 step: 52
[2025-12-23 16:16:04,551] m-LoRA: Adapter lora_winogrande_33 loss: 0.5492778420448303
[2025-12-23 16:16:04,554] m-LoRA: Adapter lora_winogrande_50 epoch: 1/1 iteration: 88/128 step: 12
[2025-12-23 16:16:04,672] m-LoRA: Adapter lora_winogrande_56 loss: 2.4599783420562744
[2025-12-23 16:16:04,738] m-LoRA: Adapter lora_winogrande_38 epoch: 1/1 iteration: 70/128 step: 36
[2025-12-23 16:16:04,874] m-LoRA: Adapter lora_winogrande_48 loss: 2.066450595855713
[2025-12-23 16:16:04,877] m-LoRA: Adapter lora_winogrande_51 epoch: 1/1 iteration: 44/128 step: 12
[2025-12-23 16:16:05,311] m-LoRA: Adapter lora_winogrande_42 epoch: 1/1 iteration: 54/128 step: 28
[2025-12-23 16:16:05,363] m-LoRA: Adapter lora_winogrande_57 loss: 2.038451671600342
[2025-12-23 16:16:05,563] m-LoRA: Adapter lora_winogrande_49 loss: 0.746520459651947
[2025-12-23 16:16:05,565] m-LoRA: Adapter lora_winogrande_34 epoch: 1/1 iteration: 86/128 step: 44
[2025-12-23 16:16:05,714] m-LoRA: Adapter lora_winogrande_54 loss: 0.6573690176010132
[2025-12-23 16:16:05,716] m-LoRA: Adapter lora_winogrande_55 epoch: 1/1 iteration: 48/128 step: 4
[2025-12-23 16:16:05,860] m-LoRA: Adapter lora_winogrande_41 loss: 0.4911620616912842
[2025-12-23 16:16:05,862] m-LoRA: Adapter lora_winogrande_32 epoch: 1/1 iteration: 102/128 step: 52
[2025-12-23 16:16:05,990] m-LoRA: Adapter lora_winogrande_29 loss: 0.6336414813995361
[2025-12-23 16:16:05,992] m-LoRA: Adapter lora_winogrande_44 epoch: 1/1 iteration: 80/128 step: 21
[2025-12-23 16:16:06,407] m-LoRA: Adapter lora_winogrande_50 loss: 0.6066261529922485
[2025-12-23 16:16:06,411] m-LoRA: Adapter lora_winogrande_53 epoch: 1/1 iteration: 22/128 step: 12
[2025-12-23 16:16:06,593] m-LoRA: Adapter lora_winogrande_38 loss: 0.4855172038078308
[2025-12-23 16:16:06,595] m-LoRA: Adapter lora_winogrande_33 epoch: 1/1 iteration: 102/128 step: 52
[2025-12-23 16:16:06,750] m-LoRA: Adapter lora_winogrande_51 loss: 0.6194775700569153
[2025-12-23 16:16:06,753] m-LoRA: Adapter lora_winogrande_56 epoch: 1/1 iteration: 12/128 step: 4
[2025-12-23 16:16:06,884] m-LoRA: Adapter lora_winogrande_42 loss: 0.5293951630592346
[2025-12-23 16:16:06,886] m-LoRA: Adapter lora_winogrande_48 epoch: 1/1 iteration: 38/128 step: 20
[2025-12-23 16:16:07,032] m-LoRA: Adapter lora_winogrande_34 loss: 0.42674458026885986
[2025-12-23 16:16:07,034] m-LoRA: Adapter lora_winogrande_57 epoch: 1/1 iteration: 48/128 step: 4
[2025-12-23 16:16:07,692] m-LoRA: Adapter lora_winogrande_55 loss: 2.065659284591675
[2025-12-23 16:16:07,698] m-LoRA: Adapter lora_winogrande_49 epoch: 1/1 iteration: 76/128 step: 20
[2025-12-23 16:16:07,779] m-LoRA: Adapter lora_winogrande_32 loss: 0.7635229229927063
[2025-12-23 16:16:07,781] m-LoRA: Adapter lora_winogrande_54 epoch: 1/1 iteration: 44/128 step: 12
[2025-12-23 16:16:07,961] m-LoRA: Adapter lora_winogrande_44 loss: 1.899033546447754
[2025-12-23 16:16:07,965] m-LoRA: Adapter lora_winogrande_41 epoch: 1/1 iteration: 112/128 step: 29
[2025-12-23 16:16:08,080] m-LoRA: Adapter lora_winogrande_53 loss: 2.4144222736358643
[2025-12-23 16:16:08,082] m-LoRA: Adapter lora_winogrande_29 epoch: 1/1 iteration: 104/128 step: 53
[2025-12-23 16:16:08,196] m-LoRA: Adapter lora_winogrande_33 loss: 0.6084502339363098
[2025-12-23 16:16:08,198] m-LoRA: Adapter lora_winogrande_50 epoch: 1/1 iteration: 96/128 step: 13
[2025-12-23 16:16:08,321] m-LoRA: Adapter lora_winogrande_56 loss: 2.187748908996582
[2025-12-23 16:16:08,324] m-LoRA: Adapter lora_winogrande_38 epoch: 1/1 iteration: 72/128 step: 37
[2025-12-23 16:16:08,446] m-LoRA: Adapter lora_winogrande_48 loss: 1.9155352115631104
[2025-12-23 16:16:08,448] m-LoRA: Adapter lora_winogrande_51 epoch: 1/1 iteration: 48/128 step: 13
[2025-12-23 16:16:09,252] m-LoRA: Adapter lora_winogrande_57 loss: 2.00105881690979
[2025-12-23 16:16:09,265] m-LoRA: Adapter lora_winogrande_42 epoch: 1/1 iteration: 56/128 step: 29
[2025-12-23 16:16:09,481] m-LoRA: Adapter lora_winogrande_49 loss: 0.6859266757965088
[2025-12-23 16:16:09,483] m-LoRA: Adapter lora_winogrande_34 epoch: 1/1 iteration: 88/128 step: 45
[2025-12-23 16:16:09,646] m-LoRA: Adapter lora_winogrande_54 loss: 0.7123755812644958
[2025-12-23 16:16:09,648] m-LoRA: Adapter lora_winogrande_55 epoch: 1/1 iteration: 64/128 step: 5
[2025-12-23 16:16:09,803] m-LoRA: Adapter lora_winogrande_41 loss: 0.43513137102127075
[2025-12-23 16:16:09,805] m-LoRA: Adapter lora_winogrande_32 epoch: 1/1 iteration: 104/128 step: 53
[2025-12-23 16:16:09,926] m-LoRA: Adapter lora_winogrande_29 loss: 0.5548296570777893
[2025-12-23 16:16:09,929] m-LoRA: Adapter lora_winogrande_44 epoch: 1/1 iteration: 84/128 step: 22
[2025-12-23 16:16:10,164] m-LoRA: Adapter lora_winogrande_50 loss: 0.5967074036598206
[2025-12-23 16:16:10,167] m-LoRA: Adapter lora_winogrande_53 epoch: 1/1 iteration: 24/128 step: 13
[2025-12-23 16:16:10,390] m-LoRA: Adapter lora_winogrande_38 loss: 0.6193592548370361
[2025-12-23 16:16:10,393] m-LoRA: Adapter lora_winogrande_33 epoch: 1/1 iteration: 104/128 step: 53
[2025-12-23 16:16:10,509] m-LoRA: Adapter lora_winogrande_51 loss: 0.6351708769798279
[2025-12-23 16:16:10,512] m-LoRA: Adapter lora_winogrande_56 epoch: 1/1 iteration: 16/128 step: 5
[2025-12-23 16:16:10,653] m-LoRA: Adapter lora_winogrande_42 loss: 0.3549138307571411
[2025-12-23 16:16:10,655] m-LoRA: Adapter lora_winogrande_48 epoch: 1/1 iteration: 40/128 step: 21
[2025-12-23 16:16:10,781] m-LoRA: Adapter lora_winogrande_34 loss: 0.6641029715538025
[2025-12-23 16:16:10,783] m-LoRA: Adapter lora_winogrande_57 epoch: 1/1 iteration: 64/128 step: 5
[2025-12-23 16:16:10,932] m-LoRA: Adapter lora_winogrande_49 epoch: 1/1 iteration: 80/128 step: 21
[2025-12-23 16:16:11,622] m-LoRA: Adapter lora_winogrande_55 loss: 1.9927517175674438
[2025-12-23 16:16:11,629] m-LoRA: Adapter lora_winogrande_54 epoch: 1/1 iteration: 48/128 step: 13
[2025-12-23 16:16:11,788] m-LoRA: Adapter lora_winogrande_32 loss: 0.6993076205253601
[2025-12-23 16:16:11,808] m-LoRA: Adapter lora_winogrande_41 epoch: 1/1 iteration: 116/128 step: 30
[2025-12-23 16:16:11,977] m-LoRA: Adapter lora_winogrande_44 loss: 1.9381557703018188
[2025-12-23 16:16:11,980] m-LoRA: Adapter lora_winogrande_29 epoch: 1/1 iteration: 106/128 step: 54
[2025-12-23 16:16:12,113] m-LoRA: Adapter lora_winogrande_53 loss: 2.1078708171844482
[2025-12-23 16:16:12,115] m-LoRA: Adapter lora_winogrande_50 epoch: 1/1 iteration: 104/128 step: 14
[2025-12-23 16:16:12,202] m-LoRA: Adapter lora_winogrande_33 loss: 0.5158641934394836
[2025-12-23 16:16:12,204] m-LoRA: Adapter lora_winogrande_38 epoch: 1/1 iteration: 74/128 step: 38
[2025-12-23 16:16:12,284] m-LoRA: Adapter lora_winogrande_56 loss: 2.144723415374756
[2025-12-23 16:16:12,288] m-LoRA: Adapter lora_winogrande_51 epoch: 1/1 iteration: 52/128 step: 14
[2025-12-23 16:16:12,396] m-LoRA: Adapter lora_winogrande_48 loss: 2.080051898956299
[2025-12-23 16:16:12,399] m-LoRA: Adapter lora_winogrande_42 epoch: 1/1 iteration: 58/128 step: 30
[2025-12-23 16:16:12,535] m-LoRA: Adapter lora_winogrande_49 loss: 0.6585217714309692
[2025-12-23 16:16:12,539] m-LoRA: Adapter lora_winogrande_34 epoch: 1/1 iteration: 90/128 step: 46
[2025-12-23 16:16:13,300] m-LoRA: Adapter lora_winogrande_57 loss: 1.7436482906341553
[2025-12-23 16:16:13,307] m-LoRA: Adapter lora_winogrande_55 epoch: 1/1 iteration: 80/128 step: 6
[2025-12-23 16:16:13,530] m-LoRA: Adapter lora_winogrande_54 loss: 0.6328177452087402
[2025-12-23 16:16:13,533] m-LoRA: Adapter lora_winogrande_32 epoch: 1/1 iteration: 106/128 step: 54
[2025-12-23 16:16:13,688] m-LoRA: Adapter lora_winogrande_41 loss: 0.5001009702682495
[2025-12-23 16:16:13,691] m-LoRA: Adapter lora_winogrande_44 epoch: 1/1 iteration: 88/128 step: 23
[2025-12-23 16:16:13,806] m-LoRA: Adapter lora_winogrande_29 loss: 0.3860141336917877
[2025-12-23 16:16:13,809] m-LoRA: Adapter lora_winogrande_53 epoch: 1/1 iteration: 26/128 step: 14
[2025-12-23 16:16:14,091] m-LoRA: Adapter lora_winogrande_50 loss: 0.6172038912773132
[2025-12-23 16:16:14,094] m-LoRA: Adapter lora_winogrande_33 epoch: 1/1 iteration: 106/128 step: 54
[2025-12-23 16:16:14,250] m-LoRA: Adapter lora_winogrande_38 loss: 0.5332779288291931
[2025-12-23 16:16:14,253] m-LoRA: Adapter lora_winogrande_56 epoch: 1/1 iteration: 20/128 step: 6
[2025-12-23 16:16:14,433] m-LoRA: Adapter lora_winogrande_51 loss: 0.574064314365387
[2025-12-23 16:16:14,437] m-LoRA: Adapter lora_winogrande_48 epoch: 1/1 iteration: 42/128 step: 22
[2025-12-23 16:16:14,588] m-LoRA: Adapter lora_winogrande_42 loss: 0.6442277431488037
[2025-12-23 16:16:14,590] m-LoRA: Adapter lora_winogrande_49 epoch: 1/1 iteration: 84/128 step: 22
[2025-12-23 16:16:14,646] m-LoRA: Adapter lora_winogrande_34 loss: 0.45578691363334656
[2025-12-23 16:16:15,323] m-LoRA: Adapter lora_winogrande_55 loss: 1.9922674894332886
[2025-12-23 16:16:15,330] m-LoRA: Adapter lora_winogrande_57 epoch: 1/1 iteration: 80/128 step: 6
[2025-12-23 16:16:15,581] m-LoRA: Adapter lora_winogrande_32 loss: 0.6475846171379089
[2025-12-23 16:16:15,583] m-LoRA: Adapter lora_winogrande_54 epoch: 1/1 iteration: 52/128 step: 14
[2025-12-23 16:16:15,749] m-LoRA: Adapter lora_winogrande_44 loss: 1.8174598217010498
[2025-12-23 16:16:15,752] m-LoRA: Adapter lora_winogrande_41 epoch: 1/1 iteration: 120/128 step: 31
[2025-12-23 16:16:15,866] m-LoRA: Adapter lora_winogrande_53 loss: 2.3158271312713623
[2025-12-23 16:16:15,868] m-LoRA: Adapter lora_winogrande_29 epoch: 1/1 iteration: 108/128 step: 55
[2025-12-23 16:16:15,977] m-LoRA: Adapter lora_winogrande_33 loss: 0.44426774978637695
[2025-12-23 16:16:15,979] m-LoRA: Adapter lora_winogrande_50 epoch: 1/1 iteration: 112/128 step: 15
[2025-12-23 16:16:16,141] m-LoRA: Adapter lora_winogrande_56 loss: 2.0101969242095947
[2025-12-23 16:16:16,144] m-LoRA: Adapter lora_winogrande_38 epoch: 1/1 iteration: 76/128 step: 39
[2025-12-23 16:16:16,307] m-LoRA: Adapter lora_winogrande_48 loss: 1.8860840797424316
[2025-12-23 16:16:16,309] m-LoRA: Adapter lora_winogrande_51 epoch: 1/1 iteration: 56/128 step: 15
[2025-12-23 16:16:16,428] m-LoRA: Adapter lora_winogrande_49 loss: 0.6416571140289307
[2025-12-23 16:16:16,430] m-LoRA: Adapter lora_winogrande_42 epoch: 1/1 iteration: 60/128 step: 31
[2025-12-23 16:16:17,038] m-LoRA: Adapter lora_winogrande_34 epoch: 1/1 iteration: 92/128 step: 47
[2025-12-23 16:16:17,077] m-LoRA: Adapter lora_winogrande_57 loss: 1.648361086845398
[2025-12-23 16:16:17,225] m-LoRA: Adapter lora_winogrande_54 loss: 0.6413764357566833
[2025-12-23 16:16:17,228] m-LoRA: Adapter lora_winogrande_55 epoch: 1/1 iteration: 96/128 step: 7
[2025-12-23 16:16:17,360] m-LoRA: Adapter lora_winogrande_41 loss: 0.5270305871963501
[2025-12-23 16:16:17,363] m-LoRA: Adapter lora_winogrande_32 epoch: 1/1 iteration: 108/128 step: 55
[2025-12-23 16:16:17,469] m-LoRA: Adapter lora_winogrande_29 loss: 0.5593127608299255
[2025-12-23 16:16:17,471] m-LoRA: Adapter lora_winogrande_44 epoch: 1/1 iteration: 92/128 step: 24
[2025-12-23 16:16:17,816] m-LoRA: Adapter lora_winogrande_50 loss: 0.5609709024429321
[2025-12-23 16:16:17,821] m-LoRA: Adapter lora_winogrande_53 epoch: 1/1 iteration: 28/128 step: 15
[2025-12-23 16:16:18,035] m-LoRA: Adapter lora_winogrande_38 loss: 0.6578571796417236
[2025-12-23 16:16:18,037] m-LoRA: Adapter lora_winogrande_33 epoch: 1/1 iteration: 108/128 step: 55
[2025-12-23 16:16:18,216] m-LoRA: Adapter lora_winogrande_51 loss: 0.5693627595901489
[2025-12-23 16:16:18,219] m-LoRA: Adapter lora_winogrande_56 epoch: 1/1 iteration: 24/128 step: 7
[2025-12-23 16:16:18,343] m-LoRA: Adapter lora_winogrande_42 loss: 0.41398799419403076
[2025-12-23 16:16:18,345] m-LoRA: Adapter lora_winogrande_48 epoch: 1/1 iteration: 44/128 step: 23
[2025-12-23 16:16:18,449] m-LoRA: Adapter lora_winogrande_34 loss: 0.4523147940635681
[2025-12-23 16:16:18,452] m-LoRA: Adapter lora_winogrande_49 epoch: 1/1 iteration: 88/128 step: 23
[2025-12-23 16:16:19,012] m-LoRA: Adapter lora_winogrande_57 epoch: 1/1 iteration: 96/128 step: 7
[2025-12-23 16:16:19,100] m-LoRA: Adapter lora_winogrande_55 loss: 1.8604860305786133
[2025-12-23 16:16:19,266] m-LoRA: Adapter lora_winogrande_32 loss: 0.7792523503303528
[2025-12-23 16:16:19,268] m-LoRA: Adapter lora_winogrande_54 epoch: 1/1 iteration: 56/128 step: 15
[2025-12-23 16:16:19,426] m-LoRA: Adapter lora_winogrande_44 loss: 1.9037787914276123
[2025-12-23 16:16:19,428] m-LoRA: Adapter lora_winogrande_41 epoch: 1/1 iteration: 124/128 step: 32
[2025-12-23 16:16:19,542] m-LoRA: Adapter lora_winogrande_53 loss: 2.252943277359009
[2025-12-23 16:16:19,544] m-LoRA: Adapter lora_winogrande_29 epoch: 1/1 iteration: 110/128 step: 56
[2025-12-23 16:16:19,646] m-LoRA: Adapter lora_winogrande_33 loss: 0.591781497001648
[2025-12-23 16:16:19,648] m-LoRA: Adapter lora_winogrande_50 epoch: 1/1 iteration: 120/128 step: 16
[2025-12-23 16:16:19,782] m-LoRA: Adapter lora_winogrande_56 loss: 1.8690944910049438
[2025-12-23 16:16:19,786] m-LoRA: Adapter lora_winogrande_38 epoch: 1/1 iteration: 78/128 step: 40
[2025-12-23 16:16:19,910] m-LoRA: Adapter lora_winogrande_48 loss: 1.7442609071731567
[2025-12-23 16:16:19,913] m-LoRA: Adapter lora_winogrande_51 epoch: 1/1 iteration: 60/128 step: 16
[2025-12-23 16:16:20,023] m-LoRA: Adapter lora_winogrande_49 loss: 0.6339836120605469
[2025-12-23 16:16:20,025] m-LoRA: Adapter lora_winogrande_42 epoch: 1/1 iteration: 62/128 step: 32
[2025-12-23 16:16:21,279] m-LoRA: Adapter lora_winogrande_57 loss: 1.4371362924575806
[2025-12-23 16:16:21,285] m-LoRA: Adapter lora_winogrande_34 epoch: 1/1 iteration: 94/128 step: 48
[2025-12-23 16:16:21,506] m-LoRA: Adapter lora_winogrande_54 loss: 0.6584958434104919
[2025-12-23 16:16:21,509] m-LoRA: Adapter lora_winogrande_55 epoch: 1/1 iteration: 112/128 step: 8
[2025-12-23 16:16:21,680] m-LoRA: Adapter lora_winogrande_41 loss: 0.5510996580123901
[2025-12-23 16:16:21,683] m-LoRA: Adapter lora_winogrande_32 epoch: 1/1 iteration: 110/128 step: 56
[2025-12-23 16:16:21,850] m-LoRA: Adapter lora_winogrande_29 loss: 0.5367303490638733
[2025-12-23 16:16:21,852] m-LoRA: Adapter lora_winogrande_44 epoch: 1/1 iteration: 96/128 step: 25
[2025-12-23 16:16:21,981] m-LoRA: Adapter lora_winogrande_50 loss: 0.5742520689964294
[2025-12-23 16:16:21,984] m-LoRA: Adapter lora_winogrande_53 epoch: 1/1 iteration: 30/128 step: 16
[2025-12-23 16:16:22,132] m-LoRA: Adapter lora_winogrande_38 loss: 0.5948163270950317
[2025-12-23 16:16:22,134] m-LoRA: Adapter lora_winogrande_33 epoch: 1/1 iteration: 110/128 step: 56
[2025-12-23 16:16:22,261] m-LoRA: Adapter lora_winogrande_51 loss: 0.6000989675521851
[2025-12-23 16:16:22,263] m-LoRA: Adapter lora_winogrande_56 epoch: 1/1 iteration: 28/128 step: 8
[2025-12-23 16:16:22,357] m-LoRA: Adapter lora_winogrande_42 loss: 0.4828379452228546
[2025-12-23 16:16:22,359] m-LoRA: Adapter lora_winogrande_48 epoch: 1/1 iteration: 46/128 step: 24
[2025-12-23 16:16:22,447] m-LoRA: Adapter lora_winogrande_34 loss: 0.4530223608016968
[2025-12-23 16:16:22,450] m-LoRA: Adapter lora_winogrande_49 epoch: 1/1 iteration: 92/128 step: 24
[2025-12-23 16:16:23,084] m-LoRA: Adapter lora_winogrande_57 epoch: 1/1 iteration: 112/128 step: 8
[2025-12-23 16:16:23,218] m-LoRA: Adapter lora_winogrande_55 loss: 1.8199670314788818
[2025-12-23 16:16:23,225] m-LoRA: Adapter lora_winogrande_54 epoch: 1/1 iteration: 60/128 step: 16
[2025-12-23 16:16:23,267] m-LoRA: Adapter lora_winogrande_32 loss: 0.7318909764289856
[2025-12-23 16:16:23,494] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_41']
[2025-12-23 16:16:23,867] m-LoRA: Adapter lora_winogrande_44 loss: 1.7063674926757812
[2025-12-23 16:16:23,869] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_58']
[2025-12-23 16:16:23,961] m-LoRA: Adapter lora_winogrande_58 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:16:24,072] m-LoRA: Adapter lora_winogrande_53 loss: 2.172724962234497
[2025-12-23 16:16:24,074] m-LoRA: Adapter lora_winogrande_29 epoch: 1/1 iteration: 112/128 step: 57
[2025-12-23 16:16:24,167] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_50']
[2025-12-23 16:16:24,812] m-LoRA: Adapter lora_winogrande_33 loss: 0.4670630395412445
[2025-12-23 16:16:24,815] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_59']
[2025-12-23 16:16:24,971] m-LoRA: Adapter lora_winogrande_59 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:16:25,116] m-LoRA: Adapter lora_winogrande_56 loss: 1.8450682163238525
[2025-12-23 16:16:25,118] m-LoRA: Adapter lora_winogrande_38 epoch: 1/1 iteration: 80/128 step: 41
[2025-12-23 16:16:25,253] m-LoRA: Adapter lora_winogrande_48 loss: 1.8260432481765747
[2025-12-23 16:16:25,255] m-LoRA: Adapter lora_winogrande_51 epoch: 1/1 iteration: 64/128 step: 17
[2025-12-23 16:16:25,459] m-LoRA: Adapter lora_winogrande_49 loss: 0.5800127387046814
[2025-12-23 16:16:25,462] m-LoRA: Adapter lora_winogrande_42 epoch: 1/1 iteration: 64/128 step: 33
[2025-12-23 16:16:25,604] m-LoRA: Adapter lora_winogrande_57 loss: 1.237497329711914
[2025-12-23 16:16:25,610] m-LoRA: Adapter lora_winogrande_34 epoch: 1/1 iteration: 96/128 step: 49
[2025-12-23 16:16:25,782] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_55']
[2025-12-23 16:16:25,946] m-LoRA: Adapter lora_winogrande_54 loss: 0.5947429537773132
[2025-12-23 16:16:25,948] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_60']
[2025-12-23 16:16:26,016] m-LoRA: Adapter lora_winogrande_60 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:16:26,136] m-LoRA: Adapter lora_winogrande_58 loss: 3.262098789215088
[2025-12-23 16:16:26,138] m-LoRA: Adapter lora_winogrande_32 epoch: 1/1 iteration: 112/128 step: 57
[2025-12-23 16:16:26,270] m-LoRA: Adapter lora_winogrande_29 loss: 0.48318397998809814
[2025-12-23 16:16:26,273] m-LoRA: Adapter lora_winogrande_44 epoch: 1/1 iteration: 100/128 step: 26
[2025-12-23 16:16:26,393] m-LoRA: Adapter lora_winogrande_53 epoch: 1/1 iteration: 32/128 step: 17
[2025-12-23 16:16:26,979] m-LoRA: Adapter lora_winogrande_59 loss: 3.124107837677002
[2025-12-23 16:16:27,210] m-LoRA: Adapter lora_winogrande_38 loss: 0.46346262097358704
[2025-12-23 16:16:27,212] m-LoRA: Adapter lora_winogrande_33 epoch: 1/1 iteration: 112/128 step: 57
[2025-12-23 16:16:27,368] m-LoRA: Adapter lora_winogrande_51 loss: 0.5215966701507568
[2025-12-23 16:16:27,389] m-LoRA: Adapter lora_winogrande_56 epoch: 1/1 iteration: 32/128 step: 9
[2025-12-23 16:16:27,547] m-LoRA: Adapter lora_winogrande_42 loss: 0.49351778626441956
[2025-12-23 16:16:27,550] m-LoRA: Adapter lora_winogrande_48 epoch: 1/1 iteration: 48/128 step: 25
[2025-12-23 16:16:27,687] m-LoRA: Adapter lora_winogrande_34 loss: 0.5497846007347107
[2025-12-23 16:16:27,689] m-LoRA: Adapter lora_winogrande_49 epoch: 1/1 iteration: 96/128 step: 25
[2025-12-23 16:16:27,821] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_57']
[2025-12-23 16:16:28,448] m-LoRA: Adapter lora_winogrande_60 loss: 3.051689386367798
[2025-12-23 16:16:28,451] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_61']
[2025-12-23 16:16:28,650] m-LoRA: Adapter lora_winogrande_61 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:16:28,780] m-LoRA: Adapter lora_winogrande_32 loss: 0.6541678309440613
[2025-12-23 16:16:28,783] m-LoRA: Adapter lora_winogrande_54 epoch: 1/1 iteration: 64/128 step: 17
[2025-12-23 16:16:28,917] m-LoRA: Adapter lora_winogrande_44 loss: 1.7770451307296753
[2025-12-23 16:16:28,921] m-LoRA: Adapter lora_winogrande_58 epoch: 1/1 iteration: 4/128 step: 2
[2025-12-23 16:16:29,066] m-LoRA: Adapter lora_winogrande_53 loss: 2.070655107498169
[2025-12-23 16:16:29,068] m-LoRA: Adapter lora_winogrande_29 epoch: 1/1 iteration: 114/128 step: 58
[2025-12-23 16:16:29,232] m-LoRA: Adapter lora_winogrande_33 loss: 0.6243877410888672
[2025-12-23 16:16:29,235] m-LoRA: Adapter lora_winogrande_59 epoch: 1/1 iteration: 16/128 step: 2
[2025-12-23 16:16:29,370] m-LoRA: Adapter lora_winogrande_56 loss: 1.674053430557251
[2025-12-23 16:16:29,373] m-LoRA: Adapter lora_winogrande_38 epoch: 1/1 iteration: 82/128 step: 42
[2025-12-23 16:16:29,471] m-LoRA: Adapter lora_winogrande_48 loss: 1.752553105354309
[2025-12-23 16:16:29,474] m-LoRA: Adapter lora_winogrande_51 epoch: 1/1 iteration: 68/128 step: 18
[2025-12-23 16:16:29,588] m-LoRA: Adapter lora_winogrande_49 loss: 0.7101701498031616
[2025-12-23 16:16:29,591] m-LoRA: Adapter lora_winogrande_42 epoch: 1/1 iteration: 66/128 step: 34
[2025-12-23 16:16:29,884] m-LoRA: Adapter lora_winogrande_61 loss: 3.252587080001831
[2025-12-23 16:16:29,888] m-LoRA: Adapter lora_winogrande_34 epoch: 1/1 iteration: 98/128 step: 50
[2025-12-23 16:16:30,091] m-LoRA: Adapter lora_winogrande_54 loss: 0.5350108742713928
[2025-12-23 16:16:30,093] m-LoRA: Adapter lora_winogrande_60 epoch: 1/1 iteration: 4/128 step: 2
[2025-12-23 16:16:30,234] m-LoRA: Adapter lora_winogrande_58 loss: 2.656625986099243
[2025-12-23 16:16:30,237] m-LoRA: Adapter lora_winogrande_32 epoch: 1/1 iteration: 114/128 step: 58
[2025-12-23 16:16:30,351] m-LoRA: Adapter lora_winogrande_29 loss: 0.38776683807373047
[2025-12-23 16:16:30,353] m-LoRA: Adapter lora_winogrande_44 epoch: 1/1 iteration: 104/128 step: 27
[2025-12-23 16:16:30,910] m-LoRA: Adapter lora_winogrande_53 epoch: 1/1 iteration: 34/128 step: 18
[2025-12-23 16:16:31,017] m-LoRA: Adapter lora_winogrande_59 loss: 2.8048970699310303
[2025-12-23 16:16:31,023] m-LoRA: Adapter lora_winogrande_33 epoch: 1/1 iteration: 114/128 step: 58
[2025-12-23 16:16:31,059] m-LoRA: Adapter lora_winogrande_38 loss: 0.4420848786830902
[2025-12-23 16:16:31,270] m-LoRA: Adapter lora_winogrande_51 loss: 0.484519362449646
[2025-12-23 16:16:31,273] m-LoRA: Adapter lora_winogrande_56 epoch: 1/1 iteration: 36/128 step: 10
[2025-12-23 16:16:31,413] m-LoRA: Adapter lora_winogrande_42 loss: 0.45309746265411377
[2025-12-23 16:16:31,416] m-LoRA: Adapter lora_winogrande_48 epoch: 1/1 iteration: 50/128 step: 26
[2025-12-23 16:16:31,547] m-LoRA: Adapter lora_winogrande_34 loss: 0.5928341150283813
[2025-12-23 16:16:31,549] m-LoRA: Adapter lora_winogrande_49 epoch: 1/1 iteration: 100/128 step: 26
[2025-12-23 16:16:31,663] m-LoRA: Adapter lora_winogrande_60 loss: 2.698554039001465
[2025-12-23 16:16:31,666] m-LoRA: Adapter lora_winogrande_61 epoch: 1/1 iteration: 8/128 step: 2
[2025-12-23 16:16:31,788] m-LoRA: Adapter lora_winogrande_32 loss: 0.66432785987854
[2025-12-23 16:16:31,790] m-LoRA: Adapter lora_winogrande_54 epoch: 1/1 iteration: 68/128 step: 18
[2025-12-23 16:16:31,982] m-LoRA: Adapter lora_winogrande_44 loss: 1.6588748693466187
[2025-12-23 16:16:31,986] m-LoRA: Adapter lora_winogrande_58 epoch: 1/1 iteration: 8/128 step: 3
[2025-12-23 16:16:32,115] m-LoRA: Adapter lora_winogrande_53 loss: 2.0159966945648193
[2025-12-23 16:16:32,117] m-LoRA: Adapter lora_winogrande_29 epoch: 1/1 iteration: 116/128 step: 59
[2025-12-23 16:16:32,163] m-LoRA: Adapter lora_winogrande_33 loss: 0.5233579277992249
[2025-12-23 16:16:32,246] m-LoRA: Adapter lora_winogrande_56 loss: 1.5700562000274658
[2025-12-23 16:16:32,324] m-LoRA: Adapter lora_winogrande_48 loss: 1.6445120573043823
[2025-12-23 16:16:32,423] m-LoRA: Adapter lora_winogrande_59 epoch: 1/1 iteration: 32/128 step: 3
[2025-12-23 16:16:32,623] m-LoRA: Adapter lora_winogrande_49 loss: 0.6494320631027222
[2025-12-23 16:16:32,625] m-LoRA: Adapter lora_winogrande_38 epoch: 1/1 iteration: 84/128 step: 43
[2025-12-23 16:16:32,990] m-LoRA: Adapter lora_winogrande_61 loss: 2.4616715908050537
[2025-12-23 16:16:32,993] m-LoRA: Adapter lora_winogrande_51 epoch: 1/1 iteration: 72/128 step: 19
[2025-12-23 16:16:33,183] m-LoRA: Adapter lora_winogrande_54 loss: 0.6179267764091492
[2025-12-23 16:16:33,186] m-LoRA: Adapter lora_winogrande_42 epoch: 1/1 iteration: 68/128 step: 35
[2025-12-23 16:16:33,339] m-LoRA: Adapter lora_winogrande_58 loss: 2.227766752243042
[2025-12-23 16:16:33,342] m-LoRA: Adapter lora_winogrande_34 epoch: 1/1 iteration: 100/128 step: 51
[2025-12-23 16:16:33,499] m-LoRA: Adapter lora_winogrande_29 loss: 0.3830486238002777
[2025-12-23 16:16:33,502] m-LoRA: Adapter lora_winogrande_60 epoch: 1/1 iteration: 8/128 step: 3
[2025-12-23 16:16:34,080] m-LoRA: Adapter lora_winogrande_32 epoch: 1/1 iteration: 116/128 step: 59
[2025-12-23 16:16:34,119] m-LoRA: Adapter lora_winogrande_59 loss: 2.1254398822784424
[2025-12-23 16:16:34,347] m-LoRA: Adapter lora_winogrande_38 loss: 0.5103567838668823
[2025-12-23 16:16:34,349] m-LoRA: Adapter lora_winogrande_44 epoch: 1/1 iteration: 108/128 step: 28
[2025-12-23 16:16:34,514] m-LoRA: Adapter lora_winogrande_51 loss: 0.6277117729187012
[2025-12-23 16:16:34,517] m-LoRA: Adapter lora_winogrande_53 epoch: 1/1 iteration: 36/128 step: 19
[2025-12-23 16:16:34,654] m-LoRA: Adapter lora_winogrande_42 loss: 0.4518801271915436
[2025-12-23 16:16:34,656] m-LoRA: Adapter lora_winogrande_33 epoch: 1/1 iteration: 116/128 step: 59
[2025-12-23 16:16:34,817] m-LoRA: Adapter lora_winogrande_34 loss: 0.4292835295200348
[2025-12-23 16:16:34,819] m-LoRA: Adapter lora_winogrande_56 epoch: 1/1 iteration: 40/128 step: 11
[2025-12-23 16:16:34,943] m-LoRA: Adapter lora_winogrande_60 loss: 2.389446258544922
[2025-12-23 16:16:34,947] m-LoRA: Adapter lora_winogrande_48 epoch: 1/1 iteration: 52/128 step: 27
[2025-12-23 16:16:35,054] m-LoRA: Adapter lora_winogrande_32 loss: 0.7201945185661316
[2025-12-23 16:16:35,056] m-LoRA: Adapter lora_winogrande_49 epoch: 1/1 iteration: 104/128 step: 27
[2025-12-23 16:16:35,150] m-LoRA: Adapter lora_winogrande_61 epoch: 1/1 iteration: 16/128 step: 3
[2025-12-23 16:16:35,237] m-LoRA: Adapter lora_winogrande_54 epoch: 1/1 iteration: 72/128 step: 19
[2025-12-23 16:16:35,367] m-LoRA: Adapter lora_winogrande_44 loss: 1.6697516441345215
[2025-12-23 16:16:35,370] m-LoRA: Adapter lora_winogrande_58 epoch: 1/1 iteration: 12/128 step: 4
[2025-12-23 16:16:35,493] m-LoRA: Adapter lora_winogrande_53 loss: 1.9446730613708496
[2025-12-23 16:16:35,495] m-LoRA: Adapter lora_winogrande_29 epoch: 1/1 iteration: 118/128 step: 60
[2025-12-23 16:16:35,659] m-LoRA: Adapter lora_winogrande_33 loss: 0.4735606908798218
[2025-12-23 16:16:35,661] m-LoRA: Adapter lora_winogrande_59 epoch: 1/1 iteration: 48/128 step: 4
[2025-12-23 16:16:35,864] m-LoRA: Adapter lora_winogrande_56 loss: 1.4446508884429932
[2025-12-23 16:16:35,867] m-LoRA: Adapter lora_winogrande_38 epoch: 1/1 iteration: 86/128 step: 44
[2025-12-23 16:16:36,001] m-LoRA: Adapter lora_winogrande_48 loss: 1.6269090175628662
[2025-12-23 16:16:36,004] m-LoRA: Adapter lora_winogrande_51 epoch: 1/1 iteration: 76/128 step: 20
[2025-12-23 16:16:36,191] m-LoRA: Adapter lora_winogrande_49 loss: 0.5766775012016296
[2025-12-23 16:16:36,194] m-LoRA: Adapter lora_winogrande_42 epoch: 1/1 iteration: 70/128 step: 36
[2025-12-23 16:16:36,544] m-LoRA: Adapter lora_winogrande_61 loss: 1.8228274583816528
[2025-12-23 16:16:36,548] m-LoRA: Adapter lora_winogrande_34 epoch: 1/1 iteration: 102/128 step: 52
[2025-12-23 16:16:36,740] m-LoRA: Adapter lora_winogrande_54 loss: 0.7472440004348755
[2025-12-23 16:16:36,742] m-LoRA: Adapter lora_winogrande_60 epoch: 1/1 iteration: 12/128 step: 4
[2025-12-23 16:16:36,942] m-LoRA: Adapter lora_winogrande_58 loss: 2.0416088104248047
[2025-12-23 16:16:36,944] m-LoRA: Adapter lora_winogrande_32 epoch: 1/1 iteration: 118/128 step: 60
[2025-12-23 16:16:37,069] m-LoRA: Adapter lora_winogrande_29 loss: 0.5447376370429993
[2025-12-23 16:16:37,071] m-LoRA: Adapter lora_winogrande_44 epoch: 1/1 iteration: 112/128 step: 29
[2025-12-23 16:16:37,708] m-LoRA: Adapter lora_winogrande_59 loss: 2.016228437423706
[2025-12-23 16:16:37,715] m-LoRA: Adapter lora_winogrande_53 epoch: 1/1 iteration: 38/128 step: 20
[2025-12-23 16:16:37,942] m-LoRA: Adapter lora_winogrande_38 loss: 0.5092716813087463
[2025-12-23 16:16:37,944] m-LoRA: Adapter lora_winogrande_33 epoch: 1/1 iteration: 118/128 step: 60
[2025-12-23 16:16:38,085] m-LoRA: Adapter lora_winogrande_51 loss: 0.48600539565086365
[2025-12-23 16:16:38,088] m-LoRA: Adapter lora_winogrande_56 epoch: 1/1 iteration: 44/128 step: 12
[2025-12-23 16:16:38,244] m-LoRA: Adapter lora_winogrande_42 loss: 0.4529179334640503
[2025-12-23 16:16:38,247] m-LoRA: Adapter lora_winogrande_48 epoch: 1/1 iteration: 54/128 step: 28
[2025-12-23 16:16:38,361] m-LoRA: Adapter lora_winogrande_34 loss: 0.522555947303772
[2025-12-23 16:16:38,363] m-LoRA: Adapter lora_winogrande_49 epoch: 1/1 iteration: 108/128 step: 28
[2025-12-23 16:16:38,513] m-LoRA: Adapter lora_winogrande_60 loss: 2.2057089805603027
[2025-12-23 16:16:38,515] m-LoRA: Adapter lora_winogrande_61 epoch: 1/1 iteration: 24/128 step: 4
[2025-12-23 16:16:38,714] m-LoRA: Adapter lora_winogrande_32 loss: 0.6777157187461853
[2025-12-23 16:16:38,716] m-LoRA: Adapter lora_winogrande_54 epoch: 1/1 iteration: 76/128 step: 20
[2025-12-23 16:16:38,853] m-LoRA: Adapter lora_winogrande_44 loss: 1.5452430248260498
[2025-12-23 16:16:38,856] m-LoRA: Adapter lora_winogrande_58 epoch: 1/1 iteration: 16/128 step: 5
[2025-12-23 16:16:38,969] m-LoRA: Adapter lora_winogrande_53 loss: 2.094683885574341
[2025-12-23 16:16:38,972] m-LoRA: Adapter lora_winogrande_29 epoch: 1/1 iteration: 120/128 step: 61
[2025-12-23 16:16:39,163] m-LoRA: Adapter lora_winogrande_33 loss: 0.5953213572502136
[2025-12-23 16:16:39,165] m-LoRA: Adapter lora_winogrande_59 epoch: 1/1 iteration: 64/128 step: 5
[2025-12-23 16:16:39,371] m-LoRA: Adapter lora_winogrande_56 loss: 1.3293676376342773
[2025-12-23 16:16:39,376] m-LoRA: Adapter lora_winogrande_38 epoch: 1/1 iteration: 88/128 step: 45
[2025-12-23 16:16:39,503] m-LoRA: Adapter lora_winogrande_48 loss: 1.6650497913360596
[2025-12-23 16:16:39,505] m-LoRA: Adapter lora_winogrande_51 epoch: 1/1 iteration: 80/128 step: 21
[2025-12-23 16:16:39,662] m-LoRA: Adapter lora_winogrande_49 loss: 0.657989501953125
[2025-12-23 16:16:39,665] m-LoRA: Adapter lora_winogrande_42 epoch: 1/1 iteration: 72/128 step: 37
[2025-12-23 16:16:39,972] m-LoRA: Adapter lora_winogrande_34 epoch: 1/1 iteration: 104/128 step: 53
[2025-12-23 16:16:40,021] m-LoRA: Adapter lora_winogrande_61 loss: 1.5963151454925537
[2025-12-23 16:16:40,192] m-LoRA: Adapter lora_winogrande_54 loss: 0.503818154335022
[2025-12-23 16:16:40,196] m-LoRA: Adapter lora_winogrande_60 epoch: 1/1 iteration: 16/128 step: 5
[2025-12-23 16:16:40,342] m-LoRA: Adapter lora_winogrande_58 loss: 1.768417239189148
[2025-12-23 16:16:40,345] m-LoRA: Adapter lora_winogrande_32 epoch: 1/1 iteration: 120/128 step: 61
[2025-12-23 16:16:40,430] m-LoRA: Adapter lora_winogrande_29 loss: 0.5157432556152344
[2025-12-23 16:16:40,432] m-LoRA: Adapter lora_winogrande_44 epoch: 1/1 iteration: 116/128 step: 30
[2025-12-23 16:16:40,502] m-LoRA: Adapter lora_winogrande_53 epoch: 1/1 iteration: 40/128 step: 21
[2025-12-23 16:16:41,211] m-LoRA: Adapter lora_winogrande_59 loss: 1.7262245416641235
[2025-12-23 16:16:41,218] m-LoRA: Adapter lora_winogrande_33 epoch: 1/1 iteration: 120/128 step: 61
[2025-12-23 16:16:41,418] m-LoRA: Adapter lora_winogrande_38 loss: 0.3984355032444
[2025-12-23 16:16:41,420] m-LoRA: Adapter lora_winogrande_56 epoch: 1/1 iteration: 48/128 step: 13
[2025-12-23 16:16:41,570] m-LoRA: Adapter lora_winogrande_51 loss: 0.4785217344760895
[2025-12-23 16:16:41,573] m-LoRA: Adapter lora_winogrande_48 epoch: 1/1 iteration: 56/128 step: 29
[2025-12-23 16:16:41,718] m-LoRA: Adapter lora_winogrande_42 loss: 0.5722668170928955
[2025-12-23 16:16:41,721] m-LoRA: Adapter lora_winogrande_49 epoch: 1/1 iteration: 112/128 step: 29
[2025-12-23 16:16:41,868] m-LoRA: Adapter lora_winogrande_34 loss: 0.7434496879577637
[2025-12-23 16:16:41,870] m-LoRA: Adapter lora_winogrande_61 epoch: 1/1 iteration: 32/128 step: 5
[2025-12-23 16:16:41,982] m-LoRA: Adapter lora_winogrande_60 loss: 2.0803987979888916
[2025-12-23 16:16:42,003] m-LoRA: Adapter lora_winogrande_54 epoch: 1/1 iteration: 80/128 step: 21
[2025-12-23 16:16:42,183] m-LoRA: Adapter lora_winogrande_32 loss: 0.6160997748374939
[2025-12-23 16:16:42,185] m-LoRA: Adapter lora_winogrande_58 epoch: 1/1 iteration: 20/128 step: 6
[2025-12-23 16:16:42,303] m-LoRA: Adapter lora_winogrande_44 loss: 1.617019772529602
[2025-12-23 16:16:42,305] m-LoRA: Adapter lora_winogrande_29 epoch: 1/1 iteration: 122/128 step: 62
[2025-12-23 16:16:42,374] m-LoRA: Adapter lora_winogrande_53 loss: 1.9300007820129395
[2025-12-23 16:16:42,600] m-LoRA: Adapter lora_winogrande_33 loss: 0.49590542912483215
[2025-12-23 16:16:42,868] m-LoRA: Adapter lora_winogrande_56 loss: 1.2212090492248535
[2025-12-23 16:16:43,073] m-LoRA: Adapter lora_winogrande_48 loss: 1.4924143552780151
[2025-12-23 16:16:43,075] m-LoRA: Adapter lora_winogrande_59 epoch: 1/1 iteration: 80/128 step: 6
[2025-12-23 16:16:43,231] m-LoRA: Adapter lora_winogrande_38 epoch: 1/1 iteration: 90/128 step: 46
[2025-12-23 16:16:43,321] m-LoRA: Adapter lora_winogrande_49 loss: 0.5960242748260498
[2025-12-23 16:16:43,324] m-LoRA: Adapter lora_winogrande_51 epoch: 1/1 iteration: 84/128 step: 22
[2025-12-23 16:16:43,430] m-LoRA: Adapter lora_winogrande_42 epoch: 1/1 iteration: 74/128 step: 38
[2025-12-23 16:16:43,634] m-LoRA: Adapter lora_winogrande_34 epoch: 1/1 iteration: 106/128 step: 54
[2025-12-23 16:16:43,676] m-LoRA: Adapter lora_winogrande_61 loss: 1.2433708906173706
[2025-12-23 16:16:43,903] m-LoRA: Adapter lora_winogrande_54 loss: 0.5107941031455994
[2025-12-23 16:16:43,906] m-LoRA: Adapter lora_winogrande_60 epoch: 1/1 iteration: 20/128 step: 6
[2025-12-23 16:16:44,058] m-LoRA: Adapter lora_winogrande_58 loss: 1.4999090433120728
[2025-12-23 16:16:44,061] m-LoRA: Adapter lora_winogrande_32 epoch: 1/1 iteration: 122/128 step: 62
[2025-12-23 16:16:44,199] m-LoRA: Adapter lora_winogrande_29 loss: 0.5058314204216003
[2025-12-23 16:16:44,201] m-LoRA: Adapter lora_winogrande_44 epoch: 1/1 iteration: 120/128 step: 31
[2025-12-23 16:16:44,947] m-LoRA: Adapter lora_winogrande_59 loss: 1.5579606294631958
[2025-12-23 16:16:44,954] m-LoRA: Adapter lora_winogrande_53 epoch: 1/1 iteration: 42/128 step: 22
[2025-12-23 16:16:45,112] m-LoRA: Adapter lora_winogrande_38 loss: 0.4319306015968323
[2025-12-23 16:16:45,115] m-LoRA: Adapter lora_winogrande_33 epoch: 1/1 iteration: 122/128 step: 62
[2025-12-23 16:16:45,303] m-LoRA: Adapter lora_winogrande_51 loss: 0.46944597363471985
[2025-12-23 16:16:45,306] m-LoRA: Adapter lora_winogrande_56 epoch: 1/1 iteration: 52/128 step: 14
[2025-12-23 16:16:45,471] m-LoRA: Adapter lora_winogrande_42 loss: 0.40277788043022156
[2025-12-23 16:16:45,478] m-LoRA: Adapter lora_winogrande_48 epoch: 1/1 iteration: 58/128 step: 30
[2025-12-23 16:16:45,608] m-LoRA: Adapter lora_winogrande_34 loss: 0.6266721487045288
[2025-12-23 16:16:45,610] m-LoRA: Adapter lora_winogrande_49 epoch: 1/1 iteration: 116/128 step: 30
[2025-12-23 16:16:45,789] m-LoRA: Adapter lora_winogrande_60 loss: 1.9063634872436523
[2025-12-23 16:16:45,792] m-LoRA: Adapter lora_winogrande_61 epoch: 1/1 iteration: 40/128 step: 6
[2025-12-23 16:16:45,947] m-LoRA: Adapter lora_winogrande_32 loss: 0.6634917855262756
[2025-12-23 16:16:45,949] m-LoRA: Adapter lora_winogrande_54 epoch: 1/1 iteration: 84/128 step: 22
[2025-12-23 16:16:46,120] m-LoRA: Adapter lora_winogrande_44 loss: 1.5417277812957764
[2025-12-23 16:16:46,123] m-LoRA: Adapter lora_winogrande_58 epoch: 1/1 iteration: 24/128 step: 7
[2025-12-23 16:16:46,278] m-LoRA: Adapter lora_winogrande_53 loss: 1.9512207508087158
[2025-12-23 16:16:46,280] m-LoRA: Adapter lora_winogrande_29 epoch: 1/1 iteration: 124/128 step: 63
[2025-12-23 16:16:46,430] m-LoRA: Adapter lora_winogrande_33 loss: 0.5519654750823975
[2025-12-23 16:16:46,433] m-LoRA: Adapter lora_winogrande_59 epoch: 1/1 iteration: 96/128 step: 7
[2025-12-23 16:16:46,642] m-LoRA: Adapter lora_winogrande_56 loss: 1.0017266273498535
[2025-12-23 16:16:46,646] m-LoRA: Adapter lora_winogrande_38 epoch: 1/1 iteration: 92/128 step: 47
[2025-12-23 16:16:46,846] m-LoRA: Adapter lora_winogrande_48 loss: 1.5549850463867188
[2025-12-23 16:16:46,849] m-LoRA: Adapter lora_winogrande_51 epoch: 1/1 iteration: 88/128 step: 23
[2025-12-23 16:16:46,986] m-LoRA: Adapter lora_winogrande_49 loss: 0.5509778261184692
[2025-12-23 16:16:46,990] m-LoRA: Adapter lora_winogrande_42 epoch: 1/1 iteration: 76/128 step: 39
[2025-12-23 16:16:47,188] m-LoRA: Adapter lora_winogrande_34 epoch: 1/1 iteration: 108/128 step: 55
[2025-12-23 16:16:47,228] m-LoRA: Adapter lora_winogrande_61 loss: 0.9560215473175049
[2025-12-23 16:16:47,400] m-LoRA: Adapter lora_winogrande_54 loss: 0.6736441254615784
[2025-12-23 16:16:47,403] m-LoRA: Adapter lora_winogrande_60 epoch: 1/1 iteration: 24/128 step: 7
[2025-12-23 16:16:47,599] m-LoRA: Adapter lora_winogrande_58 loss: 1.3827204704284668
[2025-12-23 16:16:47,602] m-LoRA: Adapter lora_winogrande_32 epoch: 1/1 iteration: 124/128 step: 63
[2025-12-23 16:16:47,732] m-LoRA: Adapter lora_winogrande_29 loss: 0.35904380679130554
[2025-12-23 16:16:47,735] m-LoRA: Adapter lora_winogrande_44 epoch: 1/1 iteration: 124/128 step: 32
[2025-12-23 16:16:48,481] m-LoRA: Adapter lora_winogrande_59 loss: 1.3333479166030884
[2025-12-23 16:16:48,488] m-LoRA: Adapter lora_winogrande_53 epoch: 1/1 iteration: 44/128 step: 23
[2025-12-23 16:16:48,695] m-LoRA: Adapter lora_winogrande_38 loss: 0.42552295327186584
[2025-12-23 16:16:48,697] m-LoRA: Adapter lora_winogrande_33 epoch: 1/1 iteration: 124/128 step: 63
[2025-12-23 16:16:48,844] m-LoRA: Adapter lora_winogrande_51 loss: 0.5336941480636597
[2025-12-23 16:16:48,847] m-LoRA: Adapter lora_winogrande_56 epoch: 1/1 iteration: 56/128 step: 15
[2025-12-23 16:16:49,032] m-LoRA: Adapter lora_winogrande_42 loss: 0.5539525151252747
[2025-12-23 16:16:49,035] m-LoRA: Adapter lora_winogrande_48 epoch: 1/1 iteration: 60/128 step: 31
[2025-12-23 16:16:49,172] m-LoRA: Adapter lora_winogrande_34 loss: 0.6257852911949158
[2025-12-23 16:16:49,175] m-LoRA: Adapter lora_winogrande_49 epoch: 1/1 iteration: 120/128 step: 31
[2025-12-23 16:16:49,442] m-LoRA: Adapter lora_winogrande_60 loss: 1.794511079788208
[2025-12-23 16:16:49,445] m-LoRA: Adapter lora_winogrande_61 epoch: 1/1 iteration: 48/128 step: 7
[2025-12-23 16:16:49,591] m-LoRA: Adapter lora_winogrande_32 loss: 0.6060856580734253
[2025-12-23 16:16:49,593] m-LoRA: Adapter lora_winogrande_54 epoch: 1/1 iteration: 88/128 step: 23
[2025-12-23 16:16:49,744] m-LoRA: Adapter lora_winogrande_44 loss: 1.5101310014724731
[2025-12-23 16:16:49,747] m-LoRA: Adapter lora_winogrande_58 epoch: 1/1 iteration: 28/128 step: 8
[2025-12-23 16:16:49,909] m-LoRA: Adapter lora_winogrande_53 loss: 1.672807216644287
[2025-12-23 16:16:49,911] m-LoRA: Adapter lora_winogrande_29 epoch: 1/1 iteration: 126/128 step: 64
[2025-12-23 16:16:50,066] m-LoRA: Adapter lora_winogrande_33 loss: 0.5231456756591797
[2025-12-23 16:16:50,069] m-LoRA: Adapter lora_winogrande_59 epoch: 1/1 iteration: 112/128 step: 8
[2025-12-23 16:16:50,206] m-LoRA: Adapter lora_winogrande_56 loss: 1.0053123235702515
[2025-12-23 16:16:50,210] m-LoRA: Adapter lora_winogrande_38 epoch: 1/1 iteration: 94/128 step: 48
[2025-12-23 16:16:50,320] m-LoRA: Adapter lora_winogrande_48 loss: 1.6077598333358765
[2025-12-23 16:16:50,322] m-LoRA: Adapter lora_winogrande_51 epoch: 1/1 iteration: 92/128 step: 24
[2025-12-23 16:16:50,375] m-LoRA: Adapter lora_winogrande_49 loss: 0.509722113609314
[2025-12-23 16:16:50,612] m-LoRA: Adapter lora_winogrande_61 loss: 0.7700503468513489
[2025-12-23 16:16:50,616] m-LoRA: Adapter lora_winogrande_42 epoch: 1/1 iteration: 78/128 step: 40
[2025-12-23 16:16:50,767] m-LoRA: Adapter lora_winogrande_54 loss: 0.57949298620224
[2025-12-23 16:16:50,770] m-LoRA: Adapter lora_winogrande_34 epoch: 1/1 iteration: 110/128 step: 56
[2025-12-23 16:16:50,969] m-LoRA: Adapter lora_winogrande_58 loss: 1.1502456665039062
[2025-12-23 16:16:50,972] m-LoRA: Adapter lora_winogrande_60 epoch: 1/1 iteration: 28/128 step: 8
[2025-12-23 16:16:51,101] m-LoRA: Adapter lora_winogrande_29 loss: 0.47333014011383057
[2025-12-23 16:16:51,103] m-LoRA: Adapter lora_winogrande_32 epoch: 1/1 iteration: 126/128 step: 64
[2025-12-23 16:16:51,761] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_44']
[2025-12-23 16:16:52,141] m-LoRA: Adapter lora_winogrande_59 loss: 1.088985800743103
[2025-12-23 16:16:52,154] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_62']
[2025-12-23 16:16:52,483] m-LoRA: Adapter lora_winogrande_62 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:16:52,581] m-LoRA: Adapter lora_winogrande_38 loss: 0.4906085431575775
[2025-12-23 16:16:52,583] m-LoRA: Adapter lora_winogrande_53 epoch: 1/1 iteration: 46/128 step: 24
[2025-12-23 16:16:52,668] m-LoRA: Adapter lora_winogrande_51 loss: 0.4538852572441101
[2025-12-23 16:16:52,672] m-LoRA: Adapter lora_winogrande_33 epoch: 1/1 iteration: 126/128 step: 64
[2025-12-23 16:16:52,776] m-LoRA: Adapter lora_winogrande_42 loss: 0.34726274013519287
[2025-12-23 16:16:52,779] m-LoRA: Adapter lora_winogrande_56 epoch: 1/1 iteration: 60/128 step: 16
[2025-12-23 16:16:52,869] m-LoRA: Adapter lora_winogrande_34 loss: 0.4987696409225464
[2025-12-23 16:16:52,872] m-LoRA: Adapter lora_winogrande_48 epoch: 1/1 iteration: 62/128 step: 32
[2025-12-23 16:16:53,026] m-LoRA: Adapter lora_winogrande_60 loss: 1.636041283607483
[2025-12-23 16:16:53,029] m-LoRA: Adapter lora_winogrande_49 epoch: 1/1 iteration: 124/128 step: 32
[2025-12-23 16:16:53,160] m-LoRA: Adapter lora_winogrande_32 loss: 0.6691383719444275
[2025-12-23 16:16:53,162] m-LoRA: Adapter lora_winogrande_61 epoch: 1/1 iteration: 56/128 step: 8
[2025-12-23 16:16:53,304] m-LoRA: Adapter lora_winogrande_62 loss: 3.1804392337799072
[2025-12-23 16:16:53,307] m-LoRA: Adapter lora_winogrande_54 epoch: 1/1 iteration: 92/128 step: 24
[2025-12-23 16:16:53,453] m-LoRA: Adapter lora_winogrande_53 loss: 1.9246453046798706
[2025-12-23 16:16:53,455] m-LoRA: Adapter lora_winogrande_58 epoch: 1/1 iteration: 32/128 step: 9
[2025-12-23 16:16:53,581] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_29']
[2025-12-23 16:16:54,209] m-LoRA: Adapter lora_winogrande_33 loss: 0.4056359529495239
[2025-12-23 16:16:54,212] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_63']
[2025-12-23 16:16:54,485] m-LoRA: Adapter lora_winogrande_63 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:16:54,580] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_59']
[2025-12-23 16:16:55,033] m-LoRA: Adapter lora_winogrande_56 loss: 0.9402682185173035
[2025-12-23 16:16:55,035] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_64']
[2025-12-23 16:16:55,165] m-LoRA: Adapter lora_winogrande_64 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:16:55,314] m-LoRA: Adapter lora_winogrande_48 loss: 1.426758885383606
[2025-12-23 16:16:55,316] m-LoRA: Adapter lora_winogrande_38 epoch: 1/1 iteration: 96/128 step: 49
[2025-12-23 16:16:55,450] m-LoRA: Adapter lora_winogrande_49 loss: 0.6015886664390564
[2025-12-23 16:16:55,453] m-LoRA: Adapter lora_winogrande_51 epoch: 1/1 iteration: 96/128 step: 25
[2025-12-23 16:16:55,586] m-LoRA: Adapter lora_winogrande_61 loss: 0.6009137630462646
[2025-12-23 16:16:55,590] m-LoRA: Adapter lora_winogrande_42 epoch: 1/1 iteration: 80/128 step: 41
[2025-12-23 16:16:55,753] m-LoRA: Adapter lora_winogrande_54 loss: 0.4847412109375
[2025-12-23 16:16:55,757] m-LoRA: Adapter lora_winogrande_34 epoch: 1/1 iteration: 112/128 step: 57
[2025-12-23 16:16:55,884] m-LoRA: Adapter lora_winogrande_58 loss: 0.9465893507003784
[2025-12-23 16:16:55,887] m-LoRA: Adapter lora_winogrande_60 epoch: 1/1 iteration: 32/128 step: 9
[2025-12-23 16:16:55,982] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_32']
[2025-12-23 16:16:56,223] m-LoRA: Adapter lora_winogrande_63 loss: 2.888007402420044
[2025-12-23 16:16:56,225] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_65']
[2025-12-23 16:16:56,278] m-LoRA: Adapter lora_winogrande_65 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:16:56,372] m-LoRA: Adapter lora_winogrande_62 epoch: 1/1 iteration: 4/128 step: 2
[2025-12-23 16:16:56,428] m-LoRA: Adapter lora_winogrande_53 epoch: 1/1 iteration: 48/128 step: 25
[2025-12-23 16:16:56,483] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_33']
[2025-12-23 16:16:56,955] m-LoRA: Adapter lora_winogrande_64 loss: 3.3915276527404785
[2025-12-23 16:16:56,962] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_66']
[2025-12-23 16:16:57,261] m-LoRA: Adapter lora_winogrande_66 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:16:57,359] m-LoRA: Adapter lora_winogrande_38 loss: 0.46777862310409546
[2025-12-23 16:16:57,361] m-LoRA: Adapter lora_winogrande_56 epoch: 1/1 iteration: 64/128 step: 17
[2025-12-23 16:16:57,439] m-LoRA: Adapter lora_winogrande_51 loss: 0.5009742975234985
[2025-12-23 16:16:57,441] m-LoRA: Adapter lora_winogrande_48 epoch: 1/1 iteration: 64/128 step: 33
[2025-12-23 16:16:57,561] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_49']
[2025-12-23 16:16:57,761] m-LoRA: Adapter lora_winogrande_42 loss: 0.5674034953117371
[2025-12-23 16:16:57,807] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_67']
[2025-12-23 16:16:57,900] m-LoRA: Adapter lora_winogrande_67 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:16:57,987] m-LoRA: Adapter lora_winogrande_34 loss: 0.47217079997062683
[2025-12-23 16:16:57,989] m-LoRA: Adapter lora_winogrande_61 epoch: 1/1 iteration: 64/128 step: 9
[2025-12-23 16:16:58,092] m-LoRA: Adapter lora_winogrande_60 loss: 1.602019190788269
[2025-12-23 16:16:58,094] m-LoRA: Adapter lora_winogrande_54 epoch: 1/1 iteration: 96/128 step: 25
[2025-12-23 16:16:58,266] m-LoRA: Adapter lora_winogrande_65 loss: 3.10080885887146
[2025-12-23 16:16:58,270] m-LoRA: Adapter lora_winogrande_58 epoch: 1/1 iteration: 36/128 step: 10
[2025-12-23 16:16:58,442] m-LoRA: Adapter lora_winogrande_62 loss: 2.758255958557129
[2025-12-23 16:16:58,444] m-LoRA: Adapter lora_winogrande_63 epoch: 1/1 iteration: 2/128 step: 2
[2025-12-23 16:16:58,614] m-LoRA: Adapter lora_winogrande_53 loss: 1.817143201828003
[2025-12-23 16:16:58,616] m-LoRA: Adapter lora_winogrande_64 epoch: 1/1 iteration: 16/128 step: 2
[2025-12-23 16:16:58,764] m-LoRA: Adapter lora_winogrande_66 loss: 2.803647518157959
[2025-12-23 16:16:58,766] m-LoRA: Adapter lora_winogrande_38 epoch: 1/1 iteration: 98/128 step: 50
[2025-12-23 16:16:59,112] m-LoRA: Adapter lora_winogrande_56 loss: 0.8115374445915222
[2025-12-23 16:16:59,114] m-LoRA: Adapter lora_winogrande_51 epoch: 1/1 iteration: 100/128 step: 26
[2025-12-23 16:16:59,246] m-LoRA: Adapter lora_winogrande_48 loss: 1.446359395980835
[2025-12-23 16:16:59,249] m-LoRA: Adapter lora_winogrande_42 epoch: 1/1 iteration: 82/128 step: 42
[2025-12-23 16:16:59,411] m-LoRA: Adapter lora_winogrande_67 loss: 3.180363655090332
[2025-12-23 16:16:59,414] m-LoRA: Adapter lora_winogrande_34 epoch: 1/1 iteration: 114/128 step: 58
[2025-12-23 16:16:59,800] m-LoRA: Adapter lora_winogrande_61 loss: 0.6313682794570923
[2025-12-23 16:16:59,805] m-LoRA: Adapter lora_winogrande_60 epoch: 1/1 iteration: 36/128 step: 10
[2025-12-23 16:17:00,020] m-LoRA: Adapter lora_winogrande_54 loss: 0.5561701655387878
[2025-12-23 16:17:00,023] m-LoRA: Adapter lora_winogrande_65 epoch: 1/1 iteration: 8/128 step: 2
[2025-12-23 16:17:00,163] m-LoRA: Adapter lora_winogrande_58 loss: 0.8514031767845154
[2025-12-23 16:17:00,166] m-LoRA: Adapter lora_winogrande_62 epoch: 1/1 iteration: 8/128 step: 3
[2025-12-23 16:17:00,269] m-LoRA: Adapter lora_winogrande_63 loss: 2.5275683403015137
[2025-12-23 16:17:00,271] m-LoRA: Adapter lora_winogrande_53 epoch: 1/1 iteration: 50/128 step: 26
[2025-12-23 16:17:01,043] m-LoRA: Adapter lora_winogrande_64 loss: 3.1609041690826416
[2025-12-23 16:17:01,049] m-LoRA: Adapter lora_winogrande_66 epoch: 1/1 iteration: 2/128 step: 2
[2025-12-23 16:17:01,211] m-LoRA: Adapter lora_winogrande_38 loss: 0.5183296203613281
[2025-12-23 16:17:01,213] m-LoRA: Adapter lora_winogrande_56 epoch: 1/1 iteration: 68/128 step: 18
[2025-12-23 16:17:01,363] m-LoRA: Adapter lora_winogrande_51 loss: 0.48415055871009827
[2025-12-23 16:17:01,365] m-LoRA: Adapter lora_winogrande_48 epoch: 1/1 iteration: 66/128 step: 34
[2025-12-23 16:17:01,498] m-LoRA: Adapter lora_winogrande_42 loss: 0.5384083390235901
[2025-12-23 16:17:01,500] m-LoRA: Adapter lora_winogrande_67 epoch: 1/1 iteration: 4/128 step: 2
[2025-12-23 16:17:01,631] m-LoRA: Adapter lora_winogrande_34 loss: 0.5042645931243896
[2025-12-23 16:17:01,633] m-LoRA: Adapter lora_winogrande_61 epoch: 1/1 iteration: 72/128 step: 10
[2025-12-23 16:17:01,755] m-LoRA: Adapter lora_winogrande_60 loss: 1.4797002077102661
[2025-12-23 16:17:01,758] m-LoRA: Adapter lora_winogrande_54 epoch: 1/1 iteration: 100/128 step: 26
[2025-12-23 16:17:02,027] m-LoRA: Adapter lora_winogrande_65 loss: 2.8935341835021973
[2025-12-23 16:17:02,032] m-LoRA: Adapter lora_winogrande_58 epoch: 1/1 iteration: 40/128 step: 11
[2025-12-23 16:17:02,279] m-LoRA: Adapter lora_winogrande_62 loss: 2.142367362976074
[2025-12-23 16:17:02,281] m-LoRA: Adapter lora_winogrande_63 epoch: 1/1 iteration: 4/128 step: 3
[2025-12-23 16:17:02,353] m-LoRA: Adapter lora_winogrande_53 loss: 1.7453819513320923
[2025-12-23 16:17:02,523] m-LoRA: Adapter lora_winogrande_66 loss: 2.4428906440734863
[2025-12-23 16:17:02,525] m-LoRA: Adapter lora_winogrande_64 epoch: 1/1 iteration: 32/128 step: 3
[2025-12-23 16:17:02,690] m-LoRA: Adapter lora_winogrande_56 loss: 0.721574068069458
[2025-12-23 16:17:02,693] m-LoRA: Adapter lora_winogrande_38 epoch: 1/1 iteration: 100/128 step: 51
[2025-12-23 16:17:02,852] m-LoRA: Adapter lora_winogrande_48 loss: 1.4017534255981445
[2025-12-23 16:17:02,854] m-LoRA: Adapter lora_winogrande_51 epoch: 1/1 iteration: 104/128 step: 27
[2025-12-23 16:17:02,981] m-LoRA: Adapter lora_winogrande_67 loss: 2.7491636276245117
[2025-12-23 16:17:02,984] m-LoRA: Adapter lora_winogrande_42 epoch: 1/1 iteration: 84/128 step: 43
[2025-12-23 16:17:03,298] m-LoRA: Adapter lora_winogrande_34 epoch: 1/1 iteration: 116/128 step: 59
[2025-12-23 16:17:03,339] m-LoRA: Adapter lora_winogrande_61 loss: 0.5738924741744995
[2025-12-23 16:17:03,521] m-LoRA: Adapter lora_winogrande_54 loss: 0.49276602268218994
[2025-12-23 16:17:03,523] m-LoRA: Adapter lora_winogrande_60 epoch: 1/1 iteration: 40/128 step: 11
[2025-12-23 16:17:03,729] m-LoRA: Adapter lora_winogrande_58 loss: 0.8191240429878235
[2025-12-23 16:17:03,733] m-LoRA: Adapter lora_winogrande_65 epoch: 1/1 iteration: 16/128 step: 3
[2025-12-23 16:17:03,858] m-LoRA: Adapter lora_winogrande_63 loss: 2.1758012771606445
[2025-12-23 16:17:03,860] m-LoRA: Adapter lora_winogrande_62 epoch: 1/1 iteration: 12/128 step: 4
[2025-12-23 16:17:04,512] m-LoRA: Adapter lora_winogrande_53 epoch: 1/1 iteration: 52/128 step: 27
[2025-12-23 16:17:04,628] m-LoRA: Adapter lora_winogrande_64 loss: 3.008070945739746
[2025-12-23 16:17:04,635] m-LoRA: Adapter lora_winogrande_66 epoch: 1/1 iteration: 4/128 step: 3
[2025-12-23 16:17:04,674] m-LoRA: Adapter lora_winogrande_38 loss: 0.5102971196174622
[2025-12-23 16:17:04,863] m-LoRA: Adapter lora_winogrande_51 loss: 0.46731722354888916
[2025-12-23 16:17:04,865] m-LoRA: Adapter lora_winogrande_56 epoch: 1/1 iteration: 72/128 step: 19
[2025-12-23 16:17:05,004] m-LoRA: Adapter lora_winogrande_42 loss: 0.45569974184036255
[2025-12-23 16:17:05,006] m-LoRA: Adapter lora_winogrande_48 epoch: 1/1 iteration: 68/128 step: 35
[2025-12-23 16:17:05,113] m-LoRA: Adapter lora_winogrande_34 loss: 0.5528755187988281
[2025-12-23 16:17:05,115] m-LoRA: Adapter lora_winogrande_67 epoch: 1/1 iteration: 8/128 step: 3
[2025-12-23 16:17:05,233] m-LoRA: Adapter lora_winogrande_60 loss: 1.28054678440094
[2025-12-23 16:17:05,236] m-LoRA: Adapter lora_winogrande_61 epoch: 1/1 iteration: 80/128 step: 11
[2025-12-23 16:17:05,544] m-LoRA: Adapter lora_winogrande_54 epoch: 1/1 iteration: 104/128 step: 27
[2025-12-23 16:17:05,585] m-LoRA: Adapter lora_winogrande_65 loss: 2.300321340560913
[2025-12-23 16:17:05,893] m-LoRA: Adapter lora_winogrande_62 loss: 2.1056065559387207
[2025-12-23 16:17:05,896] m-LoRA: Adapter lora_winogrande_58 epoch: 1/1 iteration: 44/128 step: 12
[2025-12-23 16:17:06,027] m-LoRA: Adapter lora_winogrande_53 loss: 1.6853669881820679
[2025-12-23 16:17:06,029] m-LoRA: Adapter lora_winogrande_63 epoch: 1/1 iteration: 6/128 step: 4
[2025-12-23 16:17:06,081] m-LoRA: Adapter lora_winogrande_66 loss: 1.9312776327133179
[2025-12-23 16:17:06,252] m-LoRA: Adapter lora_winogrande_56 loss: 0.7311633229255676
[2025-12-23 16:17:06,254] m-LoRA: Adapter lora_winogrande_64 epoch: 1/1 iteration: 48/128 step: 4
[2025-12-23 16:17:06,373] m-LoRA: Adapter lora_winogrande_48 loss: 1.2498929500579834
[2025-12-23 16:17:06,376] m-LoRA: Adapter lora_winogrande_38 epoch: 1/1 iteration: 102/128 step: 52
[2025-12-23 16:17:06,501] m-LoRA: Adapter lora_winogrande_67 loss: 2.2285053730010986
[2025-12-23 16:17:06,504] m-LoRA: Adapter lora_winogrande_51 epoch: 1/1 iteration: 108/128 step: 28
[2025-12-23 16:17:06,867] m-LoRA: Adapter lora_winogrande_61 loss: 0.6168670058250427
[2025-12-23 16:17:06,872] m-LoRA: Adapter lora_winogrande_42 epoch: 1/1 iteration: 86/128 step: 44
[2025-12-23 16:17:07,068] m-LoRA: Adapter lora_winogrande_54 loss: 0.5188958048820496
[2025-12-23 16:17:07,070] m-LoRA: Adapter lora_winogrande_34 epoch: 1/1 iteration: 118/128 step: 60
[2025-12-23 16:17:07,267] m-LoRA: Adapter lora_winogrande_58 loss: 0.6674971580505371
[2025-12-23 16:17:07,269] m-LoRA: Adapter lora_winogrande_60 epoch: 1/1 iteration: 44/128 step: 12
[2025-12-23 16:17:07,399] m-LoRA: Adapter lora_winogrande_63 loss: 1.8507380485534668
[2025-12-23 16:17:07,401] m-LoRA: Adapter lora_winogrande_65 epoch: 1/1 iteration: 24/128 step: 4
[2025-12-23 16:17:08,002] m-LoRA: Adapter lora_winogrande_62 epoch: 1/1 iteration: 16/128 step: 5
[2025-12-23 16:17:08,051] m-LoRA: Adapter lora_winogrande_64 loss: 2.9733943939208984
[2025-12-23 16:17:08,123] m-LoRA: Adapter lora_winogrande_38 loss: 0.41762685775756836
[2025-12-23 16:17:08,125] m-LoRA: Adapter lora_winogrande_53 epoch: 1/1 iteration: 54/128 step: 28
[2025-12-23 16:17:08,317] m-LoRA: Adapter lora_winogrande_51 loss: 0.5598186254501343
[2025-12-23 16:17:08,319] m-LoRA: Adapter lora_winogrande_66 epoch: 1/1 iteration: 6/128 step: 4
[2025-12-23 16:17:08,460] m-LoRA: Adapter lora_winogrande_42 loss: 0.4615671634674072
[2025-12-23 16:17:08,463] m-LoRA: Adapter lora_winogrande_56 epoch: 1/1 iteration: 76/128 step: 20
[2025-12-23 16:17:08,613] m-LoRA: Adapter lora_winogrande_34 loss: 0.44958412647247314
[2025-12-23 16:17:08,615] m-LoRA: Adapter lora_winogrande_48 epoch: 1/1 iteration: 70/128 step: 36
[2025-12-23 16:17:08,729] m-LoRA: Adapter lora_winogrande_60 loss: 1.169512391090393
[2025-12-23 16:17:08,731] m-LoRA: Adapter lora_winogrande_67 epoch: 1/1 iteration: 12/128 step: 4
[2025-12-23 16:17:08,979] m-LoRA: Adapter lora_winogrande_65 loss: 2.148240566253662
[2025-12-23 16:17:08,984] m-LoRA: Adapter lora_winogrande_61 epoch: 1/1 iteration: 88/128 step: 12
[2025-12-23 16:17:09,260] m-LoRA: Adapter lora_winogrande_62 loss: 1.889936089515686
[2025-12-23 16:17:09,263] m-LoRA: Adapter lora_winogrande_54 epoch: 1/1 iteration: 108/128 step: 28
[2025-12-23 16:17:09,395] m-LoRA: Adapter lora_winogrande_53 loss: 1.6385903358459473
[2025-12-23 16:17:09,398] m-LoRA: Adapter lora_winogrande_58 epoch: 1/1 iteration: 48/128 step: 13
[2025-12-23 16:17:09,522] m-LoRA: Adapter lora_winogrande_66 loss: 1.679225206375122
[2025-12-23 16:17:09,524] m-LoRA: Adapter lora_winogrande_63 epoch: 1/1 iteration: 8/128 step: 5
[2025-12-23 16:17:09,701] m-LoRA: Adapter lora_winogrande_56 loss: 0.6838645339012146
[2025-12-23 16:17:09,703] m-LoRA: Adapter lora_winogrande_64 epoch: 1/1 iteration: 64/128 step: 5
[2025-12-23 16:17:09,833] m-LoRA: Adapter lora_winogrande_48 loss: 1.1797327995300293
[2025-12-23 16:17:09,835] m-LoRA: Adapter lora_winogrande_38 epoch: 1/1 iteration: 104/128 step: 53
[2025-12-23 16:17:09,949] m-LoRA: Adapter lora_winogrande_67 loss: 1.8939458131790161
[2025-12-23 16:17:09,953] m-LoRA: Adapter lora_winogrande_51 epoch: 1/1 iteration: 112/128 step: 29
[2025-12-23 16:17:10,323] m-LoRA: Adapter lora_winogrande_42 epoch: 1/1 iteration: 88/128 step: 45
[2025-12-23 16:17:10,363] m-LoRA: Adapter lora_winogrande_61 loss: 0.6367281079292297
[2025-12-23 16:17:10,517] m-LoRA: Adapter lora_winogrande_54 loss: 0.5245806574821472
[2025-12-23 16:17:10,520] m-LoRA: Adapter lora_winogrande_34 epoch: 1/1 iteration: 120/128 step: 61
[2025-12-23 16:17:10,707] m-LoRA: Adapter lora_winogrande_58 loss: 0.7153145670890808
[2025-12-23 16:17:10,710] m-LoRA: Adapter lora_winogrande_60 epoch: 1/1 iteration: 48/128 step: 13
[2025-12-23 16:17:10,833] m-LoRA: Adapter lora_winogrande_63 loss: 1.8419533967971802
[2025-12-23 16:17:10,836] m-LoRA: Adapter lora_winogrande_65 epoch: 1/1 iteration: 32/128 step: 5
[2025-12-23 16:17:11,531] m-LoRA: Adapter lora_winogrande_64 loss: 3.0569167137145996
[2025-12-23 16:17:11,537] m-LoRA: Adapter lora_winogrande_62 epoch: 1/1 iteration: 20/128 step: 6
[2025-12-23 16:17:11,788] m-LoRA: Adapter lora_winogrande_38 loss: 0.4818374514579773
[2025-12-23 16:17:11,790] m-LoRA: Adapter lora_winogrande_53 epoch: 1/1 iteration: 56/128 step: 29
[2025-12-23 16:17:11,929] m-LoRA: Adapter lora_winogrande_51 loss: 0.48999011516571045
[2025-12-23 16:17:11,931] m-LoRA: Adapter lora_winogrande_66 epoch: 1/1 iteration: 8/128 step: 5
[2025-12-23 16:17:12,031] m-LoRA: Adapter lora_winogrande_42 loss: 0.5043010711669922
[2025-12-23 16:17:12,033] m-LoRA: Adapter lora_winogrande_56 epoch: 1/1 iteration: 80/128 step: 21
[2025-12-23 16:17:12,171] m-LoRA: Adapter lora_winogrande_34 loss: 0.47263476252555847
[2025-12-23 16:17:12,173] m-LoRA: Adapter lora_winogrande_48 epoch: 1/1 iteration: 72/128 step: 37
[2025-12-23 16:17:12,303] m-LoRA: Adapter lora_winogrande_60 loss: 1.0636985301971436
[2025-12-23 16:17:12,306] m-LoRA: Adapter lora_winogrande_67 epoch: 1/1 iteration: 16/128 step: 5
[2025-12-23 16:17:12,507] m-LoRA: Adapter lora_winogrande_65 loss: 2.166740894317627
[2025-12-23 16:17:12,510] m-LoRA: Adapter lora_winogrande_61 epoch: 1/1 iteration: 96/128 step: 13
[2025-12-23 16:17:12,664] m-LoRA: Adapter lora_winogrande_54 epoch: 1/1 iteration: 112/128 step: 29
[2025-12-23 16:17:12,796] m-LoRA: Adapter lora_winogrande_62 loss: 1.6781166791915894
[2025-12-23 16:17:12,799] m-LoRA: Adapter lora_winogrande_58 epoch: 1/1 iteration: 52/128 step: 14
[2025-12-23 16:17:12,978] m-LoRA: Adapter lora_winogrande_53 loss: 1.626420021057129
[2025-12-23 16:17:12,981] m-LoRA: Adapter lora_winogrande_63 epoch: 1/1 iteration: 10/128 step: 6
[2025-12-23 16:17:13,131] m-LoRA: Adapter lora_winogrande_66 loss: 1.3763909339904785
[2025-12-23 16:17:13,133] m-LoRA: Adapter lora_winogrande_64 epoch: 1/1 iteration: 80/128 step: 6
[2025-12-23 16:17:13,287] m-LoRA: Adapter lora_winogrande_56 loss: 0.6668362617492676
[2025-12-23 16:17:13,289] m-LoRA: Adapter lora_winogrande_38 epoch: 1/1 iteration: 106/128 step: 54
[2025-12-23 16:17:13,435] m-LoRA: Adapter lora_winogrande_48 loss: 1.1541329622268677
[2025-12-23 16:17:13,438] m-LoRA: Adapter lora_winogrande_51 epoch: 1/1 iteration: 116/128 step: 30
[2025-12-23 16:17:13,586] m-LoRA: Adapter lora_winogrande_67 loss: 1.8085585832595825
[2025-12-23 16:17:13,589] m-LoRA: Adapter lora_winogrande_42 epoch: 1/1 iteration: 90/128 step: 46
[2025-12-23 16:17:13,699] m-LoRA: Adapter lora_winogrande_34 epoch: 1/1 iteration: 122/128 step: 62
[2025-12-23 16:17:13,771] m-LoRA: Adapter lora_winogrande_60 epoch: 1/1 iteration: 52/128 step: 14
[2025-12-23 16:17:13,913] m-LoRA: Adapter lora_winogrande_65 epoch: 1/1 iteration: 40/128 step: 6
[2025-12-23 16:17:13,940] m-LoRA: Adapter lora_winogrande_61 loss: 0.6211278438568115
[2025-12-23 16:17:14,125] m-LoRA: Adapter lora_winogrande_54 loss: 0.5235099792480469
[2025-12-23 16:17:14,128] m-LoRA: Adapter lora_winogrande_62 epoch: 1/1 iteration: 24/128 step: 7
[2025-12-23 16:17:14,324] m-LoRA: Adapter lora_winogrande_58 loss: 0.6295991539955139
[2025-12-23 16:17:14,327] m-LoRA: Adapter lora_winogrande_53 epoch: 1/1 iteration: 58/128 step: 30
[2025-12-23 16:17:14,445] m-LoRA: Adapter lora_winogrande_63 loss: 1.5043957233428955
[2025-12-23 16:17:14,447] m-LoRA: Adapter lora_winogrande_66 epoch: 1/1 iteration: 10/128 step: 6
[2025-12-23 16:17:15,141] m-LoRA: Adapter lora_winogrande_64 loss: 2.9053475856781006
[2025-12-23 16:17:15,147] m-LoRA: Adapter lora_winogrande_56 epoch: 1/1 iteration: 84/128 step: 22
[2025-12-23 16:17:15,217] m-LoRA: Adapter lora_winogrande_38 loss: 0.37499961256980896
[2025-12-23 16:17:15,219] m-LoRA: Adapter lora_winogrande_48 epoch: 1/1 iteration: 74/128 step: 38
[2025-12-23 16:17:15,393] m-LoRA: Adapter lora_winogrande_51 loss: 0.522953987121582
[2025-12-23 16:17:15,396] m-LoRA: Adapter lora_winogrande_67 epoch: 1/1 iteration: 20/128 step: 6
[2025-12-23 16:17:15,509] m-LoRA: Adapter lora_winogrande_42 loss: 0.5462489724159241
[2025-12-23 16:17:15,511] m-LoRA: Adapter lora_winogrande_61 epoch: 1/1 iteration: 104/128 step: 14
[2025-12-23 16:17:15,609] m-LoRA: Adapter lora_winogrande_34 loss: 0.5460097193717957
[2025-12-23 16:17:15,611] m-LoRA: Adapter lora_winogrande_54 epoch: 1/1 iteration: 116/128 step: 30
[2025-12-23 16:17:15,735] m-LoRA: Adapter lora_winogrande_60 loss: 1.0510036945343018
[2025-12-23 16:17:15,738] m-LoRA: Adapter lora_winogrande_58 epoch: 1/1 iteration: 56/128 step: 15
[2025-12-23 16:17:16,082] m-LoRA: Adapter lora_winogrande_63 epoch: 1/1 iteration: 12/128 step: 7
[2025-12-23 16:17:16,120] m-LoRA: Adapter lora_winogrande_65 loss: 2.0143423080444336
[2025-12-23 16:17:16,343] m-LoRA: Adapter lora_winogrande_62 loss: 1.3544479608535767
[2025-12-23 16:17:16,421] m-LoRA: Adapter lora_winogrande_66 loss: 1.004686951637268
[2025-12-23 16:17:16,698] m-LoRA: Adapter lora_winogrande_53 loss: 1.4960367679595947
[2025-12-23 16:17:16,700] m-LoRA: Adapter lora_winogrande_64 epoch: 1/1 iteration: 96/128 step: 7
[2025-12-23 16:17:16,861] m-LoRA: Adapter lora_winogrande_56 loss: 0.7646812200546265
[2025-12-23 16:17:16,864] m-LoRA: Adapter lora_winogrande_38 epoch: 1/1 iteration: 108/128 step: 55
[2025-12-23 16:17:17,039] m-LoRA: Adapter lora_winogrande_48 loss: 1.1245269775390625
[2025-12-23 16:17:17,041] m-LoRA: Adapter lora_winogrande_51 epoch: 1/1 iteration: 120/128 step: 31
[2025-12-23 16:17:17,299] m-LoRA: Adapter lora_winogrande_67 loss: 1.4838206768035889
[2025-12-23 16:17:17,301] m-LoRA: Adapter lora_winogrande_42 epoch: 1/1 iteration: 92/128 step: 47
[2025-12-23 16:17:17,675] m-LoRA: Adapter lora_winogrande_61 loss: 0.5111697912216187
[2025-12-23 16:17:17,678] m-LoRA: Adapter lora_winogrande_34 epoch: 1/1 iteration: 124/128 step: 63
[2025-12-23 16:17:18,015] m-LoRA: Adapter lora_winogrande_54 loss: 0.4801841974258423
[2025-12-23 16:17:18,017] m-LoRA: Adapter lora_winogrande_60 epoch: 1/1 iteration: 56/128 step: 15
[2025-12-23 16:17:18,152] m-LoRA: Adapter lora_winogrande_58 loss: 0.6776156425476074
[2025-12-23 16:17:18,155] m-LoRA: Adapter lora_winogrande_65 epoch: 1/1 iteration: 48/128 step: 7
[2025-12-23 16:17:18,352] m-LoRA: Adapter lora_winogrande_63 loss: 1.358038067817688
[2025-12-23 16:17:18,354] m-LoRA: Adapter lora_winogrande_62 epoch: 1/1 iteration: 28/128 step: 8
[2025-12-23 16:17:19,115] m-LoRA: Adapter lora_winogrande_64 loss: 2.6811885833740234
[2025-12-23 16:17:19,123] m-LoRA: Adapter lora_winogrande_66 epoch: 1/1 iteration: 12/128 step: 7
[2025-12-23 16:17:19,291] m-LoRA: Adapter lora_winogrande_38 loss: 0.5859195590019226
[2025-12-23 16:17:19,293] m-LoRA: Adapter lora_winogrande_53 epoch: 1/1 iteration: 60/128 step: 31
[2025-12-23 16:17:19,379] m-LoRA: Adapter lora_winogrande_51 loss: 0.5038318037986755
[2025-12-23 16:17:19,381] m-LoRA: Adapter lora_winogrande_56 epoch: 1/1 iteration: 88/128 step: 23
[2025-12-23 16:17:19,464] m-LoRA: Adapter lora_winogrande_42 loss: 0.40318727493286133
[2025-12-23 16:17:19,465] m-LoRA: Adapter lora_winogrande_48 epoch: 1/1 iteration: 76/128 step: 39
[2025-12-23 16:17:19,535] m-LoRA: Adapter lora_winogrande_34 loss: 0.495258629322052
[2025-12-23 16:17:19,537] m-LoRA: Adapter lora_winogrande_67 epoch: 1/1 iteration: 24/128 step: 7
[2025-12-23 16:17:19,678] m-LoRA: Adapter lora_winogrande_60 loss: 0.784717857837677
[2025-12-23 16:17:19,680] m-LoRA: Adapter lora_winogrande_61 epoch: 1/1 iteration: 112/128 step: 15
[2025-12-23 16:17:20,010] m-LoRA: Adapter lora_winogrande_54 epoch: 1/1 iteration: 120/128 step: 31
[2025-12-23 16:17:20,031] m-LoRA: Adapter lora_winogrande_65 loss: 1.7839215993881226
[2025-12-23 16:17:20,283] m-LoRA: Adapter lora_winogrande_62 loss: 1.2978200912475586
[2025-12-23 16:17:20,285] m-LoRA: Adapter lora_winogrande_58 epoch: 1/1 iteration: 60/128 step: 16
[2025-12-23 16:17:20,417] m-LoRA: Adapter lora_winogrande_66 loss: 0.8242546319961548
[2025-12-23 16:17:20,419] m-LoRA: Adapter lora_winogrande_63 epoch: 1/1 iteration: 14/128 step: 8
[2025-12-23 16:17:20,569] m-LoRA: Adapter lora_winogrande_53 loss: 1.4335142374038696
[2025-12-23 16:17:20,571] m-LoRA: Adapter lora_winogrande_64 epoch: 1/1 iteration: 112/128 step: 8
[2025-12-23 16:17:20,700] m-LoRA: Adapter lora_winogrande_38 epoch: 1/1 iteration: 110/128 step: 56
[2025-12-23 16:17:20,735] m-LoRA: Adapter lora_winogrande_56 loss: 0.5900775194168091
[2025-12-23 16:17:20,855] m-LoRA: Adapter lora_winogrande_48 loss: 1.1320558786392212
[2025-12-23 16:17:20,857] m-LoRA: Adapter lora_winogrande_51 epoch: 1/1 iteration: 124/128 step: 32
[2025-12-23 16:17:21,010] m-LoRA: Adapter lora_winogrande_67 loss: 1.3637343645095825
[2025-12-23 16:17:21,013] m-LoRA: Adapter lora_winogrande_42 epoch: 1/1 iteration: 94/128 step: 48
[2025-12-23 16:17:21,366] m-LoRA: Adapter lora_winogrande_34 epoch: 1/1 iteration: 126/128 step: 64
[2025-12-23 16:17:21,405] m-LoRA: Adapter lora_winogrande_61 loss: 0.5507493019104004
[2025-12-23 16:17:21,613] m-LoRA: Adapter lora_winogrande_54 loss: 0.5358884930610657
[2025-12-23 16:17:21,616] m-LoRA: Adapter lora_winogrande_60 epoch: 1/1 iteration: 60/128 step: 16
[2025-12-23 16:17:21,814] m-LoRA: Adapter lora_winogrande_58 loss: 0.6090928912162781
[2025-12-23 16:17:21,816] m-LoRA: Adapter lora_winogrande_65 epoch: 1/1 iteration: 56/128 step: 8
[2025-12-23 16:17:21,961] m-LoRA: Adapter lora_winogrande_63 loss: 1.1223013401031494
[2025-12-23 16:17:21,963] m-LoRA: Adapter lora_winogrande_62 epoch: 1/1 iteration: 32/128 step: 9
[2025-12-23 16:17:22,505] m-LoRA: Adapter lora_winogrande_66 epoch: 1/1 iteration: 14/128 step: 8
[2025-12-23 16:17:22,552] m-LoRA: Adapter lora_winogrande_64 loss: 2.5302538871765137
[2025-12-23 16:17:22,737] m-LoRA: Adapter lora_winogrande_38 loss: 0.5426127314567566
[2025-12-23 16:17:22,740] m-LoRA: Adapter lora_winogrande_53 epoch: 1/1 iteration: 62/128 step: 32
[2025-12-23 16:17:22,874] m-LoRA: Adapter lora_winogrande_56 epoch: 1/1 iteration: 92/128 step: 24
[2025-12-23 16:17:22,961] m-LoRA: Adapter lora_winogrande_51 loss: 0.499592661857605
[2025-12-23 16:17:22,964] m-LoRA: Adapter lora_winogrande_48 epoch: 1/1 iteration: 78/128 step: 40
[2025-12-23 16:17:23,052] m-LoRA: Adapter lora_winogrande_42 loss: 0.5189903378486633
[2025-12-23 16:17:23,054] m-LoRA: Adapter lora_winogrande_67 epoch: 1/1 iteration: 28/128 step: 8
[2025-12-23 16:17:23,103] m-LoRA: Adapter lora_winogrande_34 loss: 0.4083646833896637
[2025-12-23 16:17:23,236] m-LoRA: Adapter lora_winogrande_60 loss: 0.7602738738059998
[2025-12-23 16:17:23,239] m-LoRA: Adapter lora_winogrande_61 epoch: 1/1 iteration: 120/128 step: 16
[2025-12-23 16:17:23,615] m-LoRA: Adapter lora_winogrande_65 loss: 1.7571542263031006
[2025-12-23 16:17:23,619] m-LoRA: Adapter lora_winogrande_54 epoch: 1/1 iteration: 124/128 step: 32
[2025-12-23 16:17:23,786] m-LoRA: Adapter lora_winogrande_62 loss: 1.2261980772018433
[2025-12-23 16:17:23,789] m-LoRA: Adapter lora_winogrande_58 epoch: 1/1 iteration: 64/128 step: 17
[2025-12-23 16:17:23,918] m-LoRA: Adapter lora_winogrande_66 loss: 0.6981785893440247
[2025-12-23 16:17:23,920] m-LoRA: Adapter lora_winogrande_63 epoch: 1/1 iteration: 16/128 step: 9
[2025-12-23 16:17:24,037] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_64']
[2025-12-23 16:17:24,430] m-LoRA: Adapter lora_winogrande_53 loss: 1.481286883354187
[2025-12-23 16:17:24,460] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_68']
[2025-12-23 16:17:24,555] m-LoRA: Adapter lora_winogrande_68 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:17:24,654] m-LoRA: Adapter lora_winogrande_56 loss: 0.6520925164222717
[2025-12-23 16:17:24,656] m-LoRA: Adapter lora_winogrande_38 epoch: 1/1 iteration: 112/128 step: 57
[2025-12-23 16:17:24,738] m-LoRA: Adapter lora_winogrande_48 loss: 1.1317001581192017
[2025-12-23 16:17:24,746] m-LoRA: Adapter lora_winogrande_67 loss: 1.1278938055038452
[2025-12-23 16:17:24,972] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_51']
[2025-12-23 16:17:25,664] m-LoRA: Adapter lora_winogrande_61 loss: 0.554843008518219
[2025-12-23 16:17:25,699] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_69']
[2025-12-23 16:17:25,864] m-LoRA: Adapter lora_winogrande_69 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:17:25,960] m-LoRA: Adapter lora_winogrande_54 loss: 0.4709559977054596
[2025-12-23 16:17:25,962] m-LoRA: Adapter lora_winogrande_42 epoch: 1/1 iteration: 96/128 step: 49
[2025-12-23 16:17:26,053] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_34']
[2025-12-23 16:17:26,268] m-LoRA: Adapter lora_winogrande_58 loss: 0.5713794827461243
[2025-12-23 16:17:26,270] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_70']
[2025-12-23 16:17:26,497] m-LoRA: Adapter lora_winogrande_70 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:17:26,649] m-LoRA: Adapter lora_winogrande_63 loss: 1.0389986038208008
[2025-12-23 16:17:26,652] m-LoRA: Adapter lora_winogrande_60 epoch: 1/1 iteration: 64/128 step: 17
[2025-12-23 16:17:26,779] m-LoRA: Adapter lora_winogrande_68 loss: 3.144521951675415
[2025-12-23 16:17:26,782] m-LoRA: Adapter lora_winogrande_65 epoch: 1/1 iteration: 64/128 step: 9
[2025-12-23 16:17:26,906] m-LoRA: Adapter lora_winogrande_38 loss: 0.37203365564346313
[2025-12-23 16:17:26,909] m-LoRA: Adapter lora_winogrande_62 epoch: 1/1 iteration: 36/128 step: 10
[2025-12-23 16:17:27,022] m-LoRA: Adapter lora_winogrande_69 loss: 3.116722822189331
[2025-12-23 16:17:27,025] m-LoRA: Adapter lora_winogrande_66 epoch: 1/1 iteration: 16/128 step: 9
[2025-12-23 16:17:27,171] m-LoRA: Adapter lora_winogrande_42 loss: 0.7225337028503418
[2025-12-23 16:17:27,174] m-LoRA: Adapter lora_winogrande_53 epoch: 1/1 iteration: 64/128 step: 33
[2025-12-23 16:17:27,281] m-LoRA: Adapter lora_winogrande_70 loss: 3.051384449005127
[2025-12-23 16:17:27,283] m-LoRA: Adapter lora_winogrande_56 epoch: 1/1 iteration: 96/128 step: 25
[2025-12-23 16:17:27,447] m-LoRA: Adapter lora_winogrande_60 loss: 0.739328145980835
[2025-12-23 16:17:27,451] m-LoRA: Adapter lora_winogrande_48 epoch: 1/1 iteration: 80/128 step: 41
[2025-12-23 16:17:27,575] m-LoRA: Adapter lora_winogrande_67 epoch: 1/1 iteration: 32/128 step: 9
[2025-12-23 16:17:27,653] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_61']
[2025-12-23 16:17:28,221] m-LoRA: Adapter lora_winogrande_65 loss: 1.5823343992233276
[2025-12-23 16:17:28,254] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_71']
[2025-12-23 16:17:28,399] m-LoRA: Adapter lora_winogrande_71 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:17:28,519] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_54']
[2025-12-23 16:17:28,944] m-LoRA: Adapter lora_winogrande_62 loss: 0.8568481206893921
[2025-12-23 16:17:28,946] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_72']
[2025-12-23 16:17:29,145] m-LoRA: Adapter lora_winogrande_72 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:17:29,252] m-LoRA: Adapter lora_winogrande_66 loss: 0.7188412547111511
[2025-12-23 16:17:29,254] m-LoRA: Adapter lora_winogrande_58 epoch: 1/1 iteration: 68/128 step: 18
[2025-12-23 16:17:29,351] m-LoRA: Adapter lora_winogrande_53 loss: 1.4129912853240967
[2025-12-23 16:17:29,353] m-LoRA: Adapter lora_winogrande_63 epoch: 1/1 iteration: 18/128 step: 10
[2025-12-23 16:17:29,426] m-LoRA: Adapter lora_winogrande_56 loss: 0.6020275950431824
[2025-12-23 16:17:29,429] m-LoRA: Adapter lora_winogrande_68 epoch: 1/1 iteration: 4/128 step: 2
[2025-12-23 16:17:29,502] m-LoRA: Adapter lora_winogrande_48 loss: 1.0030251741409302
[2025-12-23 16:17:29,504] m-LoRA: Adapter lora_winogrande_38 epoch: 1/1 iteration: 114/128 step: 58
[2025-12-23 16:17:29,575] m-LoRA: Adapter lora_winogrande_67 loss: 0.9777505397796631
[2025-12-23 16:17:29,578] m-LoRA: Adapter lora_winogrande_69 epoch: 1/1 iteration: 4/128 step: 2
[2025-12-23 16:17:29,649] m-LoRA: Adapter lora_winogrande_42 epoch: 1/1 iteration: 98/128 step: 50
[2025-12-23 16:17:30,078] m-LoRA: Adapter lora_winogrande_70 epoch: 1/1 iteration: 4/128 step: 2
[2025-12-23 16:17:30,121] m-LoRA: Adapter lora_winogrande_71 loss: 2.913630723953247
[2025-12-23 16:17:30,462] m-LoRA: Adapter lora_winogrande_72 loss: 3.140202045440674
[2025-12-23 16:17:30,466] m-LoRA: Adapter lora_winogrande_60 epoch: 1/1 iteration: 68/128 step: 18
[2025-12-23 16:17:30,596] m-LoRA: Adapter lora_winogrande_58 loss: 0.5929914116859436
[2025-12-23 16:17:30,606] m-LoRA: Adapter lora_winogrande_65 epoch: 1/1 iteration: 72/128 step: 10
[2025-12-23 16:17:30,739] m-LoRA: Adapter lora_winogrande_63 loss: 0.7579156160354614
[2025-12-23 16:17:30,741] m-LoRA: Adapter lora_winogrande_62 epoch: 1/1 iteration: 40/128 step: 11
[2025-12-23 16:17:30,887] m-LoRA: Adapter lora_winogrande_68 loss: 3.0890378952026367
[2025-12-23 16:17:30,890] m-LoRA: Adapter lora_winogrande_66 epoch: 1/1 iteration: 18/128 step: 10
[2025-12-23 16:17:31,085] m-LoRA: Adapter lora_winogrande_38 loss: 0.4657442271709442
[2025-12-23 16:17:31,087] m-LoRA: Adapter lora_winogrande_53 epoch: 1/1 iteration: 66/128 step: 34
[2025-12-23 16:17:31,327] m-LoRA: Adapter lora_winogrande_42 loss: 0.4047890901565552
[2025-12-23 16:17:31,330] m-LoRA: Adapter lora_winogrande_56 epoch: 1/1 iteration: 100/128 step: 26
[2025-12-23 16:17:31,460] m-LoRA: Adapter lora_winogrande_69 loss: 3.1924386024475098
[2025-12-23 16:17:31,463] m-LoRA: Adapter lora_winogrande_48 epoch: 1/1 iteration: 82/128 step: 42
[2025-12-23 16:17:31,622] m-LoRA: Adapter lora_winogrande_70 loss: 2.3341739177703857
[2025-12-23 16:17:31,625] m-LoRA: Adapter lora_winogrande_67 epoch: 1/1 iteration: 36/128 step: 10
[2025-12-23 16:17:31,779] m-LoRA: Adapter lora_winogrande_60 loss: 0.7115973234176636
[2025-12-23 16:17:31,782] m-LoRA: Adapter lora_winogrande_71 epoch: 1/1 iteration: 16/128 step: 2
[2025-12-23 16:17:32,162] m-LoRA: Adapter lora_winogrande_65 loss: 1.4619718790054321
[2025-12-23 16:17:32,166] m-LoRA: Adapter lora_winogrande_72 epoch: 1/1 iteration: 8/128 step: 2
[2025-12-23 16:17:32,338] m-LoRA: Adapter lora_winogrande_62 loss: 0.7791585922241211
[2025-12-23 16:17:32,340] m-LoRA: Adapter lora_winogrande_58 epoch: 1/1 iteration: 72/128 step: 19
[2025-12-23 16:17:32,476] m-LoRA: Adapter lora_winogrande_66 loss: 0.6704050302505493
[2025-12-23 16:17:32,479] m-LoRA: Adapter lora_winogrande_63 epoch: 1/1 iteration: 20/128 step: 11
[2025-12-23 16:17:32,663] m-LoRA: Adapter lora_winogrande_53 loss: 1.4323984384536743
[2025-12-23 16:17:32,666] m-LoRA: Adapter lora_winogrande_68 epoch: 1/1 iteration: 8/128 step: 3
[2025-12-23 16:17:32,777] m-LoRA: Adapter lora_winogrande_56 loss: 0.5981158018112183
[2025-12-23 16:17:32,780] m-LoRA: Adapter lora_winogrande_38 epoch: 1/1 iteration: 116/128 step: 59
[2025-12-23 16:17:32,937] m-LoRA: Adapter lora_winogrande_48 loss: 0.9128884077072144
[2025-12-23 16:17:32,940] m-LoRA: Adapter lora_winogrande_42 epoch: 1/1 iteration: 100/128 step: 51
[2025-12-23 16:17:33,049] m-LoRA: Adapter lora_winogrande_67 loss: 0.804257869720459
[2025-12-23 16:17:33,052] m-LoRA: Adapter lora_winogrande_69 epoch: 1/1 iteration: 8/128 step: 3
[2025-12-23 16:17:33,567] m-LoRA: Adapter lora_winogrande_70 epoch: 1/1 iteration: 8/128 step: 3
[2025-12-23 16:17:33,641] m-LoRA: Adapter lora_winogrande_71 loss: 2.9893693923950195
[2025-12-23 16:17:34,033] m-LoRA: Adapter lora_winogrande_72 loss: 2.7233612537384033
[2025-12-23 16:17:34,036] m-LoRA: Adapter lora_winogrande_60 epoch: 1/1 iteration: 72/128 step: 19
[2025-12-23 16:17:34,222] m-LoRA: Adapter lora_winogrande_58 loss: 0.5663138628005981
[2025-12-23 16:17:34,225] m-LoRA: Adapter lora_winogrande_65 epoch: 1/1 iteration: 80/128 step: 11
[2025-12-23 16:17:34,387] m-LoRA: Adapter lora_winogrande_63 loss: 0.9319775104522705
[2025-12-23 16:17:34,389] m-LoRA: Adapter lora_winogrande_62 epoch: 1/1 iteration: 44/128 step: 12
[2025-12-23 16:17:34,532] m-LoRA: Adapter lora_winogrande_68 loss: 3.106778383255005
[2025-12-23 16:17:34,535] m-LoRA: Adapter lora_winogrande_66 epoch: 1/1 iteration: 20/128 step: 11
[2025-12-23 16:17:34,678] m-LoRA: Adapter lora_winogrande_38 loss: 0.48404502868652344
[2025-12-23 16:17:34,681] m-LoRA: Adapter lora_winogrande_53 epoch: 1/1 iteration: 68/128 step: 35
[2025-12-23 16:17:34,807] m-LoRA: Adapter lora_winogrande_42 loss: 0.4650801420211792
[2025-12-23 16:17:34,810] m-LoRA: Adapter lora_winogrande_56 epoch: 1/1 iteration: 104/128 step: 27
[2025-12-23 16:17:35,010] m-LoRA: Adapter lora_winogrande_69 loss: 3.1096930503845215
[2025-12-23 16:17:35,012] m-LoRA: Adapter lora_winogrande_48 epoch: 1/1 iteration: 84/128 step: 43
[2025-12-23 16:17:35,148] m-LoRA: Adapter lora_winogrande_70 loss: 1.8112233877182007
[2025-12-23 16:17:35,151] m-LoRA: Adapter lora_winogrande_67 epoch: 1/1 iteration: 40/128 step: 11
[2025-12-23 16:17:35,233] m-LoRA: Adapter lora_winogrande_60 loss: 0.7477675676345825
[2025-12-23 16:17:35,390] m-LoRA: Adapter lora_winogrande_71 epoch: 1/1 iteration: 32/128 step: 3
[2025-12-23 16:17:35,776] m-LoRA: Adapter lora_winogrande_72 epoch: 1/1 iteration: 16/128 step: 3
[2025-12-23 16:17:35,830] m-LoRA: Adapter lora_winogrande_65 loss: 1.460358738899231
[2025-12-23 16:17:36,017] m-LoRA: Adapter lora_winogrande_62 loss: 0.8448544144630432
[2025-12-23 16:17:36,021] m-LoRA: Adapter lora_winogrande_58 epoch: 1/1 iteration: 76/128 step: 20
[2025-12-23 16:17:36,186] m-LoRA: Adapter lora_winogrande_66 loss: 0.5503988265991211
[2025-12-23 16:17:36,189] m-LoRA: Adapter lora_winogrande_63 epoch: 1/1 iteration: 22/128 step: 12
[2025-12-23 16:17:36,299] m-LoRA: Adapter lora_winogrande_53 loss: 1.4107184410095215
[2025-12-23 16:17:36,302] m-LoRA: Adapter lora_winogrande_68 epoch: 1/1 iteration: 12/128 step: 4
[2025-12-23 16:17:36,442] m-LoRA: Adapter lora_winogrande_56 loss: 0.6151133179664612
[2025-12-23 16:17:36,444] m-LoRA: Adapter lora_winogrande_38 epoch: 1/1 iteration: 118/128 step: 60
[2025-12-23 16:17:36,592] m-LoRA: Adapter lora_winogrande_48 loss: 0.9245622158050537
[2025-12-23 16:17:36,594] m-LoRA: Adapter lora_winogrande_42 epoch: 1/1 iteration: 102/128 step: 52
[2025-12-23 16:17:36,738] m-LoRA: Adapter lora_winogrande_67 loss: 0.7719736695289612
[2025-12-23 16:17:36,740] m-LoRA: Adapter lora_winogrande_69 epoch: 1/1 iteration: 12/128 step: 4
[2025-12-23 16:17:37,322] m-LoRA: Adapter lora_winogrande_70 epoch: 1/1 iteration: 12/128 step: 4
[2025-12-23 16:17:37,366] m-LoRA: Adapter lora_winogrande_71 loss: 3.096313953399658
[2025-12-23 16:17:37,742] m-LoRA: Adapter lora_winogrande_72 loss: 1.8619911670684814
[2025-12-23 16:17:37,747] m-LoRA: Adapter lora_winogrande_60 epoch: 1/1 iteration: 76/128 step: 20
[2025-12-23 16:17:37,922] m-LoRA: Adapter lora_winogrande_58 loss: 0.5864672660827637
[2025-12-23 16:17:37,925] m-LoRA: Adapter lora_winogrande_65 epoch: 1/1 iteration: 88/128 step: 12
[2025-12-23 16:17:38,049] m-LoRA: Adapter lora_winogrande_63 loss: 0.7093738913536072
[2025-12-23 16:17:38,069] m-LoRA: Adapter lora_winogrande_62 epoch: 1/1 iteration: 48/128 step: 13
[2025-12-23 16:17:38,214] m-LoRA: Adapter lora_winogrande_68 loss: 2.981133460998535
[2025-12-23 16:17:38,217] m-LoRA: Adapter lora_winogrande_66 epoch: 1/1 iteration: 22/128 step: 12
[2025-12-23 16:17:38,353] m-LoRA: Adapter lora_winogrande_38 loss: 0.44019678235054016
[2025-12-23 16:17:38,356] m-LoRA: Adapter lora_winogrande_53 epoch: 1/1 iteration: 70/128 step: 36
[2025-12-23 16:17:38,493] m-LoRA: Adapter lora_winogrande_42 loss: 0.4927743375301361
[2025-12-23 16:17:38,495] m-LoRA: Adapter lora_winogrande_56 epoch: 1/1 iteration: 108/128 step: 28
[2025-12-23 16:17:38,625] m-LoRA: Adapter lora_winogrande_69 loss: 3.019678831100464
[2025-12-23 16:17:38,629] m-LoRA: Adapter lora_winogrande_48 epoch: 1/1 iteration: 86/128 step: 44
[2025-12-23 16:17:38,749] m-LoRA: Adapter lora_winogrande_70 loss: 1.536633849143982
[2025-12-23 16:17:38,752] m-LoRA: Adapter lora_winogrande_67 epoch: 1/1 iteration: 44/128 step: 12
[2025-12-23 16:17:38,954] m-LoRA: Adapter lora_winogrande_60 loss: 0.6268704533576965
[2025-12-23 16:17:38,956] m-LoRA: Adapter lora_winogrande_71 epoch: 1/1 iteration: 48/128 step: 4
[2025-12-23 16:17:39,394] m-LoRA: Adapter lora_winogrande_65 loss: 1.2146309614181519
[2025-12-23 16:17:39,398] m-LoRA: Adapter lora_winogrande_72 epoch: 1/1 iteration: 24/128 step: 4
[2025-12-23 16:17:39,574] m-LoRA: Adapter lora_winogrande_62 loss: 0.6244409680366516
[2025-12-23 16:17:39,576] m-LoRA: Adapter lora_winogrande_58 epoch: 1/1 iteration: 80/128 step: 21
[2025-12-23 16:17:39,726] m-LoRA: Adapter lora_winogrande_66 loss: 0.6214049458503723
[2025-12-23 16:17:39,728] m-LoRA: Adapter lora_winogrande_63 epoch: 1/1 iteration: 24/128 step: 13
[2025-12-23 16:17:39,876] m-LoRA: Adapter lora_winogrande_53 loss: 1.2299563884735107
[2025-12-23 16:17:39,878] m-LoRA: Adapter lora_winogrande_68 epoch: 1/1 iteration: 16/128 step: 5
[2025-12-23 16:17:39,977] m-LoRA: Adapter lora_winogrande_56 loss: 0.5336248278617859
[2025-12-23 16:17:39,979] m-LoRA: Adapter lora_winogrande_38 epoch: 1/1 iteration: 120/128 step: 61
[2025-12-23 16:17:40,102] m-LoRA: Adapter lora_winogrande_48 loss: 0.8212307095527649
[2025-12-23 16:17:40,105] m-LoRA: Adapter lora_winogrande_42 epoch: 1/1 iteration: 104/128 step: 53
[2025-12-23 16:17:40,249] m-LoRA: Adapter lora_winogrande_67 loss: 0.6568002104759216
[2025-12-23 16:17:40,252] m-LoRA: Adapter lora_winogrande_69 epoch: 1/1 iteration: 16/128 step: 5
[2025-12-23 16:17:40,961] m-LoRA: Adapter lora_winogrande_71 loss: 3.2061243057250977
[2025-12-23 16:17:40,968] m-LoRA: Adapter lora_winogrande_70 epoch: 1/1 iteration: 16/128 step: 5
[2025-12-23 16:17:41,333] m-LoRA: Adapter lora_winogrande_72 loss: 1.7018873691558838
[2025-12-23 16:17:41,337] m-LoRA: Adapter lora_winogrande_60 epoch: 1/1 iteration: 80/128 step: 21
[2025-12-23 16:17:41,477] m-LoRA: Adapter lora_winogrande_58 loss: 0.5323660969734192
[2025-12-23 16:17:41,479] m-LoRA: Adapter lora_winogrande_65 epoch: 1/1 iteration: 96/128 step: 13
[2025-12-23 16:17:41,593] m-LoRA: Adapter lora_winogrande_63 loss: 0.5853540301322937
[2025-12-23 16:17:41,595] m-LoRA: Adapter lora_winogrande_62 epoch: 1/1 iteration: 52/128 step: 14
[2025-12-23 16:17:41,704] m-LoRA: Adapter lora_winogrande_68 loss: 2.8209638595581055
[2025-12-23 16:17:41,706] m-LoRA: Adapter lora_winogrande_66 epoch: 1/1 iteration: 24/128 step: 13
[2025-12-23 16:17:41,816] m-LoRA: Adapter lora_winogrande_38 loss: 0.4038054049015045
[2025-12-23 16:17:41,826] m-LoRA: Adapter lora_winogrande_53 epoch: 1/1 iteration: 72/128 step: 37
[2025-12-23 16:17:41,926] m-LoRA: Adapter lora_winogrande_42 loss: 0.524356484413147
[2025-12-23 16:17:41,928] m-LoRA: Adapter lora_winogrande_56 epoch: 1/1 iteration: 112/128 step: 29
[2025-12-23 16:17:42,136] m-LoRA: Adapter lora_winogrande_69 loss: 2.6664364337921143
[2025-12-23 16:17:42,138] m-LoRA: Adapter lora_winogrande_48 epoch: 1/1 iteration: 88/128 step: 45
[2025-12-23 16:17:42,306] m-LoRA: Adapter lora_winogrande_70 loss: 1.2368496656417847
[2025-12-23 16:17:42,309] m-LoRA: Adapter lora_winogrande_67 epoch: 1/1 iteration: 48/128 step: 13
[2025-12-23 16:17:42,576] m-LoRA: Adapter lora_winogrande_60 loss: 0.6129493117332458
[2025-12-23 16:17:42,579] m-LoRA: Adapter lora_winogrande_71 epoch: 1/1 iteration: 64/128 step: 5
[2025-12-23 16:17:42,983] m-LoRA: Adapter lora_winogrande_65 loss: 1.1241289377212524
[2025-12-23 16:17:42,988] m-LoRA: Adapter lora_winogrande_72 epoch: 1/1 iteration: 32/128 step: 5
[2025-12-23 16:17:43,170] m-LoRA: Adapter lora_winogrande_62 loss: 0.623870849609375
[2025-12-23 16:17:43,174] m-LoRA: Adapter lora_winogrande_58 epoch: 1/1 iteration: 84/128 step: 22
[2025-12-23 16:17:43,331] m-LoRA: Adapter lora_winogrande_66 loss: 0.5244992971420288
[2025-12-23 16:17:43,334] m-LoRA: Adapter lora_winogrande_63 epoch: 1/1 iteration: 26/128 step: 14
[2025-12-23 16:17:43,480] m-LoRA: Adapter lora_winogrande_53 loss: 1.229632019996643
[2025-12-23 16:17:43,482] m-LoRA: Adapter lora_winogrande_68 epoch: 1/1 iteration: 20/128 step: 6
[2025-12-23 16:17:43,613] m-LoRA: Adapter lora_winogrande_56 loss: 0.5812227129936218
[2025-12-23 16:17:43,616] m-LoRA: Adapter lora_winogrande_38 epoch: 1/1 iteration: 122/128 step: 62
[2025-12-23 16:17:43,741] m-LoRA: Adapter lora_winogrande_48 loss: 0.76546710729599
[2025-12-23 16:17:43,743] m-LoRA: Adapter lora_winogrande_42 epoch: 1/1 iteration: 106/128 step: 54
[2025-12-23 16:17:43,869] m-LoRA: Adapter lora_winogrande_67 loss: 0.6670699715614319
[2025-12-23 16:17:43,873] m-LoRA: Adapter lora_winogrande_69 epoch: 1/1 iteration: 20/128 step: 6
[2025-12-23 16:17:44,453] m-LoRA: Adapter lora_winogrande_70 epoch: 1/1 iteration: 20/128 step: 6
[2025-12-23 16:17:44,502] m-LoRA: Adapter lora_winogrande_71 loss: 2.9563567638397217
[2025-12-23 16:17:44,958] m-LoRA: Adapter lora_winogrande_72 loss: 1.3590171337127686
[2025-12-23 16:17:44,962] m-LoRA: Adapter lora_winogrande_60 epoch: 1/1 iteration: 84/128 step: 22
[2025-12-23 16:17:45,102] m-LoRA: Adapter lora_winogrande_58 loss: 0.6294844150543213
[2025-12-23 16:17:45,105] m-LoRA: Adapter lora_winogrande_65 epoch: 1/1 iteration: 104/128 step: 14
[2025-12-23 16:17:45,231] m-LoRA: Adapter lora_winogrande_63 loss: 0.6681118607521057
[2025-12-23 16:17:45,232] m-LoRA: Adapter lora_winogrande_62 epoch: 1/1 iteration: 56/128 step: 15
[2025-12-23 16:17:45,323] m-LoRA: Adapter lora_winogrande_68 loss: 2.672672986984253
[2025-12-23 16:17:45,325] m-LoRA: Adapter lora_winogrande_66 epoch: 1/1 iteration: 26/128 step: 14
[2025-12-23 16:17:45,451] m-LoRA: Adapter lora_winogrande_38 loss: 0.5213028788566589
[2025-12-23 16:17:45,454] m-LoRA: Adapter lora_winogrande_53 epoch: 1/1 iteration: 74/128 step: 38
[2025-12-23 16:17:45,590] m-LoRA: Adapter lora_winogrande_42 loss: 0.5652885437011719
[2025-12-23 16:17:45,625] m-LoRA: Adapter lora_winogrande_56 epoch: 1/1 iteration: 116/128 step: 30
[2025-12-23 16:17:45,729] m-LoRA: Adapter lora_winogrande_69 loss: 2.786207675933838
[2025-12-23 16:17:45,732] m-LoRA: Adapter lora_winogrande_48 epoch: 1/1 iteration: 90/128 step: 46
[2025-12-23 16:17:45,882] m-LoRA: Adapter lora_winogrande_70 loss: 1.018139123916626
[2025-12-23 16:17:45,885] m-LoRA: Adapter lora_winogrande_67 epoch: 1/1 iteration: 52/128 step: 14
[2025-12-23 16:17:46,174] m-LoRA: Adapter lora_winogrande_60 loss: 0.65569007396698
[2025-12-23 16:17:46,177] m-LoRA: Adapter lora_winogrande_71 epoch: 1/1 iteration: 80/128 step: 6
[2025-12-23 16:17:46,530] m-LoRA: Adapter lora_winogrande_65 loss: 1.081371545791626
[2025-12-23 16:17:46,533] m-LoRA: Adapter lora_winogrande_72 epoch: 1/1 iteration: 40/128 step: 6
[2025-12-23 16:17:46,741] m-LoRA: Adapter lora_winogrande_62 loss: 0.5879945158958435
[2025-12-23 16:17:46,743] m-LoRA: Adapter lora_winogrande_58 epoch: 1/1 iteration: 88/128 step: 23
[2025-12-23 16:17:46,905] m-LoRA: Adapter lora_winogrande_66 loss: 0.6410903334617615
[2025-12-23 16:17:46,907] m-LoRA: Adapter lora_winogrande_63 epoch: 1/1 iteration: 28/128 step: 15
[2025-12-23 16:17:47,008] m-LoRA: Adapter lora_winogrande_53 loss: 1.2227001190185547
[2025-12-23 16:17:47,010] m-LoRA: Adapter lora_winogrande_68 epoch: 1/1 iteration: 24/128 step: 7
[2025-12-23 16:17:47,128] m-LoRA: Adapter lora_winogrande_56 loss: 0.579043447971344
[2025-12-23 16:17:47,130] m-LoRA: Adapter lora_winogrande_38 epoch: 1/1 iteration: 124/128 step: 63
[2025-12-23 16:17:47,286] m-LoRA: Adapter lora_winogrande_48 loss: 0.6794847249984741
[2025-12-23 16:17:47,288] m-LoRA: Adapter lora_winogrande_42 epoch: 1/1 iteration: 108/128 step: 55
[2025-12-23 16:17:47,450] m-LoRA: Adapter lora_winogrande_67 loss: 0.5315664410591125
[2025-12-23 16:17:47,452] m-LoRA: Adapter lora_winogrande_69 epoch: 1/1 iteration: 24/128 step: 7
[2025-12-23 16:17:48,214] m-LoRA: Adapter lora_winogrande_71 loss: 3.011246919631958
[2025-12-23 16:17:48,220] m-LoRA: Adapter lora_winogrande_70 epoch: 1/1 iteration: 24/128 step: 7
[2025-12-23 16:17:48,575] m-LoRA: Adapter lora_winogrande_72 loss: 1.0796557664871216
[2025-12-23 16:17:48,579] m-LoRA: Adapter lora_winogrande_60 epoch: 1/1 iteration: 88/128 step: 23
[2025-12-23 16:17:48,789] m-LoRA: Adapter lora_winogrande_58 loss: 0.4776938855648041
[2025-12-23 16:17:48,791] m-LoRA: Adapter lora_winogrande_65 epoch: 1/1 iteration: 112/128 step: 15
[2025-12-23 16:17:48,947] m-LoRA: Adapter lora_winogrande_63 loss: 0.6688560247421265
[2025-12-23 16:17:48,950] m-LoRA: Adapter lora_winogrande_62 epoch: 1/1 iteration: 60/128 step: 16
[2025-12-23 16:17:49,106] m-LoRA: Adapter lora_winogrande_68 loss: 2.739058256149292
[2025-12-23 16:17:49,110] m-LoRA: Adapter lora_winogrande_66 epoch: 1/1 iteration: 28/128 step: 15
[2025-12-23 16:17:49,320] m-LoRA: Adapter lora_winogrande_38 loss: 0.6209174990653992
[2025-12-23 16:17:49,322] m-LoRA: Adapter lora_winogrande_53 epoch: 1/1 iteration: 76/128 step: 39
[2025-12-23 16:17:49,468] m-LoRA: Adapter lora_winogrande_42 loss: 0.44777870178222656
[2025-12-23 16:17:49,470] m-LoRA: Adapter lora_winogrande_56 epoch: 1/1 iteration: 120/128 step: 31
[2025-12-23 16:17:49,630] m-LoRA: Adapter lora_winogrande_69 loss: 2.7104146480560303
[2025-12-23 16:17:49,634] m-LoRA: Adapter lora_winogrande_48 epoch: 1/1 iteration: 92/128 step: 47
[2025-12-23 16:17:49,767] m-LoRA: Adapter lora_winogrande_70 loss: 0.8290061354637146
[2025-12-23 16:17:49,769] m-LoRA: Adapter lora_winogrande_67 epoch: 1/1 iteration: 56/128 step: 15
[2025-12-23 16:17:49,952] m-LoRA: Adapter lora_winogrande_60 loss: 0.6025905609130859
[2025-12-23 16:17:49,954] m-LoRA: Adapter lora_winogrande_71 epoch: 1/1 iteration: 96/128 step: 7
[2025-12-23 16:17:50,115] m-LoRA: Adapter lora_winogrande_72 epoch: 1/1 iteration: 48/128 step: 7
[2025-12-23 16:17:50,344] m-LoRA: Adapter lora_winogrande_58 epoch: 1/1 iteration: 92/128 step: 24
[2025-12-23 16:17:50,384] m-LoRA: Adapter lora_winogrande_65 loss: 0.9331614971160889
[2025-12-23 16:17:50,540] m-LoRA: Adapter lora_winogrande_62 loss: 0.5881184935569763
[2025-12-23 16:17:50,543] m-LoRA: Adapter lora_winogrande_63 epoch: 1/1 iteration: 30/128 step: 16
[2025-12-23 16:17:50,673] m-LoRA: Adapter lora_winogrande_66 loss: 0.6811637282371521
[2025-12-23 16:17:50,675] m-LoRA: Adapter lora_winogrande_68 epoch: 1/1 iteration: 28/128 step: 8
[2025-12-23 16:17:50,794] m-LoRA: Adapter lora_winogrande_53 loss: 1.257014513015747
[2025-12-23 16:17:50,796] m-LoRA: Adapter lora_winogrande_38 epoch: 1/1 iteration: 126/128 step: 64
[2025-12-23 16:17:50,951] m-LoRA: Adapter lora_winogrande_56 loss: 0.7273092865943909
[2025-12-23 16:17:50,953] m-LoRA: Adapter lora_winogrande_42 epoch: 1/1 iteration: 110/128 step: 56
[2025-12-23 16:17:51,075] m-LoRA: Adapter lora_winogrande_48 loss: 0.7396136522293091
[2025-12-23 16:17:51,077] m-LoRA: Adapter lora_winogrande_69 epoch: 1/1 iteration: 28/128 step: 8
[2025-12-23 16:17:51,251] m-LoRA: Adapter lora_winogrande_67 loss: 0.711831271648407
[2025-12-23 16:17:51,255] m-LoRA: Adapter lora_winogrande_70 epoch: 1/1 iteration: 28/128 step: 8
[2025-12-23 16:17:51,917] m-LoRA: Adapter lora_winogrande_71 loss: 2.744117259979248
[2025-12-23 16:17:51,924] m-LoRA: Adapter lora_winogrande_60 epoch: 1/1 iteration: 92/128 step: 24
[2025-12-23 16:17:52,347] m-LoRA: Adapter lora_winogrande_72 loss: 0.9466919898986816
[2025-12-23 16:17:52,351] m-LoRA: Adapter lora_winogrande_65 epoch: 1/1 iteration: 120/128 step: 16
[2025-12-23 16:17:52,499] m-LoRA: Adapter lora_winogrande_58 loss: 0.4562332034111023
[2025-12-23 16:17:52,502] m-LoRA: Adapter lora_winogrande_62 epoch: 1/1 iteration: 64/128 step: 17
[2025-12-23 16:17:52,576] m-LoRA: Adapter lora_winogrande_63 loss: 0.5910829901695251
[2025-12-23 16:17:52,578] m-LoRA: Adapter lora_winogrande_66 epoch: 1/1 iteration: 30/128 step: 16
[2025-12-23 16:17:52,694] m-LoRA: Adapter lora_winogrande_68 loss: 2.5640063285827637
[2025-12-23 16:17:52,697] m-LoRA: Adapter lora_winogrande_53 epoch: 1/1 iteration: 78/128 step: 40
[2025-12-23 16:17:52,905] m-LoRA: Adapter lora_winogrande_38 loss: 0.45462819933891296
[2025-12-23 16:17:52,907] m-LoRA: Adapter lora_winogrande_56 epoch: 1/1 iteration: 124/128 step: 32
[2025-12-23 16:17:53,025] m-LoRA: Adapter lora_winogrande_42 loss: 0.5375571250915527
[2025-12-23 16:17:53,027] m-LoRA: Adapter lora_winogrande_48 epoch: 1/1 iteration: 94/128 step: 48
[2025-12-23 16:17:53,140] m-LoRA: Adapter lora_winogrande_69 loss: 2.5590996742248535
[2025-12-23 16:17:53,143] m-LoRA: Adapter lora_winogrande_67 epoch: 1/1 iteration: 60/128 step: 16
[2025-12-23 16:17:53,419] m-LoRA: Adapter lora_winogrande_70 loss: 0.7228072881698608
[2025-12-23 16:17:53,421] m-LoRA: Adapter lora_winogrande_71 epoch: 1/1 iteration: 112/128 step: 8
[2025-12-23 16:17:53,603] m-LoRA: Adapter lora_winogrande_60 loss: 0.6060540080070496
[2025-12-23 16:17:53,605] m-LoRA: Adapter lora_winogrande_72 epoch: 1/1 iteration: 56/128 step: 8
[2025-12-23 16:17:53,904] m-LoRA: Adapter lora_winogrande_58 epoch: 1/1 iteration: 96/128 step: 25
[2025-12-23 16:17:53,941] m-LoRA: Adapter lora_winogrande_65 loss: 0.8252058625221252
[2025-12-23 16:17:54,149] m-LoRA: Adapter lora_winogrande_62 loss: 0.6187224388122559
[2025-12-23 16:17:54,151] m-LoRA: Adapter lora_winogrande_63 epoch: 1/1 iteration: 32/128 step: 17
[2025-12-23 16:17:54,283] m-LoRA: Adapter lora_winogrande_66 loss: 0.5846031308174133
[2025-12-23 16:17:54,285] m-LoRA: Adapter lora_winogrande_68 epoch: 1/1 iteration: 32/128 step: 9
[2025-12-23 16:17:54,421] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_38']
[2025-12-23 16:17:55,153] m-LoRA: Adapter lora_winogrande_53 loss: 1.044359803199768
[2025-12-23 16:17:55,156] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_73']
[2025-12-23 16:17:55,239] m-LoRA: Adapter lora_winogrande_73 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:17:55,436] m-LoRA: Adapter lora_winogrande_56 loss: 0.6181302666664124
[2025-12-23 16:17:55,438] m-LoRA: Adapter lora_winogrande_42 epoch: 1/1 iteration: 112/128 step: 57
[2025-12-23 16:17:55,616] m-LoRA: Adapter lora_winogrande_48 loss: 0.7512516379356384
[2025-12-23 16:17:55,618] m-LoRA: Adapter lora_winogrande_69 epoch: 1/1 iteration: 32/128 step: 9
[2025-12-23 16:17:55,777] m-LoRA: Adapter lora_winogrande_67 loss: 0.522793173789978
[2025-12-23 16:17:55,779] m-LoRA: Adapter lora_winogrande_70 epoch: 1/1 iteration: 32/128 step: 9
[2025-12-23 16:17:55,965] m-LoRA: Adapter lora_winogrande_71 loss: 2.5934536457061768
[2025-12-23 16:17:55,971] m-LoRA: Adapter lora_winogrande_60 epoch: 1/1 iteration: 96/128 step: 25
[2025-12-23 16:17:56,158] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_65']
[2025-12-23 16:17:56,378] m-LoRA: Adapter lora_winogrande_72 loss: 0.7710226774215698
[2025-12-23 16:17:56,382] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_74']
[2025-12-23 16:17:56,617] m-LoRA: Adapter lora_winogrande_74 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:17:56,733] m-LoRA: Adapter lora_winogrande_58 loss: 0.5004727840423584
[2025-12-23 16:17:56,735] m-LoRA: Adapter lora_winogrande_62 epoch: 1/1 iteration: 68/128 step: 18
[2025-12-23 16:17:56,847] m-LoRA: Adapter lora_winogrande_63 loss: 0.6205376982688904
[2025-12-23 16:17:56,849] m-LoRA: Adapter lora_winogrande_66 epoch: 1/1 iteration: 32/128 step: 17
[2025-12-23 16:17:56,967] m-LoRA: Adapter lora_winogrande_68 loss: 2.540316581726074
[2025-12-23 16:17:57,961] m-LoRA: Adapter lora_winogrande_73 loss: 3.3277268409729004
[2025-12-23 16:17:57,968] m-LoRA: Adapter lora_winogrande_53 epoch: 1/1 iteration: 80/128 step: 41
[2025-12-23 16:17:58,128] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_56']
[2025-12-23 16:17:58,258] m-LoRA: Adapter lora_winogrande_42 loss: 0.4756138026714325
[2025-12-23 16:17:58,260] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_75']
[2025-12-23 16:17:58,487] m-LoRA: Adapter lora_winogrande_75 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:17:58,630] m-LoRA: Adapter lora_winogrande_69 loss: 2.396308422088623
[2025-12-23 16:17:58,632] m-LoRA: Adapter lora_winogrande_48 epoch: 1/1 iteration: 96/128 step: 49
[2025-12-23 16:17:58,754] m-LoRA: Adapter lora_winogrande_70 loss: 0.6290054321289062
[2025-12-23 16:17:58,757] m-LoRA: Adapter lora_winogrande_67 epoch: 1/1 iteration: 64/128 step: 17
[2025-12-23 16:17:58,875] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_71']
[2025-12-23 16:17:59,165] m-LoRA: Adapter lora_winogrande_60 loss: 0.6256842017173767
[2025-12-23 16:17:59,167] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_76']
[2025-12-23 16:17:59,240] m-LoRA: Adapter lora_winogrande_76 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:17:59,367] m-LoRA: Adapter lora_winogrande_74 loss: 3.0999367237091064
[2025-12-23 16:17:59,374] m-LoRA: Adapter lora_winogrande_72 epoch: 1/1 iteration: 64/128 step: 9
[2025-12-23 16:17:59,510] m-LoRA: Adapter lora_winogrande_62 loss: 0.5810614824295044
[2025-12-23 16:17:59,512] m-LoRA: Adapter lora_winogrande_58 epoch: 1/1 iteration: 100/128 step: 26
[2025-12-23 16:17:59,634] m-LoRA: Adapter lora_winogrande_66 loss: 0.5090413093566895
[2025-12-23 16:17:59,637] m-LoRA: Adapter lora_winogrande_63 epoch: 1/1 iteration: 34/128 step: 18
[2025-12-23 16:17:59,719] m-LoRA: Adapter lora_winogrande_53 loss: 1.0172231197357178
[2025-12-23 16:17:59,721] m-LoRA: Adapter lora_winogrande_68 epoch: 1/1 iteration: 36/128 step: 10
[2025-12-23 16:18:00,052] m-LoRA: Adapter lora_winogrande_75 loss: 3.1528472900390625
[2025-12-23 16:18:00,058] m-LoRA: Adapter lora_winogrande_73 epoch: 1/1 iteration: 16/128 step: 2
[2025-12-23 16:18:00,285] m-LoRA: Adapter lora_winogrande_48 loss: 0.7927320599555969
[2025-12-23 16:18:00,288] m-LoRA: Adapter lora_winogrande_42 epoch: 1/1 iteration: 114/128 step: 58
[2025-12-23 16:18:00,400] m-LoRA: Adapter lora_winogrande_67 loss: 0.5896527767181396
[2025-12-23 16:18:00,404] m-LoRA: Adapter lora_winogrande_69 epoch: 1/1 iteration: 36/128 step: 10
[2025-12-23 16:18:01,008] m-LoRA: Adapter lora_winogrande_70 epoch: 1/1 iteration: 36/128 step: 10
[2025-12-23 16:18:01,047] m-LoRA: Adapter lora_winogrande_76 loss: 3.3566653728485107
[2025-12-23 16:18:01,335] m-LoRA: Adapter lora_winogrande_72 loss: 0.7131326794624329
[2025-12-23 16:18:01,339] m-LoRA: Adapter lora_winogrande_60 epoch: 1/1 iteration: 100/128 step: 26
[2025-12-23 16:18:01,653] m-LoRA: Adapter lora_winogrande_58 loss: 0.4992249011993408
[2025-12-23 16:18:01,655] m-LoRA: Adapter lora_winogrande_74 epoch: 1/1 iteration: 16/128 step: 2
[2025-12-23 16:18:01,764] m-LoRA: Adapter lora_winogrande_63 loss: 0.6018003821372986
[2025-12-23 16:18:01,766] m-LoRA: Adapter lora_winogrande_62 epoch: 1/1 iteration: 72/128 step: 19
[2025-12-23 16:18:01,876] m-LoRA: Adapter lora_winogrande_68 loss: 2.376466989517212
[2025-12-23 16:18:01,880] m-LoRA: Adapter lora_winogrande_66 epoch: 1/1 iteration: 34/128 step: 18
[2025-12-23 16:18:02,423] m-LoRA: Adapter lora_winogrande_53 epoch: 1/1 iteration: 82/128 step: 42
[2025-12-23 16:18:02,471] m-LoRA: Adapter lora_winogrande_73 loss: 3.0896763801574707
[2025-12-23 16:18:02,698] m-LoRA: Adapter lora_winogrande_42 loss: 0.3621767461299896
[2025-12-23 16:18:02,701] m-LoRA: Adapter lora_winogrande_75 epoch: 1/1 iteration: 16/128 step: 2
[2025-12-23 16:18:02,846] m-LoRA: Adapter lora_winogrande_69 loss: 2.2370975017547607
[2025-12-23 16:18:02,849] m-LoRA: Adapter lora_winogrande_48 epoch: 1/1 iteration: 98/128 step: 50
[2025-12-23 16:18:03,030] m-LoRA: Adapter lora_winogrande_70 loss: 0.536766529083252
[2025-12-23 16:18:03,032] m-LoRA: Adapter lora_winogrande_67 epoch: 1/1 iteration: 68/128 step: 18
[2025-12-23 16:18:03,258] m-LoRA: Adapter lora_winogrande_60 loss: 0.5936661958694458
[2025-12-23 16:18:03,260] m-LoRA: Adapter lora_winogrande_76 epoch: 1/1 iteration: 16/128 step: 2
[2025-12-23 16:18:03,917] m-LoRA: Adapter lora_winogrande_74 loss: 2.653364896774292
[2025-12-23 16:18:03,923] m-LoRA: Adapter lora_winogrande_72 epoch: 1/1 iteration: 72/128 step: 10
[2025-12-23 16:18:04,146] m-LoRA: Adapter lora_winogrande_62 loss: 0.5667872428894043
[2025-12-23 16:18:04,149] m-LoRA: Adapter lora_winogrande_58 epoch: 1/1 iteration: 104/128 step: 27
[2025-12-23 16:18:04,226] m-LoRA: Adapter lora_winogrande_66 loss: 0.5680235624313354
[2025-12-23 16:18:04,228] m-LoRA: Adapter lora_winogrande_63 epoch: 1/1 iteration: 36/128 step: 19
[2025-12-23 16:18:04,307] m-LoRA: Adapter lora_winogrande_53 loss: 0.9974220991134644
[2025-12-23 16:18:04,309] m-LoRA: Adapter lora_winogrande_68 epoch: 1/1 iteration: 40/128 step: 11
[2025-12-23 16:18:05,042] m-LoRA: Adapter lora_winogrande_75 loss: 2.6876182556152344
[2025-12-23 16:18:05,049] m-LoRA: Adapter lora_winogrande_73 epoch: 1/1 iteration: 32/128 step: 3
[2025-12-23 16:18:05,221] m-LoRA: Adapter lora_winogrande_48 loss: 0.809927225112915
[2025-12-23 16:18:05,223] m-LoRA: Adapter lora_winogrande_42 epoch: 1/1 iteration: 116/128 step: 59
[2025-12-23 16:18:05,331] m-LoRA: Adapter lora_winogrande_67 loss: 0.5820639729499817
[2025-12-23 16:18:05,333] m-LoRA: Adapter lora_winogrande_69 epoch: 1/1 iteration: 40/128 step: 11
[2025-12-23 16:18:05,923] m-LoRA: Adapter lora_winogrande_70 epoch: 1/1 iteration: 40/128 step: 11
[2025-12-23 16:18:05,969] m-LoRA: Adapter lora_winogrande_76 loss: 2.8303558826446533
[2025-12-23 16:18:06,266] m-LoRA: Adapter lora_winogrande_72 loss: 0.6652675271034241
[2025-12-23 16:18:06,270] m-LoRA: Adapter lora_winogrande_60 epoch: 1/1 iteration: 104/128 step: 27
[2025-12-23 16:18:06,502] m-LoRA: Adapter lora_winogrande_58 loss: 0.4297471344470978
[2025-12-23 16:18:06,505] m-LoRA: Adapter lora_winogrande_74 epoch: 1/1 iteration: 32/128 step: 3
[2025-12-23 16:18:06,627] m-LoRA: Adapter lora_winogrande_63 loss: 0.5676335096359253
[2025-12-23 16:18:06,629] m-LoRA: Adapter lora_winogrande_62 epoch: 1/1 iteration: 76/128 step: 20
[2025-12-23 16:18:06,767] m-LoRA: Adapter lora_winogrande_68 loss: 2.2601146697998047
[2025-12-23 16:18:06,770] m-LoRA: Adapter lora_winogrande_66 epoch: 1/1 iteration: 36/128 step: 19
[2025-12-23 16:18:07,363] m-LoRA: Adapter lora_winogrande_53 epoch: 1/1 iteration: 84/128 step: 43
[2025-12-23 16:18:07,406] m-LoRA: Adapter lora_winogrande_73 loss: 3.1017043590545654
[2025-12-23 16:18:07,551] m-LoRA: Adapter lora_winogrande_42 loss: 0.4895186126232147
[2025-12-23 16:18:07,635] m-LoRA: Adapter lora_winogrande_75 epoch: 1/1 iteration: 32/128 step: 3
[2025-12-23 16:18:07,792] m-LoRA: Adapter lora_winogrande_69 loss: 2.412158966064453
[2025-12-23 16:18:07,794] m-LoRA: Adapter lora_winogrande_48 epoch: 1/1 iteration: 100/128 step: 51
[2025-12-23 16:18:07,974] m-LoRA: Adapter lora_winogrande_70 loss: 0.5648471713066101
[2025-12-23 16:18:07,977] m-LoRA: Adapter lora_winogrande_67 epoch: 1/1 iteration: 72/128 step: 19
[2025-12-23 16:18:08,186] m-LoRA: Adapter lora_winogrande_60 loss: 0.6547057628631592
[2025-12-23 16:18:08,190] m-LoRA: Adapter lora_winogrande_76 epoch: 1/1 iteration: 32/128 step: 3
[2025-12-23 16:18:08,864] m-LoRA: Adapter lora_winogrande_74 loss: 2.1253435611724854
[2025-12-23 16:18:08,871] m-LoRA: Adapter lora_winogrande_72 epoch: 1/1 iteration: 80/128 step: 11
[2025-12-23 16:18:09,102] m-LoRA: Adapter lora_winogrande_62 loss: 0.5121285319328308
[2025-12-23 16:18:09,104] m-LoRA: Adapter lora_winogrande_58 epoch: 1/1 iteration: 108/128 step: 28
[2025-12-23 16:18:09,231] m-LoRA: Adapter lora_winogrande_66 loss: 0.64652019739151
[2025-12-23 16:18:09,233] m-LoRA: Adapter lora_winogrande_63 epoch: 1/1 iteration: 38/128 step: 20
[2025-12-23 16:18:09,348] m-LoRA: Adapter lora_winogrande_53 loss: 0.978266716003418
[2025-12-23 16:18:09,350] m-LoRA: Adapter lora_winogrande_68 epoch: 1/1 iteration: 44/128 step: 12
[2025-12-23 16:18:10,029] m-LoRA: Adapter lora_winogrande_75 loss: 2.041011095046997
[2025-12-23 16:18:10,035] m-LoRA: Adapter lora_winogrande_73 epoch: 1/1 iteration: 48/128 step: 4
[2025-12-23 16:18:10,205] m-LoRA: Adapter lora_winogrande_48 loss: 0.7222421765327454
[2025-12-23 16:18:10,208] m-LoRA: Adapter lora_winogrande_42 epoch: 1/1 iteration: 118/128 step: 60
[2025-12-23 16:18:10,378] m-LoRA: Adapter lora_winogrande_67 loss: 0.5917661786079407
[2025-12-23 16:18:10,382] m-LoRA: Adapter lora_winogrande_69 epoch: 1/1 iteration: 44/128 step: 12
[2025-12-23 16:18:10,990] m-LoRA: Adapter lora_winogrande_70 epoch: 1/1 iteration: 44/128 step: 12
[2025-12-23 16:18:11,033] m-LoRA: Adapter lora_winogrande_76 loss: 2.4367620944976807
[2025-12-23 16:18:11,334] m-LoRA: Adapter lora_winogrande_72 loss: 0.6530241966247559
[2025-12-23 16:18:11,338] m-LoRA: Adapter lora_winogrande_60 epoch: 1/1 iteration: 108/128 step: 28
[2025-12-23 16:18:11,644] m-LoRA: Adapter lora_winogrande_58 loss: 0.5342344045639038
[2025-12-23 16:18:11,646] m-LoRA: Adapter lora_winogrande_74 epoch: 1/1 iteration: 48/128 step: 4
[2025-12-23 16:18:11,848] m-LoRA: Adapter lora_winogrande_63 loss: 0.5190340876579285
[2025-12-23 16:18:11,851] m-LoRA: Adapter lora_winogrande_62 epoch: 1/1 iteration: 80/128 step: 21
[2025-12-23 16:18:11,976] m-LoRA: Adapter lora_winogrande_68 loss: 2.198652505874634
[2025-12-23 16:18:11,978] m-LoRA: Adapter lora_winogrande_66 epoch: 1/1 iteration: 38/128 step: 20
[2025-12-23 16:18:12,533] m-LoRA: Adapter lora_winogrande_53 epoch: 1/1 iteration: 86/128 step: 44
[2025-12-23 16:18:12,575] m-LoRA: Adapter lora_winogrande_73 loss: 3.183095932006836
[2025-12-23 16:18:12,816] m-LoRA: Adapter lora_winogrande_42 loss: 0.5082136988639832
[2025-12-23 16:18:12,823] m-LoRA: Adapter lora_winogrande_75 epoch: 1/1 iteration: 48/128 step: 4
[2025-12-23 16:18:12,970] m-LoRA: Adapter lora_winogrande_69 loss: 2.189749002456665
[2025-12-23 16:18:12,973] m-LoRA: Adapter lora_winogrande_48 epoch: 1/1 iteration: 102/128 step: 52
[2025-12-23 16:18:13,133] m-LoRA: Adapter lora_winogrande_70 loss: 0.5316615700721741
[2025-12-23 16:18:13,136] m-LoRA: Adapter lora_winogrande_67 epoch: 1/1 iteration: 76/128 step: 20
[2025-12-23 16:18:13,369] m-LoRA: Adapter lora_winogrande_60 loss: 0.5748313069343567
[2025-12-23 16:18:13,371] m-LoRA: Adapter lora_winogrande_76 epoch: 1/1 iteration: 48/128 step: 4
[2025-12-23 16:18:14,050] m-LoRA: Adapter lora_winogrande_74 loss: 1.9158129692077637
[2025-12-23 16:18:14,057] m-LoRA: Adapter lora_winogrande_72 epoch: 1/1 iteration: 88/128 step: 12
[2025-12-23 16:18:14,298] m-LoRA: Adapter lora_winogrande_62 loss: 0.5509747862815857
[2025-12-23 16:18:14,300] m-LoRA: Adapter lora_winogrande_58 epoch: 1/1 iteration: 112/128 step: 29
[2025-12-23 16:18:14,436] m-LoRA: Adapter lora_winogrande_66 loss: 0.5857611298561096
[2025-12-23 16:18:14,439] m-LoRA: Adapter lora_winogrande_63 epoch: 1/1 iteration: 40/128 step: 21
[2025-12-23 16:18:14,548] m-LoRA: Adapter lora_winogrande_53 loss: 0.9506108164787292
[2025-12-23 16:18:14,550] m-LoRA: Adapter lora_winogrande_68 epoch: 1/1 iteration: 48/128 step: 13
[2025-12-23 16:18:15,182] m-LoRA: Adapter lora_winogrande_75 loss: 2.01997971534729
[2025-12-23 16:18:15,189] m-LoRA: Adapter lora_winogrande_73 epoch: 1/1 iteration: 64/128 step: 5
[2025-12-23 16:18:15,372] m-LoRA: Adapter lora_winogrande_48 loss: 0.847034215927124
[2025-12-23 16:18:15,374] m-LoRA: Adapter lora_winogrande_42 epoch: 1/1 iteration: 120/128 step: 61
[2025-12-23 16:18:15,458] m-LoRA: Adapter lora_winogrande_67 loss: 0.6356170177459717
[2025-12-23 16:18:15,460] m-LoRA: Adapter lora_winogrande_69 epoch: 1/1 iteration: 48/128 step: 13
[2025-12-23 16:18:16,157] m-LoRA: Adapter lora_winogrande_70 epoch: 1/1 iteration: 48/128 step: 13
[2025-12-23 16:18:16,205] m-LoRA: Adapter lora_winogrande_76 loss: 2.1942124366760254
[2025-12-23 16:18:16,523] m-LoRA: Adapter lora_winogrande_60 epoch: 1/1 iteration: 112/128 step: 29
[2025-12-23 16:18:16,561] m-LoRA: Adapter lora_winogrande_72 loss: 0.5215564966201782
[2025-12-23 16:18:16,800] m-LoRA: Adapter lora_winogrande_58 loss: 0.5627850294113159
[2025-12-23 16:18:16,802] m-LoRA: Adapter lora_winogrande_74 epoch: 1/1 iteration: 64/128 step: 5
[2025-12-23 16:18:16,913] m-LoRA: Adapter lora_winogrande_63 loss: 0.6585994362831116
[2025-12-23 16:18:16,916] m-LoRA: Adapter lora_winogrande_62 epoch: 1/1 iteration: 84/128 step: 22
[2025-12-23 16:18:17,068] m-LoRA: Adapter lora_winogrande_68 loss: 2.144395351409912
[2025-12-23 16:18:17,070] m-LoRA: Adapter lora_winogrande_66 epoch: 1/1 iteration: 40/128 step: 21
[2025-12-23 16:18:18,241] m-LoRA: Adapter lora_winogrande_53 epoch: 1/1 iteration: 88/128 step: 45
[2025-12-23 16:18:18,303] m-LoRA: Adapter lora_winogrande_73 loss: 2.923126220703125
[2025-12-23 16:18:18,438] m-LoRA: Adapter lora_winogrande_42 loss: 0.5017426609992981
[2025-12-23 16:18:18,524] m-LoRA: Adapter lora_winogrande_75 epoch: 1/1 iteration: 64/128 step: 5
[2025-12-23 16:18:18,669] m-LoRA: Adapter lora_winogrande_69 loss: 2.1959352493286133
[2025-12-23 16:18:18,672] m-LoRA: Adapter lora_winogrande_48 epoch: 1/1 iteration: 104/128 step: 53
[2025-12-23 16:18:18,802] m-LoRA: Adapter lora_winogrande_70 loss: 0.5650814771652222
[2025-12-23 16:18:18,804] m-LoRA: Adapter lora_winogrande_67 epoch: 1/1 iteration: 80/128 step: 21
[2025-12-23 16:18:19,000] m-LoRA: Adapter lora_winogrande_60 loss: 0.5700337886810303
[2025-12-23 16:18:19,002] m-LoRA: Adapter lora_winogrande_76 epoch: 1/1 iteration: 64/128 step: 5
[2025-12-23 16:18:20,362] m-LoRA: Adapter lora_winogrande_72 epoch: 1/1 iteration: 96/128 step: 13
[2025-12-23 16:18:20,514] m-LoRA: Adapter lora_winogrande_74 loss: 1.7973557710647583
[2025-12-23 16:18:20,521] m-LoRA: Adapter lora_winogrande_58 epoch: 1/1 iteration: 116/128 step: 30
[2025-12-23 16:18:20,703] m-LoRA: Adapter lora_winogrande_62 loss: 0.6026974320411682
[2025-12-23 16:18:20,705] m-LoRA: Adapter lora_winogrande_63 epoch: 1/1 iteration: 42/128 step: 22
[2025-12-23 16:18:20,809] m-LoRA: Adapter lora_winogrande_66 loss: 0.5643627047538757
[2025-12-23 16:18:20,812] m-LoRA: Adapter lora_winogrande_68 epoch: 1/1 iteration: 52/128 step: 14
[2025-12-23 16:18:20,858] m-LoRA: Adapter lora_winogrande_53 loss: 0.8501070141792297
[2025-12-23 16:18:21,519] m-LoRA: Adapter lora_winogrande_75 loss: 1.8957432508468628
[2025-12-23 16:18:21,526] m-LoRA: Adapter lora_winogrande_73 epoch: 1/1 iteration: 80/128 step: 6
[2025-12-23 16:18:21,730] m-LoRA: Adapter lora_winogrande_48 loss: 0.7805455327033997
[2025-12-23 16:18:21,732] m-LoRA: Adapter lora_winogrande_42 epoch: 1/1 iteration: 122/128 step: 62
[2025-12-23 16:18:21,948] m-LoRA: Adapter lora_winogrande_67 loss: 0.5672773122787476
[2025-12-23 16:18:21,950] m-LoRA: Adapter lora_winogrande_69 epoch: 1/1 iteration: 52/128 step: 14
[2025-12-23 16:18:22,640] m-LoRA: Adapter lora_winogrande_76 loss: 2.07719349861145
[2025-12-23 16:18:22,647] m-LoRA: Adapter lora_winogrande_70 epoch: 1/1 iteration: 52/128 step: 14
[2025-12-23 16:18:23,163] m-LoRA: Adapter lora_winogrande_72 loss: 0.5764718055725098
[2025-12-23 16:18:23,167] m-LoRA: Adapter lora_winogrande_60 epoch: 1/1 iteration: 116/128 step: 30
[2025-12-23 16:18:23,355] m-LoRA: Adapter lora_winogrande_58 loss: 0.42309871315956116
[2025-12-23 16:18:23,358] m-LoRA: Adapter lora_winogrande_74 epoch: 1/1 iteration: 80/128 step: 6
[2025-12-23 16:18:23,522] m-LoRA: Adapter lora_winogrande_63 loss: 0.6494480967521667
[2025-12-23 16:18:23,524] m-LoRA: Adapter lora_winogrande_62 epoch: 1/1 iteration: 88/128 step: 23
[2025-12-23 16:18:23,739] m-LoRA: Adapter lora_winogrande_68 loss: 2.2197275161743164
[2025-12-23 16:18:23,741] m-LoRA: Adapter lora_winogrande_66 epoch: 1/1 iteration: 42/128 step: 22
[2025-12-23 16:18:24,564] m-LoRA: Adapter lora_winogrande_73 loss: 2.882362127304077
[2025-12-23 16:18:24,571] m-LoRA: Adapter lora_winogrande_53 epoch: 1/1 iteration: 90/128 step: 46
[2025-12-23 16:18:24,767] m-LoRA: Adapter lora_winogrande_42 loss: 0.5654340386390686
[2025-12-23 16:18:24,769] m-LoRA: Adapter lora_winogrande_75 epoch: 1/1 iteration: 80/128 step: 6
[2025-12-23 16:18:24,933] m-LoRA: Adapter lora_winogrande_69 loss: 2.20884370803833
[2025-12-23 16:18:24,936] m-LoRA: Adapter lora_winogrande_48 epoch: 1/1 iteration: 106/128 step: 54
[2025-12-23 16:18:25,106] m-LoRA: Adapter lora_winogrande_70 loss: 0.5213221907615662
[2025-12-23 16:18:25,110] m-LoRA: Adapter lora_winogrande_67 epoch: 1/1 iteration: 84/128 step: 22
[2025-12-23 16:18:25,258] m-LoRA: Adapter lora_winogrande_60 loss: 0.5513938665390015
[2025-12-23 16:18:25,260] m-LoRA: Adapter lora_winogrande_76 epoch: 1/1 iteration: 80/128 step: 6
[2025-12-23 16:18:25,825] m-LoRA: Adapter lora_winogrande_72 epoch: 1/1 iteration: 104/128 step: 14
[2025-12-23 16:18:25,872] m-LoRA: Adapter lora_winogrande_74 loss: 1.461667776107788
[2025-12-23 16:18:26,134] m-LoRA: Adapter lora_winogrande_62 loss: 0.5069476962089539
[2025-12-23 16:18:26,136] m-LoRA: Adapter lora_winogrande_58 epoch: 1/1 iteration: 120/128 step: 31
[2025-12-23 16:18:26,256] m-LoRA: Adapter lora_winogrande_66 loss: 0.5535677671432495
[2025-12-23 16:18:26,259] m-LoRA: Adapter lora_winogrande_63 epoch: 1/1 iteration: 44/128 step: 23
[2025-12-23 16:18:26,410] m-LoRA: Adapter lora_winogrande_53 loss: 0.9482154250144958
[2025-12-23 16:18:26,412] m-LoRA: Adapter lora_winogrande_68 epoch: 1/1 iteration: 56/128 step: 15
[2025-12-23 16:18:27,040] m-LoRA: Adapter lora_winogrande_75 loss: 1.6862444877624512
[2025-12-23 16:18:27,047] m-LoRA: Adapter lora_winogrande_73 epoch: 1/1 iteration: 96/128 step: 7
[2025-12-23 16:18:27,223] m-LoRA: Adapter lora_winogrande_48 loss: 0.7073625326156616
[2025-12-23 16:18:27,225] m-LoRA: Adapter lora_winogrande_42 epoch: 1/1 iteration: 124/128 step: 63
[2025-12-23 16:18:27,313] m-LoRA: Adapter lora_winogrande_67 loss: 0.5296126008033752
[2025-12-23 16:18:27,315] m-LoRA: Adapter lora_winogrande_69 epoch: 1/1 iteration: 56/128 step: 15
[2025-12-23 16:18:28,024] m-LoRA: Adapter lora_winogrande_70 epoch: 1/1 iteration: 56/128 step: 15
[2025-12-23 16:18:28,077] m-LoRA: Adapter lora_winogrande_76 loss: 1.8919150829315186
[2025-12-23 16:18:28,357] m-LoRA: Adapter lora_winogrande_60 epoch: 1/1 iteration: 120/128 step: 31
[2025-12-23 16:18:28,378] m-LoRA: Adapter lora_winogrande_72 loss: 0.5143243670463562
[2025-12-23 16:18:28,686] m-LoRA: Adapter lora_winogrande_58 loss: 0.5446199178695679
[2025-12-23 16:18:28,689] m-LoRA: Adapter lora_winogrande_74 epoch: 1/1 iteration: 96/128 step: 7
[2025-12-23 16:18:28,879] m-LoRA: Adapter lora_winogrande_63 loss: 0.5652649998664856
[2025-12-23 16:18:28,881] m-LoRA: Adapter lora_winogrande_62 epoch: 1/1 iteration: 92/128 step: 24
[2025-12-23 16:18:29,004] m-LoRA: Adapter lora_winogrande_68 loss: 2.09960675239563
[2025-12-23 16:18:29,006] m-LoRA: Adapter lora_winogrande_66 epoch: 1/1 iteration: 44/128 step: 23
[2025-12-23 16:18:29,622] m-LoRA: Adapter lora_winogrande_73 loss: 2.6799733638763428
[2025-12-23 16:18:29,628] m-LoRA: Adapter lora_winogrande_53 epoch: 1/1 iteration: 92/128 step: 47
[2025-12-23 16:18:29,817] m-LoRA: Adapter lora_winogrande_42 loss: 0.5053455233573914
[2025-12-23 16:18:29,819] m-LoRA: Adapter lora_winogrande_75 epoch: 1/1 iteration: 96/128 step: 7
[2025-12-23 16:18:29,991] m-LoRA: Adapter lora_winogrande_69 loss: 2.2004692554473877
[2025-12-23 16:18:29,995] m-LoRA: Adapter lora_winogrande_48 epoch: 1/1 iteration: 108/128 step: 55
[2025-12-23 16:18:30,114] m-LoRA: Adapter lora_winogrande_70 loss: 0.64382004737854
[2025-12-23 16:18:30,117] m-LoRA: Adapter lora_winogrande_67 epoch: 1/1 iteration: 88/128 step: 23
[2025-12-23 16:18:30,313] m-LoRA: Adapter lora_winogrande_60 loss: 0.6008292436599731
[2025-12-23 16:18:30,315] m-LoRA: Adapter lora_winogrande_76 epoch: 1/1 iteration: 96/128 step: 7
[2025-12-23 16:18:30,958] m-LoRA: Adapter lora_winogrande_74 loss: 1.3689807653427124
[2025-12-23 16:18:30,965] m-LoRA: Adapter lora_winogrande_72 epoch: 1/1 iteration: 112/128 step: 15
[2025-12-23 16:18:31,211] m-LoRA: Adapter lora_winogrande_62 loss: 0.4827854037284851
[2025-12-23 16:18:31,214] m-LoRA: Adapter lora_winogrande_58 epoch: 1/1 iteration: 124/128 step: 32
[2025-12-23 16:18:31,337] m-LoRA: Adapter lora_winogrande_66 loss: 0.45107755064964294
[2025-12-23 16:18:31,340] m-LoRA: Adapter lora_winogrande_63 epoch: 1/1 iteration: 46/128 step: 24
[2025-12-23 16:18:31,439] m-LoRA: Adapter lora_winogrande_53 loss: 0.7855333685874939
[2025-12-23 16:18:31,451] m-LoRA: Adapter lora_winogrande_68 epoch: 1/1 iteration: 60/128 step: 16
[2025-12-23 16:18:32,111] m-LoRA: Adapter lora_winogrande_75 loss: 1.3639516830444336
[2025-12-23 16:18:32,117] m-LoRA: Adapter lora_winogrande_73 epoch: 1/1 iteration: 112/128 step: 8
[2025-12-23 16:18:32,288] m-LoRA: Adapter lora_winogrande_48 loss: 0.6963684558868408
[2025-12-23 16:18:32,290] m-LoRA: Adapter lora_winogrande_42 epoch: 1/1 iteration: 126/128 step: 64
[2025-12-23 16:18:32,389] m-LoRA: Adapter lora_winogrande_67 loss: 0.5432482957839966
[2025-12-23 16:18:32,392] m-LoRA: Adapter lora_winogrande_69 epoch: 1/1 iteration: 60/128 step: 16
[2025-12-23 16:18:32,995] m-LoRA: Adapter lora_winogrande_70 epoch: 1/1 iteration: 60/128 step: 16
[2025-12-23 16:18:33,047] m-LoRA: Adapter lora_winogrande_76 loss: 1.9012295007705688
[2025-12-23 16:18:33,363] m-LoRA: Adapter lora_winogrande_60 epoch: 1/1 iteration: 124/128 step: 32
[2025-12-23 16:18:33,383] m-LoRA: Adapter lora_winogrande_72 loss: 0.5551602840423584
[2025-12-23 16:18:33,574] m-LoRA: Adapter lora_winogrande_58 loss: 0.5144341588020325
[2025-12-23 16:18:33,576] m-LoRA: Adapter lora_winogrande_74 epoch: 1/1 iteration: 112/128 step: 8
[2025-12-23 16:18:33,705] m-LoRA: Adapter lora_winogrande_63 loss: 0.567507803440094
[2025-12-23 16:18:33,707] m-LoRA: Adapter lora_winogrande_62 epoch: 1/1 iteration: 96/128 step: 25
[2025-12-23 16:18:33,842] m-LoRA: Adapter lora_winogrande_68 loss: 2.2111423015594482
[2025-12-23 16:18:33,844] m-LoRA: Adapter lora_winogrande_66 epoch: 1/1 iteration: 46/128 step: 24
[2025-12-23 16:18:34,644] m-LoRA: Adapter lora_winogrande_73 loss: 2.5172278881073
[2025-12-23 16:18:34,651] m-LoRA: Adapter lora_winogrande_53 epoch: 1/1 iteration: 94/128 step: 48
[2025-12-23 16:18:34,847] m-LoRA: Adapter lora_winogrande_42 loss: 0.45550039410591125
[2025-12-23 16:18:34,850] m-LoRA: Adapter lora_winogrande_75 epoch: 1/1 iteration: 112/128 step: 8
[2025-12-23 16:18:34,957] m-LoRA: Adapter lora_winogrande_69 loss: 2.0964338779449463
[2025-12-23 16:18:34,959] m-LoRA: Adapter lora_winogrande_48 epoch: 1/1 iteration: 110/128 step: 56
[2025-12-23 16:18:35,119] m-LoRA: Adapter lora_winogrande_70 loss: 0.5299561619758606
[2025-12-23 16:18:35,122] m-LoRA: Adapter lora_winogrande_67 epoch: 1/1 iteration: 92/128 step: 24
[2025-12-23 16:18:35,360] m-LoRA: Adapter lora_winogrande_60 loss: 0.5648424029350281
[2025-12-23 16:18:35,362] m-LoRA: Adapter lora_winogrande_76 epoch: 1/1 iteration: 112/128 step: 8
[2025-12-23 16:18:36,019] m-LoRA: Adapter lora_winogrande_72 epoch: 1/1 iteration: 120/128 step: 16
[2025-12-23 16:18:36,137] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_58']
[2025-12-23 16:18:36,482] m-LoRA: Adapter lora_winogrande_74 loss: 1.145071029663086
[2025-12-23 16:18:36,494] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_77']
[2025-12-23 16:18:36,689] m-LoRA: Adapter lora_winogrande_77 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:18:36,784] m-LoRA: Adapter lora_winogrande_62 loss: 0.5055543184280396
[2025-12-23 16:18:36,786] m-LoRA: Adapter lora_winogrande_63 epoch: 1/1 iteration: 48/128 step: 25
[2025-12-23 16:18:36,860] m-LoRA: Adapter lora_winogrande_66 loss: 0.49175822734832764
[2025-12-23 16:18:36,862] m-LoRA: Adapter lora_winogrande_68 epoch: 1/1 iteration: 64/128 step: 17
[2025-12-23 16:18:36,892] m-LoRA: Adapter lora_winogrande_53 loss: 0.807964563369751
[2025-12-23 16:18:37,328] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_73']
[2025-12-23 16:18:37,573] m-LoRA: Adapter lora_winogrande_75 loss: 1.3297606706619263
[2025-12-23 16:18:37,631] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_78']
[2025-12-23 16:18:37,783] m-LoRA: Adapter lora_winogrande_78 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:18:37,865] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_42']
[2025-12-23 16:18:38,087] m-LoRA: Adapter lora_winogrande_48 loss: 0.6500096321105957
[2025-12-23 16:18:38,089] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_79']
[2025-12-23 16:18:38,350] m-LoRA: Adapter lora_winogrande_79 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:18:38,514] m-LoRA: Adapter lora_winogrande_67 loss: 0.5542731285095215
[2025-12-23 16:18:38,516] m-LoRA: Adapter lora_winogrande_69 epoch: 1/1 iteration: 64/128 step: 17
[2025-12-23 16:18:38,670] m-LoRA: Adapter lora_winogrande_76 loss: 1.6905566453933716
[2025-12-23 16:18:38,676] m-LoRA: Adapter lora_winogrande_70 epoch: 1/1 iteration: 64/128 step: 17
[2025-12-23 16:18:38,914] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_60']
[2025-12-23 16:18:39,135] m-LoRA: Adapter lora_winogrande_72 loss: 0.47895124554634094
[2025-12-23 16:18:39,155] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_80']
[2025-12-23 16:18:39,283] m-LoRA: Adapter lora_winogrande_80 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:18:39,363] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_74']
[2025-12-23 16:18:40,010] m-LoRA: Adapter lora_winogrande_77 loss: 3.010383129119873
[2025-12-23 16:18:40,012] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_81']
[2025-12-23 16:18:40,124] m-LoRA: Adapter lora_winogrande_81 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:18:40,219] m-LoRA: Adapter lora_winogrande_63 loss: 0.6445000767707825
[2025-12-23 16:18:40,221] m-LoRA: Adapter lora_winogrande_62 epoch: 1/1 iteration: 100/128 step: 26
[2025-12-23 16:18:40,310] m-LoRA: Adapter lora_winogrande_68 loss: 2.149184226989746
[2025-12-23 16:18:40,313] m-LoRA: Adapter lora_winogrande_66 epoch: 1/1 iteration: 48/128 step: 25
[2025-12-23 16:18:40,475] m-LoRA: Adapter lora_winogrande_78 loss: 2.943162202835083
[2025-12-23 16:18:40,478] m-LoRA: Adapter lora_winogrande_53 epoch: 1/1 iteration: 96/128 step: 49
[2025-12-23 16:18:40,604] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_75']
[2025-12-23 16:18:41,079] m-LoRA: Adapter lora_winogrande_79 loss: 3.1268012523651123
[2025-12-23 16:18:41,086] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_82']
[2025-12-23 16:18:41,261] m-LoRA: Adapter lora_winogrande_82 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:18:41,390] m-LoRA: Adapter lora_winogrande_69 loss: 2.040027618408203
[2025-12-23 16:18:41,392] m-LoRA: Adapter lora_winogrande_48 epoch: 1/1 iteration: 112/128 step: 57
[2025-12-23 16:18:41,514] m-LoRA: Adapter lora_winogrande_70 loss: 0.5202950239181519
[2025-12-23 16:18:41,516] m-LoRA: Adapter lora_winogrande_67 epoch: 1/1 iteration: 96/128 step: 25
[2025-12-23 16:18:41,689] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_76']
[2025-12-23 16:18:41,837] m-LoRA: Adapter lora_winogrande_80 loss: 3.2014331817626953
[2025-12-23 16:18:41,877] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_83']
[2025-12-23 16:18:41,982] m-LoRA: Adapter lora_winogrande_83 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:18:42,078] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_72']
[2025-12-23 16:18:42,600] m-LoRA: Adapter lora_winogrande_81 loss: 2.9548513889312744
[2025-12-23 16:18:42,602] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_84']
[2025-12-23 16:18:42,784] m-LoRA: Adapter lora_winogrande_84 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:18:42,967] m-LoRA: Adapter lora_winogrande_62 loss: 0.5952140092849731
[2025-12-23 16:18:42,969] m-LoRA: Adapter lora_winogrande_77 epoch: 1/1 iteration: 4/128 step: 2
[2025-12-23 16:18:43,140] m-LoRA: Adapter lora_winogrande_66 loss: 0.6093590259552002
[2025-12-23 16:18:43,142] m-LoRA: Adapter lora_winogrande_63 epoch: 1/1 iteration: 50/128 step: 26
[2025-12-23 16:18:43,335] m-LoRA: Adapter lora_winogrande_53 loss: 0.9405775666236877
[2025-12-23 16:18:43,338] m-LoRA: Adapter lora_winogrande_68 epoch: 1/1 iteration: 68/128 step: 18
[2025-12-23 16:18:43,475] m-LoRA: Adapter lora_winogrande_82 loss: 2.998168468475342
[2025-12-23 16:18:43,479] m-LoRA: Adapter lora_winogrande_78 epoch: 1/1 iteration: 4/128 step: 2
[2025-12-23 16:18:43,677] m-LoRA: Adapter lora_winogrande_48 loss: 0.6203306317329407
[2025-12-23 16:18:43,679] m-LoRA: Adapter lora_winogrande_79 epoch: 1/1 iteration: 16/128 step: 2
[2025-12-23 16:18:43,778] m-LoRA: Adapter lora_winogrande_67 loss: 0.5567395687103271
[2025-12-23 16:18:43,781] m-LoRA: Adapter lora_winogrande_69 epoch: 1/1 iteration: 68/128 step: 18
[2025-12-23 16:18:43,899] m-LoRA: Adapter lora_winogrande_83 loss: 3.165642023086548
[2025-12-23 16:18:43,901] m-LoRA: Adapter lora_winogrande_70 epoch: 1/1 iteration: 68/128 step: 18
[2025-12-23 16:18:44,042] m-LoRA: Adapter lora_winogrande_80 epoch: 1/1 iteration: 8/128 step: 2
[2025-12-23 16:18:44,142] m-LoRA: Adapter lora_winogrande_81 epoch: 1/1 iteration: 2/128 step: 2
[2025-12-23 16:18:44,550] m-LoRA: Adapter lora_winogrande_62 epoch: 1/1 iteration: 104/128 step: 27
[2025-12-23 16:18:44,591] m-LoRA: Adapter lora_winogrande_84 loss: 3.320666790008545
[2025-12-23 16:18:44,816] m-LoRA: Adapter lora_winogrande_77 loss: 2.715749502182007
[2025-12-23 16:18:44,819] m-LoRA: Adapter lora_winogrande_66 epoch: 1/1 iteration: 50/128 step: 26
[2025-12-23 16:18:44,913] m-LoRA: Adapter lora_winogrande_63 loss: 0.571638822555542
[2025-12-23 16:18:44,915] m-LoRA: Adapter lora_winogrande_53 epoch: 1/1 iteration: 98/128 step: 50
[2025-12-23 16:18:45,028] m-LoRA: Adapter lora_winogrande_68 loss: 2.1699280738830566
[2025-12-23 16:18:45,031] m-LoRA: Adapter lora_winogrande_82 epoch: 1/1 iteration: 8/128 step: 2
[2025-12-23 16:18:45,222] m-LoRA: Adapter lora_winogrande_78 loss: 2.9095067977905273
[2025-12-23 16:18:45,225] m-LoRA: Adapter lora_winogrande_48 epoch: 1/1 iteration: 114/128 step: 58
[2025-12-23 16:18:45,983] m-LoRA: Adapter lora_winogrande_79 loss: 2.63478684425354
[2025-12-23 16:18:45,989] m-LoRA: Adapter lora_winogrande_67 epoch: 1/1 iteration: 100/128 step: 26
[2025-12-23 16:18:46,198] m-LoRA: Adapter lora_winogrande_69 loss: 2.04457688331604
[2025-12-23 16:18:46,201] m-LoRA: Adapter lora_winogrande_83 epoch: 1/1 iteration: 4/128 step: 2
[2025-12-23 16:18:46,361] m-LoRA: Adapter lora_winogrande_70 loss: 0.5312018394470215
[2025-12-23 16:18:46,363] m-LoRA: Adapter lora_winogrande_84 epoch: 1/1 iteration: 16/128 step: 2
[2025-12-23 16:18:46,625] m-LoRA: Adapter lora_winogrande_80 loss: 2.660569667816162
[2025-12-23 16:18:46,628] m-LoRA: Adapter lora_winogrande_77 epoch: 1/1 iteration: 8/128 step: 3
[2025-12-23 16:18:46,796] m-LoRA: Adapter lora_winogrande_81 loss: 2.691357374191284
[2025-12-23 16:18:46,798] m-LoRA: Adapter lora_winogrande_63 epoch: 1/1 iteration: 52/128 step: 27
[2025-12-23 16:18:46,927] m-LoRA: Adapter lora_winogrande_62 loss: 0.5249533653259277
[2025-12-23 16:18:46,931] m-LoRA: Adapter lora_winogrande_68 epoch: 1/1 iteration: 72/128 step: 19
[2025-12-23 16:18:47,069] m-LoRA: Adapter lora_winogrande_66 loss: 0.40340563654899597
[2025-12-23 16:18:47,071] m-LoRA: Adapter lora_winogrande_78 epoch: 1/1 iteration: 8/128 step: 3
[2025-12-23 16:18:47,138] m-LoRA: Adapter lora_winogrande_53 loss: 0.7944718599319458
[2025-12-23 16:18:47,414] m-LoRA: Adapter lora_winogrande_82 loss: 2.899474620819092
[2025-12-23 16:18:47,594] m-LoRA: Adapter lora_winogrande_48 loss: 0.6720008850097656
[2025-12-23 16:18:47,596] m-LoRA: Adapter lora_winogrande_79 epoch: 1/1 iteration: 32/128 step: 3
[2025-12-23 16:18:47,767] m-LoRA: Adapter lora_winogrande_67 loss: 0.5894231796264648
[2025-12-23 16:18:47,769] m-LoRA: Adapter lora_winogrande_69 epoch: 1/1 iteration: 72/128 step: 19
[2025-12-23 16:18:47,940] m-LoRA: Adapter lora_winogrande_83 loss: 2.758026599884033
[2025-12-23 16:18:47,942] m-LoRA: Adapter lora_winogrande_70 epoch: 1/1 iteration: 72/128 step: 19
[2025-12-23 16:18:48,704] m-LoRA: Adapter lora_winogrande_84 loss: 2.652439594268799
[2025-12-23 16:18:48,711] m-LoRA: Adapter lora_winogrande_80 epoch: 1/1 iteration: 16/128 step: 3
[2025-12-23 16:18:48,930] m-LoRA: Adapter lora_winogrande_77 loss: 2.1290171146392822
[2025-12-23 16:18:48,933] m-LoRA: Adapter lora_winogrande_81 epoch: 1/1 iteration: 4/128 step: 3
[2025-12-23 16:18:49,020] m-LoRA: Adapter lora_winogrande_63 loss: 0.477818101644516
[2025-12-23 16:18:49,022] m-LoRA: Adapter lora_winogrande_62 epoch: 1/1 iteration: 108/128 step: 28
[2025-12-23 16:18:49,305] m-LoRA: Adapter lora_winogrande_68 loss: 2.073519706726074
[2025-12-23 16:18:49,307] m-LoRA: Adapter lora_winogrande_66 epoch: 1/1 iteration: 52/128 step: 27
[2025-12-23 16:18:49,519] m-LoRA: Adapter lora_winogrande_78 loss: 2.5065479278564453
[2025-12-23 16:18:49,523] m-LoRA: Adapter lora_winogrande_53 epoch: 1/1 iteration: 100/128 step: 51
[2025-12-23 16:18:50,233] m-LoRA: Adapter lora_winogrande_79 loss: 2.0762391090393066
[2025-12-23 16:18:50,240] m-LoRA: Adapter lora_winogrande_82 epoch: 1/1 iteration: 16/128 step: 3
[2025-12-23 16:18:50,534] m-LoRA: Adapter lora_winogrande_69 loss: 1.9274522066116333
[2025-12-23 16:18:50,537] m-LoRA: Adapter lora_winogrande_48 epoch: 1/1 iteration: 116/128 step: 59
[2025-12-23 16:18:50,783] m-LoRA: Adapter lora_winogrande_70 loss: 0.5841727256774902
[2025-12-23 16:18:50,786] m-LoRA: Adapter lora_winogrande_67 epoch: 1/1 iteration: 104/128 step: 27
[2025-12-23 16:18:51,594] m-LoRA: Adapter lora_winogrande_80 loss: 2.261445999145508
[2025-12-23 16:18:51,598] m-LoRA: Adapter lora_winogrande_83 epoch: 1/1 iteration: 8/128 step: 3
[2025-12-23 16:18:51,802] m-LoRA: Adapter lora_winogrande_81 loss: 2.138370990753174
[2025-12-23 16:18:51,805] m-LoRA: Adapter lora_winogrande_84 epoch: 1/1 iteration: 32/128 step: 3
[2025-12-23 16:18:51,975] m-LoRA: Adapter lora_winogrande_62 loss: 0.5522696375846863
[2025-12-23 16:18:51,978] m-LoRA: Adapter lora_winogrande_77 epoch: 1/1 iteration: 12/128 step: 4
[2025-12-23 16:18:52,124] m-LoRA: Adapter lora_winogrande_66 loss: 0.4369592070579529
[2025-12-23 16:18:52,126] m-LoRA: Adapter lora_winogrande_63 epoch: 1/1 iteration: 54/128 step: 28
[2025-12-23 16:18:52,246] m-LoRA: Adapter lora_winogrande_53 loss: 0.7562500238418579
[2025-12-23 16:18:52,248] m-LoRA: Adapter lora_winogrande_68 epoch: 1/1 iteration: 76/128 step: 20
[2025-12-23 16:18:52,463] m-LoRA: Adapter lora_winogrande_82 loss: 2.359576463699341
[2025-12-23 16:18:52,467] m-LoRA: Adapter lora_winogrande_78 epoch: 1/1 iteration: 12/128 step: 4
[2025-12-23 16:18:52,598] m-LoRA: Adapter lora_winogrande_48 loss: 0.7762455344200134
[2025-12-23 16:18:52,857] m-LoRA: Adapter lora_winogrande_67 loss: 0.5737411975860596
[2025-12-23 16:18:53,134] m-LoRA: Adapter lora_winogrande_83 loss: 2.6659414768218994
[2025-12-23 16:18:53,136] m-LoRA: Adapter lora_winogrande_79 epoch: 1/1 iteration: 48/128 step: 4
[2025-12-23 16:18:53,266] m-LoRA: Adapter lora_winogrande_69 epoch: 1/1 iteration: 76/128 step: 20
[2025-12-23 16:18:53,356] m-LoRA: Adapter lora_winogrande_70 epoch: 1/1 iteration: 76/128 step: 20
[2025-12-23 16:18:53,819] m-LoRA: Adapter lora_winogrande_80 epoch: 1/1 iteration: 24/128 step: 4
[2025-12-23 16:18:53,867] m-LoRA: Adapter lora_winogrande_84 loss: 2.1735570430755615
[2025-12-23 16:18:54,065] m-LoRA: Adapter lora_winogrande_77 loss: 1.982147455215454
[2025-12-23 16:18:54,067] m-LoRA: Adapter lora_winogrande_81 epoch: 1/1 iteration: 6/128 step: 4
[2025-12-23 16:18:54,166] m-LoRA: Adapter lora_winogrande_63 loss: 0.4984666109085083
[2025-12-23 16:18:54,168] m-LoRA: Adapter lora_winogrande_62 epoch: 1/1 iteration: 112/128 step: 29
[2025-12-23 16:18:54,296] m-LoRA: Adapter lora_winogrande_68 loss: 2.085899591445923
[2025-12-23 16:18:54,298] m-LoRA: Adapter lora_winogrande_66 epoch: 1/1 iteration: 54/128 step: 28
[2025-12-23 16:18:54,490] m-LoRA: Adapter lora_winogrande_78 loss: 2.266491413116455
[2025-12-23 16:18:54,493] m-LoRA: Adapter lora_winogrande_53 epoch: 1/1 iteration: 102/128 step: 52
[2025-12-23 16:18:55,109] m-LoRA: Adapter lora_winogrande_82 epoch: 1/1 iteration: 24/128 step: 4
[2025-12-23 16:18:55,154] m-LoRA: Adapter lora_winogrande_79 loss: 1.9487102031707764
[2025-12-23 16:18:55,364] m-LoRA: Adapter lora_winogrande_69 loss: 2.050851821899414
[2025-12-23 16:18:55,366] m-LoRA: Adapter lora_winogrande_48 epoch: 1/1 iteration: 118/128 step: 60
[2025-12-23 16:18:55,503] m-LoRA: Adapter lora_winogrande_70 loss: 0.4685262441635132
[2025-12-23 16:18:55,506] m-LoRA: Adapter lora_winogrande_67 epoch: 1/1 iteration: 108/128 step: 28
[2025-12-23 16:18:55,985] m-LoRA: Adapter lora_winogrande_80 loss: 2.0329184532165527
[2025-12-23 16:18:55,988] m-LoRA: Adapter lora_winogrande_83 epoch: 1/1 iteration: 12/128 step: 4
[2025-12-23 16:18:56,168] m-LoRA: Adapter lora_winogrande_81 loss: 1.9024581909179688
[2025-12-23 16:18:56,170] m-LoRA: Adapter lora_winogrande_84 epoch: 1/1 iteration: 48/128 step: 4
[2025-12-23 16:18:56,328] m-LoRA: Adapter lora_winogrande_62 loss: 0.5733045935630798
[2025-12-23 16:18:56,331] m-LoRA: Adapter lora_winogrande_77 epoch: 1/1 iteration: 16/128 step: 5
[2025-12-23 16:18:56,456] m-LoRA: Adapter lora_winogrande_66 loss: 0.5450806021690369
[2025-12-23 16:18:56,459] m-LoRA: Adapter lora_winogrande_63 epoch: 1/1 iteration: 56/128 step: 29
[2025-12-23 16:18:56,569] m-LoRA: Adapter lora_winogrande_53 loss: 0.7401810884475708
[2025-12-23 16:18:56,572] m-LoRA: Adapter lora_winogrande_68 epoch: 1/1 iteration: 80/128 step: 21
[2025-12-23 16:18:56,736] m-LoRA: Adapter lora_winogrande_82 loss: 2.1400673389434814
[2025-12-23 16:18:56,741] m-LoRA: Adapter lora_winogrande_78 epoch: 1/1 iteration: 16/128 step: 5
[2025-12-23 16:18:56,850] m-LoRA: Adapter lora_winogrande_48 loss: 0.6941126585006714
[2025-12-23 16:18:57,070] m-LoRA: Adapter lora_winogrande_67 loss: 0.5380588173866272
[2025-12-23 16:18:57,407] m-LoRA: Adapter lora_winogrande_83 loss: 2.1598408222198486
[2025-12-23 16:18:57,409] m-LoRA: Adapter lora_winogrande_79 epoch: 1/1 iteration: 64/128 step: 5
[2025-12-23 16:18:57,562] m-LoRA: Adapter lora_winogrande_69 epoch: 1/1 iteration: 80/128 step: 21
[2025-12-23 16:18:58,060] m-LoRA: Adapter lora_winogrande_70 epoch: 1/1 iteration: 80/128 step: 21
[2025-12-23 16:18:58,116] m-LoRA: Adapter lora_winogrande_84 loss: 1.9228655099868774
[2025-12-23 16:18:58,322] m-LoRA: Adapter lora_winogrande_77 loss: 1.7411577701568604
[2025-12-23 16:18:58,325] m-LoRA: Adapter lora_winogrande_80 epoch: 1/1 iteration: 32/128 step: 5
[2025-12-23 16:18:58,442] m-LoRA: Adapter lora_winogrande_63 loss: 0.6351152658462524
[2025-12-23 16:18:58,444] m-LoRA: Adapter lora_winogrande_81 epoch: 1/1 iteration: 8/128 step: 5
[2025-12-23 16:18:58,591] m-LoRA: Adapter lora_winogrande_68 loss: 1.9923441410064697
[2025-12-23 16:18:58,593] m-LoRA: Adapter lora_winogrande_62 epoch: 1/1 iteration: 116/128 step: 30
[2025-12-23 16:18:58,839] m-LoRA: Adapter lora_winogrande_78 loss: 2.12518572807312
[2025-12-23 16:18:58,841] m-LoRA: Adapter lora_winogrande_66 epoch: 1/1 iteration: 56/128 step: 29
[2025-12-23 16:18:59,439] m-LoRA: Adapter lora_winogrande_79 loss: 1.7881041765213013
[2025-12-23 16:18:59,446] m-LoRA: Adapter lora_winogrande_53 epoch: 1/1 iteration: 104/128 step: 53
[2025-12-23 16:18:59,698] m-LoRA: Adapter lora_winogrande_69 loss: 1.9171053171157837
[2025-12-23 16:18:59,702] m-LoRA: Adapter lora_winogrande_82 epoch: 1/1 iteration: 32/128 step: 5
[2025-12-23 16:18:59,842] m-LoRA: Adapter lora_winogrande_70 loss: 0.5669776797294617
[2025-12-23 16:18:59,844] m-LoRA: Adapter lora_winogrande_48 epoch: 1/1 iteration: 120/128 step: 61
[2025-12-23 16:19:00,255] m-LoRA: Adapter lora_winogrande_80 loss: 1.6571226119995117
[2025-12-23 16:19:00,259] m-LoRA: Adapter lora_winogrande_67 epoch: 1/1 iteration: 112/128 step: 29
[2025-12-23 16:19:00,439] m-LoRA: Adapter lora_winogrande_81 loss: 1.7090117931365967
[2025-12-23 16:19:00,441] m-LoRA: Adapter lora_winogrande_83 epoch: 1/1 iteration: 16/128 step: 5
[2025-12-23 16:19:00,622] m-LoRA: Adapter lora_winogrande_62 loss: 0.5793707370758057
[2025-12-23 16:19:00,624] m-LoRA: Adapter lora_winogrande_84 epoch: 1/1 iteration: 64/128 step: 5
[2025-12-23 16:19:00,783] m-LoRA: Adapter lora_winogrande_66 loss: 0.6418220400810242
[2025-12-23 16:19:00,785] m-LoRA: Adapter lora_winogrande_77 epoch: 1/1 iteration: 20/128 step: 6
[2025-12-23 16:19:00,964] m-LoRA: Adapter lora_winogrande_53 loss: 0.7176927924156189
[2025-12-23 16:19:00,967] m-LoRA: Adapter lora_winogrande_63 epoch: 1/1 iteration: 58/128 step: 30
[2025-12-23 16:19:01,095] m-LoRA: Adapter lora_winogrande_82 loss: 2.166971206665039
[2025-12-23 16:19:01,099] m-LoRA: Adapter lora_winogrande_68 epoch: 1/1 iteration: 84/128 step: 22
[2025-12-23 16:19:01,230] m-LoRA: Adapter lora_winogrande_48 loss: 0.5917401313781738
[2025-12-23 16:19:01,232] m-LoRA: Adapter lora_winogrande_78 epoch: 1/1 iteration: 20/128 step: 6
[2025-12-23 16:19:01,475] m-LoRA: Adapter lora_winogrande_67 loss: 0.46221476793289185
[2025-12-23 16:19:01,477] m-LoRA: Adapter lora_winogrande_79 epoch: 1/1 iteration: 80/128 step: 6
[2025-12-23 16:19:01,598] m-LoRA: Adapter lora_winogrande_83 loss: 2.1000428199768066
[2025-12-23 16:19:01,601] m-LoRA: Adapter lora_winogrande_69 epoch: 1/1 iteration: 84/128 step: 22
[2025-12-23 16:19:01,725] m-LoRA: Adapter lora_winogrande_70 epoch: 1/1 iteration: 84/128 step: 22
[2025-12-23 16:19:02,560] m-LoRA: Adapter lora_winogrande_80 epoch: 1/1 iteration: 40/128 step: 6
[2025-12-23 16:19:02,609] m-LoRA: Adapter lora_winogrande_84 loss: 1.8663530349731445
[2025-12-23 16:19:02,820] m-LoRA: Adapter lora_winogrande_77 loss: 1.5519455671310425
[2025-12-23 16:19:02,822] m-LoRA: Adapter lora_winogrande_81 epoch: 1/1 iteration: 10/128 step: 6
[2025-12-23 16:19:02,944] m-LoRA: Adapter lora_winogrande_63 loss: 0.6108399033546448
[2025-12-23 16:19:02,946] m-LoRA: Adapter lora_winogrande_62 epoch: 1/1 iteration: 120/128 step: 31
[2025-12-23 16:19:03,127] m-LoRA: Adapter lora_winogrande_68 loss: 1.9376329183578491
[2025-12-23 16:19:03,130] m-LoRA: Adapter lora_winogrande_66 epoch: 1/1 iteration: 58/128 step: 30
[2025-12-23 16:19:03,314] m-LoRA: Adapter lora_winogrande_78 loss: 2.0662851333618164
[2025-12-23 16:19:03,316] m-LoRA: Adapter lora_winogrande_53 epoch: 1/1 iteration: 106/128 step: 54
[2025-12-23 16:19:04,055] m-LoRA: Adapter lora_winogrande_79 loss: 1.4491147994995117
[2025-12-23 16:19:04,062] m-LoRA: Adapter lora_winogrande_82 epoch: 1/1 iteration: 40/128 step: 6
[2025-12-23 16:19:04,256] m-LoRA: Adapter lora_winogrande_69 loss: 1.986710786819458
[2025-12-23 16:19:04,257] m-LoRA: Adapter lora_winogrande_48 epoch: 1/1 iteration: 122/128 step: 62
[2025-12-23 16:19:04,411] m-LoRA: Adapter lora_winogrande_70 loss: 0.4932402968406677
[2025-12-23 16:19:04,413] m-LoRA: Adapter lora_winogrande_67 epoch: 1/1 iteration: 116/128 step: 30
[2025-12-23 16:19:04,711] m-LoRA: Adapter lora_winogrande_83 epoch: 1/1 iteration: 20/128 step: 6
[2025-12-23 16:19:04,863] m-LoRA: Adapter lora_winogrande_80 loss: 1.5661559104919434
[2025-12-23 16:19:04,867] m-LoRA: Adapter lora_winogrande_84 epoch: 1/1 iteration: 80/128 step: 6
[2025-12-23 16:19:05,147] m-LoRA: Adapter lora_winogrande_81 loss: 1.4600625038146973
[2025-12-23 16:19:05,149] m-LoRA: Adapter lora_winogrande_77 epoch: 1/1 iteration: 24/128 step: 7
[2025-12-23 16:19:05,308] m-LoRA: Adapter lora_winogrande_62 loss: 0.4750751852989197
[2025-12-23 16:19:05,312] m-LoRA: Adapter lora_winogrande_63 epoch: 1/1 iteration: 60/128 step: 31
[2025-12-23 16:19:05,439] m-LoRA: Adapter lora_winogrande_66 loss: 0.44200482964515686
[2025-12-23 16:19:05,441] m-LoRA: Adapter lora_winogrande_68 epoch: 1/1 iteration: 88/128 step: 23
[2025-12-23 16:19:05,495] m-LoRA: Adapter lora_winogrande_53 loss: 0.6976449489593506
[2025-12-23 16:19:05,703] m-LoRA: Adapter lora_winogrande_82 loss: 1.9270362854003906
[2025-12-23 16:19:05,708] m-LoRA: Adapter lora_winogrande_78 epoch: 1/1 iteration: 24/128 step: 7
[2025-12-23 16:19:05,936] m-LoRA: Adapter lora_winogrande_48 loss: 0.6726912260055542
[2025-12-23 16:19:05,977] m-LoRA: Adapter lora_winogrande_79 epoch: 1/1 iteration: 96/128 step: 7
[2025-12-23 16:19:06,158] m-LoRA: Adapter lora_winogrande_67 loss: 0.5424884557723999
[2025-12-23 16:19:06,162] m-LoRA: Adapter lora_winogrande_69 epoch: 1/1 iteration: 88/128 step: 23
[2025-12-23 16:19:06,309] m-LoRA: Adapter lora_winogrande_83 loss: 2.01458740234375
[2025-12-23 16:19:06,312] m-LoRA: Adapter lora_winogrande_70 epoch: 1/1 iteration: 88/128 step: 23
[2025-12-23 16:19:06,949] m-LoRA: Adapter lora_winogrande_84 loss: 1.692355751991272
[2025-12-23 16:19:06,956] m-LoRA: Adapter lora_winogrande_80 epoch: 1/1 iteration: 48/128 step: 7
[2025-12-23 16:19:07,169] m-LoRA: Adapter lora_winogrande_77 loss: 1.3779499530792236
[2025-12-23 16:19:07,171] m-LoRA: Adapter lora_winogrande_81 epoch: 1/1 iteration: 12/128 step: 7
[2025-12-23 16:19:07,292] m-LoRA: Adapter lora_winogrande_63 loss: 0.5366275906562805
[2025-12-23 16:19:07,294] m-LoRA: Adapter lora_winogrande_62 epoch: 1/1 iteration: 124/128 step: 32
[2025-12-23 16:19:07,425] m-LoRA: Adapter lora_winogrande_68 loss: 1.9661387205123901
[2025-12-23 16:19:07,428] m-LoRA: Adapter lora_winogrande_66 epoch: 1/1 iteration: 60/128 step: 31
[2025-12-23 16:19:07,570] m-LoRA: Adapter lora_winogrande_78 loss: 1.8638397455215454
[2025-12-23 16:19:07,573] m-LoRA: Adapter lora_winogrande_53 epoch: 1/1 iteration: 108/128 step: 55
[2025-12-23 16:19:08,329] m-LoRA: Adapter lora_winogrande_79 loss: 1.3177608251571655
[2025-12-23 16:19:08,335] m-LoRA: Adapter lora_winogrande_82 epoch: 1/1 iteration: 48/128 step: 7
[2025-12-23 16:19:08,542] m-LoRA: Adapter lora_winogrande_69 loss: 1.8612767457962036
[2025-12-23 16:19:08,546] m-LoRA: Adapter lora_winogrande_48 epoch: 1/1 iteration: 124/128 step: 63
[2025-12-23 16:19:08,682] m-LoRA: Adapter lora_winogrande_70 loss: 0.4656704068183899
[2025-12-23 16:19:08,685] m-LoRA: Adapter lora_winogrande_67 epoch: 1/1 iteration: 120/128 step: 31
[2025-12-23 16:19:08,969] m-LoRA: Adapter lora_winogrande_80 loss: 1.3097343444824219
[2025-12-23 16:19:08,972] m-LoRA: Adapter lora_winogrande_83 epoch: 1/1 iteration: 24/128 step: 7
[2025-12-23 16:19:09,183] m-LoRA: Adapter lora_winogrande_81 loss: 1.123236894607544
[2025-12-23 16:19:09,185] m-LoRA: Adapter lora_winogrande_84 epoch: 1/1 iteration: 96/128 step: 7
[2025-12-23 16:19:09,397] m-LoRA: Adapter lora_winogrande_62 loss: 0.4520554542541504
[2025-12-23 16:19:09,400] m-LoRA: Adapter lora_winogrande_77 epoch: 1/1 iteration: 28/128 step: 8
[2025-12-23 16:19:09,567] m-LoRA: Adapter lora_winogrande_66 loss: 0.6351619362831116
[2025-12-23 16:19:09,569] m-LoRA: Adapter lora_winogrande_63 epoch: 1/1 iteration: 62/128 step: 32
[2025-12-23 16:19:09,676] m-LoRA: Adapter lora_winogrande_53 loss: 0.820013701915741
[2025-12-23 16:19:09,679] m-LoRA: Adapter lora_winogrande_68 epoch: 1/1 iteration: 92/128 step: 24
[2025-12-23 16:19:09,847] m-LoRA: Adapter lora_winogrande_78 epoch: 1/1 iteration: 28/128 step: 8
[2025-12-23 16:19:10,003] m-LoRA: Adapter lora_winogrande_82 loss: 1.8215067386627197
[2025-12-23 16:19:10,007] m-LoRA: Adapter lora_winogrande_79 epoch: 1/1 iteration: 112/128 step: 8
[2025-12-23 16:19:10,094] m-LoRA: Adapter lora_winogrande_48 loss: 0.5939429998397827
[2025-12-23 16:19:10,157] m-LoRA: Adapter lora_winogrande_67 loss: 0.6164278388023376
[2025-12-23 16:19:10,160] m-LoRA: Adapter lora_winogrande_69 epoch: 1/1 iteration: 92/128 step: 24
[2025-12-23 16:19:10,259] m-LoRA: Adapter lora_winogrande_70 epoch: 1/1 iteration: 92/128 step: 24
[2025-12-23 16:19:10,378] m-LoRA: Adapter lora_winogrande_83 loss: 1.9239610433578491
[2025-12-23 16:19:10,381] m-LoRA: Adapter lora_winogrande_80 epoch: 1/1 iteration: 56/128 step: 8
[2025-12-23 16:19:11,060] m-LoRA: Adapter lora_winogrande_81 epoch: 1/1 iteration: 14/128 step: 8
[2025-12-23 16:19:11,104] m-LoRA: Adapter lora_winogrande_84 loss: 1.548749327659607
[2025-12-23 16:19:11,315] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_62']
[2025-12-23 16:19:11,995] m-LoRA: Adapter lora_winogrande_77 loss: 1.108721375465393
[2025-12-23 16:19:11,998] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_85']
[2025-12-23 16:19:12,173] m-LoRA: Adapter lora_winogrande_85 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:19:12,384] m-LoRA: Adapter lora_winogrande_63 loss: 0.3615850806236267
[2025-12-23 16:19:12,387] m-LoRA: Adapter lora_winogrande_66 epoch: 1/1 iteration: 62/128 step: 32
[2025-12-23 16:19:12,563] m-LoRA: Adapter lora_winogrande_68 loss: 1.8752485513687134
[2025-12-23 16:19:12,566] m-LoRA: Adapter lora_winogrande_53 epoch: 1/1 iteration: 110/128 step: 56
[2025-12-23 16:19:12,737] m-LoRA: Adapter lora_winogrande_78 loss: 1.7265784740447998
[2025-12-23 16:19:12,741] m-LoRA: Adapter lora_winogrande_82 epoch: 1/1 iteration: 56/128 step: 8
[2025-12-23 16:19:12,866] m-LoRA: Adapter lora_winogrande_79 loss: 1.155120849609375
[2025-12-23 16:19:12,873] m-LoRA: Adapter lora_winogrande_48 epoch: 1/1 iteration: 126/128 step: 64
[2025-12-23 16:19:13,048] m-LoRA: Adapter lora_winogrande_69 loss: 1.774950385093689
[2025-12-23 16:19:13,051] m-LoRA: Adapter lora_winogrande_67 epoch: 1/1 iteration: 124/128 step: 32
[2025-12-23 16:19:13,207] m-LoRA: Adapter lora_winogrande_70 loss: 0.44257640838623047
[2025-12-23 16:19:13,210] m-LoRA: Adapter lora_winogrande_83 epoch: 1/1 iteration: 28/128 step: 8
[2025-12-23 16:19:13,409] m-LoRA: Adapter lora_winogrande_80 loss: 1.0994092226028442
[2025-12-23 16:19:13,412] m-LoRA: Adapter lora_winogrande_84 epoch: 1/1 iteration: 112/128 step: 8
[2025-12-23 16:19:13,571] m-LoRA: Adapter lora_winogrande_81 loss: 1.0600401163101196
[2025-12-23 16:19:13,573] m-LoRA: Adapter lora_winogrande_77 epoch: 1/1 iteration: 32/128 step: 9
[2025-12-23 16:19:13,701] m-LoRA: Adapter lora_winogrande_85 loss: 2.878002643585205
[2025-12-23 16:19:13,703] m-LoRA: Adapter lora_winogrande_63 epoch: 1/1 iteration: 64/128 step: 33
[2025-12-23 16:19:13,814] m-LoRA: Adapter lora_winogrande_66 loss: 0.6412427425384521
[2025-12-23 16:19:13,816] m-LoRA: Adapter lora_winogrande_68 epoch: 1/1 iteration: 96/128 step: 25
[2025-12-23 16:19:13,922] m-LoRA: Adapter lora_winogrande_53 loss: 0.622545063495636
[2025-12-23 16:19:13,925] m-LoRA: Adapter lora_winogrande_78 epoch: 1/1 iteration: 32/128 step: 9
[2025-12-23 16:19:14,391] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_79']
[2025-12-23 16:19:14,867] m-LoRA: Adapter lora_winogrande_82 loss: 1.6639214754104614
[2025-12-23 16:19:14,889] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_86']
[2025-12-23 16:19:15,130] m-LoRA: Adapter lora_winogrande_86 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:19:15,228] m-LoRA: Adapter lora_winogrande_48 loss: 0.6318168640136719
[2025-12-23 16:19:15,230] m-LoRA: Adapter lora_winogrande_69 epoch: 1/1 iteration: 96/128 step: 25
[2025-12-23 16:19:15,319] m-LoRA: Adapter lora_winogrande_67 loss: 0.43642374873161316
[2025-12-23 16:19:15,321] m-LoRA: Adapter lora_winogrande_70 epoch: 1/1 iteration: 96/128 step: 25
[2025-12-23 16:19:15,402] m-LoRA: Adapter lora_winogrande_83 loss: 1.7140759229660034
[2025-12-23 16:19:15,725] m-LoRA: Adapter lora_winogrande_84 loss: 1.3542159795761108
[2025-12-23 16:19:15,732] m-LoRA: Adapter lora_winogrande_80 epoch: 1/1 iteration: 64/128 step: 9
[2025-12-23 16:19:15,948] m-LoRA: Adapter lora_winogrande_77 loss: 1.0500571727752686
[2025-12-23 16:19:15,950] m-LoRA: Adapter lora_winogrande_81 epoch: 1/1 iteration: 16/128 step: 9
[2025-12-23 16:19:16,073] m-LoRA: Adapter lora_winogrande_63 loss: 0.5489132404327393
[2025-12-23 16:19:16,076] m-LoRA: Adapter lora_winogrande_85 epoch: 1/1 iteration: 2/128 step: 2
[2025-12-23 16:19:16,225] m-LoRA: Adapter lora_winogrande_68 loss: 1.8133502006530762
[2025-12-23 16:19:16,228] m-LoRA: Adapter lora_winogrande_66 epoch: 1/1 iteration: 64/128 step: 33
[2025-12-23 16:19:16,369] m-LoRA: Adapter lora_winogrande_78 loss: 1.6124556064605713
[2025-12-23 16:19:16,371] m-LoRA: Adapter lora_winogrande_53 epoch: 1/1 iteration: 112/128 step: 57
[2025-12-23 16:19:16,541] m-LoRA: Adapter lora_winogrande_86 loss: 3.1910531520843506
[2025-12-23 16:19:16,544] m-LoRA: Adapter lora_winogrande_82 epoch: 1/1 iteration: 64/128 step: 9
[2025-12-23 16:19:16,706] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_48']
[2025-12-23 16:19:17,037] m-LoRA: Adapter lora_winogrande_69 loss: 1.8164818286895752
[2025-12-23 16:19:17,040] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_87']
[2025-12-23 16:19:17,246] m-LoRA: Adapter lora_winogrande_87 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:19:17,411] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_67']
[2025-12-23 16:19:17,686] m-LoRA: Adapter lora_winogrande_70 loss: 0.5187460780143738
[2025-12-23 16:19:17,689] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_88']
[2025-12-23 16:19:17,823] m-LoRA: Adapter lora_winogrande_88 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:19:17,929] m-LoRA: Adapter lora_winogrande_80 loss: 0.9671509265899658
[2025-12-23 16:19:17,933] m-LoRA: Adapter lora_winogrande_83 epoch: 1/1 iteration: 32/128 step: 9
[2025-12-23 16:19:18,038] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_84']
[2025-12-23 16:19:18,535] m-LoRA: Adapter lora_winogrande_81 loss: 0.9541099071502686
[2025-12-23 16:19:18,538] m-LoRA: Task to running, need to load adapters: ['lora_winogrande_89']
[2025-12-23 16:19:18,748] m-LoRA: Adapter lora_winogrande_89 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 16:19:18,843] m-LoRA: Adapter lora_winogrande_85 loss: 2.5337679386138916
[2025-12-23 16:19:18,845] m-LoRA: Adapter lora_winogrande_77 epoch: 1/1 iteration: 36/128 step: 10
[2025-12-23 16:19:18,942] m-LoRA: Adapter lora_winogrande_66 loss: 0.46046775579452515
[2025-12-23 16:19:18,944] m-LoRA: Adapter lora_winogrande_63 epoch: 1/1 iteration: 66/128 step: 34
[2025-12-23 16:19:19,134] m-LoRA: Adapter lora_winogrande_53 loss: 0.684643030166626
[2025-12-23 16:19:19,137] m-LoRA: Adapter lora_winogrande_68 epoch: 1/1 iteration: 100/128 step: 26
[2025-12-23 16:19:19,282] m-LoRA: Adapter lora_winogrande_82 loss: 1.5911972522735596
[2025-12-23 16:19:19,286] m-LoRA: Adapter lora_winogrande_78 epoch: 1/1 iteration: 36/128 step: 10
[2025-12-23 16:19:19,434] m-LoRA: Adapter lora_winogrande_87 loss: 2.756438970565796
[2025-12-23 16:19:19,436] m-LoRA: Adapter lora_winogrande_86 epoch: 1/1 iteration: 4/128 step: 2
[2025-12-23 16:19:19,546] m-LoRA: Adapter lora_winogrande_88 loss: 3.11490535736084
[2025-12-23 16:19:19,550] m-LoRA: Adapter lora_winogrande_69 epoch: 1/1 iteration: 100/128 step: 26
[2025-12-23 16:19:19,691] m-LoRA: Adapter lora_winogrande_83 loss: 1.683000087738037
[2025-12-23 16:19:19,694] m-LoRA: Adapter lora_winogrande_70 epoch: 1/1 iteration: 100/128 step: 26
[2025-12-23 16:19:20,056] m-LoRA: Adapter lora_winogrande_89 loss: 3.113734006881714
[2025-12-23 16:19:20,059] m-LoRA: Adapter lora_winogrande_80 epoch: 1/1 iteration: 72/128 step: 10
[2025-12-23 16:19:20,439] m-LoRA: Adapter lora_winogrande_77 loss: 0.7145001888275146
[2025-12-23 16:19:20,449] m-LoRA: Adapter lora_winogrande_81 epoch: 1/1 iteration: 18/128 step: 10
[2025-12-23 16:19:20,564] m-LoRA: Adapter lora_winogrande_63 loss: 0.4552766978740692
[2025-12-23 16:19:20,566] m-LoRA: Adapter lora_winogrande_85 epoch: 1/1 iteration: 4/128 step: 3
[2025-12-23 16:19:20,686] m-LoRA: Adapter lora_winogrande_68 loss: 1.6621328592300415
[2025-12-23 16:19:20,690] m-LoRA: Adapter lora_winogrande_66 epoch: 1/1 iteration: 66/128 step: 34
[2025-12-23 16:19:20,865] m-LoRA: Adapter lora_winogrande_53 epoch: 1/1 iteration: 114/128 step: 58
[2025-12-23 16:19:20,901] m-LoRA: Adapter lora_winogrande_78 loss: 1.4162259101867676
[2025-12-23 16:19:21,091] m-LoRA: Adapter lora_winogrande_86 loss: 2.6633009910583496
[2025-12-23 16:19:21,094] m-LoRA: Adapter lora_winogrande_82 epoch: 1/1 iteration: 72/128 step: 10
[2025-12-23 16:19:21,259] m-LoRA: Adapter lora_winogrande_69 loss: 1.7993501424789429
[2025-12-23 16:19:21,262] m-LoRA: Adapter lora_winogrande_87 epoch: 1/1 iteration: 2/128 step: 2
[2025-12-23 16:19:21,458] m-LoRA: Adapter lora_winogrande_70 loss: 0.478699266910553
[2025-12-23 16:19:21,461] m-LoRA: Adapter lora_winogrande_88 epoch: 1/1 iteration: 8/128 step: 2
[2025-12-23 16:19:21,808] m-LoRA: Adapter lora_winogrande_83 epoch: 1/1 iteration: 36/128 step: 10
[2025-12-23 16:19:21,922] m-LoRA: Adapter lora_winogrande_80 loss: 0.7978925108909607
[2025-12-23 16:19:21,927] m-LoRA: Adapter lora_winogrande_89 epoch: 1/1 iteration: 4/128 step: 2
[2025-12-23 16:19:22,048] m-LoRA: Adapter lora_winogrande_81 loss: 0.6870343685150146
[2025-12-23 16:19:22,050] m-LoRA: Adapter lora_winogrande_77 epoch: 1/1 iteration: 40/128 step: 11
[2025-12-23 16:19:22,141] m-LoRA: Adapter lora_winogrande_85 loss: 2.2764992713928223
[2025-12-23 16:19:22,143] m-LoRA: Adapter lora_winogrande_63 epoch: 1/1 iteration: 68/128 step: 35
[2025-12-23 16:19:22,246] m-LoRA: Adapter lora_winogrande_66 loss: 0.49767738580703735
[2025-12-23 16:19:22,248] m-LoRA: Adapter lora_winogrande_68 epoch: 1/1 iteration: 104/128 step: 27
[2025-12-23 16:19:22,295] m-LoRA: Adapter lora_winogrande_53 loss: 0.7598901987075806
[2025-12-23 16:19:22,588] m-LoRA: Adapter lora_winogrande_82 loss: 1.412047266960144
[2025-12-23 16:19:22,592] m-LoRA: Adapter lora_winogrande_78 epoch: 1/1 iteration: 40/128 step: 11
[2025-12-23 16:19:22,697] m-LoRA: Adapter lora_winogrande_87 loss: 2.329986810684204
[2025-12-23 16:19:22,699] m-LoRA: Adapter lora_winogrande_86 epoch: 1/1 iteration: 8/128 step: 3
[2025-12-23 16:19:23,018] m-LoRA: Adapter lora_winogrande_88 loss: 3.0122077465057373
[2025-12-23 16:19:23,020] m-LoRA: Adapter lora_winogrande_69 epoch: 1/1 iteration: 104/128 step: 27
[2025-12-23 16:19:23,146] m-LoRA: Adapter lora_winogrande_70 epoch: 1/1 iteration: 104/128 step: 27
[2025-12-23 16:19:23,225] m-LoRA: Adapter lora_winogrande_83 loss: 1.5331954956054688
[2025-12-23 16:19:23,419] m-LoRA: Adapter lora_winogrande_89 loss: 2.5742743015289307
[2025-12-23 16:19:23,422] m-LoRA: Adapter lora_winogrande_80 epoch: 1/1 iteration: 80/128 step: 11
[2025-12-23 16:19:23,572] m-LoRA: Adapter lora_winogrande_77 loss: 0.7346740365028381
[2025-12-23 16:19:23,574] m-LoRA: Adapter lora_winogrande_81 epoch: 1/1 iteration: 20/128 step: 11
[2025-12-23 16:19:23,701] m-LoRA: Adapter lora_winogrande_63 loss: 0.7887510061264038
[2025-12-23 16:19:23,703] m-LoRA: Adapter lora_winogrande_85 epoch: 1/1 iteration: 6/128 step: 4
[2025-12-23 16:19:23,836] m-LoRA: Adapter lora_winogrande_68 loss: 1.8041714429855347
[2025-12-23 16:19:23,840] m-LoRA: Adapter lora_winogrande_66 epoch: 1/1 iteration: 68/128 step: 35
[2025-12-23 16:19:24,026] m-LoRA: Adapter lora_winogrande_78 loss: 1.340930461883545
[2025-12-23 16:19:24,028] m-LoRA: Adapter lora_winogrande_53 epoch: 1/1 iteration: 116/128 step: 59
[2025-12-23 16:19:24,202] m-LoRA: Adapter lora_winogrande_86 loss: 2.053760290145874
[2025-12-23 16:19:24,204] m-LoRA: Adapter lora_winogrande_82 epoch: 1/1 iteration: 80/128 step: 11
[2025-12-23 16:19:24,393] m-LoRA: Adapter lora_winogrande_69 loss: 1.7802494764328003
[2025-12-23 16:19:24,396] m-LoRA: Adapter lora_winogrande_87 epoch: 1/1 iteration: 4/128 step: 3
[2025-12-23 16:19:24,556] m-LoRA: Adapter lora_winogrande_70 loss: 0.4342041611671448
[2025-12-23 16:19:24,559] m-LoRA: Adapter lora_winogrande_88 epoch: 1/1 iteration: 16/128 step: 3
[2025-12-23 16:19:24,891] m-LoRA: Adapter lora_winogrande_83 epoch: 1/1 iteration: 40/128 step: 11
[2025-12-23 16:19:25,004] m-LoRA: Adapter lora_winogrande_80 loss: 0.7499616146087646
[2025-12-23 16:19:25,016] m-LoRA: Adapter lora_winogrande_89 epoch: 1/1 iteration: 8/128 step: 3
[2025-12-23 16:19:25,191] m-LoRA: Adapter lora_winogrande_81 loss: 0.7414736747741699
[2025-12-23 16:19:25,193] m-LoRA: Adapter lora_winogrande_77 epoch: 1/1 iteration: 44/128 step: 12
[2025-12-23 16:19:25,313] m-LoRA: Adapter lora_winogrande_85 loss: 1.9476109743118286
[2025-12-23 16:19:25,316] m-LoRA: Adapter lora_winogrande_63 epoch: 1/1 iteration: 70/128 step: 36
[2025-12-23 16:19:25,396] m-LoRA: Adapter lora_winogrande_66 loss: 0.5721941590309143
[2025-12-23 16:19:25,399] m-LoRA: Adapter lora_winogrande_68 epoch: 1/1 iteration: 108/128 step: 28
[2025-12-23 16:19:25,442] m-LoRA: Adapter lora_winogrande_53 loss: 0.6169825196266174
[2025-12-23 16:19:25,637] m-LoRA: Adapter lora_winogrande_82 loss: 1.281376838684082
[2025-12-23 16:19:25,642] m-LoRA: Adapter lora_winogrande_78 epoch: 1/1 iteration: 44/128 step: 12
[2025-12-23 16:19:25,797] m-LoRA: Adapter lora_winogrande_87 loss: 2.0076839923858643
[2025-12-23 16:19:25,800] m-LoRA: Adapter lora_winogrande_86 epoch: 1/1 iteration: 12/128 step: 4
[2025-12-23 16:19:26,097] m-LoRA: Adapter lora_winogrande_69 epoch: 1/1 iteration: 108/128 step: 28
[2025-12-23 16:19:26,133] m-LoRA: Adapter lora_winogrande_88 loss: 3.0140726566314697
[2025-12-23 16:19:26,281] m-LoRA: Adapter lora_winogrande_83 loss: 1.4178928136825562
[2025-12-23 16:19:26,285] m-LoRA: Adapter lora_winogrande_70 epoch: 1/1 iteration: 108/128 step: 28
[2025-12-23 16:19:26,532] m-LoRA: Adapter lora_winogrande_89 loss: 2.1924374103546143
[2025-12-23 16:19:26,535] m-LoRA: Adapter lora_winogrande_80 epoch: 1/1 iteration: 88/128 step: 12
[2025-12-23 16:19:26,703] m-LoRA: Adapter lora_winogrande_77 loss: 0.6332013010978699
[2025-12-23 16:19:26,705] m-LoRA: Adapter lora_winogrande_81 epoch: 1/1 iteration: 22/128 step: 12
[2025-12-23 16:19:26,866] m-LoRA: Adapter lora_winogrande_63 loss: 0.4985828995704651
[2025-12-23 16:19:26,868] m-LoRA: Adapter lora_winogrande_85 epoch: 1/1 iteration: 8/128 step: 5
[2025-12-23 16:19:26,976] m-LoRA: Adapter lora_winogrande_68 loss: 1.768675446510315
[2025-12-23 16:19:26,979] m-LoRA: Adapter lora_winogrande_66 epoch: 1/1 iteration: 70/128 step: 36
[2025-12-23 16:19:27,180] m-LoRA: Adapter lora_winogrande_78 loss: 1.1612515449523926
[2025-12-23 16:19:27,183] m-LoRA: Adapter lora_winogrande_53 epoch: 1/1 iteration: 118/128 step: 60
[2025-12-23 16:19:27,435] m-LoRA: Adapter lora_winogrande_86 loss: 1.6368606090545654
[2025-12-23 16:19:27,439] m-LoRA: Adapter lora_winogrande_82 epoch: 1/1 iteration: 88/128 step: 12
[2025-12-23 16:19:27,595] m-LoRA: Adapter lora_winogrande_69 loss: 1.575677752494812
[2025-12-23 16:19:27,597] m-LoRA: Adapter lora_winogrande_87 epoch: 1/1 iteration: 6/128 step: 4
[2025-12-23 16:19:27,759] m-LoRA: Adapter lora_winogrande_70 loss: 0.5795037150382996
[2025-12-23 16:19:27,761] m-LoRA: Adapter lora_winogrande_88 epoch: 1/1 iteration: 24/128 step: 4
[2025-12-23 16:19:28,142] m-LoRA: Adapter lora_winogrande_80 loss: 0.7006828188896179
[2025-12-23 16:19:28,146] m-LoRA: Adapter lora_winogrande_83 epoch: 1/1 iteration: 44/128 step: 12
[2025-12-23 16:19:28,323] m-LoRA: Adapter lora_winogrande_81 loss: 0.7356909513473511
[2025-12-23 16:19:28,325] m-LoRA: Adapter lora_winogrande_89 epoch: 1/1 iteration: 12/128 step: 4
[2025-12-23 16:19:28,430] m-LoRA: Adapter lora_winogrande_85 loss: 1.6351953744888306
[2025-12-23 16:19:28,433] m-LoRA: Adapter lora_winogrande_77 epoch: 1/1 iteration: 48/128 step: 13
[2025-12-23 16:19:28,591] m-LoRA: Adapter lora_winogrande_66 loss: 0.5028943419456482
[2025-12-23 16:19:28,594] m-LoRA: Adapter lora_winogrande_63 epoch: 1/1 iteration: 72/128 step: 37
[2025-12-23 16:19:28,700] m-LoRA: Adapter lora_winogrande_53 loss: 0.7706960439682007
[2025-12-23 16:19:28,702] m-LoRA: Adapter lora_winogrande_68 epoch: 1/1 iteration: 112/128 step: 29
[2025-12-23 16:19:28,971] m-LoRA: Adapter lora_winogrande_82 loss: 1.2164084911346436
[2025-12-23 16:19:28,976] m-LoRA: Adapter lora_winogrande_78 epoch: 1/1 iteration: 48/128 step: 13
[2025-12-23 16:19:29,151] m-LoRA: Adapter lora_winogrande_87 loss: 1.5059535503387451
[2025-12-23 16:19:29,153] m-LoRA: Adapter lora_winogrande_86 epoch: 1/1 iteration: 16/128 step: 5
[2025-12-23 16:19:29,437] m-LoRA: Adapter lora_winogrande_69 epoch: 1/1 iteration: 112/128 step: 29
[2025-12-23 16:19:29,476] m-LoRA: Adapter lora_winogrande_88 loss: 2.9906015396118164
[2025-12-23 16:19:29,614] m-LoRA: Adapter lora_winogrande_83 loss: 1.3140031099319458
[2025-12-23 16:19:29,616] m-LoRA: Adapter lora_winogrande_70 epoch: 1/1 iteration: 112/128 step: 29
[2025-12-23 16:19:29,875] m-LoRA: Adapter lora_winogrande_89 loss: 1.959500789642334
[2025-12-23 16:19:29,878] m-LoRA: Adapter lora_winogrande_80 epoch: 1/1 iteration: 96/128 step: 13
[2025-12-23 16:19:30,044] m-LoRA: Adapter lora_winogrande_77 loss: 0.6577261686325073
[2025-12-23 16:19:30,047] m-LoRA: Adapter lora_winogrande_81 epoch: 1/1 iteration: 24/128 step: 13
[2025-12-23 16:19:30,153] m-LoRA: Adapter lora_winogrande_63 loss: 0.5523486733436584
[2025-12-23 16:19:30,156] m-LoRA: Adapter lora_winogrande_85 epoch: 1/1 iteration: 10/128 step: 6
[2025-12-23 16:19:30,325] m-LoRA: Adapter lora_winogrande_68 loss: 1.6743124723434448
[2025-12-23 16:19:30,327] m-LoRA: Adapter lora_winogrande_66 epoch: 1/1 iteration: 72/128 step: 37
[2025-12-23 16:19:30,576] m-LoRA: Adapter lora_winogrande_78 loss: 1.0383622646331787
[2025-12-23 16:19:30,578] m-LoRA: Adapter lora_winogrande_53 epoch: 1/1 iteration: 120/128 step: 61
[2025-12-23 16:19:30,769] m-LoRA: Adapter lora_winogrande_86 loss: 1.4014761447906494
[2025-12-23 16:19:30,773] m-LoRA: Adapter lora_winogrande_82 epoch: 1/1 iteration: 96/128 step: 13
[2025-12-23 16:19:30,927] m-LoRA: Adapter lora_winogrande_87 epoch: 1/1 iteration: 8/128 step: 5
[2025-12-23 16:19:30,966] m-LoRA: Adapter lora_winogrande_69 loss: 1.5687248706817627
[2025-12-23 16:19:31,136] m-LoRA: Adapter lora_winogrande_70 loss: 0.4554945230484009
[2025-12-23 16:19:31,139] m-LoRA: Adapter lora_winogrande_88 epoch: 1/1 iteration: 32/128 step: 5
[2025-12-23 16:19:31,532] m-LoRA: Adapter lora_winogrande_80 loss: 0.6952576041221619
[2025-12-23 16:19:31,537] m-LoRA: Adapter lora_winogrande_83 epoch: 1/1 iteration: 48/128 step: 13
[2025-12-23 16:19:31,689] m-LoRA: Adapter lora_winogrande_81 loss: 0.6970033049583435
[2025-12-23 16:19:31,691] m-LoRA: Adapter lora_winogrande_89 epoch: 1/1 iteration: 16/128 step: 5
[2025-12-23 16:19:31,841] m-LoRA: Adapter lora_winogrande_85 loss: 1.5049283504486084
[2025-12-23 16:19:31,843] m-LoRA: Adapter lora_winogrande_77 epoch: 1/1 iteration: 52/128 step: 14
[2025-12-23 16:19:32,001] m-LoRA: Adapter lora_winogrande_66 loss: 0.5769567489624023
[2025-12-23 16:19:32,003] m-LoRA: Adapter lora_winogrande_63 epoch: 1/1 iteration: 74/128 step: 38
[2025-12-23 16:19:32,119] m-LoRA: Adapter lora_winogrande_53 loss: 0.687734842300415
[2025-12-23 16:19:32,121] m-LoRA: Adapter lora_winogrande_68 epoch: 1/1 iteration: 116/128 step: 30
[2025-12-23 16:19:32,316] m-LoRA: Adapter lora_winogrande_78 epoch: 1/1 iteration: 52/128 step: 14
[2025-12-23 16:19:32,361] m-LoRA: Adapter lora_winogrande_82 loss: 1.0358915328979492
[2025-12-23 16:19:32,523] m-LoRA: Adapter lora_winogrande_87 loss: 1.2296524047851562
[2025-12-23 16:19:32,525] m-LoRA: Adapter lora_winogrande_86 epoch: 1/1 iteration: 20/128 step: 6
[2025-12-23 16:19:32,816] m-LoRA: Adapter lora_winogrande_69 epoch: 1/1 iteration: 116/128 step: 30
[2025-12-23 16:19:32,857] m-LoRA: Adapter lora_winogrande_88 loss: 2.984309673309326
[2025-12-23 16:19:33,081] m-LoRA: Adapter lora_winogrande_83 loss: 1.108074426651001
[2025-12-23 16:19:33,084] m-LoRA: Adapter lora_winogrande_70 epoch: 1/1 iteration: 116/128 step: 30
[2025-12-23 16:19:33,283] m-LoRA: Adapter lora_winogrande_89 loss: 1.5921969413757324
[2025-12-23 16:19:33,286] m-LoRA: Adapter lora_winogrande_80 epoch: 1/1 iteration: 104/128 step: 14
[2025-12-23 16:19:33,450] m-LoRA: Adapter lora_winogrande_77 loss: 0.7386841773986816
[2025-12-23 16:19:33,454] m-LoRA: Adapter lora_winogrande_81 epoch: 1/1 iteration: 26/128 step: 14
[2025-12-23 16:19:33,566] m-LoRA: Adapter lora_winogrande_63 loss: 0.6230493187904358
[2025-12-23 16:19:33,568] m-LoRA: Adapter lora_winogrande_85 epoch: 1/1 iteration: 12/128 step: 7
[2025-12-23 16:19:33,810] m-LoRA: Adapter lora_winogrande_68 loss: 1.8180876970291138
[2025-12-23 16:19:33,812] m-LoRA: Adapter lora_winogrande_66 epoch: 1/1 iteration: 74/128 step: 38
[2025-12-23 16:19:34,012] m-LoRA: Adapter lora_winogrande_78 loss: 1.0010015964508057
[2025-12-23 16:19:34,015] m-LoRA: Adapter lora_winogrande_53 epoch: 1/1 iteration: 122/128 step: 62
[2025-12-23 16:19:34,230] m-LoRA: Adapter lora_winogrande_86 loss: 1.0290182828903198
[2025-12-23 16:19:34,233] m-LoRA: Adapter lora_winogrande_82 epoch: 1/1 iteration: 104/128 step: 14
[2025-12-23 16:19:34,479] m-LoRA: Adapter lora_winogrande_69 loss: 1.6091026067733765
[2025-12-23 16:19:34,482] m-LoRA: Adapter lora_winogrande_87 epoch: 1/1 iteration: 10/128 step: 6
[2025-12-23 16:19:34,714] m-LoRA: Adapter lora_winogrande_70 loss: 0.4813498258590698
[2025-12-23 16:19:34,718] m-LoRA: Adapter lora_winogrande_88 epoch: 1/1 iteration: 40/128 step: 6
[2025-12-23 16:19:35,057] m-LoRA: Adapter lora_winogrande_80 loss: 0.6430308222770691
[2025-12-23 16:19:35,062] m-LoRA: Adapter lora_winogrande_83 epoch: 1/1 iteration: 52/128 step: 14
[2025-12-23 16:19:35,246] m-LoRA: Adapter lora_winogrande_81 loss: 0.5841504335403442
[2025-12-23 16:19:35,248] m-LoRA: Adapter lora_winogrande_89 epoch: 1/1 iteration: 20/128 step: 6
[2025-12-23 16:19:35,386] m-LoRA: Adapter lora_winogrande_85 loss: 1.2648375034332275
[2025-12-23 16:19:35,389] m-LoRA: Adapter lora_winogrande_77 epoch: 1/1 iteration: 56/128 step: 15
[2025-12-23 16:19:35,504] m-LoRA: Adapter lora_winogrande_66 loss: 0.4450419247150421
[2025-12-23 16:19:35,506] m-LoRA: Adapter lora_winogrande_63 epoch: 1/1 iteration: 76/128 step: 39
[2025-12-23 16:19:35,615] m-LoRA: Adapter lora_winogrande_53 loss: 0.7258565425872803
[2025-12-23 16:19:35,618] m-LoRA: Adapter lora_winogrande_68 epoch: 1/1 iteration: 120/128 step: 31
[2025-12-23 16:19:35,779] m-LoRA: Adapter lora_winogrande_78 epoch: 1/1 iteration: 56/128 step: 15
[2025-12-23 16:19:35,820] m-LoRA: Adapter lora_winogrande_82 loss: 0.9347357153892517
[2025-12-23 16:19:35,976] m-LoRA: Adapter lora_winogrande_87 loss: 1.070488691329956
[2025-12-23 16:19:35,978] m-LoRA: Adapter lora_winogrande_86 epoch: 1/1 iteration: 24/128 step: 7
[2025-12-23 16:19:36,266] m-LoRA: Adapter lora_winogrande_88 loss: 2.7887372970581055
[2025-12-23 16:19:36,269] m-LoRA: Adapter lora_winogrande_69 epoch: 1/1 iteration: 120/128 step: 31
[2025-12-23 16:19:36,411] m-LoRA: Adapter lora_winogrande_83 loss: 1.0197558403015137
[2025-12-23 16:19:36,414] m-LoRA: Adapter lora_winogrande_70 epoch: 1/1 iteration: 120/128 step: 31
[2025-12-23 16:19:36,616] m-LoRA: Adapter lora_winogrande_89 loss: 1.4221699237823486
[2025-12-23 16:19:36,619] m-LoRA: Adapter lora_winogrande_80 epoch: 1/1 iteration: 112/128 step: 15
[2025-12-23 16:19:36,866] m-LoRA: Adapter lora_winogrande_77 loss: 0.5116907358169556
[2025-12-23 16:19:36,868] m-LoRA: Adapter lora_winogrande_81 epoch: 1/1 iteration: 28/128 step: 15
[2025-12-23 16:19:36,963] m-LoRA: Adapter lora_winogrande_63 loss: 0.4536066949367523
[2025-12-23 16:19:36,965] m-LoRA: Adapter lora_winogrande_85 epoch: 1/1 iteration: 14/128 step: 8
[2025-12-23 16:19:37,102] m-LoRA: Adapter lora_winogrande_68 loss: 1.6236276626586914
[2025-12-23 16:19:37,105] m-LoRA: Adapter lora_winogrande_66 epoch: 1/1 iteration: 76/128 step: 39
[2025-12-23 16:19:37,300] m-LoRA: Adapter lora_winogrande_78 loss: 0.7987121343612671
[2025-12-23 16:19:37,304] m-LoRA: Adapter lora_winogrande_53 epoch: 1/1 iteration: 124/128 step: 63
[2025-12-23 16:19:37,600] m-LoRA: Adapter lora_winogrande_86 loss: 0.9544783234596252
[2025-12-23 16:19:37,603] m-LoRA: Adapter lora_winogrande_82 epoch: 1/1 iteration: 112/128 step: 15
[2025-12-23 16:19:37,968] m-LoRA: Adapter lora_winogrande_69 loss: 1.533908486366272
[2025-12-23 16:19:37,970] m-LoRA: Adapter lora_winogrande_87 epoch: 1/1 iteration: 12/128 step: 7
[2025-12-23 16:19:38,335] m-LoRA: Adapter lora_winogrande_70 loss: 0.48478397727012634
[2025-12-23 16:19:38,338] m-LoRA: Adapter lora_winogrande_88 epoch: 1/1 iteration: 48/128 step: 7
[2025-12-23 16:19:38,661] m-LoRA: Adapter lora_winogrande_83 epoch: 1/1 iteration: 56/128 step: 15
[2025-12-23 16:19:38,701] m-LoRA: Adapter lora_winogrande_80 loss: 0.5510618090629578
[2025-12-23 16:19:38,853] m-LoRA: Adapter lora_winogrande_81 loss: 0.6480775475502014
[2025-12-23 16:19:38,855] m-LoRA: Adapter lora_winogrande_89 epoch: 1/1 iteration: 24/128 step: 7
[2025-12-23 16:19:38,981] m-LoRA: Adapter lora_winogrande_85 loss: 1.167339563369751
[2025-12-23 16:19:38,983] m-LoRA: Adapter lora_winogrande_77 epoch: 1/1 iteration: 60/128 step: 16
[2025-12-23 16:19:39,120] m-LoRA: Adapter lora_winogrande_66 loss: 0.4075126647949219
[2025-12-23 16:19:39,123] m-LoRA: Adapter lora_winogrande_63 epoch: 1/1 iteration: 78/128 step: 40
[2025-12-23 16:19:39,225] m-LoRA: Adapter lora_winogrande_53 loss: 0.6298047304153442
[2025-12-23 16:19:39,228] m-LoRA: Adapter lora_winogrande_68 epoch: 1/1 iteration: 124/128 step: 32
[2025-12-23 16:19:39,521] m-LoRA: Adapter lora_winogrande_82 loss: 0.8972397446632385
[2025-12-23 16:19:39,524] m-LoRA: Adapter lora_winogrande_78 epoch: 1/1 iteration: 60/128 step: 16
[2025-12-23 16:19:39,675] m-LoRA: Adapter lora_winogrande_87 loss: 0.9121808409690857
[2025-12-23 16:19:39,678] m-LoRA: Adapter lora_winogrande_86 epoch: 1/1 iteration: 28/128 step: 8
[2025-12-23 16:19:39,960] m-LoRA: Adapter lora_winogrande_88 loss: 2.70627760887146
[2025-12-23 16:19:39,964] m-LoRA: Adapter lora_winogrande_69 epoch: 1/1 iteration: 124/128 step: 32
[2025-12-23 16:19:40,176] m-LoRA: Adapter lora_winogrande_83 loss: 0.9313474893569946
[2025-12-23 16:19:40,179] m-LoRA: Adapter lora_winogrande_70 epoch: 1/1 iteration: 124/128 step: 32
[2025-12-23 16:19:40,329] m-LoRA: Adapter lora_winogrande_89 loss: 1.1715960502624512
[2025-12-23 16:19:40,332] m-LoRA: Adapter lora_winogrande_80 epoch: 1/1 iteration: 120/128 step: 16
[2025-12-23 16:19:40,504] m-LoRA: Adapter lora_winogrande_77 loss: 0.5906198620796204
[2025-12-23 16:19:40,513] m-LoRA: Adapter lora_winogrande_81 epoch: 1/1 iteration: 30/128 step: 16
[2025-12-23 16:19:40,660] m-LoRA: Adapter lora_winogrande_63 loss: 0.4341530501842499
[2025-12-23 16:19:40,662] m-LoRA: Adapter lora_winogrande_85 epoch: 1/1 iteration: 16/128 step: 9
[2025-12-23 16:19:40,812] m-LoRA: Adapter lora_winogrande_68 loss: 1.4988614320755005
[2025-12-23 16:19:40,816] m-LoRA: Adapter lora_winogrande_66 epoch: 1/1 iteration: 78/128 step: 40
[2025-12-23 16:19:40,977] m-LoRA: Adapter lora_winogrande_78 loss: 0.8812590837478638
[2025-12-23 16:19:40,980] m-LoRA: Adapter lora_winogrande_53 epoch: 1/1 iteration: 126/128 step: 64
[2025-12-23 16:19:41,171] m-LoRA: Adapter lora_winogrande_86 loss: 0.806885302066803
[2025-12-23 16:19:41,175] m-LoRA: Adapter lora_winogrande_82 epoch: 1/1 iteration: 120/128 step: 16
[2025-12-23 16:19:41,393] m-LoRA: Adapter lora_winogrande_69 loss: 1.5487533807754517
[2025-12-23 16:19:41,396] m-LoRA: Adapter lora_winogrande_87 epoch: 1/1 iteration: 14/128 step: 8
[2025-12-23 16:19:41,554] m-LoRA: Adapter lora_winogrande_70 loss: 0.4536738097667694
[2025-12-23 16:19:41,556] m-LoRA: Adapter lora_winogrande_88 epoch: 1/1 iteration: 56/128 step: 8
[2025-12-23 16:19:41,890] m-LoRA: Adapter lora_winogrande_80 loss: 0.6077471971511841
[2025-12-23 16:19:41,895] m-LoRA: Adapter lora_winogrande_83 epoch: 1/1 iteration: 60/128 step: 16
[2025-12-23 16:19:42,090] m-LoRA: Adapter lora_winogrande_81 loss: 0.5365023016929626
[2025-12-23 16:19:42,092] m-LoRA: Adapter lora_winogrande_89 epoch: 1/1 iteration: 28/128 step: 8
[2025-12-23 16:19:42,243] m-LoRA: Adapter lora_winogrande_85 loss: 0.9656299948692322
[2025-12-23 16:19:42,246] m-LoRA: Adapter lora_winogrande_77 epoch: 1/1 iteration: 64/128 step: 17
[2025-12-23 16:19:42,365] m-LoRA: Adapter lora_winogrande_66 loss: 0.3933756947517395
[2025-12-23 16:19:42,367] m-LoRA: Adapter lora_winogrande_63 epoch: 1/1 iteration: 80/128 step: 41
[2025-12-23 16:19:42,474] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_68']
[2025-12-23 16:19:42,979] m-LoRA: Adapter lora_winogrande_53 loss: 0.6797117590904236
[2025-12-23 16:19:43,116] m-LoRA: Adapter lora_winogrande_82 loss: 0.7762662172317505
[2025-12-23 16:19:43,120] m-LoRA: Adapter lora_winogrande_78 epoch: 1/1 iteration: 64/128 step: 17
[2025-12-23 16:19:43,279] m-LoRA: Adapter lora_winogrande_87 loss: 0.6867364645004272
[2025-12-23 16:19:43,281] m-LoRA: Adapter lora_winogrande_86 epoch: 1/1 iteration: 32/128 step: 9
[2025-12-23 16:19:43,410] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_69']
[2025-12-23 16:19:43,677] m-LoRA: Adapter lora_winogrande_88 loss: 2.5391035079956055
[2025-12-23 16:19:43,815] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_70']
[2025-12-23 16:19:44,456] m-LoRA: Adapter lora_winogrande_83 loss: 0.8617535829544067
[2025-12-23 16:19:44,564] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_80']
[2025-12-23 16:19:44,773] m-LoRA: Adapter lora_winogrande_89 loss: 1.0261259078979492
[2025-12-23 16:19:44,876] m-LoRA: Adapter lora_winogrande_77 loss: 0.5829221606254578
[2025-12-23 16:19:44,878] m-LoRA: Adapter lora_winogrande_81 epoch: 1/1 iteration: 32/128 step: 17
[2025-12-23 16:19:44,992] m-LoRA: Adapter lora_winogrande_63 loss: 0.40310198068618774
[2025-12-23 16:19:44,994] m-LoRA: Adapter lora_winogrande_85 epoch: 1/1 iteration: 18/128 step: 10
[2025-12-23 16:19:45,116] m-LoRA: Adapter lora_winogrande_78 loss: 0.7873691320419312
[2025-12-23 16:19:45,119] m-LoRA: Adapter lora_winogrande_66 epoch: 1/1 iteration: 80/128 step: 41
[2025-12-23 16:19:45,256] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_53']
[2025-12-23 16:19:45,513] m-LoRA: Adapter lora_winogrande_86 loss: 0.6338587999343872
[2025-12-23 16:19:45,618] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_82']
[2025-12-23 16:19:45,774] m-LoRA: Adapter lora_winogrande_81 loss: 0.7257871031761169
[2025-12-23 16:19:45,866] m-LoRA: Adapter lora_winogrande_85 loss: 0.7901172637939453
[2025-12-23 16:19:45,869] m-LoRA: Adapter lora_winogrande_87 epoch: 1/1 iteration: 16/128 step: 9
[2025-12-23 16:19:45,965] m-LoRA: Adapter lora_winogrande_88 epoch: 1/1 iteration: 64/128 step: 9
[2025-12-23 16:19:46,060] m-LoRA: Adapter lora_winogrande_83 epoch: 1/1 iteration: 64/128 step: 17
[2025-12-23 16:19:46,142] m-LoRA: Adapter lora_winogrande_66 loss: 0.4916827976703644
[2025-12-23 16:19:46,144] m-LoRA: Adapter lora_winogrande_89 epoch: 1/1 iteration: 32/128 step: 9
[2025-12-23 16:19:46,239] m-LoRA: Adapter lora_winogrande_77 epoch: 1/1 iteration: 68/128 step: 18
[2025-12-23 16:19:46,330] m-LoRA: Adapter lora_winogrande_87 loss: 0.8106573224067688
[2025-12-23 16:19:46,332] m-LoRA: Adapter lora_winogrande_63 epoch: 1/1 iteration: 82/128 step: 42
[2025-12-23 16:19:46,427] m-LoRA: Adapter lora_winogrande_78 epoch: 1/1 iteration: 68/128 step: 18
[2025-12-23 16:19:46,507] m-LoRA: Adapter lora_winogrande_86 epoch: 1/1 iteration: 36/128 step: 10
[2025-12-23 16:19:46,584] m-LoRA: Adapter lora_winogrande_81 epoch: 1/1 iteration: 34/128 step: 18
[2025-12-23 16:19:46,705] m-LoRA: Adapter lora_winogrande_88 loss: 2.380882740020752
[2025-12-23 16:19:46,709] m-LoRA: Adapter lora_winogrande_85 epoch: 1/1 iteration: 20/128 step: 11
[2025-12-23 16:19:46,859] m-LoRA: Adapter lora_winogrande_83 loss: 0.6441372632980347
[2025-12-23 16:19:46,862] m-LoRA: Adapter lora_winogrande_66 epoch: 1/1 iteration: 82/128 step: 42
[2025-12-23 16:19:47,006] m-LoRA: Adapter lora_winogrande_89 loss: 0.8729987740516663
[2025-12-23 16:19:47,010] m-LoRA: Adapter lora_winogrande_87 epoch: 1/1 iteration: 18/128 step: 10
[2025-12-23 16:19:47,104] m-LoRA: Adapter lora_winogrande_77 loss: 0.5282068848609924
[2025-12-23 16:19:47,212] m-LoRA: Adapter lora_winogrande_63 loss: 0.6397044658660889
[2025-12-23 16:19:47,419] m-LoRA: Adapter lora_winogrande_78 loss: 0.6694880723953247
[2025-12-23 16:19:47,574] m-LoRA: Adapter lora_winogrande_86 loss: 0.6306762099266052
[2025-12-23 16:19:47,712] m-LoRA: Adapter lora_winogrande_81 loss: 0.6182871460914612
[2025-12-23 16:19:47,714] m-LoRA: Adapter lora_winogrande_88 epoch: 1/1 iteration: 72/128 step: 10
[2025-12-23 16:19:47,845] m-LoRA: Adapter lora_winogrande_85 loss: 0.7939519882202148
[2025-12-23 16:19:47,847] m-LoRA: Adapter lora_winogrande_83 epoch: 1/1 iteration: 68/128 step: 18
[2025-12-23 16:19:48,007] m-LoRA: Adapter lora_winogrande_66 loss: 0.3937722444534302
[2025-12-23 16:19:48,009] m-LoRA: Adapter lora_winogrande_89 epoch: 1/1 iteration: 36/128 step: 10
[2025-12-23 16:19:48,129] m-LoRA: Adapter lora_winogrande_87 loss: 0.7102237343788147
[2025-12-23 16:19:48,131] m-LoRA: Adapter lora_winogrande_77 epoch: 1/1 iteration: 72/128 step: 19
[2025-12-23 16:19:48,223] m-LoRA: Adapter lora_winogrande_63 epoch: 1/1 iteration: 84/128 step: 43
[2025-12-23 16:19:48,311] m-LoRA: Adapter lora_winogrande_78 epoch: 1/1 iteration: 72/128 step: 19
[2025-12-23 16:19:48,596] m-LoRA: Adapter lora_winogrande_86 epoch: 1/1 iteration: 40/128 step: 11
[2025-12-23 16:19:48,634] m-LoRA: Adapter lora_winogrande_88 loss: 2.1589643955230713
[2025-12-23 16:19:48,797] m-LoRA: Adapter lora_winogrande_83 loss: 0.8395763039588928
[2025-12-23 16:19:48,800] m-LoRA: Adapter lora_winogrande_81 epoch: 1/1 iteration: 36/128 step: 19
[2025-12-23 16:19:48,957] m-LoRA: Adapter lora_winogrande_89 loss: 0.7924729585647583
[2025-12-23 16:19:48,959] m-LoRA: Adapter lora_winogrande_85 epoch: 1/1 iteration: 22/128 step: 12
[2025-12-23 16:19:49,092] m-LoRA: Adapter lora_winogrande_77 loss: 0.6073139309883118
[2025-12-23 16:19:49,095] m-LoRA: Adapter lora_winogrande_66 epoch: 1/1 iteration: 84/128 step: 43
[2025-12-23 16:19:49,205] m-LoRA: Adapter lora_winogrande_63 loss: 0.5162864923477173
[2025-12-23 16:19:49,207] m-LoRA: Adapter lora_winogrande_87 epoch: 1/1 iteration: 20/128 step: 11
[2025-12-23 16:19:49,362] m-LoRA: Adapter lora_winogrande_78 loss: 0.6338497996330261
[2025-12-23 16:19:49,600] m-LoRA: Adapter lora_winogrande_86 loss: 0.5945994853973389
[2025-12-23 16:19:49,603] m-LoRA: Adapter lora_winogrande_88 epoch: 1/1 iteration: 80/128 step: 11
[2025-12-23 16:19:49,758] m-LoRA: Adapter lora_winogrande_81 loss: 0.5200579166412354
[2025-12-23 16:19:49,760] m-LoRA: Adapter lora_winogrande_83 epoch: 1/1 iteration: 72/128 step: 19
[2025-12-23 16:19:49,880] m-LoRA: Adapter lora_winogrande_85 loss: 0.6984112858772278
[2025-12-23 16:19:49,882] m-LoRA: Adapter lora_winogrande_89 epoch: 1/1 iteration: 40/128 step: 11
[2025-12-23 16:19:49,953] m-LoRA: Adapter lora_winogrande_66 loss: 0.3867189586162567
[2025-12-23 16:19:50,131] m-LoRA: Adapter lora_winogrande_87 loss: 0.6713767647743225
[2025-12-23 16:19:50,133] m-LoRA: Adapter lora_winogrande_77 epoch: 1/1 iteration: 76/128 step: 20
[2025-12-23 16:19:50,243] m-LoRA: Adapter lora_winogrande_63 epoch: 1/1 iteration: 86/128 step: 44
[2025-12-23 16:19:50,710] m-LoRA: Adapter lora_winogrande_88 loss: 2.1324572563171387
[2025-12-23 16:19:50,715] m-LoRA: Adapter lora_winogrande_78 epoch: 1/1 iteration: 76/128 step: 20
[2025-12-23 16:19:50,871] m-LoRA: Adapter lora_winogrande_83 loss: 0.7220914363861084
[2025-12-23 16:19:50,873] m-LoRA: Adapter lora_winogrande_86 epoch: 1/1 iteration: 44/128 step: 12
[2025-12-23 16:19:51,045] m-LoRA: Adapter lora_winogrande_89 loss: 0.599511981010437
[2025-12-23 16:19:51,048] m-LoRA: Adapter lora_winogrande_81 epoch: 1/1 iteration: 38/128 step: 20
[2025-12-23 16:19:51,224] m-LoRA: Adapter lora_winogrande_77 loss: 0.5408229827880859
[2025-12-23 16:19:51,227] m-LoRA: Adapter lora_winogrande_85 epoch: 1/1 iteration: 24/128 step: 13
[2025-12-23 16:19:51,369] m-LoRA: Adapter lora_winogrande_63 loss: 0.45412129163742065
[2025-12-23 16:19:51,372] m-LoRA: Adapter lora_winogrande_66 epoch: 1/1 iteration: 86/128 step: 44
[2025-12-23 16:19:51,484] m-LoRA: Adapter lora_winogrande_87 epoch: 1/1 iteration: 22/128 step: 12
[2025-12-23 16:19:51,595] m-LoRA: Adapter lora_winogrande_78 loss: 0.6203311085700989
[2025-12-23 16:19:51,863] m-LoRA: Adapter lora_winogrande_86 loss: 0.5958253145217896
[2025-12-23 16:19:51,866] m-LoRA: Adapter lora_winogrande_88 epoch: 1/1 iteration: 88/128 step: 12
[2025-12-23 16:19:51,999] m-LoRA: Adapter lora_winogrande_81 loss: 0.5778667330741882
[2025-12-23 16:19:52,008] m-LoRA: Adapter lora_winogrande_83 epoch: 1/1 iteration: 76/128 step: 20
[2025-12-23 16:19:52,133] m-LoRA: Adapter lora_winogrande_85 loss: 0.6454120874404907
[2025-12-23 16:19:52,135] m-LoRA: Adapter lora_winogrande_89 epoch: 1/1 iteration: 44/128 step: 12
[2025-12-23 16:19:52,258] m-LoRA: Adapter lora_winogrande_66 loss: 0.4693385362625122
[2025-12-23 16:19:52,261] m-LoRA: Adapter lora_winogrande_77 epoch: 1/1 iteration: 80/128 step: 21
[2025-12-23 16:19:52,388] m-LoRA: Adapter lora_winogrande_87 loss: 0.6179559230804443
[2025-12-23 16:19:52,391] m-LoRA: Adapter lora_winogrande_63 epoch: 1/1 iteration: 88/128 step: 45
[2025-12-23 16:19:52,510] m-LoRA: Adapter lora_winogrande_78 epoch: 1/1 iteration: 80/128 step: 21
[2025-12-23 16:19:52,797] m-LoRA: Adapter lora_winogrande_86 epoch: 1/1 iteration: 48/128 step: 13
[2025-12-23 16:19:52,838] m-LoRA: Adapter lora_winogrande_88 loss: 2.2655656337738037
[2025-12-23 16:19:53,010] m-LoRA: Adapter lora_winogrande_83 loss: 0.6199582815170288
[2025-12-23 16:19:53,012] m-LoRA: Adapter lora_winogrande_81 epoch: 1/1 iteration: 40/128 step: 21
[2025-12-23 16:19:53,200] m-LoRA: Adapter lora_winogrande_89 loss: 0.7538284063339233
[2025-12-23 16:19:53,204] m-LoRA: Adapter lora_winogrande_85 epoch: 1/1 iteration: 26/128 step: 14
[2025-12-23 16:19:53,381] m-LoRA: Adapter lora_winogrande_77 loss: 0.5553489923477173
[2025-12-23 16:19:53,385] m-LoRA: Adapter lora_winogrande_66 epoch: 1/1 iteration: 88/128 step: 45
[2025-12-23 16:19:53,524] m-LoRA: Adapter lora_winogrande_63 loss: 0.5331030488014221
[2025-12-23 16:19:53,526] m-LoRA: Adapter lora_winogrande_87 epoch: 1/1 iteration: 24/128 step: 13
[2025-12-23 16:19:53,665] m-LoRA: Adapter lora_winogrande_78 loss: 0.7592852115631104
[2025-12-23 16:19:53,913] m-LoRA: Adapter lora_winogrande_86 loss: 0.6124197244644165
[2025-12-23 16:19:53,925] m-LoRA: Adapter lora_winogrande_88 epoch: 1/1 iteration: 96/128 step: 13
[2025-12-23 16:19:54,117] m-LoRA: Adapter lora_winogrande_81 loss: 0.6545729637145996
[2025-12-23 16:19:54,120] m-LoRA: Adapter lora_winogrande_83 epoch: 1/1 iteration: 80/128 step: 21
[2025-12-23 16:19:54,271] m-LoRA: Adapter lora_winogrande_85 loss: 0.6799802780151367
[2025-12-23 16:19:54,274] m-LoRA: Adapter lora_winogrande_89 epoch: 1/1 iteration: 48/128 step: 13
[2025-12-23 16:19:54,398] m-LoRA: Adapter lora_winogrande_66 loss: 0.4467247426509857
[2025-12-23 16:19:54,400] m-LoRA: Adapter lora_winogrande_77 epoch: 1/1 iteration: 84/128 step: 22
[2025-12-23 16:19:54,567] m-LoRA: Adapter lora_winogrande_87 loss: 0.42591455578804016
[2025-12-23 16:19:54,569] m-LoRA: Adapter lora_winogrande_63 epoch: 1/1 iteration: 90/128 step: 46
[2025-12-23 16:19:54,767] m-LoRA: Adapter lora_winogrande_88 loss: 2.1717019081115723
[2025-12-23 16:19:54,772] m-LoRA: Adapter lora_winogrande_78 epoch: 1/1 iteration: 84/128 step: 22
[2025-12-23 16:19:54,967] m-LoRA: Adapter lora_winogrande_83 loss: 0.6594974994659424
[2025-12-23 16:19:54,970] m-LoRA: Adapter lora_winogrande_86 epoch: 1/1 iteration: 52/128 step: 14
[2025-12-23 16:19:55,143] m-LoRA: Adapter lora_winogrande_89 loss: 0.6816149353981018
[2025-12-23 16:19:55,147] m-LoRA: Adapter lora_winogrande_81 epoch: 1/1 iteration: 42/128 step: 22
[2025-12-23 16:19:55,339] m-LoRA: Adapter lora_winogrande_77 loss: 0.5582302212715149
[2025-12-23 16:19:55,341] m-LoRA: Adapter lora_winogrande_85 epoch: 1/1 iteration: 28/128 step: 15
[2025-12-23 16:19:55,501] m-LoRA: Adapter lora_winogrande_63 loss: 0.5164573788642883
[2025-12-23 16:19:55,503] m-LoRA: Adapter lora_winogrande_87 epoch: 1/1 iteration: 26/128 step: 14
[2025-12-23 16:19:55,624] m-LoRA: Adapter lora_winogrande_66 epoch: 1/1 iteration: 90/128 step: 46
[2025-12-23 16:19:55,703] m-LoRA: Adapter lora_winogrande_78 loss: 0.5649860501289368
[2025-12-23 16:19:55,948] m-LoRA: Adapter lora_winogrande_86 loss: 0.5956256985664368
[2025-12-23 16:19:55,952] m-LoRA: Adapter lora_winogrande_88 epoch: 1/1 iteration: 104/128 step: 14
[2025-12-23 16:19:56,084] m-LoRA: Adapter lora_winogrande_81 loss: 0.5672630667686462
[2025-12-23 16:19:56,086] m-LoRA: Adapter lora_winogrande_83 epoch: 1/1 iteration: 84/128 step: 22
[2025-12-23 16:19:56,219] m-LoRA: Adapter lora_winogrande_85 loss: 0.5968284010887146
[2025-12-23 16:19:56,221] m-LoRA: Adapter lora_winogrande_89 epoch: 1/1 iteration: 52/128 step: 14
[2025-12-23 16:19:56,346] m-LoRA: Adapter lora_winogrande_87 loss: 0.6310502886772156
[2025-12-23 16:19:56,348] m-LoRA: Adapter lora_winogrande_77 epoch: 1/1 iteration: 88/128 step: 23
[2025-12-23 16:19:56,473] m-LoRA: Adapter lora_winogrande_66 loss: 0.525912344455719
[2025-12-23 16:19:56,476] m-LoRA: Adapter lora_winogrande_63 epoch: 1/1 iteration: 92/128 step: 47
[2025-12-23 16:19:56,593] m-LoRA: Adapter lora_winogrande_78 epoch: 1/1 iteration: 88/128 step: 23
[2025-12-23 16:19:56,940] m-LoRA: Adapter lora_winogrande_86 epoch: 1/1 iteration: 56/128 step: 15
[2025-12-23 16:19:56,979] m-LoRA: Adapter lora_winogrande_88 loss: 2.2602927684783936
[2025-12-23 16:19:57,168] m-LoRA: Adapter lora_winogrande_83 loss: 0.6445491909980774
[2025-12-23 16:19:57,172] m-LoRA: Adapter lora_winogrande_81 epoch: 1/1 iteration: 44/128 step: 23
[2025-12-23 16:19:57,327] m-LoRA: Adapter lora_winogrande_89 loss: 0.6172701716423035
[2025-12-23 16:19:57,330] m-LoRA: Adapter lora_winogrande_85 epoch: 1/1 iteration: 30/128 step: 16
[2025-12-23 16:19:57,490] m-LoRA: Adapter lora_winogrande_77 loss: 0.5932386517524719
[2025-12-23 16:19:57,492] m-LoRA: Adapter lora_winogrande_87 epoch: 1/1 iteration: 28/128 step: 15
[2025-12-23 16:19:57,631] m-LoRA: Adapter lora_winogrande_63 loss: 0.45664718747138977
[2025-12-23 16:19:57,633] m-LoRA: Adapter lora_winogrande_66 epoch: 1/1 iteration: 92/128 step: 47
[2025-12-23 16:19:57,725] m-LoRA: Adapter lora_winogrande_78 loss: 0.6985471248626709
[2025-12-23 16:19:57,952] m-LoRA: Adapter lora_winogrande_86 loss: 0.5128118991851807
[2025-12-23 16:19:57,954] m-LoRA: Adapter lora_winogrande_88 epoch: 1/1 iteration: 112/128 step: 15
[2025-12-23 16:19:58,127] m-LoRA: Adapter lora_winogrande_81 loss: 0.5169596672058105
[2025-12-23 16:19:58,130] m-LoRA: Adapter lora_winogrande_83 epoch: 1/1 iteration: 88/128 step: 23
[2025-12-23 16:19:58,266] m-LoRA: Adapter lora_winogrande_85 loss: 0.7319515943527222
[2025-12-23 16:19:58,269] m-LoRA: Adapter lora_winogrande_89 epoch: 1/1 iteration: 56/128 step: 15
[2025-12-23 16:19:58,402] m-LoRA: Adapter lora_winogrande_87 loss: 0.5036365389823914
[2025-12-23 16:19:58,404] m-LoRA: Adapter lora_winogrande_77 epoch: 1/1 iteration: 92/128 step: 24
[2025-12-23 16:19:58,514] m-LoRA: Adapter lora_winogrande_66 loss: 0.4938785135746002
[2025-12-23 16:19:58,516] m-LoRA: Adapter lora_winogrande_63 epoch: 1/1 iteration: 94/128 step: 48
[2025-12-23 16:19:58,833] m-LoRA: Adapter lora_winogrande_88 loss: 2.1454460620880127
[2025-12-23 16:19:58,836] m-LoRA: Adapter lora_winogrande_78 epoch: 1/1 iteration: 92/128 step: 24
[2025-12-23 16:19:59,004] m-LoRA: Adapter lora_winogrande_83 loss: 0.6495624780654907
[2025-12-23 16:19:59,006] m-LoRA: Adapter lora_winogrande_86 epoch: 1/1 iteration: 60/128 step: 16
[2025-12-23 16:19:59,183] m-LoRA: Adapter lora_winogrande_89 loss: 0.5743963718414307
[2025-12-23 16:19:59,185] m-LoRA: Adapter lora_winogrande_81 epoch: 1/1 iteration: 46/128 step: 24
[2025-12-23 16:19:59,354] m-LoRA: Adapter lora_winogrande_77 loss: 0.514415442943573
[2025-12-23 16:19:59,356] m-LoRA: Adapter lora_winogrande_85 epoch: 1/1 iteration: 32/128 step: 17
[2025-12-23 16:19:59,507] m-LoRA: Adapter lora_winogrande_63 loss: 0.4809386134147644
[2025-12-23 16:19:59,509] m-LoRA: Adapter lora_winogrande_87 epoch: 1/1 iteration: 30/128 step: 16
[2025-12-23 16:19:59,688] m-LoRA: Adapter lora_winogrande_78 loss: 0.6622734069824219
[2025-12-23 16:19:59,691] m-LoRA: Adapter lora_winogrande_66 epoch: 1/1 iteration: 94/128 step: 48
[2025-12-23 16:19:59,897] m-LoRA: Adapter lora_winogrande_86 loss: 0.4950076639652252
[2025-12-23 16:19:59,900] m-LoRA: Adapter lora_winogrande_88 epoch: 1/1 iteration: 120/128 step: 16
[2025-12-23 16:20:00,062] m-LoRA: Adapter lora_winogrande_81 loss: 0.7062684297561646
[2025-12-23 16:20:00,065] m-LoRA: Adapter lora_winogrande_83 epoch: 1/1 iteration: 92/128 step: 24
[2025-12-23 16:20:00,210] m-LoRA: Adapter lora_winogrande_85 loss: 0.662652313709259
[2025-12-23 16:20:00,213] m-LoRA: Adapter lora_winogrande_89 epoch: 1/1 iteration: 60/128 step: 16
[2025-12-23 16:20:00,317] m-LoRA: Adapter lora_winogrande_87 loss: 0.6905614733695984
[2025-12-23 16:20:00,319] m-LoRA: Adapter lora_winogrande_77 epoch: 1/1 iteration: 96/128 step: 25
[2025-12-23 16:20:00,456] m-LoRA: Adapter lora_winogrande_66 loss: 0.4369535744190216
[2025-12-23 16:20:00,458] m-LoRA: Adapter lora_winogrande_63 epoch: 1/1 iteration: 96/128 step: 49
[2025-12-23 16:20:00,577] m-LoRA: Adapter lora_winogrande_78 epoch: 1/1 iteration: 96/128 step: 25
[2025-12-23 16:20:00,904] m-LoRA: Adapter lora_winogrande_88 loss: 2.109241008758545
[2025-12-23 16:20:00,908] m-LoRA: Adapter lora_winogrande_86 epoch: 1/1 iteration: 64/128 step: 17
[2025-12-23 16:20:01,043] m-LoRA: Adapter lora_winogrande_83 loss: 0.6247621774673462
[2025-12-23 16:20:01,046] m-LoRA: Adapter lora_winogrande_81 epoch: 1/1 iteration: 48/128 step: 25
[2025-12-23 16:20:01,163] m-LoRA: Adapter lora_winogrande_89 loss: 0.5000966787338257
[2025-12-23 16:20:01,165] m-LoRA: Adapter lora_winogrande_85 epoch: 1/1 iteration: 34/128 step: 18
[2025-12-23 16:20:01,366] m-LoRA: Adapter lora_winogrande_77 loss: 0.4470406174659729
[2025-12-23 16:20:01,368] m-LoRA: Adapter lora_winogrande_87 epoch: 1/1 iteration: 32/128 step: 17
[2025-12-23 16:20:01,504] m-LoRA: Adapter lora_winogrande_63 loss: 0.513532817363739
[2025-12-23 16:20:01,507] m-LoRA: Adapter lora_winogrande_66 epoch: 1/1 iteration: 96/128 step: 49
[2025-12-23 16:20:01,601] m-LoRA: Adapter lora_winogrande_78 loss: 0.6026715040206909
[2025-12-23 16:20:01,844] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_88']
[2025-12-23 16:20:02,200] m-LoRA: Adapter lora_winogrande_86 loss: 0.5544463396072388
[2025-12-23 16:20:02,284] m-LoRA: Adapter lora_winogrande_81 loss: 0.567866325378418
[2025-12-23 16:20:02,286] m-LoRA: Adapter lora_winogrande_83 epoch: 1/1 iteration: 96/128 step: 25
[2025-12-23 16:20:02,349] m-LoRA: Adapter lora_winogrande_85 loss: 0.7528818845748901
[2025-12-23 16:20:02,354] m-LoRA: Adapter lora_winogrande_87 loss: 0.4919777810573578
[2025-12-23 16:20:02,356] m-LoRA: Adapter lora_winogrande_66 loss: 0.37963956594467163
[2025-12-23 16:20:02,434] m-LoRA: Adapter lora_winogrande_89 epoch: 1/1 iteration: 64/128 step: 17
[2025-12-23 16:20:02,533] m-LoRA: Adapter lora_winogrande_77 epoch: 1/1 iteration: 100/128 step: 26
[2025-12-23 16:20:02,659] m-LoRA: Adapter lora_winogrande_63 epoch: 1/1 iteration: 98/128 step: 50
[2025-12-23 16:20:02,884] m-LoRA: Adapter lora_winogrande_83 loss: 0.6045606732368469
[2025-12-23 16:20:02,886] m-LoRA: Adapter lora_winogrande_78 epoch: 1/1 iteration: 100/128 step: 26
[2025-12-23 16:20:03,039] m-LoRA: Adapter lora_winogrande_89 loss: 0.6245600581169128
[2025-12-23 16:20:03,041] m-LoRA: Adapter lora_winogrande_86 epoch: 1/1 iteration: 68/128 step: 18
[2025-12-23 16:20:03,249] m-LoRA: Adapter lora_winogrande_77 loss: 0.5666796565055847
[2025-12-23 16:20:03,251] m-LoRA: Adapter lora_winogrande_81 epoch: 1/1 iteration: 50/128 step: 26
[2025-12-23 16:20:03,370] m-LoRA: Adapter lora_winogrande_63 loss: 0.43968328833580017
[2025-12-23 16:20:03,372] m-LoRA: Adapter lora_winogrande_85 epoch: 1/1 iteration: 36/128 step: 19
[2025-12-23 16:20:03,517] m-LoRA: Adapter lora_winogrande_78 loss: 0.47473907470703125
[2025-12-23 16:20:03,520] m-LoRA: Adapter lora_winogrande_87 epoch: 1/1 iteration: 34/128 step: 18
[2025-12-23 16:20:03,655] m-LoRA: Adapter lora_winogrande_86 loss: 0.5094976425170898
[2025-12-23 16:20:03,659] m-LoRA: Adapter lora_winogrande_66 epoch: 1/1 iteration: 98/128 step: 50
[2025-12-23 16:20:03,762] m-LoRA: Adapter lora_winogrande_81 loss: 0.44223517179489136
[2025-12-23 16:20:03,764] m-LoRA: Adapter lora_winogrande_83 epoch: 1/1 iteration: 100/128 step: 26
[2025-12-23 16:20:03,874] m-LoRA: Adapter lora_winogrande_85 loss: 0.5589281916618347
[2025-12-23 16:20:03,877] m-LoRA: Adapter lora_winogrande_89 epoch: 1/1 iteration: 68/128 step: 18
[2025-12-23 16:20:03,997] m-LoRA: Adapter lora_winogrande_77 epoch: 1/1 iteration: 104/128 step: 27
[2025-12-23 16:20:04,087] m-LoRA: Adapter lora_winogrande_87 loss: 0.5647979974746704
[2025-12-23 16:20:04,089] m-LoRA: Adapter lora_winogrande_63 epoch: 1/1 iteration: 100/128 step: 51
[2025-12-23 16:20:04,221] m-LoRA: Adapter lora_winogrande_66 loss: 0.41951584815979004
[2025-12-23 16:20:04,223] m-LoRA: Adapter lora_winogrande_78 epoch: 1/1 iteration: 104/128 step: 27
[2025-12-23 16:20:04,366] m-LoRA: Adapter lora_winogrande_83 loss: 0.5902550220489502
[2025-12-23 16:20:04,369] m-LoRA: Adapter lora_winogrande_86 epoch: 1/1 iteration: 72/128 step: 19
[2025-12-23 16:20:04,565] m-LoRA: Adapter lora_winogrande_89 loss: 0.5557029843330383
[2025-12-23 16:20:04,568] m-LoRA: Adapter lora_winogrande_81 epoch: 1/1 iteration: 52/128 step: 27
[2025-12-23 16:20:04,753] m-LoRA: Adapter lora_winogrande_77 loss: 0.555902361869812
[2025-12-23 16:20:04,755] m-LoRA: Adapter lora_winogrande_85 epoch: 1/1 iteration: 38/128 step: 20
[2025-12-23 16:20:04,883] m-LoRA: Adapter lora_winogrande_63 loss: 0.47048330307006836
[2025-12-23 16:20:04,885] m-LoRA: Adapter lora_winogrande_87 epoch: 1/1 iteration: 36/128 step: 19
[2025-12-23 16:20:05,010] m-LoRA: Adapter lora_winogrande_78 loss: 0.5626162886619568
[2025-12-23 16:20:05,014] m-LoRA: Adapter lora_winogrande_66 epoch: 1/1 iteration: 100/128 step: 51
[2025-12-23 16:20:05,215] m-LoRA: Adapter lora_winogrande_86 loss: 0.5709881782531738
[2025-12-23 16:20:05,218] m-LoRA: Adapter lora_winogrande_83 epoch: 1/1 iteration: 104/128 step: 27
[2025-12-23 16:20:05,370] m-LoRA: Adapter lora_winogrande_81 loss: 0.6720718741416931
[2025-12-23 16:20:05,373] m-LoRA: Adapter lora_winogrande_89 epoch: 1/1 iteration: 72/128 step: 19
[2025-12-23 16:20:05,526] m-LoRA: Adapter lora_winogrande_85 loss: 0.5235887169837952
[2025-12-23 16:20:05,528] m-LoRA: Adapter lora_winogrande_77 epoch: 1/1 iteration: 108/128 step: 28
[2025-12-23 16:20:05,653] m-LoRA: Adapter lora_winogrande_87 loss: 0.6223279237747192
[2025-12-23 16:20:05,655] m-LoRA: Adapter lora_winogrande_63 epoch: 1/1 iteration: 102/128 step: 52
[2025-12-23 16:20:05,755] m-LoRA: Adapter lora_winogrande_66 loss: 0.38746950030326843
[2025-12-23 16:20:05,757] m-LoRA: Adapter lora_winogrande_78 epoch: 1/1 iteration: 108/128 step: 28
[2025-12-23 16:20:05,907] m-LoRA: Adapter lora_winogrande_83 loss: 0.6130171418190002
[2025-12-23 16:20:05,910] m-LoRA: Adapter lora_winogrande_86 epoch: 1/1 iteration: 76/128 step: 20
[2025-12-23 16:20:06,094] m-LoRA: Adapter lora_winogrande_89 loss: 0.5640230178833008
[2025-12-23 16:20:06,096] m-LoRA: Adapter lora_winogrande_81 epoch: 1/1 iteration: 54/128 step: 28
[2025-12-23 16:20:06,299] m-LoRA: Adapter lora_winogrande_77 loss: 0.49692225456237793
[2025-12-23 16:20:06,301] m-LoRA: Adapter lora_winogrande_85 epoch: 1/1 iteration: 40/128 step: 21
[2025-12-23 16:20:06,420] m-LoRA: Adapter lora_winogrande_63 loss: 0.5000081062316895
[2025-12-23 16:20:06,422] m-LoRA: Adapter lora_winogrande_87 epoch: 1/1 iteration: 38/128 step: 20
[2025-12-23 16:20:06,563] m-LoRA: Adapter lora_winogrande_78 loss: 0.5518171191215515
[2025-12-23 16:20:06,566] m-LoRA: Adapter lora_winogrande_66 epoch: 1/1 iteration: 102/128 step: 52
[2025-12-23 16:20:06,789] m-LoRA: Adapter lora_winogrande_86 loss: 0.5738067030906677
[2025-12-23 16:20:06,792] m-LoRA: Adapter lora_winogrande_83 epoch: 1/1 iteration: 108/128 step: 28
[2025-12-23 16:20:06,955] m-LoRA: Adapter lora_winogrande_81 loss: 0.6019477248191833
[2025-12-23 16:20:06,958] m-LoRA: Adapter lora_winogrande_89 epoch: 1/1 iteration: 76/128 step: 20
[2025-12-23 16:20:07,108] m-LoRA: Adapter lora_winogrande_85 loss: 0.7152877449989319
[2025-12-23 16:20:07,111] m-LoRA: Adapter lora_winogrande_77 epoch: 1/1 iteration: 112/128 step: 29
[2025-12-23 16:20:07,254] m-LoRA: Adapter lora_winogrande_87 loss: 0.560283899307251
[2025-12-23 16:20:07,256] m-LoRA: Adapter lora_winogrande_63 epoch: 1/1 iteration: 104/128 step: 53
[2025-12-23 16:20:07,400] m-LoRA: Adapter lora_winogrande_66 loss: 0.571293294429779
[2025-12-23 16:20:07,403] m-LoRA: Adapter lora_winogrande_78 epoch: 1/1 iteration: 112/128 step: 29
[2025-12-23 16:20:07,458] m-LoRA: Adapter lora_winogrande_83 loss: 0.5402355790138245
[2025-12-23 16:20:07,710] m-LoRA: Adapter lora_winogrande_89 loss: 0.5065712928771973
[2025-12-23 16:20:07,713] m-LoRA: Adapter lora_winogrande_86 epoch: 1/1 iteration: 80/128 step: 21
[2025-12-23 16:20:07,888] m-LoRA: Adapter lora_winogrande_77 loss: 0.4973618686199188
[2025-12-23 16:20:07,897] m-LoRA: Adapter lora_winogrande_81 epoch: 1/1 iteration: 56/128 step: 29
[2025-12-23 16:20:08,056] m-LoRA: Adapter lora_winogrande_63 loss: 0.5033831596374512
[2025-12-23 16:20:08,058] m-LoRA: Adapter lora_winogrande_85 epoch: 1/1 iteration: 42/128 step: 22
[2025-12-23 16:20:08,216] m-LoRA: Adapter lora_winogrande_78 loss: 0.6471864581108093
[2025-12-23 16:20:08,219] m-LoRA: Adapter lora_winogrande_87 epoch: 1/1 iteration: 40/128 step: 21
[2025-12-23 16:20:08,455] m-LoRA: Adapter lora_winogrande_86 loss: 0.4809735417366028
[2025-12-23 16:20:08,457] m-LoRA: Adapter lora_winogrande_66 epoch: 1/1 iteration: 104/128 step: 53
[2025-12-23 16:20:08,636] m-LoRA: Adapter lora_winogrande_81 loss: 0.4961446523666382
[2025-12-23 16:20:08,638] m-LoRA: Adapter lora_winogrande_83 epoch: 1/1 iteration: 112/128 step: 29
[2025-12-23 16:20:08,763] m-LoRA: Adapter lora_winogrande_85 loss: 0.5105405449867249
[2025-12-23 16:20:08,765] m-LoRA: Adapter lora_winogrande_89 epoch: 1/1 iteration: 80/128 step: 21
[2025-12-23 16:20:08,877] m-LoRA: Adapter lora_winogrande_87 loss: 0.5176659822463989
[2025-12-23 16:20:08,879] m-LoRA: Adapter lora_winogrande_77 epoch: 1/1 iteration: 116/128 step: 30
[2025-12-23 16:20:08,974] m-LoRA: Adapter lora_winogrande_66 loss: 0.39088353514671326
[2025-12-23 16:20:08,976] m-LoRA: Adapter lora_winogrande_63 epoch: 1/1 iteration: 106/128 step: 54
[2025-12-23 16:20:09,076] m-LoRA: Adapter lora_winogrande_78 epoch: 1/1 iteration: 116/128 step: 30
[2025-12-23 16:20:09,160] m-LoRA: Adapter lora_winogrande_86 epoch: 1/1 iteration: 84/128 step: 22
[2025-12-23 16:20:09,259] m-LoRA: Adapter lora_winogrande_83 loss: 0.5613635182380676
[2025-12-23 16:20:09,261] m-LoRA: Adapter lora_winogrande_81 epoch: 1/1 iteration: 58/128 step: 30
[2025-12-23 16:20:09,423] m-LoRA: Adapter lora_winogrande_89 loss: 0.5661827325820923
[2025-12-23 16:20:09,426] m-LoRA: Adapter lora_winogrande_85 epoch: 1/1 iteration: 44/128 step: 23
[2025-12-23 16:20:09,604] m-LoRA: Adapter lora_winogrande_77 loss: 0.5233440399169922
[2025-12-23 16:20:09,607] m-LoRA: Adapter lora_winogrande_87 epoch: 1/1 iteration: 42/128 step: 22
[2025-12-23 16:20:09,751] m-LoRA: Adapter lora_winogrande_63 loss: 0.43107864260673523
[2025-12-23 16:20:09,754] m-LoRA: Adapter lora_winogrande_66 epoch: 1/1 iteration: 106/128 step: 54
[2025-12-23 16:20:09,955] m-LoRA: Adapter lora_winogrande_78 loss: 0.6146214008331299
[2025-12-23 16:20:09,957] m-LoRA: Adapter lora_winogrande_83 epoch: 1/1 iteration: 116/128 step: 30
[2025-12-23 16:20:10,129] m-LoRA: Adapter lora_winogrande_86 loss: 0.488819420337677
[2025-12-23 16:20:10,132] m-LoRA: Adapter lora_winogrande_89 epoch: 1/1 iteration: 84/128 step: 22
[2025-12-23 16:20:10,282] m-LoRA: Adapter lora_winogrande_81 loss: 0.4653671979904175
[2025-12-23 16:20:10,284] m-LoRA: Adapter lora_winogrande_77 epoch: 1/1 iteration: 120/128 step: 31
[2025-12-23 16:20:10,440] m-LoRA: Adapter lora_winogrande_85 loss: 0.5032172203063965
[2025-12-23 16:20:10,442] m-LoRA: Adapter lora_winogrande_63 epoch: 1/1 iteration: 108/128 step: 55
[2025-12-23 16:20:10,495] m-LoRA: Adapter lora_winogrande_87 loss: 0.43382081389427185
[2025-12-23 16:20:10,499] m-LoRA: Adapter lora_winogrande_66 loss: 0.5231980681419373
[2025-12-23 16:20:10,670] m-LoRA: Adapter lora_winogrande_83 loss: 0.571609377861023
[2025-12-23 16:20:10,673] m-LoRA: Adapter lora_winogrande_78 epoch: 1/1 iteration: 120/128 step: 31
[2025-12-23 16:20:10,821] m-LoRA: Adapter lora_winogrande_89 loss: 0.617468535900116
[2025-12-23 16:20:10,823] m-LoRA: Adapter lora_winogrande_86 epoch: 1/1 iteration: 88/128 step: 23
[2025-12-23 16:20:11,060] m-LoRA: Adapter lora_winogrande_77 loss: 0.568583607673645
[2025-12-23 16:20:11,062] m-LoRA: Adapter lora_winogrande_81 epoch: 1/1 iteration: 60/128 step: 31
[2025-12-23 16:20:11,189] m-LoRA: Adapter lora_winogrande_63 loss: 0.5158299803733826
[2025-12-23 16:20:11,191] m-LoRA: Adapter lora_winogrande_85 epoch: 1/1 iteration: 46/128 step: 24
[2025-12-23 16:20:11,335] m-LoRA: Adapter lora_winogrande_78 loss: 0.5901362895965576
[2025-12-23 16:20:11,337] m-LoRA: Adapter lora_winogrande_66 epoch: 1/1 iteration: 108/128 step: 55
[2025-12-23 16:20:11,457] m-LoRA: Adapter lora_winogrande_87 epoch: 1/1 iteration: 44/128 step: 23
[2025-12-23 16:20:11,580] m-LoRA: Adapter lora_winogrande_86 loss: 0.4984326958656311
[2025-12-23 16:20:11,582] m-LoRA: Adapter lora_winogrande_83 epoch: 1/1 iteration: 120/128 step: 31
[2025-12-23 16:20:11,734] m-LoRA: Adapter lora_winogrande_81 loss: 0.47133705019950867
[2025-12-23 16:20:11,736] m-LoRA: Adapter lora_winogrande_89 epoch: 1/1 iteration: 88/128 step: 23
[2025-12-23 16:20:11,858] m-LoRA: Adapter lora_winogrande_85 loss: 0.5649213194847107
[2025-12-23 16:20:11,860] m-LoRA: Adapter lora_winogrande_77 epoch: 1/1 iteration: 124/128 step: 32
[2025-12-23 16:20:11,975] m-LoRA: Adapter lora_winogrande_66 loss: 0.5136966109275818
[2025-12-23 16:20:11,977] m-LoRA: Adapter lora_winogrande_63 epoch: 1/1 iteration: 110/128 step: 56
[2025-12-23 16:20:12,069] m-LoRA: Adapter lora_winogrande_78 epoch: 1/1 iteration: 124/128 step: 32
[2025-12-23 16:20:12,106] m-LoRA: Adapter lora_winogrande_87 loss: 0.6321458220481873
[2025-12-23 16:20:12,362] m-LoRA: Adapter lora_winogrande_83 loss: 0.6524168252944946
[2025-12-23 16:20:12,365] m-LoRA: Adapter lora_winogrande_86 epoch: 1/1 iteration: 92/128 step: 24
[2025-12-23 16:20:12,513] m-LoRA: Adapter lora_winogrande_89 loss: 0.4949113428592682
[2025-12-23 16:20:12,516] m-LoRA: Adapter lora_winogrande_81 epoch: 1/1 iteration: 62/128 step: 32
[2025-12-23 16:20:12,633] m-LoRA: Adapter lora_winogrande_63 loss: 0.44404399394989014
[2025-12-23 16:20:12,635] m-LoRA: Adapter lora_winogrande_85 epoch: 1/1 iteration: 48/128 step: 25
[2025-12-23 16:20:12,770] m-LoRA: Adapter lora_winogrande_77 loss: 0.4841472804546356
[2025-12-23 16:20:12,773] m-LoRA: Adapter lora_winogrande_66 epoch: 1/1 iteration: 110/128 step: 56
[2025-12-23 16:20:13,005] m-LoRA: Adapter lora_winogrande_78 loss: 0.5750590562820435
[2025-12-23 16:20:13,007] m-LoRA: Adapter lora_winogrande_87 epoch: 1/1 iteration: 46/128 step: 24
[2025-12-23 16:20:13,110] m-LoRA: Adapter lora_winogrande_86 loss: 0.4857008755207062
[2025-12-23 16:20:13,112] m-LoRA: Adapter lora_winogrande_83 epoch: 1/1 iteration: 124/128 step: 32
[2025-12-23 16:20:13,266] m-LoRA: Adapter lora_winogrande_81 loss: 0.5213927626609802
[2025-12-23 16:20:13,268] m-LoRA: Adapter lora_winogrande_89 epoch: 1/1 iteration: 92/128 step: 24
[2025-12-23 16:20:13,420] m-LoRA: Adapter lora_winogrande_85 loss: 0.5755939483642578
[2025-12-23 16:20:13,422] m-LoRA: Adapter lora_winogrande_63 epoch: 1/1 iteration: 112/128 step: 57
[2025-12-23 16:20:13,546] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_77']
[2025-12-23 16:20:13,818] m-LoRA: Adapter lora_winogrande_66 loss: 0.5839880108833313
[2025-12-23 16:20:13,921] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_78']
[2025-12-23 16:20:14,092] m-LoRA: Adapter lora_winogrande_87 loss: 0.50824373960495
[2025-12-23 16:20:14,095] m-LoRA: Adapter lora_winogrande_83 loss: 0.4878310561180115
[2025-12-23 16:20:14,098] m-LoRA: Adapter lora_winogrande_89 loss: 0.5399183630943298
[2025-12-23 16:20:14,302] m-LoRA: Adapter lora_winogrande_63 loss: 0.47525814175605774
[2025-12-23 16:20:14,304] m-LoRA: Adapter lora_winogrande_86 epoch: 1/1 iteration: 96/128 step: 25
[2025-12-23 16:20:14,450] m-LoRA: Adapter lora_winogrande_81 epoch: 1/1 iteration: 64/128 step: 33
[2025-12-23 16:20:14,529] m-LoRA: Adapter lora_winogrande_85 epoch: 1/1 iteration: 50/128 step: 26
[2025-12-23 16:20:14,621] m-LoRA: Adapter lora_winogrande_66 epoch: 1/1 iteration: 112/128 step: 57
[2025-12-23 16:20:14,691] m-LoRA: Adapter lora_winogrande_87 epoch: 1/1 iteration: 48/128 step: 25
[2025-12-23 16:20:14,849] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_83']
[2025-12-23 16:20:15,003] m-LoRA: Adapter lora_winogrande_86 loss: 0.5330789089202881
[2025-12-23 16:20:15,138] m-LoRA: Adapter lora_winogrande_81 loss: 0.4844663143157959
[2025-12-23 16:20:15,140] m-LoRA: Adapter lora_winogrande_89 epoch: 1/1 iteration: 96/128 step: 25
[2025-12-23 16:20:15,242] m-LoRA: Adapter lora_winogrande_85 loss: 0.4827171564102173
[2025-12-23 16:20:15,244] m-LoRA: Adapter lora_winogrande_63 epoch: 1/1 iteration: 114/128 step: 58
[2025-12-23 16:20:15,288] m-LoRA: Adapter lora_winogrande_66 loss: 0.45165401697158813
[2025-12-23 16:20:15,293] m-LoRA: Adapter lora_winogrande_87 loss: 0.47562175989151
[2025-12-23 16:20:15,492] m-LoRA: Adapter lora_winogrande_86 epoch: 1/1 iteration: 100/128 step: 26
[2025-12-23 16:20:15,602] m-LoRA: Adapter lora_winogrande_89 loss: 0.44623124599456787
[2025-12-23 16:20:15,606] m-LoRA: Adapter lora_winogrande_81 epoch: 1/1 iteration: 66/128 step: 34
[2025-12-23 16:20:15,748] m-LoRA: Adapter lora_winogrande_63 loss: 0.5754486322402954
[2025-12-23 16:20:15,750] m-LoRA: Adapter lora_winogrande_85 epoch: 1/1 iteration: 52/128 step: 27
[2025-12-23 16:20:15,834] m-LoRA: Adapter lora_winogrande_66 epoch: 1/1 iteration: 114/128 step: 58
[2025-12-23 16:20:15,972] m-LoRA: Adapter lora_winogrande_86 loss: 0.47531649470329285
[2025-12-23 16:20:15,976] m-LoRA: Adapter lora_winogrande_87 epoch: 1/1 iteration: 50/128 step: 26
[2025-12-23 16:20:16,036] m-LoRA: Adapter lora_winogrande_81 loss: 0.42784854769706726
[2025-12-23 16:20:16,211] m-LoRA: Adapter lora_winogrande_85 loss: 0.6940150260925293
[2025-12-23 16:20:16,214] m-LoRA: Adapter lora_winogrande_89 epoch: 1/1 iteration: 100/128 step: 26
[2025-12-23 16:20:16,360] m-LoRA: Adapter lora_winogrande_66 loss: 0.5001067519187927
[2025-12-23 16:20:16,362] m-LoRA: Adapter lora_winogrande_63 epoch: 1/1 iteration: 116/128 step: 59
[2025-12-23 16:20:16,446] m-LoRA: Adapter lora_winogrande_87 loss: 0.5148939490318298
[2025-12-23 16:20:16,597] m-LoRA: Adapter lora_winogrande_86 epoch: 1/1 iteration: 104/128 step: 27
[2025-12-23 16:20:16,754] m-LoRA: Adapter lora_winogrande_89 loss: 0.5777416229248047
[2025-12-23 16:20:16,756] m-LoRA: Adapter lora_winogrande_81 epoch: 1/1 iteration: 68/128 step: 35
[2025-12-23 16:20:16,889] m-LoRA: Adapter lora_winogrande_63 loss: 0.4600137770175934
[2025-12-23 16:20:16,892] m-LoRA: Adapter lora_winogrande_85 epoch: 1/1 iteration: 54/128 step: 28
[2025-12-23 16:20:17,025] m-LoRA: Adapter lora_winogrande_66 epoch: 1/1 iteration: 116/128 step: 59
[2025-12-23 16:20:17,137] m-LoRA: Adapter lora_winogrande_86 loss: 0.47112005949020386
[2025-12-23 16:20:17,140] m-LoRA: Adapter lora_winogrande_87 epoch: 1/1 iteration: 52/128 step: 27
[2025-12-23 16:20:17,245] m-LoRA: Adapter lora_winogrande_81 loss: 0.5437955260276794
[2025-12-23 16:20:17,451] m-LoRA: Adapter lora_winogrande_85 loss: 0.711361825466156
[2025-12-23 16:20:17,454] m-LoRA: Adapter lora_winogrande_89 epoch: 1/1 iteration: 104/128 step: 27
[2025-12-23 16:20:17,611] m-LoRA: Adapter lora_winogrande_66 loss: 0.49041831493377686
[2025-12-23 16:20:17,613] m-LoRA: Adapter lora_winogrande_63 epoch: 1/1 iteration: 118/128 step: 60
[2025-12-23 16:20:17,668] m-LoRA: Adapter lora_winogrande_87 loss: 0.47592636942863464
[2025-12-23 16:20:17,770] m-LoRA: Adapter lora_winogrande_86 epoch: 1/1 iteration: 108/128 step: 28
[2025-12-23 16:20:17,962] m-LoRA: Adapter lora_winogrande_89 loss: 0.4911520779132843
[2025-12-23 16:20:17,965] m-LoRA: Adapter lora_winogrande_81 epoch: 1/1 iteration: 70/128 step: 36
[2025-12-23 16:20:18,118] m-LoRA: Adapter lora_winogrande_63 loss: 0.4393625557422638
[2025-12-23 16:20:18,120] m-LoRA: Adapter lora_winogrande_85 epoch: 1/1 iteration: 56/128 step: 29
[2025-12-23 16:20:18,259] m-LoRA: Adapter lora_winogrande_66 epoch: 1/1 iteration: 118/128 step: 60
[2025-12-23 16:20:18,363] m-LoRA: Adapter lora_winogrande_86 loss: 0.5296854972839355
[2025-12-23 16:20:18,366] m-LoRA: Adapter lora_winogrande_87 epoch: 1/1 iteration: 54/128 step: 28
[2025-12-23 16:20:18,486] m-LoRA: Adapter lora_winogrande_89 epoch: 1/1 iteration: 108/128 step: 28
[2025-12-23 16:20:18,549] m-LoRA: Adapter lora_winogrande_81 loss: 0.5982137322425842
[2025-12-23 16:20:18,694] m-LoRA: Adapter lora_winogrande_85 loss: 0.5203313231468201
[2025-12-23 16:20:18,696] m-LoRA: Adapter lora_winogrande_63 epoch: 1/1 iteration: 120/128 step: 61
[2025-12-23 16:20:18,777] m-LoRA: Adapter lora_winogrande_66 loss: 0.443584680557251
[2025-12-23 16:20:18,880] m-LoRA: Adapter lora_winogrande_87 loss: 0.5322329998016357
[2025-12-23 16:20:19,125] m-LoRA: Adapter lora_winogrande_89 loss: 0.48855361342430115
[2025-12-23 16:20:19,127] m-LoRA: Adapter lora_winogrande_86 epoch: 1/1 iteration: 112/128 step: 29
[2025-12-23 16:20:19,280] m-LoRA: Adapter lora_winogrande_63 loss: 0.4333362579345703
[2025-12-23 16:20:19,282] m-LoRA: Adapter lora_winogrande_85 epoch: 1/1 iteration: 58/128 step: 30
[2025-12-23 16:20:19,380] m-LoRA: Adapter lora_winogrande_81 epoch: 1/1 iteration: 72/128 step: 37
[2025-12-23 16:20:19,456] m-LoRA: Adapter lora_winogrande_66 epoch: 1/1 iteration: 120/128 step: 61
[2025-12-23 16:20:19,529] m-LoRA: Adapter lora_winogrande_87 epoch: 1/1 iteration: 56/128 step: 29
[2025-12-23 16:20:19,671] m-LoRA: Adapter lora_winogrande_86 loss: 0.49787235260009766
[2025-12-23 16:20:19,830] m-LoRA: Adapter lora_winogrande_85 loss: 0.5252840518951416
[2025-12-23 16:20:19,832] m-LoRA: Adapter lora_winogrande_89 epoch: 1/1 iteration: 112/128 step: 29
[2025-12-23 16:20:19,976] m-LoRA: Adapter lora_winogrande_81 loss: 0.4773362874984741
[2025-12-23 16:20:19,979] m-LoRA: Adapter lora_winogrande_63 epoch: 1/1 iteration: 122/128 step: 62
[2025-12-23 16:20:20,033] m-LoRA: Adapter lora_winogrande_66 loss: 0.4724181592464447
[2025-12-23 16:20:20,037] m-LoRA: Adapter lora_winogrande_87 loss: 0.4714120328426361
[2025-12-23 16:20:20,236] m-LoRA: Adapter lora_winogrande_86 epoch: 1/1 iteration: 116/128 step: 30
[2025-12-23 16:20:20,411] m-LoRA: Adapter lora_winogrande_89 loss: 0.5757699608802795
[2025-12-23 16:20:20,414] m-LoRA: Adapter lora_winogrande_85 epoch: 1/1 iteration: 60/128 step: 31
[2025-12-23 16:20:20,553] m-LoRA: Adapter lora_winogrande_63 loss: 0.4677385091781616
[2025-12-23 16:20:20,555] m-LoRA: Adapter lora_winogrande_81 epoch: 1/1 iteration: 74/128 step: 38
[2025-12-23 16:20:20,798] m-LoRA: Adapter lora_winogrande_86 loss: 0.5592483282089233
[2025-12-23 16:20:20,801] m-LoRA: Adapter lora_winogrande_66 epoch: 1/1 iteration: 122/128 step: 62
[2025-12-23 16:20:20,954] m-LoRA: Adapter lora_winogrande_85 loss: 0.47953519225120544
[2025-12-23 16:20:20,957] m-LoRA: Adapter lora_winogrande_87 epoch: 1/1 iteration: 58/128 step: 30
[2025-12-23 16:20:21,088] m-LoRA: Adapter lora_winogrande_81 loss: 0.4388849437236786
[2025-12-23 16:20:21,090] m-LoRA: Adapter lora_winogrande_89 epoch: 1/1 iteration: 116/128 step: 30
[2025-12-23 16:20:21,214] m-LoRA: Adapter lora_winogrande_63 epoch: 1/1 iteration: 124/128 step: 63
[2025-12-23 16:20:21,253] m-LoRA: Adapter lora_winogrande_66 loss: 0.4303848147392273
[2025-12-23 16:20:21,454] m-LoRA: Adapter lora_winogrande_87 loss: 0.5502341985702515
[2025-12-23 16:20:21,457] m-LoRA: Adapter lora_winogrande_86 epoch: 1/1 iteration: 120/128 step: 31
[2025-12-23 16:20:21,571] m-LoRA: Adapter lora_winogrande_85 epoch: 1/1 iteration: 62/128 step: 32
[2025-12-23 16:20:21,696] m-LoRA: Adapter lora_winogrande_89 loss: 0.5229290127754211
[2025-12-23 16:20:21,698] m-LoRA: Adapter lora_winogrande_81 epoch: 1/1 iteration: 76/128 step: 39
[2025-12-23 16:20:21,835] m-LoRA: Adapter lora_winogrande_63 loss: 0.5183806419372559
[2025-12-23 16:20:21,837] m-LoRA: Adapter lora_winogrande_66 epoch: 1/1 iteration: 124/128 step: 63
[2025-12-23 16:20:21,939] m-LoRA: Adapter lora_winogrande_87 epoch: 1/1 iteration: 60/128 step: 31
[2025-12-23 16:20:22,000] m-LoRA: Adapter lora_winogrande_86 loss: 0.4919365346431732
[2025-12-23 16:20:22,175] m-LoRA: Adapter lora_winogrande_85 loss: 0.5009950399398804
[2025-12-23 16:20:22,354] m-LoRA: Adapter lora_winogrande_66 loss: 0.5001329779624939
[2025-12-23 16:20:22,356] m-LoRA: Adapter lora_winogrande_89 epoch: 1/1 iteration: 120/128 step: 31
[2025-12-23 16:20:22,498] m-LoRA: Adapter lora_winogrande_81 loss: 0.6009891033172607
[2025-12-23 16:20:22,500] m-LoRA: Adapter lora_winogrande_63 epoch: 1/1 iteration: 126/128 step: 64
[2025-12-23 16:20:22,618] m-LoRA: Adapter lora_winogrande_87 loss: 0.4237806499004364
[2025-12-23 16:20:22,620] m-LoRA: Adapter lora_winogrande_86 epoch: 1/1 iteration: 124/128 step: 32
[2025-12-23 16:20:22,730] m-LoRA: Adapter lora_winogrande_85 epoch: 1/1 iteration: 64/128 step: 33
[2025-12-23 16:20:22,807] m-LoRA: Adapter lora_winogrande_66 epoch: 1/1 iteration: 126/128 step: 64
[2025-12-23 16:20:22,987] m-LoRA: Adapter lora_winogrande_89 loss: 0.5125818848609924
[2025-12-23 16:20:22,991] m-LoRA: Adapter lora_winogrande_81 epoch: 1/1 iteration: 78/128 step: 40
[2025-12-23 16:20:23,057] m-LoRA: Adapter lora_winogrande_63 loss: 0.4846987724304199
[2025-12-23 16:20:23,267] m-LoRA: Adapter lora_winogrande_86 loss: 0.49134281277656555
[2025-12-23 16:20:23,270] m-LoRA: Adapter lora_winogrande_87 epoch: 1/1 iteration: 62/128 step: 32
[2025-12-23 16:20:23,348] m-LoRA: Adapter lora_winogrande_85 loss: 0.5032334327697754
[2025-12-23 16:20:23,356] m-LoRA: Adapter lora_winogrande_66 loss: 0.4310186207294464
[2025-12-23 16:20:23,473] m-LoRA: Adapter lora_winogrande_81 loss: 0.6182566285133362
[2025-12-23 16:20:23,572] m-LoRA: Adapter lora_winogrande_89 epoch: 1/1 iteration: 124/128 step: 32
[2025-12-23 16:20:23,641] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_63']
[2025-12-23 16:20:24,260] m-LoRA: Adapter lora_winogrande_87 loss: 0.4905204474925995
[2025-12-23 16:20:24,669] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_86']
[2025-12-23 16:20:25,105] m-LoRA: Adapter lora_winogrande_89 loss: 0.47374382615089417
[2025-12-23 16:20:25,214] m-LoRA: Adapter lora_winogrande_85 epoch: 1/1 iteration: 66/128 step: 34
[2025-12-23 16:20:25,298] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_66']
[2025-12-23 16:20:25,769] m-LoRA: Adapter lora_winogrande_85 loss: 0.4590438902378082
[2025-12-23 16:20:25,849] m-LoRA: Adapter lora_winogrande_81 epoch: 1/1 iteration: 80/128 step: 41
[2025-12-23 16:20:26,010] m-LoRA: Adapter lora_winogrande_87 epoch: 1/1 iteration: 64/128 step: 33
[2025-12-23 16:20:26,125] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_89']
[2025-12-23 16:20:26,585] m-LoRA: Adapter lora_winogrande_81 loss: 0.6054106950759888
[2025-12-23 16:20:26,829] m-LoRA: Adapter lora_winogrande_85 epoch: 1/1 iteration: 68/128 step: 35
[2025-12-23 16:20:26,982] m-LoRA: Adapter lora_winogrande_87 loss: 0.40106719732284546
[2025-12-23 16:20:26,985] m-LoRA: Adapter lora_winogrande_81 epoch: 1/1 iteration: 82/128 step: 42
[2025-12-23 16:20:27,117] m-LoRA: Adapter lora_winogrande_85 loss: 0.33892104029655457
[2025-12-23 16:20:27,439] m-LoRA: Adapter lora_winogrande_81 loss: 0.438748836517334
[2025-12-23 16:20:27,442] m-LoRA: Adapter lora_winogrande_87 epoch: 1/1 iteration: 66/128 step: 34
[2025-12-23 16:20:27,533] m-LoRA: Adapter lora_winogrande_85 epoch: 1/1 iteration: 70/128 step: 36
[2025-12-23 16:20:27,807] m-LoRA: Adapter lora_winogrande_87 loss: 0.4655318260192871
[2025-12-23 16:20:27,810] m-LoRA: Adapter lora_winogrande_81 epoch: 1/1 iteration: 84/128 step: 43
[2025-12-23 16:20:27,923] m-LoRA: Adapter lora_winogrande_85 loss: 0.429971843957901
[2025-12-23 16:20:28,180] m-LoRA: Adapter lora_winogrande_87 epoch: 1/1 iteration: 68/128 step: 35
[2025-12-23 16:20:28,277] m-LoRA: Adapter lora_winogrande_81 loss: 0.4941853880882263
[2025-12-23 16:20:28,280] m-LoRA: Adapter lora_winogrande_85 epoch: 1/1 iteration: 72/128 step: 37
[2025-12-23 16:20:28,510] m-LoRA: Adapter lora_winogrande_87 loss: 0.44758692383766174
[2025-12-23 16:20:28,590] m-LoRA: Adapter lora_winogrande_85 loss: 0.5663487315177917
[2025-12-23 16:20:28,694] m-LoRA: Adapter lora_winogrande_81 epoch: 1/1 iteration: 86/128 step: 44
[2025-12-23 16:20:28,928] m-LoRA: Adapter lora_winogrande_87 epoch: 1/1 iteration: 70/128 step: 36
[2025-12-23 16:20:29,039] m-LoRA: Adapter lora_winogrande_81 loss: 0.47313231229782104
[2025-12-23 16:20:29,041] m-LoRA: Adapter lora_winogrande_85 epoch: 1/1 iteration: 74/128 step: 38
[2025-12-23 16:20:29,248] m-LoRA: Adapter lora_winogrande_87 loss: 0.5553451776504517
[2025-12-23 16:20:29,453] m-LoRA: Adapter lora_winogrande_85 loss: 0.6277152299880981
[2025-12-23 16:20:29,455] m-LoRA: Adapter lora_winogrande_81 epoch: 1/1 iteration: 88/128 step: 45
[2025-12-23 16:20:29,610] m-LoRA: Adapter lora_winogrande_87 epoch: 1/1 iteration: 72/128 step: 37
[2025-12-23 16:20:29,845] m-LoRA: Adapter lora_winogrande_81 loss: 0.564874529838562
[2025-12-23 16:20:29,847] m-LoRA: Adapter lora_winogrande_85 epoch: 1/1 iteration: 76/128 step: 39
[2025-12-23 16:20:29,959] m-LoRA: Adapter lora_winogrande_87 loss: 0.47347918152809143
[2025-12-23 16:20:30,221] m-LoRA: Adapter lora_winogrande_81 epoch: 1/1 iteration: 90/128 step: 46
[2025-12-23 16:20:30,258] m-LoRA: Adapter lora_winogrande_85 loss: 0.44883227348327637
[2025-12-23 16:20:30,356] m-LoRA: Adapter lora_winogrande_87 epoch: 1/1 iteration: 74/128 step: 38
[2025-12-23 16:20:30,545] m-LoRA: Adapter lora_winogrande_81 loss: 0.4168942868709564
[2025-12-23 16:20:30,743] m-LoRA: Adapter lora_winogrande_87 loss: 0.508658766746521
[2025-12-23 16:20:30,745] m-LoRA: Adapter lora_winogrande_85 epoch: 1/1 iteration: 78/128 step: 40
[2025-12-23 16:20:30,882] m-LoRA: Adapter lora_winogrande_81 epoch: 1/1 iteration: 92/128 step: 47
[2025-12-23 16:20:31,129] m-LoRA: Adapter lora_winogrande_85 loss: 0.5936042666435242
[2025-12-23 16:20:31,131] m-LoRA: Adapter lora_winogrande_87 epoch: 1/1 iteration: 76/128 step: 39
[2025-12-23 16:20:31,227] m-LoRA: Adapter lora_winogrande_81 loss: 0.5403938889503479
[2025-12-23 16:20:31,642] m-LoRA: Adapter lora_winogrande_87 loss: 0.47543200850486755
[2025-12-23 16:20:31,644] m-LoRA: Adapter lora_winogrande_85 epoch: 1/1 iteration: 80/128 step: 41
[2025-12-23 16:20:31,735] m-LoRA: Adapter lora_winogrande_81 epoch: 1/1 iteration: 94/128 step: 48
[2025-12-23 16:20:32,024] m-LoRA: Adapter lora_winogrande_85 loss: 0.5487425923347473
[2025-12-23 16:20:32,026] m-LoRA: Adapter lora_winogrande_87 epoch: 1/1 iteration: 78/128 step: 40
[2025-12-23 16:20:32,109] m-LoRA: Adapter lora_winogrande_81 loss: 0.4813094735145569
[2025-12-23 16:20:32,449] m-LoRA: Adapter lora_winogrande_87 loss: 0.4173588454723358
[2025-12-23 16:20:32,451] m-LoRA: Adapter lora_winogrande_85 epoch: 1/1 iteration: 82/128 step: 42
[2025-12-23 16:20:32,561] m-LoRA: Adapter lora_winogrande_81 epoch: 1/1 iteration: 96/128 step: 49
[2025-12-23 16:20:32,826] m-LoRA: Adapter lora_winogrande_85 loss: 0.5979906320571899
[2025-12-23 16:20:32,829] m-LoRA: Adapter lora_winogrande_87 epoch: 1/1 iteration: 80/128 step: 41
[2025-12-23 16:20:32,920] m-LoRA: Adapter lora_winogrande_81 loss: 0.3846728801727295
[2025-12-23 16:20:33,188] m-LoRA: Adapter lora_winogrande_85 epoch: 1/1 iteration: 84/128 step: 43
[2025-12-23 16:20:33,236] m-LoRA: Adapter lora_winogrande_87 loss: 0.48118096590042114
[2025-12-23 16:20:33,326] m-LoRA: Adapter lora_winogrande_81 epoch: 1/1 iteration: 98/128 step: 50
[2025-12-23 16:20:33,542] m-LoRA: Adapter lora_winogrande_85 loss: 0.5806653499603271
[2025-12-23 16:20:33,745] m-LoRA: Adapter lora_winogrande_81 loss: 0.40318799018859863
[2025-12-23 16:20:33,747] m-LoRA: Adapter lora_winogrande_87 epoch: 1/1 iteration: 82/128 step: 42
[2025-12-23 16:20:33,915] m-LoRA: Adapter lora_winogrande_85 epoch: 1/1 iteration: 86/128 step: 44
[2025-12-23 16:20:34,195] m-LoRA: Adapter lora_winogrande_87 loss: 0.4823281466960907
[2025-12-23 16:20:34,197] m-LoRA: Adapter lora_winogrande_81 epoch: 1/1 iteration: 100/128 step: 51
[2025-12-23 16:20:34,264] m-LoRA: Adapter lora_winogrande_85 loss: 0.4831289052963257
[2025-12-23 16:20:34,642] m-LoRA: Adapter lora_winogrande_81 loss: 0.5424759387969971
[2025-12-23 16:20:34,645] m-LoRA: Adapter lora_winogrande_87 epoch: 1/1 iteration: 84/128 step: 43
[2025-12-23 16:20:34,763] m-LoRA: Adapter lora_winogrande_85 epoch: 1/1 iteration: 88/128 step: 45
[2025-12-23 16:20:35,092] m-LoRA: Adapter lora_winogrande_87 loss: 0.5584467649459839
[2025-12-23 16:20:35,095] m-LoRA: Adapter lora_winogrande_81 epoch: 1/1 iteration: 102/128 step: 52
[2025-12-23 16:20:35,146] m-LoRA: Adapter lora_winogrande_85 loss: 0.45049649477005005
[2025-12-23 16:20:35,535] m-LoRA: Adapter lora_winogrande_81 loss: 0.454109787940979
[2025-12-23 16:20:35,537] m-LoRA: Adapter lora_winogrande_87 epoch: 1/1 iteration: 86/128 step: 44
[2025-12-23 16:20:35,643] m-LoRA: Adapter lora_winogrande_85 epoch: 1/1 iteration: 90/128 step: 46
[2025-12-23 16:20:35,948] m-LoRA: Adapter lora_winogrande_87 loss: 0.5002336502075195
[2025-12-23 16:20:35,950] m-LoRA: Adapter lora_winogrande_81 epoch: 1/1 iteration: 104/128 step: 53
[2025-12-23 16:20:36,017] m-LoRA: Adapter lora_winogrande_85 loss: 0.5445882678031921
[2025-12-23 16:20:36,372] m-LoRA: Adapter lora_winogrande_81 loss: 0.45167961716651917
[2025-12-23 16:20:36,374] m-LoRA: Adapter lora_winogrande_87 epoch: 1/1 iteration: 88/128 step: 45
[2025-12-23 16:20:36,480] m-LoRA: Adapter lora_winogrande_85 epoch: 1/1 iteration: 92/128 step: 47
[2025-12-23 16:20:36,743] m-LoRA: Adapter lora_winogrande_87 loss: 0.4461752474308014
[2025-12-23 16:20:36,745] m-LoRA: Adapter lora_winogrande_81 epoch: 1/1 iteration: 106/128 step: 54
[2025-12-23 16:20:36,831] m-LoRA: Adapter lora_winogrande_85 loss: 0.46001601219177246
[2025-12-23 16:20:37,176] m-LoRA: Adapter lora_winogrande_81 loss: 0.6171923875808716
[2025-12-23 16:20:37,178] m-LoRA: Adapter lora_winogrande_87 epoch: 1/1 iteration: 90/128 step: 46
[2025-12-23 16:20:37,296] m-LoRA: Adapter lora_winogrande_85 epoch: 1/1 iteration: 94/128 step: 48
[2025-12-23 16:20:37,601] m-LoRA: Adapter lora_winogrande_87 loss: 0.47776031494140625
[2025-12-23 16:20:37,603] m-LoRA: Adapter lora_winogrande_81 epoch: 1/1 iteration: 108/128 step: 55
[2025-12-23 16:20:37,670] m-LoRA: Adapter lora_winogrande_85 loss: 0.5249102115631104
[2025-12-23 16:20:37,988] m-LoRA: Adapter lora_winogrande_81 loss: 0.6356515288352966
[2025-12-23 16:20:37,990] m-LoRA: Adapter lora_winogrande_87 epoch: 1/1 iteration: 92/128 step: 47
[2025-12-23 16:20:38,126] m-LoRA: Adapter lora_winogrande_85 epoch: 1/1 iteration: 96/128 step: 49
[2025-12-23 16:20:38,361] m-LoRA: Adapter lora_winogrande_87 loss: 0.5801073908805847
[2025-12-23 16:20:38,363] m-LoRA: Adapter lora_winogrande_81 epoch: 1/1 iteration: 110/128 step: 56
[2025-12-23 16:20:38,450] m-LoRA: Adapter lora_winogrande_85 loss: 0.42456597089767456
[2025-12-23 16:20:38,748] m-LoRA: Adapter lora_winogrande_87 epoch: 1/1 iteration: 94/128 step: 48
[2025-12-23 16:20:38,766] m-LoRA: Adapter lora_winogrande_81 loss: 0.4079534709453583
[2025-12-23 16:20:38,844] m-LoRA: Adapter lora_winogrande_85 epoch: 1/1 iteration: 98/128 step: 50
[2025-12-23 16:20:39,057] m-LoRA: Adapter lora_winogrande_87 loss: 0.4975159764289856
[2025-12-23 16:20:39,261] m-LoRA: Adapter lora_winogrande_85 loss: 0.40916553139686584
[2025-12-23 16:20:39,263] m-LoRA: Adapter lora_winogrande_81 epoch: 1/1 iteration: 112/128 step: 57
[2025-12-23 16:20:39,396] m-LoRA: Adapter lora_winogrande_87 epoch: 1/1 iteration: 96/128 step: 49
[2025-12-23 16:20:39,734] m-LoRA: Adapter lora_winogrande_81 loss: 0.5235437154769897
[2025-12-23 16:20:39,736] m-LoRA: Adapter lora_winogrande_85 epoch: 1/1 iteration: 100/128 step: 51
[2025-12-23 16:20:39,791] m-LoRA: Adapter lora_winogrande_87 loss: 0.47650983929634094
[2025-12-23 16:20:40,225] m-LoRA: Adapter lora_winogrande_85 loss: 0.4553602933883667
[2025-12-23 16:20:40,227] m-LoRA: Adapter lora_winogrande_81 epoch: 1/1 iteration: 114/128 step: 58
[2025-12-23 16:20:40,340] m-LoRA: Adapter lora_winogrande_87 epoch: 1/1 iteration: 98/128 step: 50
[2025-12-23 16:20:40,623] m-LoRA: Adapter lora_winogrande_81 loss: 0.4884699583053589
[2025-12-23 16:20:40,625] m-LoRA: Adapter lora_winogrande_85 epoch: 1/1 iteration: 102/128 step: 52
[2025-12-23 16:20:40,707] m-LoRA: Adapter lora_winogrande_87 loss: 0.5460836291313171
[2025-12-23 16:20:41,029] m-LoRA: Adapter lora_winogrande_81 epoch: 1/1 iteration: 116/128 step: 59
[2025-12-23 16:20:41,133] m-LoRA: Adapter lora_winogrande_85 loss: 0.44447067379951477
[2025-12-23 16:20:41,135] m-LoRA: Adapter lora_winogrande_87 epoch: 1/1 iteration: 100/128 step: 51
[2025-12-23 16:20:41,349] m-LoRA: Adapter lora_winogrande_81 loss: 0.38998162746429443
[2025-12-23 16:20:41,565] m-LoRA: Adapter lora_winogrande_87 loss: 0.5278427004814148
[2025-12-23 16:20:41,568] m-LoRA: Adapter lora_winogrande_85 epoch: 1/1 iteration: 104/128 step: 53
[2025-12-23 16:20:41,779] m-LoRA: Adapter lora_winogrande_81 epoch: 1/1 iteration: 118/128 step: 60
[2025-12-23 16:20:41,960] m-LoRA: Adapter lora_winogrande_85 loss: 0.416511595249176
[2025-12-23 16:20:41,962] m-LoRA: Adapter lora_winogrande_87 epoch: 1/1 iteration: 102/128 step: 52
[2025-12-23 16:20:42,136] m-LoRA: Adapter lora_winogrande_81 loss: 0.42899683117866516
[2025-12-23 16:20:42,405] m-LoRA: Adapter lora_winogrande_87 loss: 0.5054168701171875
[2025-12-23 16:20:42,408] m-LoRA: Adapter lora_winogrande_85 epoch: 1/1 iteration: 106/128 step: 54
[2025-12-23 16:20:42,518] m-LoRA: Adapter lora_winogrande_81 epoch: 1/1 iteration: 120/128 step: 61
[2025-12-23 16:20:42,795] m-LoRA: Adapter lora_winogrande_85 loss: 0.5153363347053528
[2025-12-23 16:20:42,797] m-LoRA: Adapter lora_winogrande_87 epoch: 1/1 iteration: 104/128 step: 53
[2025-12-23 16:20:42,887] m-LoRA: Adapter lora_winogrande_81 loss: 0.579372227191925
[2025-12-23 16:20:43,237] m-LoRA: Adapter lora_winogrande_87 loss: 0.5881649255752563
[2025-12-23 16:20:43,239] m-LoRA: Adapter lora_winogrande_85 epoch: 1/1 iteration: 108/128 step: 55
[2025-12-23 16:20:43,348] m-LoRA: Adapter lora_winogrande_81 epoch: 1/1 iteration: 122/128 step: 62
[2025-12-23 16:20:43,648] m-LoRA: Adapter lora_winogrande_85 loss: 0.397748202085495
[2025-12-23 16:20:43,651] m-LoRA: Adapter lora_winogrande_87 epoch: 1/1 iteration: 106/128 step: 54
[2025-12-23 16:20:43,731] m-LoRA: Adapter lora_winogrande_81 loss: 0.4814150631427765
[2025-12-23 16:20:44,095] m-LoRA: Adapter lora_winogrande_87 loss: 0.4594421982765198
[2025-12-23 16:20:44,097] m-LoRA: Adapter lora_winogrande_85 epoch: 1/1 iteration: 110/128 step: 56
[2025-12-23 16:20:44,208] m-LoRA: Adapter lora_winogrande_81 epoch: 1/1 iteration: 124/128 step: 63
[2025-12-23 16:20:44,472] m-LoRA: Adapter lora_winogrande_85 loss: 0.5326831936836243
[2025-12-23 16:20:44,474] m-LoRA: Adapter lora_winogrande_87 epoch: 1/1 iteration: 108/128 step: 55
[2025-12-23 16:20:44,570] m-LoRA: Adapter lora_winogrande_81 loss: 0.5349106192588806
[2025-12-23 16:20:44,847] m-LoRA: Adapter lora_winogrande_85 epoch: 1/1 iteration: 112/128 step: 57
[2025-12-23 16:20:44,892] m-LoRA: Adapter lora_winogrande_87 loss: 0.4718163013458252
[2025-12-23 16:20:45,069] m-LoRA: Adapter lora_winogrande_81 epoch: 1/1 iteration: 126/128 step: 64
[2025-12-23 16:20:45,182] m-LoRA: Adapter lora_winogrande_85 loss: 0.5864688158035278
[2025-12-23 16:20:45,303] m-LoRA: Adapter lora_winogrande_87 epoch: 1/1 iteration: 110/128 step: 56
[2025-12-23 16:20:45,480] m-LoRA: Adapter lora_winogrande_81 loss: 0.48771727085113525
[2025-12-23 16:20:45,690] m-LoRA: Adapter lora_winogrande_87 loss: 0.49494847655296326
[2025-12-23 16:20:45,693] m-LoRA: Adapter lora_winogrande_85 epoch: 1/1 iteration: 114/128 step: 58
[2025-12-23 16:20:45,825] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_81']
[2025-12-23 16:20:46,170] m-LoRA: Adapter lora_winogrande_85 loss: 0.6704051494598389
[2025-12-23 16:20:46,439] m-LoRA: Adapter lora_winogrande_87 epoch: 1/1 iteration: 112/128 step: 57
[2025-12-23 16:20:46,537] m-LoRA: Adapter lora_winogrande_85 epoch: 1/1 iteration: 116/128 step: 59
[2025-12-23 16:20:46,761] m-LoRA: Adapter lora_winogrande_87 loss: 0.3310598134994507
[2025-12-23 16:20:46,842] m-LoRA: Adapter lora_winogrande_85 loss: 0.34702709317207336
[2025-12-23 16:20:47,176] m-LoRA: Adapter lora_winogrande_87 epoch: 1/1 iteration: 114/128 step: 58
[2025-12-23 16:20:47,272] m-LoRA: Adapter lora_winogrande_85 epoch: 1/1 iteration: 118/128 step: 60
[2025-12-23 16:20:47,491] m-LoRA: Adapter lora_winogrande_87 loss: 0.32727116346359253
[2025-12-23 16:20:47,555] m-LoRA: Adapter lora_winogrande_85 loss: 0.4132571220397949
[2025-12-23 16:20:47,899] m-LoRA: Adapter lora_winogrande_87 epoch: 1/1 iteration: 116/128 step: 59
[2025-12-23 16:20:48,000] m-LoRA: Adapter lora_winogrande_85 epoch: 1/1 iteration: 120/128 step: 61
[2025-12-23 16:20:48,222] m-LoRA: Adapter lora_winogrande_87 loss: 0.540327787399292
[2025-12-23 16:20:48,301] m-LoRA: Adapter lora_winogrande_85 loss: 0.47851529717445374
[2025-12-23 16:20:48,613] m-LoRA: Adapter lora_winogrande_87 epoch: 1/1 iteration: 118/128 step: 60
[2025-12-23 16:20:48,708] m-LoRA: Adapter lora_winogrande_85 epoch: 1/1 iteration: 122/128 step: 62
[2025-12-23 16:20:48,939] m-LoRA: Adapter lora_winogrande_87 loss: 0.4986984133720398
[2025-12-23 16:20:49,029] m-LoRA: Adapter lora_winogrande_85 loss: 0.43487271666526794
[2025-12-23 16:20:49,317] m-LoRA: Adapter lora_winogrande_87 epoch: 1/1 iteration: 120/128 step: 61
[2025-12-23 16:20:49,416] m-LoRA: Adapter lora_winogrande_85 epoch: 1/1 iteration: 124/128 step: 63
[2025-12-23 16:20:49,634] m-LoRA: Adapter lora_winogrande_87 loss: 0.39384040236473083
[2025-12-23 16:20:49,742] m-LoRA: Adapter lora_winogrande_85 loss: 0.45781004428863525
[2025-12-23 16:20:49,990] m-LoRA: Adapter lora_winogrande_87 epoch: 1/1 iteration: 122/128 step: 62
[2025-12-23 16:20:50,071] m-LoRA: Adapter lora_winogrande_85 epoch: 1/1 iteration: 126/128 step: 64
[2025-12-23 16:20:50,318] m-LoRA: Adapter lora_winogrande_87 loss: 0.4567336440086365
[2025-12-23 16:20:50,402] m-LoRA: Adapter lora_winogrande_85 loss: 0.4611377418041229
[2025-12-23 16:20:50,734] m-LoRA: Adapter lora_winogrande_87 epoch: 1/1 iteration: 124/128 step: 63
[2025-12-23 16:20:50,823] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_85']
[2025-12-23 16:20:51,325] m-LoRA: Adapter lora_winogrande_87 loss: 0.4911663830280304
[2025-12-23 16:20:51,682] m-LoRA: Adapter lora_winogrande_87 epoch: 1/1 iteration: 126/128 step: 64
[2025-12-23 16:20:51,992] m-LoRA: Adapter lora_winogrande_87 loss: 0.44226646423339844
[2025-12-23 16:20:52,365] m-LoRA: Finish and base model offload adapter - ['lora_winogrande_87']
