[2025-12-23 17:23:17,540] m-LoRA: NVIDIA CUDA initialized successfully.
[2025-12-23 17:23:17,540] m-LoRA: Total 8 GPU(s) detected.
[2025-12-23 17:23:17,760] m-LoRA: Pipeline parallelism, rank is 0 and balance is [8, 9, 9, 9].
[2025-12-23 17:23:17,762] m-LoRA: Loading model with precision - bf16
[2025-12-23 17:23:19,237] m-LoRA: Some parameters are on the meta device because they were offloaded to the disk.
[2025-12-23 17:23:19,237] m-LoRA: loading llama compatible model - llama
[2025-12-23 17:23:19,382] m-LoRA: Adapter lora_finqa_0 without lr_scheduler.
[2025-12-23 17:23:19,382] m-LoRA: Adapter lora_finqa_1 without lr_scheduler.
[2025-12-23 17:23:19,382] m-LoRA: Adapter lora_finqa_2 without lr_scheduler.
[2025-12-23 17:23:19,382] m-LoRA: Adapter lora_finqa_3 without lr_scheduler.
[2025-12-23 17:23:19,382] m-LoRA: Adapter lora_finqa_4 without lr_scheduler.
[2025-12-23 17:23:19,382] m-LoRA: Adapter lora_finqa_5 without lr_scheduler.
[2025-12-23 17:23:19,382] m-LoRA: Adapter lora_finqa_6 without lr_scheduler.
[2025-12-23 17:23:19,382] m-LoRA: Adapter lora_finqa_7 without lr_scheduler.
[2025-12-23 17:23:19,382] m-LoRA: Adapter lora_finqa_8 without lr_scheduler.
[2025-12-23 17:23:19,382] m-LoRA: Adapter lora_finqa_9 without lr_scheduler.
[2025-12-23 17:23:19,382] m-LoRA: Adapter lora_finqa_10 without lr_scheduler.
[2025-12-23 17:23:19,382] m-LoRA: Adapter lora_finqa_11 without lr_scheduler.
[2025-12-23 17:23:19,382] m-LoRA: Adapter lora_finqa_12 without lr_scheduler.
[2025-12-23 17:23:19,382] m-LoRA: Adapter lora_finqa_13 without lr_scheduler.
[2025-12-23 17:23:19,382] m-LoRA: Adapter lora_finqa_14 without lr_scheduler.
[2025-12-23 17:23:19,382] m-LoRA: Adapter lora_finqa_15 without lr_scheduler.
[2025-12-23 17:23:19,382] m-LoRA: Adapter lora_finqa_16 without lr_scheduler.
[2025-12-23 17:23:19,382] m-LoRA: Adapter lora_finqa_17 without lr_scheduler.
[2025-12-23 17:23:19,382] m-LoRA: Adapter lora_finqa_18 without lr_scheduler.
[2025-12-23 17:23:19,382] m-LoRA: Adapter lora_finqa_19 without lr_scheduler.
[2025-12-23 17:23:19,383] m-LoRA: Adapter lora_finqa_20 without lr_scheduler.
[2025-12-23 17:23:19,383] m-LoRA: Adapter lora_finqa_21 without lr_scheduler.
[2025-12-23 17:23:19,383] m-LoRA: Adapter lora_finqa_22 without lr_scheduler.
[2025-12-23 17:23:19,383] m-LoRA: Adapter lora_finqa_23 without lr_scheduler.
[2025-12-23 17:23:19,383] m-LoRA: Adapter lora_finqa_24 without lr_scheduler.
[2025-12-23 17:23:19,383] m-LoRA: Adapter lora_finqa_25 without lr_scheduler.
[2025-12-23 17:23:19,383] m-LoRA: Adapter lora_finqa_26 without lr_scheduler.
[2025-12-23 17:23:19,383] m-LoRA: Adapter lora_finqa_27 without lr_scheduler.
[2025-12-23 17:23:19,383] m-LoRA: Adapter lora_finqa_28 without lr_scheduler.
[2025-12-23 17:23:19,383] m-LoRA: Adapter lora_finqa_29 without lr_scheduler.
[2025-12-23 17:23:19,383] m-LoRA: Adapter lora_finqa_30 without lr_scheduler.
[2025-12-23 17:23:19,383] m-LoRA: Adapter lora_finqa_31 without lr_scheduler.
[2025-12-23 17:23:19,383] m-LoRA: Adapter lora_finqa_32 without lr_scheduler.
[2025-12-23 17:23:19,383] m-LoRA: Adapter lora_finqa_33 without lr_scheduler.
[2025-12-23 17:23:19,383] m-LoRA: Adapter lora_finqa_34 without lr_scheduler.
[2025-12-23 17:23:19,383] m-LoRA: Adapter lora_finqa_35 without lr_scheduler.
[2025-12-23 17:23:19,383] m-LoRA: Adapter lora_finqa_36 without lr_scheduler.
[2025-12-23 17:23:19,383] m-LoRA: Adapter lora_finqa_37 without lr_scheduler.
[2025-12-23 17:23:19,383] m-LoRA: Adapter lora_finqa_38 without lr_scheduler.
[2025-12-23 17:23:19,383] m-LoRA: Adapter lora_finqa_39 without lr_scheduler.
[2025-12-23 17:23:19,383] m-LoRA: Adapter lora_finqa_40 without lr_scheduler.
[2025-12-23 17:23:19,383] m-LoRA: Adapter lora_finqa_41 without lr_scheduler.
[2025-12-23 17:23:19,383] m-LoRA: Adapter lora_finqa_42 without lr_scheduler.
[2025-12-23 17:23:19,383] m-LoRA: Adapter lora_finqa_43 without lr_scheduler.
[2025-12-23 17:23:19,383] m-LoRA: Adapter lora_finqa_44 without lr_scheduler.
[2025-12-23 17:23:19,383] m-LoRA: Adapter lora_finqa_45 without lr_scheduler.
[2025-12-23 17:23:19,383] m-LoRA: Adapter lora_finqa_46 without lr_scheduler.
[2025-12-23 17:23:19,383] m-LoRA: Adapter lora_finqa_47 without lr_scheduler.
[2025-12-23 17:23:19,383] m-LoRA: Adapter lora_finqa_48 without lr_scheduler.
[2025-12-23 17:23:19,383] m-LoRA: Adapter lora_finqa_49 without lr_scheduler.
[2025-12-23 17:23:19,383] m-LoRA: Adapter lora_finqa_50 without lr_scheduler.
[2025-12-23 17:23:19,383] m-LoRA: Adapter lora_finqa_51 without lr_scheduler.
[2025-12-23 17:23:19,383] m-LoRA: Adapter lora_finqa_52 without lr_scheduler.
[2025-12-23 17:23:19,383] m-LoRA: Adapter lora_finqa_53 without lr_scheduler.
[2025-12-23 17:23:19,383] m-LoRA: Adapter lora_finqa_54 without lr_scheduler.
[2025-12-23 17:23:19,383] m-LoRA: Adapter lora_finqa_55 without lr_scheduler.
[2025-12-23 17:23:19,383] m-LoRA: Adapter lora_finqa_56 without lr_scheduler.
[2025-12-23 17:23:19,383] m-LoRA: Adapter lora_finqa_57 without lr_scheduler.
[2025-12-23 17:23:19,383] m-LoRA: Adapter lora_finqa_58 without lr_scheduler.
[2025-12-23 17:23:19,383] m-LoRA: Adapter lora_finqa_59 without lr_scheduler.
[2025-12-23 17:23:19,383] m-LoRA: Adapter lora_finqa_60 without lr_scheduler.
[2025-12-23 17:23:19,383] m-LoRA: Adapter lora_finqa_61 without lr_scheduler.
[2025-12-23 17:23:19,383] m-LoRA: Adapter lora_finqa_62 without lr_scheduler.
[2025-12-23 17:23:19,383] m-LoRA: Adapter lora_finqa_63 without lr_scheduler.
[2025-12-23 17:23:19,384] m-LoRA: Adapter lora_finqa_64 without lr_scheduler.
[2025-12-23 17:23:19,384] m-LoRA: Adapter lora_finqa_65 without lr_scheduler.
[2025-12-23 17:23:19,384] m-LoRA: Adapter lora_finqa_66 without lr_scheduler.
[2025-12-23 17:23:19,384] m-LoRA: Adapter lora_finqa_67 without lr_scheduler.
[2025-12-23 17:23:19,384] m-LoRA: Adapter lora_finqa_68 without lr_scheduler.
[2025-12-23 17:23:19,384] m-LoRA: Adapter lora_finqa_69 without lr_scheduler.
[2025-12-23 17:23:19,384] m-LoRA: Adapter lora_finqa_70 without lr_scheduler.
[2025-12-23 17:23:19,384] m-LoRA: Adapter lora_finqa_71 without lr_scheduler.
[2025-12-23 17:23:19,384] m-LoRA: Adapter lora_finqa_72 without lr_scheduler.
[2025-12-23 17:23:19,384] m-LoRA: Adapter lora_finqa_73 without lr_scheduler.
[2025-12-23 17:23:19,384] m-LoRA: Adapter lora_finqa_74 without lr_scheduler.
[2025-12-23 17:23:19,384] m-LoRA: Adapter lora_finqa_75 without lr_scheduler.
[2025-12-23 17:23:19,384] m-LoRA: Adapter lora_finqa_76 without lr_scheduler.
[2025-12-23 17:23:19,384] m-LoRA: Adapter lora_finqa_77 without lr_scheduler.
[2025-12-23 17:23:19,384] m-LoRA: Adapter lora_finqa_78 without lr_scheduler.
[2025-12-23 17:23:19,384] m-LoRA: Adapter lora_finqa_79 without lr_scheduler.
[2025-12-23 17:23:19,384] m-LoRA: Adapter lora_finqa_80 without lr_scheduler.
[2025-12-23 17:23:19,384] m-LoRA: Adapter lora_finqa_81 without lr_scheduler.
[2025-12-23 17:23:19,384] m-LoRA: Adapter lora_finqa_82 without lr_scheduler.
[2025-12-23 17:23:19,384] m-LoRA: Adapter lora_finqa_83 without lr_scheduler.
[2025-12-23 17:23:19,384] m-LoRA: Adapter lora_finqa_84 without lr_scheduler.
[2025-12-23 17:23:19,384] m-LoRA: Adapter lora_finqa_85 without lr_scheduler.
[2025-12-23 17:23:19,384] m-LoRA: Adapter lora_finqa_86 without lr_scheduler.
[2025-12-23 17:23:19,384] m-LoRA: Adapter lora_finqa_87 without lr_scheduler.
[2025-12-23 17:23:19,384] m-LoRA: Adapter lora_finqa_88 without lr_scheduler.
[2025-12-23 17:23:19,384] m-LoRA: Adapter lora_finqa_89 without lr_scheduler.
[2025-12-23 17:23:19,391] m-LoRA: DeviceSwapQueue - input_data_queue start.
[2025-12-23 17:23:19,391] m-LoRA: RANK-0 in device cuda:0 to load module layers from 0 to 8.
[2025-12-23 17:23:19,393] m-LoRA: DeviceSwapQueue - ACTIVATIONS_send start.
[2025-12-23 17:23:19,393] m-LoRA: DeviceSwapQueue - GRADIENTS_send start.
[2025-12-23 17:23:19,394] m-LoRA: DeviceSwapQueue - ACTIVATIONS_recv start.
[2025-12-23 17:23:19,394] m-LoRA: DeviceSwapQueue - GRADIENTS_recv start.
[2025-12-23 17:23:23,305] m-LoRA: Init rpc with rank 0 world_size: 4
[2025-12-23 17:23:23,306] m-LoRA: Init train : task_finqa_0 task with adapters: ['lora_finqa_0']
[2025-12-23 17:23:25,404] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:23:25,682] m-LoRA: Adapter lora_finqa_0 data size: 128
[2025-12-23 17:23:25,687] m-LoRA: Init train : task_finqa_1 task with adapters: ['lora_finqa_1']
[2025-12-23 17:23:26,884] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:23:27,149] m-LoRA: Adapter lora_finqa_1 data size: 128
[2025-12-23 17:23:27,155] m-LoRA: Init train : task_finqa_2 task with adapters: ['lora_finqa_2']
[2025-12-23 17:23:27,267] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:23:27,566] m-LoRA: Adapter lora_finqa_2 data size: 128
[2025-12-23 17:23:27,582] m-LoRA: Init train : task_finqa_3 task with adapters: ['lora_finqa_3']
[2025-12-23 17:23:29,095] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:23:29,387] m-LoRA: Adapter lora_finqa_3 data size: 128
[2025-12-23 17:23:29,401] m-LoRA: Init train : task_finqa_4 task with adapters: ['lora_finqa_4']
[2025-12-23 17:23:30,759] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:23:31,036] m-LoRA: Adapter lora_finqa_4 data size: 128
[2025-12-23 17:23:31,044] m-LoRA: Init train : task_finqa_5 task with adapters: ['lora_finqa_5']
[2025-12-23 17:23:32,594] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:23:32,858] m-LoRA: Adapter lora_finqa_5 data size: 128
[2025-12-23 17:23:32,868] m-LoRA: Init train : task_finqa_6 task with adapters: ['lora_finqa_6']
[2025-12-23 17:23:33,069] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:23:33,342] m-LoRA: Adapter lora_finqa_6 data size: 128
[2025-12-23 17:23:33,355] m-LoRA: Init train : task_finqa_7 task with adapters: ['lora_finqa_7']
[2025-12-23 17:23:34,741] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:23:34,998] m-LoRA: Adapter lora_finqa_7 data size: 128
[2025-12-23 17:23:35,009] m-LoRA: Init train : task_finqa_8 task with adapters: ['lora_finqa_8']
[2025-12-23 17:23:37,036] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:23:37,295] m-LoRA: Adapter lora_finqa_8 data size: 128
[2025-12-23 17:23:37,300] m-LoRA: Init train : task_finqa_9 task with adapters: ['lora_finqa_9']
[2025-12-23 17:23:39,133] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:23:39,376] m-LoRA: Adapter lora_finqa_9 data size: 128
[2025-12-23 17:23:39,383] m-LoRA: Init train : task_finqa_10 task with adapters: ['lora_finqa_10']
[2025-12-23 17:23:40,801] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:23:41,075] m-LoRA: Adapter lora_finqa_10 data size: 128
[2025-12-23 17:23:41,086] m-LoRA: Init train : task_finqa_11 task with adapters: ['lora_finqa_11']
[2025-12-23 17:23:42,288] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:23:42,558] m-LoRA: Adapter lora_finqa_11 data size: 128
[2025-12-23 17:23:42,564] m-LoRA: Init train : task_finqa_12 task with adapters: ['lora_finqa_12']
[2025-12-23 17:23:44,434] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:23:44,697] m-LoRA: Adapter lora_finqa_12 data size: 128
[2025-12-23 17:23:44,704] m-LoRA: Init train : task_finqa_13 task with adapters: ['lora_finqa_13']
[2025-12-23 17:23:46,344] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:23:46,626] m-LoRA: Adapter lora_finqa_13 data size: 128
[2025-12-23 17:23:46,632] m-LoRA: Init train : task_finqa_14 task with adapters: ['lora_finqa_14']
[2025-12-23 17:23:46,705] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:23:46,980] m-LoRA: Adapter lora_finqa_14 data size: 128
[2025-12-23 17:23:46,988] m-LoRA: Init train : task_finqa_15 task with adapters: ['lora_finqa_15']
[2025-12-23 17:23:48,672] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:23:48,925] m-LoRA: Adapter lora_finqa_15 data size: 128
[2025-12-23 17:23:48,930] m-LoRA: Init train : task_finqa_16 task with adapters: ['lora_finqa_16']
[2025-12-23 17:23:50,522] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:23:50,780] m-LoRA: Adapter lora_finqa_16 data size: 128
[2025-12-23 17:23:50,787] m-LoRA: Init train : task_finqa_17 task with adapters: ['lora_finqa_17']
[2025-12-23 17:23:51,346] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:23:51,618] m-LoRA: Adapter lora_finqa_17 data size: 128
[2025-12-23 17:23:51,624] m-LoRA: Init train : task_finqa_18 task with adapters: ['lora_finqa_18']
[2025-12-23 17:23:52,278] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:23:52,550] m-LoRA: Adapter lora_finqa_18 data size: 128
[2025-12-23 17:23:52,557] m-LoRA: Init train : task_finqa_19 task with adapters: ['lora_finqa_19']
[2025-12-23 17:23:54,062] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:23:54,319] m-LoRA: Adapter lora_finqa_19 data size: 128
[2025-12-23 17:23:54,330] m-LoRA: Init train : task_finqa_20 task with adapters: ['lora_finqa_20']
[2025-12-23 17:23:56,124] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:23:56,402] m-LoRA: Adapter lora_finqa_20 data size: 128
[2025-12-23 17:23:56,409] m-LoRA: Init train : task_finqa_21 task with adapters: ['lora_finqa_21']
[2025-12-23 17:23:57,935] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:23:58,177] m-LoRA: Adapter lora_finqa_21 data size: 128
[2025-12-23 17:23:58,184] m-LoRA: Init train : task_finqa_22 task with adapters: ['lora_finqa_22']
[2025-12-23 17:23:58,302] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:23:58,547] m-LoRA: Adapter lora_finqa_22 data size: 128
[2025-12-23 17:23:58,555] m-LoRA: Init train : task_finqa_23 task with adapters: ['lora_finqa_23']
[2025-12-23 17:24:00,027] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:24:00,284] m-LoRA: Adapter lora_finqa_23 data size: 128
[2025-12-23 17:24:00,290] m-LoRA: Init train : task_finqa_24 task with adapters: ['lora_finqa_24']
[2025-12-23 17:24:01,772] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:24:02,035] m-LoRA: Adapter lora_finqa_24 data size: 128
[2025-12-23 17:24:02,041] m-LoRA: Init train : task_finqa_25 task with adapters: ['lora_finqa_25']
[2025-12-23 17:24:02,390] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:24:02,644] m-LoRA: Adapter lora_finqa_25 data size: 128
[2025-12-23 17:24:02,652] m-LoRA: Init train : task_finqa_26 task with adapters: ['lora_finqa_26']
[2025-12-23 17:24:04,423] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:24:04,679] m-LoRA: Adapter lora_finqa_26 data size: 128
[2025-12-23 17:24:04,686] m-LoRA: Init train : task_finqa_27 task with adapters: ['lora_finqa_27']
[2025-12-23 17:24:06,672] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:24:06,931] m-LoRA: Adapter lora_finqa_27 data size: 128
[2025-12-23 17:24:06,936] m-LoRA: Init train : task_finqa_28 task with adapters: ['lora_finqa_28']
[2025-12-23 17:24:08,614] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:24:08,879] m-LoRA: Adapter lora_finqa_28 data size: 128
[2025-12-23 17:24:08,886] m-LoRA: Init train : task_finqa_29 task with adapters: ['lora_finqa_29']
[2025-12-23 17:24:09,004] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:24:09,272] m-LoRA: Adapter lora_finqa_29 data size: 128
[2025-12-23 17:24:09,281] m-LoRA: Init train : task_finqa_30 task with adapters: ['lora_finqa_30']
[2025-12-23 17:24:11,004] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:24:11,253] m-LoRA: Adapter lora_finqa_30 data size: 128
[2025-12-23 17:24:11,259] m-LoRA: Init train : task_finqa_31 task with adapters: ['lora_finqa_31']
[2025-12-23 17:24:12,673] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:24:12,939] m-LoRA: Adapter lora_finqa_31 data size: 128
[2025-12-23 17:24:12,944] m-LoRA: Init train : task_finqa_32 task with adapters: ['lora_finqa_32']
[2025-12-23 17:24:13,048] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:24:13,312] m-LoRA: Adapter lora_finqa_32 data size: 128
[2025-12-23 17:24:13,318] m-LoRA: Init train : task_finqa_33 task with adapters: ['lora_finqa_33']
[2025-12-23 17:24:14,916] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:24:15,170] m-LoRA: Adapter lora_finqa_33 data size: 128
[2025-12-23 17:24:15,176] m-LoRA: Init train : task_finqa_34 task with adapters: ['lora_finqa_34']
[2025-12-23 17:24:17,031] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:24:17,302] m-LoRA: Adapter lora_finqa_34 data size: 128
[2025-12-23 17:24:17,307] m-LoRA: Init train : task_finqa_35 task with adapters: ['lora_finqa_35']
[2025-12-23 17:24:19,075] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:24:19,334] m-LoRA: Adapter lora_finqa_35 data size: 128
[2025-12-23 17:24:19,339] m-LoRA: Init train : task_finqa_36 task with adapters: ['lora_finqa_36']
[2025-12-23 17:24:20,283] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:24:20,537] m-LoRA: Adapter lora_finqa_36 data size: 128
[2025-12-23 17:24:20,543] m-LoRA: Init train : task_finqa_37 task with adapters: ['lora_finqa_37']
[2025-12-23 17:24:22,048] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:24:22,300] m-LoRA: Adapter lora_finqa_37 data size: 128
[2025-12-23 17:24:22,312] m-LoRA: Init train : task_finqa_38 task with adapters: ['lora_finqa_38']
[2025-12-23 17:24:23,647] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:24:23,909] m-LoRA: Adapter lora_finqa_38 data size: 128
[2025-12-23 17:24:23,915] m-LoRA: Init train : task_finqa_39 task with adapters: ['lora_finqa_39']
[2025-12-23 17:24:24,463] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:24:24,713] m-LoRA: Adapter lora_finqa_39 data size: 128
[2025-12-23 17:24:24,722] m-LoRA: Init train : task_finqa_40 task with adapters: ['lora_finqa_40']
[2025-12-23 17:24:26,297] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:24:26,553] m-LoRA: Adapter lora_finqa_40 data size: 128
[2025-12-23 17:24:26,559] m-LoRA: Init train : task_finqa_41 task with adapters: ['lora_finqa_41']
[2025-12-23 17:24:27,341] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:24:27,629] m-LoRA: Adapter lora_finqa_41 data size: 128
[2025-12-23 17:24:27,636] m-LoRA: Init train : task_finqa_42 task with adapters: ['lora_finqa_42']
[2025-12-23 17:24:28,510] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:24:28,781] m-LoRA: Adapter lora_finqa_42 data size: 128
[2025-12-23 17:24:28,787] m-LoRA: Init train : task_finqa_43 task with adapters: ['lora_finqa_43']
[2025-12-23 17:24:30,276] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:24:30,540] m-LoRA: Adapter lora_finqa_43 data size: 128
[2025-12-23 17:24:30,547] m-LoRA: Init train : task_finqa_44 task with adapters: ['lora_finqa_44']
[2025-12-23 17:24:32,338] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:24:32,595] m-LoRA: Adapter lora_finqa_44 data size: 128
[2025-12-23 17:24:32,601] m-LoRA: Init train : task_finqa_45 task with adapters: ['lora_finqa_45']
[2025-12-23 17:24:34,343] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:24:34,620] m-LoRA: Adapter lora_finqa_45 data size: 128
[2025-12-23 17:24:34,626] m-LoRA: Init train : task_finqa_46 task with adapters: ['lora_finqa_46']
[2025-12-23 17:24:36,419] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:24:36,688] m-LoRA: Adapter lora_finqa_46 data size: 128
[2025-12-23 17:24:36,694] m-LoRA: Init train : task_finqa_47 task with adapters: ['lora_finqa_47']
[2025-12-23 17:24:38,737] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:24:38,982] m-LoRA: Adapter lora_finqa_47 data size: 128
[2025-12-23 17:24:38,988] m-LoRA: Init train : task_finqa_48 task with adapters: ['lora_finqa_48']
[2025-12-23 17:24:40,752] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:24:41,015] m-LoRA: Adapter lora_finqa_48 data size: 128
[2025-12-23 17:24:41,025] m-LoRA: Init train : task_finqa_49 task with adapters: ['lora_finqa_49']
[2025-12-23 17:24:43,051] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:24:43,314] m-LoRA: Adapter lora_finqa_49 data size: 128
[2025-12-23 17:24:43,320] m-LoRA: Init train : task_finqa_50 task with adapters: ['lora_finqa_50']
[2025-12-23 17:24:44,807] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:24:45,070] m-LoRA: Adapter lora_finqa_50 data size: 128
[2025-12-23 17:24:45,076] m-LoRA: Init train : task_finqa_51 task with adapters: ['lora_finqa_51']
[2025-12-23 17:24:45,287] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:24:45,557] m-LoRA: Adapter lora_finqa_51 data size: 128
[2025-12-23 17:24:45,564] m-LoRA: Init train : task_finqa_52 task with adapters: ['lora_finqa_52']
[2025-12-23 17:24:47,261] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:24:47,532] m-LoRA: Adapter lora_finqa_52 data size: 128
[2025-12-23 17:24:47,538] m-LoRA: Init train : task_finqa_53 task with adapters: ['lora_finqa_53']
[2025-12-23 17:24:48,637] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:24:48,921] m-LoRA: Adapter lora_finqa_53 data size: 128
[2025-12-23 17:24:48,936] m-LoRA: Init train : task_finqa_54 task with adapters: ['lora_finqa_54']
[2025-12-23 17:24:49,343] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:24:49,607] m-LoRA: Adapter lora_finqa_54 data size: 128
[2025-12-23 17:24:49,615] m-LoRA: Init train : task_finqa_55 task with adapters: ['lora_finqa_55']
[2025-12-23 17:24:51,197] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:24:51,457] m-LoRA: Adapter lora_finqa_55 data size: 128
[2025-12-23 17:24:51,464] m-LoRA: Init train : task_finqa_56 task with adapters: ['lora_finqa_56']
[2025-12-23 17:24:53,411] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:24:53,688] m-LoRA: Adapter lora_finqa_56 data size: 128
[2025-12-23 17:24:53,694] m-LoRA: Init train : task_finqa_57 task with adapters: ['lora_finqa_57']
[2025-12-23 17:24:54,895] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:24:55,160] m-LoRA: Adapter lora_finqa_57 data size: 128
[2025-12-23 17:24:55,166] m-LoRA: Init train : task_finqa_58 task with adapters: ['lora_finqa_58']
[2025-12-23 17:24:56,258] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:24:56,528] m-LoRA: Adapter lora_finqa_58 data size: 128
[2025-12-23 17:24:56,536] m-LoRA: Init train : task_finqa_59 task with adapters: ['lora_finqa_59']
[2025-12-23 17:24:57,815] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:24:58,083] m-LoRA: Adapter lora_finqa_59 data size: 128
[2025-12-23 17:24:58,089] m-LoRA: Init train : task_finqa_60 task with adapters: ['lora_finqa_60']
[2025-12-23 17:24:58,166] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:24:58,468] m-LoRA: Adapter lora_finqa_60 data size: 128
[2025-12-23 17:24:58,474] m-LoRA: Init train : task_finqa_61 task with adapters: ['lora_finqa_61']
[2025-12-23 17:24:59,312] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:24:59,576] m-LoRA: Adapter lora_finqa_61 data size: 128
[2025-12-23 17:24:59,583] m-LoRA: Init train : task_finqa_62 task with adapters: ['lora_finqa_62']
[2025-12-23 17:25:01,076] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:25:01,324] m-LoRA: Adapter lora_finqa_62 data size: 128
[2025-12-23 17:25:01,330] m-LoRA: Init train : task_finqa_63 task with adapters: ['lora_finqa_63']
[2025-12-23 17:25:01,458] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:25:01,720] m-LoRA: Adapter lora_finqa_63 data size: 128
[2025-12-23 17:25:01,727] m-LoRA: Init train : task_finqa_64 task with adapters: ['lora_finqa_64']
[2025-12-23 17:25:03,683] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:25:03,949] m-LoRA: Adapter lora_finqa_64 data size: 128
[2025-12-23 17:25:03,955] m-LoRA: Init train : task_finqa_65 task with adapters: ['lora_finqa_65']
[2025-12-23 17:25:05,564] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:25:05,830] m-LoRA: Adapter lora_finqa_65 data size: 128
[2025-12-23 17:25:05,837] m-LoRA: Init train : task_finqa_66 task with adapters: ['lora_finqa_66']
[2025-12-23 17:25:07,808] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:25:08,066] m-LoRA: Adapter lora_finqa_66 data size: 128
[2025-12-23 17:25:08,071] m-LoRA: Init train : task_finqa_67 task with adapters: ['lora_finqa_67']
[2025-12-23 17:25:09,677] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:25:09,948] m-LoRA: Adapter lora_finqa_67 data size: 128
[2025-12-23 17:25:09,954] m-LoRA: Init train : task_finqa_68 task with adapters: ['lora_finqa_68']
[2025-12-23 17:25:11,810] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:25:12,068] m-LoRA: Adapter lora_finqa_68 data size: 128
[2025-12-23 17:25:12,074] m-LoRA: Init train : task_finqa_69 task with adapters: ['lora_finqa_69']
[2025-12-23 17:25:13,784] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:25:14,043] m-LoRA: Adapter lora_finqa_69 data size: 128
[2025-12-23 17:25:14,049] m-LoRA: Init train : task_finqa_70 task with adapters: ['lora_finqa_70']
[2025-12-23 17:25:15,964] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:25:16,235] m-LoRA: Adapter lora_finqa_70 data size: 128
[2025-12-23 17:25:16,246] m-LoRA: Init train : task_finqa_71 task with adapters: ['lora_finqa_71']
[2025-12-23 17:25:18,088] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:25:18,348] m-LoRA: Adapter lora_finqa_71 data size: 128
[2025-12-23 17:25:18,354] m-LoRA: Init train : task_finqa_72 task with adapters: ['lora_finqa_72']
[2025-12-23 17:25:20,171] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:25:20,454] m-LoRA: Adapter lora_finqa_72 data size: 128
[2025-12-23 17:25:20,466] m-LoRA: Init train : task_finqa_73 task with adapters: ['lora_finqa_73']
[2025-12-23 17:25:22,419] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:25:22,678] m-LoRA: Adapter lora_finqa_73 data size: 128
[2025-12-23 17:25:22,684] m-LoRA: Init train : task_finqa_74 task with adapters: ['lora_finqa_74']
[2025-12-23 17:25:24,604] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:25:24,861] m-LoRA: Adapter lora_finqa_74 data size: 128
[2025-12-23 17:25:24,868] m-LoRA: Init train : task_finqa_75 task with adapters: ['lora_finqa_75']
[2025-12-23 17:25:26,514] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:25:26,772] m-LoRA: Adapter lora_finqa_75 data size: 128
[2025-12-23 17:25:26,778] m-LoRA: Init train : task_finqa_76 task with adapters: ['lora_finqa_76']
[2025-12-23 17:25:26,905] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:25:27,175] m-LoRA: Adapter lora_finqa_76 data size: 128
[2025-12-23 17:25:27,183] m-LoRA: Init train : task_finqa_77 task with adapters: ['lora_finqa_77']
[2025-12-23 17:25:28,309] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:25:28,590] m-LoRA: Adapter lora_finqa_77 data size: 128
[2025-12-23 17:25:28,606] m-LoRA: Init train : task_finqa_78 task with adapters: ['lora_finqa_78']
[2025-12-23 17:25:30,000] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:25:30,276] m-LoRA: Adapter lora_finqa_78 data size: 128
[2025-12-23 17:25:30,282] m-LoRA: Init train : task_finqa_79 task with adapters: ['lora_finqa_79']
[2025-12-23 17:25:31,913] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:25:32,198] m-LoRA: Adapter lora_finqa_79 data size: 128
[2025-12-23 17:25:32,208] m-LoRA: Init train : task_finqa_80 task with adapters: ['lora_finqa_80']
[2025-12-23 17:25:33,180] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:25:33,455] m-LoRA: Adapter lora_finqa_80 data size: 128
[2025-12-23 17:25:33,462] m-LoRA: Init train : task_finqa_81 task with adapters: ['lora_finqa_81']
[2025-12-23 17:25:35,347] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:25:35,622] m-LoRA: Adapter lora_finqa_81 data size: 128
[2025-12-23 17:25:35,633] m-LoRA: Init train : task_finqa_82 task with adapters: ['lora_finqa_82']
[2025-12-23 17:25:37,422] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:25:37,690] m-LoRA: Adapter lora_finqa_82 data size: 128
[2025-12-23 17:25:37,696] m-LoRA: Init train : task_finqa_83 task with adapters: ['lora_finqa_83']
[2025-12-23 17:25:39,246] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:25:39,512] m-LoRA: Adapter lora_finqa_83 data size: 128
[2025-12-23 17:25:39,518] m-LoRA: Init train : task_finqa_84 task with adapters: ['lora_finqa_84']
[2025-12-23 17:25:39,597] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:25:39,850] m-LoRA: Adapter lora_finqa_84 data size: 128
[2025-12-23 17:25:39,862] m-LoRA: Init train : task_finqa_85 task with adapters: ['lora_finqa_85']
[2025-12-23 17:25:40,757] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:25:41,031] m-LoRA: Adapter lora_finqa_85 data size: 128
[2025-12-23 17:25:41,065] m-LoRA: Init train : task_finqa_86 task with adapters: ['lora_finqa_86']
[2025-12-23 17:25:42,646] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:25:42,892] m-LoRA: Adapter lora_finqa_86 data size: 128
[2025-12-23 17:25:42,898] m-LoRA: Init train : task_finqa_87 task with adapters: ['lora_finqa_87']
[2025-12-23 17:25:43,091] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:25:43,340] m-LoRA: Adapter lora_finqa_87 data size: 128
[2025-12-23 17:25:43,346] m-LoRA: Init train : task_finqa_88 task with adapters: ['lora_finqa_88']
[2025-12-23 17:25:44,575] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:25:44,834] m-LoRA: Adapter lora_finqa_88 data size: 128
[2025-12-23 17:25:44,841] m-LoRA: Init train : task_finqa_89 task with adapters: ['lora_finqa_89']
[2025-12-23 17:25:45,316] m-LoRA: Task load data from /scr/dataset/yuke/zien/mLoRA/zien_work/baseline/data/finqa_train_subset_128.json
[2025-12-23 17:25:45,577] m-LoRA: Adapter lora_finqa_89 data size: 128
[2025-12-23 17:25:45,594] m-LoRA: Task to running, need to load adapters: ['lora_finqa_0']
[2025-12-23 17:25:45,641] m-LoRA: Task to running, need to load adapters: ['lora_finqa_1']
[2025-12-23 17:25:45,682] m-LoRA: Task to running, need to load adapters: ['lora_finqa_2']
[2025-12-23 17:25:45,773] m-LoRA: Task to running, need to load adapters: ['lora_finqa_3']
[2025-12-23 17:25:45,831] m-LoRA: Task to running, need to load adapters: ['lora_finqa_4']
[2025-12-23 17:25:46,014] m-LoRA: Task to running, need to load adapters: ['lora_finqa_5']
[2025-12-23 17:25:46,189] m-LoRA: Task to running, need to load adapters: ['lora_finqa_6']
[2025-12-23 17:25:46,360] m-LoRA: Task to running, need to load adapters: ['lora_finqa_7']
[2025-12-23 17:25:46,495] m-LoRA: Task to running, need to load adapters: ['lora_finqa_8']
[2025-12-23 17:25:46,612] m-LoRA: Task to running, need to load adapters: ['lora_finqa_9']
[2025-12-23 17:25:46,762] m-LoRA: Task to running, need to load adapters: ['lora_finqa_10']
[2025-12-23 17:25:46,806] m-LoRA: Task to running, need to load adapters: ['lora_finqa_11']
[2025-12-23 17:25:46,837] m-LoRA: Task to running, need to load adapters: ['lora_finqa_12']
[2025-12-23 17:25:46,965] m-LoRA: Task to running, need to load adapters: ['lora_finqa_13']
[2025-12-23 17:25:47,033] m-LoRA: Task to running, need to load adapters: ['lora_finqa_14']
[2025-12-23 17:25:47,077] m-LoRA: Task to running, need to load adapters: ['lora_finqa_15']
[2025-12-23 17:25:47,198] m-LoRA: Task to running, need to load adapters: ['lora_finqa_16']
[2025-12-23 17:25:47,315] m-LoRA: Task to running, need to load adapters: ['lora_finqa_17']
[2025-12-23 17:25:47,368] m-LoRA: Task to running, need to load adapters: ['lora_finqa_18']
[2025-12-23 17:25:47,431] m-LoRA: Task to running, need to load adapters: ['lora_finqa_19']
[2025-12-23 17:25:47,465] m-LoRA: Task to running, need to load adapters: ['lora_finqa_20']
[2025-12-23 17:25:47,591] m-LoRA: Task to running, need to load adapters: ['lora_finqa_21']
[2025-12-23 17:25:47,660] m-LoRA: Task to running, need to load adapters: ['lora_finqa_22']
[2025-12-23 17:25:47,726] m-LoRA: Task to running, need to load adapters: ['lora_finqa_23']
[2025-12-23 17:25:47,847] m-LoRA: Task to running, need to load adapters: ['lora_finqa_24']
[2025-12-23 17:25:47,960] m-LoRA: Task to running, need to load adapters: ['lora_finqa_25']
[2025-12-23 17:25:48,051] m-LoRA: Task to running, need to load adapters: ['lora_finqa_26']
[2025-12-23 17:25:48,127] m-LoRA: Task to running, need to load adapters: ['lora_finqa_27']
[2025-12-23 17:25:48,254] m-LoRA: Task to running, need to load adapters: ['lora_finqa_28']
[2025-12-23 17:25:48,381] m-LoRA: Task to running, need to load adapters: ['lora_finqa_29']
[2025-12-23 17:25:48,455] m-LoRA: Task to running, need to load adapters: ['lora_finqa_30']
[2025-12-23 17:25:48,582] m-LoRA: Task to running, need to load adapters: ['lora_finqa_31']
[2025-12-23 17:25:48,703] m-LoRA: Task to running, need to load adapters: ['lora_finqa_32']
[2025-12-23 17:25:48,759] m-LoRA: Adapter lora_finqa_0 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:25:49,111] m-LoRA: Adapter lora_finqa_1 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:25:49,143] m-LoRA: Adapter lora_finqa_2 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:25:49,335] m-LoRA: Adapter lora_finqa_3 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:25:49,364] m-LoRA: Adapter lora_finqa_4 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:25:49,561] m-LoRA: Adapter lora_finqa_5 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:25:49,758] m-LoRA: Adapter lora_finqa_6 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:25:49,861] m-LoRA: Adapter lora_finqa_7 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:25:49,892] m-LoRA: Adapter lora_finqa_8 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:25:49,924] m-LoRA: Adapter lora_finqa_9 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:25:50,027] m-LoRA: Adapter lora_finqa_10 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:25:50,077] m-LoRA: Adapter lora_finqa_11 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:25:50,126] m-LoRA: Adapter lora_finqa_12 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:25:50,234] m-LoRA: Adapter lora_finqa_13 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:25:50,300] m-LoRA: Adapter lora_finqa_14 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:25:50,475] m-LoRA: Adapter lora_finqa_15 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:25:50,530] m-LoRA: Adapter lora_finqa_16 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:25:50,563] m-LoRA: Adapter lora_finqa_17 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:25:50,658] m-LoRA: Adapter lora_finqa_18 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:25:50,710] m-LoRA: Adapter lora_finqa_19 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:25:50,803] m-LoRA: Adapter lora_finqa_20 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:25:51,024] m-LoRA: Adapter lora_finqa_21 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:25:51,080] m-LoRA: Adapter lora_finqa_22 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:25:51,180] m-LoRA: Adapter lora_finqa_23 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:25:51,213] m-LoRA: Adapter lora_finqa_24 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:25:51,417] m-LoRA: Adapter lora_finqa_25 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:25:51,470] m-LoRA: Adapter lora_finqa_26 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:25:51,530] m-LoRA: Adapter lora_finqa_27 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:25:51,588] m-LoRA: Adapter lora_finqa_28 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:25:51,783] m-LoRA: Adapter lora_finqa_29 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:25:51,880] m-LoRA: Adapter lora_finqa_30 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:25:52,004] m-LoRA: Adapter lora_finqa_0 loss: 2.5885283946990967
[2025-12-23 17:25:52,009] m-LoRA: Adapter lora_finqa_31 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:25:52,225] m-LoRA: Adapter lora_finqa_32 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:25:52,510] m-LoRA: Adapter lora_finqa_3 loss: 2.5885283946990967
[2025-12-23 17:25:55,529] m-LoRA: Adapter lora_finqa_2 loss: 2.5885279178619385
[2025-12-23 17:25:56,163] m-LoRA: Adapter lora_finqa_1 loss: 2.5885283946990967
[2025-12-23 17:25:56,167] m-LoRA: Adapter lora_finqa_0 epoch: 1/1 iteration: 2/128 step: 2
[2025-12-23 17:25:56,357] m-LoRA: Adapter lora_finqa_3 epoch: 1/1 iteration: 2/128 step: 2
[2025-12-23 17:25:58,874] m-LoRA: Adapter lora_finqa_4 loss: 2.5885279178619385
[2025-12-23 17:26:01,186] m-LoRA: Adapter lora_finqa_5 loss: 2.5885279178619385
[2025-12-23 17:26:01,578] m-LoRA: Adapter lora_finqa_2 epoch: 1/1 iteration: 16/128 step: 2
[2025-12-23 17:26:02,523] m-LoRA: Adapter lora_finqa_6 loss: 2.588528633117676
[2025-12-23 17:26:02,532] m-LoRA: Adapter lora_finqa_1 epoch: 1/1 iteration: 2/128 step: 2
[2025-12-23 17:26:02,779] m-LoRA: Adapter lora_finqa_7 loss: 2.5885283946990967
[2025-12-23 17:26:03,015] m-LoRA: Adapter lora_finqa_8 loss: 2.5885283946990967
[2025-12-23 17:26:04,079] m-LoRA: Adapter lora_finqa_9 loss: 2.588528633117676
[2025-12-23 17:26:04,642] m-LoRA: Adapter lora_finqa_4 epoch: 1/1 iteration: 16/128 step: 2
[2025-12-23 17:26:05,125] m-LoRA: Adapter lora_finqa_10 loss: 2.5885279178619385
[2025-12-23 17:26:05,643] m-LoRA: Adapter lora_finqa_11 loss: 2.5885279178619385
[2025-12-23 17:26:06,318] m-LoRA: Adapter lora_finqa_13 loss: 2.5885279178619385
[2025-12-23 17:26:06,513] m-LoRA: Adapter lora_finqa_5 epoch: 1/1 iteration: 16/128 step: 2
[2025-12-23 17:26:07,686] m-LoRA: Adapter lora_finqa_12 loss: 2.588528633117676
[2025-12-23 17:26:07,800] m-LoRA: Adapter lora_finqa_6 epoch: 1/1 iteration: 8/128 step: 2
[2025-12-23 17:26:10,345] m-LoRA: Adapter lora_finqa_14 loss: 2.5885279178619385
[2025-12-23 17:26:10,362] m-LoRA: Adapter lora_finqa_7 epoch: 1/1 iteration: 2/128 step: 2
[2025-12-23 17:26:10,827] m-LoRA: Adapter lora_finqa_15 loss: 2.5885283946990967
[2025-12-23 17:26:10,830] m-LoRA: Adapter lora_finqa_8 epoch: 1/1 iteration: 2/128 step: 2
[2025-12-23 17:26:10,957] m-LoRA: Adapter lora_finqa_16 loss: 2.5885283946990967
[2025-12-23 17:26:11,061] m-LoRA: Adapter lora_finqa_9 epoch: 1/1 iteration: 8/128 step: 2
[2025-12-23 17:26:12,387] m-LoRA: Adapter lora_finqa_17 loss: 2.588528633117676
[2025-12-23 17:26:12,396] m-LoRA: Adapter lora_finqa_10 epoch: 1/1 iteration: 4/128 step: 2
[2025-12-23 17:26:12,975] m-LoRA: Adapter lora_finqa_18 loss: 2.5885279178619385
[2025-12-23 17:26:12,980] m-LoRA: Adapter lora_finqa_11 epoch: 1/1 iteration: 4/128 step: 2
[2025-12-23 17:26:14,204] m-LoRA: Adapter lora_finqa_19 loss: 2.588528633117676
[2025-12-23 17:26:14,215] m-LoRA: Adapter lora_finqa_13 epoch: 1/1 iteration: 4/128 step: 2
[2025-12-23 17:26:16,570] m-LoRA: Adapter lora_finqa_20 loss: 2.5885279178619385
[2025-12-23 17:26:16,716] m-LoRA: Adapter lora_finqa_12 epoch: 1/1 iteration: 8/128 step: 2
[2025-12-23 17:26:17,906] m-LoRA: Adapter lora_finqa_22 loss: 2.588528633117676
[2025-12-23 17:26:18,123] m-LoRA: Adapter lora_finqa_14 epoch: 1/1 iteration: 16/128 step: 2
[2025-12-23 17:26:18,677] m-LoRA: Adapter lora_finqa_21 loss: 2.5885279178619385
[2025-12-23 17:26:18,682] m-LoRA: Adapter lora_finqa_15 epoch: 1/1 iteration: 2/128 step: 2
[2025-12-23 17:26:19,123] m-LoRA: Adapter lora_finqa_23 loss: 2.5885283946990967
[2025-12-23 17:26:19,127] m-LoRA: Adapter lora_finqa_16 epoch: 1/1 iteration: 2/128 step: 2
[2025-12-23 17:26:23,077] m-LoRA: Adapter lora_finqa_24 loss: 2.5885279178619385
[2025-12-23 17:26:23,308] m-LoRA: Adapter lora_finqa_25 loss: 2.5885283946990967
[2025-12-23 17:26:23,311] m-LoRA: Adapter lora_finqa_17 epoch: 1/1 iteration: 8/128 step: 2
[2025-12-23 17:26:23,822] m-LoRA: Adapter lora_finqa_26 loss: 2.5885279178619385
[2025-12-23 17:26:23,828] m-LoRA: Adapter lora_finqa_18 epoch: 1/1 iteration: 4/128 step: 2
[2025-12-23 17:26:24,099] m-LoRA: Adapter lora_finqa_27 loss: 2.5885279178619385
[2025-12-23 17:26:24,105] m-LoRA: Adapter lora_finqa_19 epoch: 1/1 iteration: 8/128 step: 2
[2025-12-23 17:26:28,564] m-LoRA: Adapter lora_finqa_28 loss: 2.5885279178619385
[2025-12-23 17:26:28,947] m-LoRA: Adapter lora_finqa_20 epoch: 1/1 iteration: 16/128 step: 2
[2025-12-23 17:26:31,157] m-LoRA: Adapter lora_finqa_29 loss: 2.588528633117676
[2025-12-23 17:26:31,364] m-LoRA: Adapter lora_finqa_22 epoch: 1/1 iteration: 8/128 step: 2
[2025-12-23 17:26:33,662] m-LoRA: Adapter lora_finqa_30 loss: 2.588528633117676
[2025-12-23 17:26:33,672] m-LoRA: Adapter lora_finqa_21 epoch: 1/1 iteration: 4/128 step: 2
[2025-12-23 17:26:38,368] m-LoRA: Adapter lora_finqa_31 loss: 2.5885279178619385
[2025-12-23 17:26:38,387] m-LoRA: Adapter lora_finqa_23 epoch: 1/1 iteration: 2/128 step: 2
[2025-12-23 17:26:38,842] m-LoRA: Adapter lora_finqa_32 loss: 2.5885279178619385
[2025-12-23 17:26:39,176] m-LoRA: Adapter lora_finqa_24 epoch: 1/1 iteration: 16/128 step: 2
[2025-12-23 17:26:39,600] m-LoRA: Adapter lora_finqa_0 loss: 2.545104742050171
[2025-12-23 17:26:39,603] m-LoRA: Adapter lora_finqa_25 epoch: 1/1 iteration: 2/128 step: 2
[2025-12-23 17:26:39,750] m-LoRA: Adapter lora_finqa_3 loss: 2.5419201850891113
[2025-12-23 17:26:39,754] m-LoRA: Adapter lora_finqa_26 epoch: 1/1 iteration: 4/128 step: 2
[2025-12-23 17:26:42,700] m-LoRA: Adapter lora_finqa_2 loss: 2.5848934650421143
[2025-12-23 17:26:42,717] m-LoRA: Adapter lora_finqa_27 epoch: 1/1 iteration: 4/128 step: 2
[2025-12-23 17:26:44,078] m-LoRA: Adapter lora_finqa_1 loss: 2.5427613258361816
[2025-12-23 17:26:44,082] m-LoRA: Adapter lora_finqa_28 epoch: 1/1 iteration: 16/128 step: 2
[2025-12-23 17:26:47,656] m-LoRA: Adapter lora_finqa_4 loss: 2.3148391246795654
[2025-12-23 17:26:47,794] m-LoRA: Adapter lora_finqa_29 epoch: 1/1 iteration: 8/128 step: 2
[2025-12-23 17:26:52,250] m-LoRA: Adapter lora_finqa_5 loss: 2.4777965545654297
[2025-12-23 17:26:52,389] m-LoRA: Adapter lora_finqa_30 epoch: 1/1 iteration: 8/128 step: 2
[2025-12-23 17:26:54,773] m-LoRA: Adapter lora_finqa_6 loss: 2.317084550857544
[2025-12-23 17:26:54,975] m-LoRA: Adapter lora_finqa_31 epoch: 1/1 iteration: 16/128 step: 2
[2025-12-23 17:26:55,756] m-LoRA: Adapter lora_finqa_7 loss: 2.478285312652588
[2025-12-23 17:26:55,760] m-LoRA: Adapter lora_finqa_32 epoch: 1/1 iteration: 4/128 step: 2
[2025-12-23 17:26:56,451] m-LoRA: Adapter lora_finqa_8 loss: 2.479456901550293
[2025-12-23 17:26:56,455] m-LoRA: Adapter lora_finqa_0 epoch: 1/1 iteration: 4/128 step: 3
[2025-12-23 17:26:58,935] m-LoRA: Adapter lora_finqa_3 epoch: 1/1 iteration: 4/128 step: 3
[2025-12-23 17:26:59,000] m-LoRA: Adapter lora_finqa_9 loss: 2.3139731884002686
[2025-12-23 17:27:00,182] m-LoRA: Adapter lora_finqa_10 loss: 2.5443520545959473
[2025-12-23 17:27:00,337] m-LoRA: Adapter lora_finqa_2 epoch: 1/1 iteration: 32/128 step: 3
[2025-12-23 17:27:01,831] m-LoRA: Adapter lora_finqa_1 epoch: 1/1 iteration: 4/128 step: 3
[2025-12-23 17:27:01,887] m-LoRA: Adapter lora_finqa_11 loss: 2.5431323051452637
[2025-12-23 17:27:02,762] m-LoRA: Adapter lora_finqa_13 loss: 2.4724926948547363
[2025-12-23 17:27:03,061] m-LoRA: Adapter lora_finqa_4 epoch: 1/1 iteration: 32/128 step: 3
[2025-12-23 17:27:04,940] m-LoRA: Adapter lora_finqa_12 loss: 2.4789304733276367
[2025-12-23 17:27:05,147] m-LoRA: Adapter lora_finqa_5 epoch: 1/1 iteration: 32/128 step: 3
[2025-12-23 17:27:08,944] m-LoRA: Adapter lora_finqa_14 loss: 2.542339563369751
[2025-12-23 17:27:09,061] m-LoRA: Adapter lora_finqa_6 epoch: 1/1 iteration: 16/128 step: 3
[2025-12-23 17:27:09,540] m-LoRA: Adapter lora_finqa_15 loss: 2.318870782852173
[2025-12-23 17:27:09,545] m-LoRA: Adapter lora_finqa_7 epoch: 1/1 iteration: 4/128 step: 3
[2025-12-23 17:27:10,092] m-LoRA: Adapter lora_finqa_16 loss: 2.3157906532287598
[2025-12-23 17:27:10,095] m-LoRA: Adapter lora_finqa_8 epoch: 1/1 iteration: 4/128 step: 3
[2025-12-23 17:27:12,468] m-LoRA: Adapter lora_finqa_17 loss: 2.470754384994507
[2025-12-23 17:27:12,663] m-LoRA: Adapter lora_finqa_9 epoch: 1/1 iteration: 16/128 step: 3
[2025-12-23 17:27:13,107] m-LoRA: Adapter lora_finqa_10 epoch: 1/1 iteration: 8/128 step: 3
[2025-12-23 17:27:13,178] m-LoRA: Adapter lora_finqa_18 loss: 2.4718079566955566
[2025-12-23 17:27:14,268] m-LoRA: Adapter lora_finqa_11 epoch: 1/1 iteration: 8/128 step: 3
[2025-12-23 17:27:14,347] m-LoRA: Adapter lora_finqa_19 loss: 2.5446155071258545
[2025-12-23 17:27:18,460] m-LoRA: Adapter lora_finqa_20 loss: 2.31438946723938
[2025-12-23 17:27:18,533] m-LoRA: Adapter lora_finqa_13 epoch: 1/1 iteration: 8/128 step: 3
[2025-12-23 17:27:20,538] m-LoRA: Adapter lora_finqa_22 loss: 2.4730355739593506
[2025-12-23 17:27:20,729] m-LoRA: Adapter lora_finqa_12 epoch: 1/1 iteration: 16/128 step: 3
[2025-12-23 17:27:21,959] m-LoRA: Adapter lora_finqa_21 loss: 2.583679437637329
[2025-12-23 17:27:22,104] m-LoRA: Adapter lora_finqa_14 epoch: 1/1 iteration: 32/128 step: 3
[2025-12-23 17:27:22,574] m-LoRA: Adapter lora_finqa_23 loss: 2.318030834197998
[2025-12-23 17:27:22,577] m-LoRA: Adapter lora_finqa_15 epoch: 1/1 iteration: 4/128 step: 3
[2025-12-23 17:27:26,350] m-LoRA: Adapter lora_finqa_16 epoch: 1/1 iteration: 4/128 step: 3
[2025-12-23 17:27:26,546] m-LoRA: Adapter lora_finqa_24 loss: 2.3155765533447266
[2025-12-23 17:27:27,039] m-LoRA: Adapter lora_finqa_25 loss: 2.473344087600708
[2025-12-23 17:27:27,120] m-LoRA: Adapter lora_finqa_17 epoch: 1/1 iteration: 16/128 step: 3
[2025-12-23 17:27:28,171] m-LoRA: Adapter lora_finqa_18 epoch: 1/1 iteration: 8/128 step: 3
[2025-12-23 17:27:28,245] m-LoRA: Adapter lora_finqa_26 loss: 2.585033416748047
[2025-12-23 17:27:29,604] m-LoRA: Adapter lora_finqa_27 loss: 2.3183348178863525
[2025-12-23 17:27:29,610] m-LoRA: Adapter lora_finqa_19 epoch: 1/1 iteration: 16/128 step: 3
[2025-12-23 17:27:33,840] m-LoRA: Adapter lora_finqa_28 loss: 2.4771623611450195
[2025-12-23 17:27:34,216] m-LoRA: Adapter lora_finqa_20 epoch: 1/1 iteration: 32/128 step: 3
[2025-12-23 17:27:35,976] m-LoRA: Adapter lora_finqa_29 loss: 2.4716453552246094
[2025-12-23 17:27:36,182] m-LoRA: Adapter lora_finqa_22 epoch: 1/1 iteration: 16/128 step: 3
[2025-12-23 17:27:38,528] m-LoRA: Adapter lora_finqa_21 epoch: 1/1 iteration: 8/128 step: 3
[2025-12-23 17:27:38,616] m-LoRA: Adapter lora_finqa_30 loss: 2.316300868988037
[2025-12-23 17:27:42,461] m-LoRA: Adapter lora_finqa_23 epoch: 1/1 iteration: 4/128 step: 3
[2025-12-23 17:27:42,630] m-LoRA: Adapter lora_finqa_31 loss: 2.3124899864196777
[2025-12-23 17:27:43,587] m-LoRA: Adapter lora_finqa_32 loss: 2.5847225189208984
[2025-12-23 17:27:43,768] m-LoRA: Adapter lora_finqa_24 epoch: 1/1 iteration: 32/128 step: 3
[2025-12-23 17:27:44,154] m-LoRA: Adapter lora_finqa_0 loss: 2.4549901485443115
[2025-12-23 17:27:44,157] m-LoRA: Adapter lora_finqa_25 epoch: 1/1 iteration: 4/128 step: 3
[2025-12-23 17:27:44,727] m-LoRA: Adapter lora_finqa_3 loss: 2.453784942626953
[2025-12-23 17:27:44,731] m-LoRA: Adapter lora_finqa_26 epoch: 1/1 iteration: 8/128 step: 3
[2025-12-23 17:27:48,996] m-LoRA: Adapter lora_finqa_27 epoch: 1/1 iteration: 8/128 step: 3
[2025-12-23 17:27:49,188] m-LoRA: Adapter lora_finqa_2 loss: 2.577463388442993
[2025-12-23 17:27:49,619] m-LoRA: Adapter lora_finqa_1 loss: 2.454390525817871
[2025-12-23 17:27:49,790] m-LoRA: Adapter lora_finqa_28 epoch: 1/1 iteration: 32/128 step: 3
[2025-12-23 17:27:54,192] m-LoRA: Adapter lora_finqa_4 loss: 1.911381721496582
[2025-12-23 17:27:54,293] m-LoRA: Adapter lora_finqa_29 epoch: 1/1 iteration: 16/128 step: 3
[2025-12-23 17:27:58,502] m-LoRA: Adapter lora_finqa_5 loss: 2.260748863220215
[2025-12-23 17:27:58,613] m-LoRA: Adapter lora_finqa_30 epoch: 1/1 iteration: 16/128 step: 3
[2025-12-23 17:28:00,765] m-LoRA: Adapter lora_finqa_6 loss: 1.9099924564361572
[2025-12-23 17:28:00,968] m-LoRA: Adapter lora_finqa_31 epoch: 1/1 iteration: 32/128 step: 3
[2025-12-23 17:28:01,391] m-LoRA: Adapter lora_finqa_7 loss: 2.2625133991241455
[2025-12-23 17:28:01,394] m-LoRA: Adapter lora_finqa_32 epoch: 1/1 iteration: 8/128 step: 3
[2025-12-23 17:28:02,264] m-LoRA: Adapter lora_finqa_0 epoch: 1/1 iteration: 6/128 step: 4
[2025-12-23 17:28:02,299] m-LoRA: Adapter lora_finqa_8 loss: 2.264962911605835
[2025-12-23 17:28:04,669] m-LoRA: Adapter lora_finqa_3 epoch: 1/1 iteration: 6/128 step: 4
[2025-12-23 17:28:04,761] m-LoRA: Adapter lora_finqa_9 loss: 1.9147758483886719
[2025-12-23 17:28:05,637] m-LoRA: Adapter lora_finqa_10 loss: 2.4549009799957275
[2025-12-23 17:28:05,793] m-LoRA: Adapter lora_finqa_2 epoch: 1/1 iteration: 48/128 step: 4
[2025-12-23 17:28:07,922] m-LoRA: Adapter lora_finqa_11 loss: 2.4538626670837402
[2025-12-23 17:28:07,928] m-LoRA: Adapter lora_finqa_1 epoch: 1/1 iteration: 6/128 step: 4
[2025-12-23 17:28:08,262] m-LoRA: Adapter lora_finqa_13 loss: 2.251676559448242
[2025-12-23 17:28:08,434] m-LoRA: Adapter lora_finqa_4 epoch: 1/1 iteration: 48/128 step: 4
[2025-12-23 17:28:10,546] m-LoRA: Adapter lora_finqa_12 loss: 2.262653112411499
[2025-12-23 17:28:10,749] m-LoRA: Adapter lora_finqa_5 epoch: 1/1 iteration: 48/128 step: 4
[2025-12-23 17:28:14,594] m-LoRA: Adapter lora_finqa_14 loss: 2.4530293941497803
[2025-12-23 17:28:14,702] m-LoRA: Adapter lora_finqa_6 epoch: 1/1 iteration: 24/128 step: 4
[2025-12-23 17:28:15,175] m-LoRA: Adapter lora_finqa_7 epoch: 1/1 iteration: 6/128 step: 4
[2025-12-23 17:28:15,232] m-LoRA: Adapter lora_finqa_15 loss: 1.916074514389038
[2025-12-23 17:28:15,745] m-LoRA: Adapter lora_finqa_16 loss: 1.9150538444519043
[2025-12-23 17:28:15,748] m-LoRA: Adapter lora_finqa_8 epoch: 1/1 iteration: 6/128 step: 4
[2025-12-23 17:28:18,180] m-LoRA: Adapter lora_finqa_17 loss: 2.248502731323242
[2025-12-23 17:28:18,394] m-LoRA: Adapter lora_finqa_9 epoch: 1/1 iteration: 24/128 step: 4
[2025-12-23 17:28:19,354] m-LoRA: Adapter lora_finqa_18 loss: 2.2490687370300293
[2025-12-23 17:28:19,360] m-LoRA: Adapter lora_finqa_10 epoch: 1/1 iteration: 12/128 step: 4
[2025-12-23 17:28:21,419] m-LoRA: Adapter lora_finqa_11 epoch: 1/1 iteration: 12/128 step: 4
[2025-12-23 17:28:21,521] m-LoRA: Adapter lora_finqa_19 loss: 2.4551682472229004
[2025-12-23 17:28:25,178] m-LoRA: Adapter lora_finqa_13 epoch: 1/1 iteration: 12/128 step: 4
[2025-12-23 17:28:25,375] m-LoRA: Adapter lora_finqa_20 loss: 1.9105656147003174
[2025-12-23 17:28:27,302] m-LoRA: Adapter lora_finqa_12 epoch: 1/1 iteration: 24/128 step: 4
[2025-12-23 17:28:27,457] m-LoRA: Adapter lora_finqa_22 loss: 2.2509114742279053
[2025-12-23 17:28:28,646] m-LoRA: Adapter lora_finqa_21 loss: 2.5763912200927734
[2025-12-23 17:28:28,793] m-LoRA: Adapter lora_finqa_14 epoch: 1/1 iteration: 48/128 step: 4
[2025-12-23 17:28:29,279] m-LoRA: Adapter lora_finqa_15 epoch: 1/1 iteration: 6/128 step: 4
[2025-12-23 17:28:29,333] m-LoRA: Adapter lora_finqa_23 loss: 1.9212080240249634
[2025-12-23 17:28:34,770] m-LoRA: Adapter lora_finqa_24 loss: 1.914731502532959
[2025-12-23 17:28:34,787] m-LoRA: Adapter lora_finqa_16 epoch: 1/1 iteration: 6/128 step: 4
[2025-12-23 17:28:35,306] m-LoRA: Adapter lora_finqa_25 loss: 2.253657579421997
[2025-12-23 17:28:35,310] m-LoRA: Adapter lora_finqa_17 epoch: 1/1 iteration: 24/128 step: 4
[2025-12-23 17:28:35,575] m-LoRA: Adapter lora_finqa_26 loss: 2.576909065246582
[2025-12-23 17:28:35,580] m-LoRA: Adapter lora_finqa_18 epoch: 1/1 iteration: 12/128 step: 4
[2025-12-23 17:28:36,323] m-LoRA: Adapter lora_finqa_27 loss: 1.917376160621643
[2025-12-23 17:28:36,432] m-LoRA: Adapter lora_finqa_19 epoch: 1/1 iteration: 24/128 step: 4
[2025-12-23 17:28:41,181] m-LoRA: Adapter lora_finqa_28 loss: 2.2600061893463135
[2025-12-23 17:28:41,559] m-LoRA: Adapter lora_finqa_20 epoch: 1/1 iteration: 48/128 step: 4
[2025-12-23 17:28:43,332] m-LoRA: Adapter lora_finqa_29 loss: 2.2473816871643066
[2025-12-23 17:28:43,529] m-LoRA: Adapter lora_finqa_22 epoch: 1/1 iteration: 24/128 step: 4
[2025-12-23 17:28:45,930] m-LoRA: Adapter lora_finqa_21 epoch: 1/1 iteration: 12/128 step: 4
[2025-12-23 17:28:46,076] m-LoRA: Adapter lora_finqa_30 loss: 1.9143785238265991
[2025-12-23 17:28:50,002] m-LoRA: Adapter lora_finqa_23 epoch: 1/1 iteration: 6/128 step: 4
[2025-12-23 17:28:50,198] m-LoRA: Adapter lora_finqa_31 loss: 1.9172672033309937
[2025-12-23 17:28:51,164] m-LoRA: Adapter lora_finqa_32 loss: 2.5778543949127197
[2025-12-23 17:28:51,336] m-LoRA: Adapter lora_finqa_24 epoch: 1/1 iteration: 48/128 step: 4
[2025-12-23 17:28:51,734] m-LoRA: Adapter lora_finqa_25 epoch: 1/1 iteration: 6/128 step: 4
[2025-12-23 17:28:51,765] m-LoRA: Adapter lora_finqa_0 loss: 2.336728811264038
[2025-12-23 17:28:52,318] m-LoRA: Adapter lora_finqa_3 loss: 2.339310646057129
[2025-12-23 17:28:52,322] m-LoRA: Adapter lora_finqa_26 epoch: 1/1 iteration: 12/128 step: 4
[2025-12-23 17:28:56,865] m-LoRA: Adapter lora_finqa_2 loss: 2.566809892654419
[2025-12-23 17:28:56,994] m-LoRA: Adapter lora_finqa_27 epoch: 1/1 iteration: 12/128 step: 4
[2025-12-23 17:28:57,441] m-LoRA: Adapter lora_finqa_1 loss: 2.3366432189941406
[2025-12-23 17:28:57,615] m-LoRA: Adapter lora_finqa_28 epoch: 1/1 iteration: 48/128 step: 4
[2025-12-23 17:29:02,000] m-LoRA: Adapter lora_finqa_4 loss: 1.473885178565979
[2025-12-23 17:29:02,101] m-LoRA: Adapter lora_finqa_29 epoch: 1/1 iteration: 24/128 step: 4
[2025-12-23 17:29:06,313] m-LoRA: Adapter lora_finqa_5 loss: 1.9946892261505127
[2025-12-23 17:29:06,420] m-LoRA: Adapter lora_finqa_30 epoch: 1/1 iteration: 24/128 step: 4
[2025-12-23 17:29:08,713] m-LoRA: Adapter lora_finqa_6 loss: 1.4739900827407837
[2025-12-23 17:29:08,924] m-LoRA: Adapter lora_finqa_31 epoch: 1/1 iteration: 48/128 step: 4
[2025-12-23 17:29:09,797] m-LoRA: Adapter lora_finqa_7 loss: 2.001474618911743
[2025-12-23 17:29:09,801] m-LoRA: Adapter lora_finqa_32 epoch: 1/1 iteration: 12/128 step: 4
[2025-12-23 17:29:10,443] m-LoRA: Adapter lora_finqa_8 loss: 2.007101058959961
[2025-12-23 17:29:10,446] m-LoRA: Adapter lora_finqa_0 epoch: 1/1 iteration: 8/128 step: 5
[2025-12-23 17:29:12,829] m-LoRA: Adapter lora_finqa_3 epoch: 1/1 iteration: 8/128 step: 5
[2025-12-23 17:29:12,928] m-LoRA: Adapter lora_finqa_9 loss: 1.4812660217285156
[2025-12-23 17:29:14,008] m-LoRA: Adapter lora_finqa_10 loss: 2.3384037017822266
[2025-12-23 17:29:14,161] m-LoRA: Adapter lora_finqa_2 epoch: 1/1 iteration: 64/128 step: 5
[2025-12-23 17:29:15,231] m-LoRA: Adapter lora_finqa_1 epoch: 1/1 iteration: 8/128 step: 5
[2025-12-23 17:29:15,286] m-LoRA: Adapter lora_finqa_11 loss: 2.3388168811798096
[2025-12-23 17:29:16,476] m-LoRA: Adapter lora_finqa_13 loss: 1.986716628074646
[2025-12-23 17:29:16,652] m-LoRA: Adapter lora_finqa_4 epoch: 1/1 iteration: 64/128 step: 5
[2025-12-23 17:29:18,679] m-LoRA: Adapter lora_finqa_12 loss: 1.998282551765442
[2025-12-23 17:29:18,879] m-LoRA: Adapter lora_finqa_5 epoch: 1/1 iteration: 64/128 step: 5
[2025-12-23 17:29:22,881] m-LoRA: Adapter lora_finqa_14 loss: 2.334260940551758
[2025-12-23 17:29:22,989] m-LoRA: Adapter lora_finqa_6 epoch: 1/1 iteration: 32/128 step: 5
[2025-12-23 17:29:23,518] m-LoRA: Adapter lora_finqa_7 epoch: 1/1 iteration: 8/128 step: 5
[2025-12-23 17:29:23,571] m-LoRA: Adapter lora_finqa_15 loss: 1.4801199436187744
[2025-12-23 17:29:24,082] m-LoRA: Adapter lora_finqa_16 loss: 1.4852797985076904
[2025-12-23 17:29:24,086] m-LoRA: Adapter lora_finqa_8 epoch: 1/1 iteration: 8/128 step: 5
[2025-12-23 17:29:26,844] m-LoRA: Adapter lora_finqa_17 loss: 1.9825096130371094
[2025-12-23 17:29:26,854] m-LoRA: Adapter lora_finqa_9 epoch: 1/1 iteration: 32/128 step: 5
[2025-12-23 17:29:27,898] m-LoRA: Adapter lora_finqa_18 loss: 1.9843024015426636
[2025-12-23 17:29:27,905] m-LoRA: Adapter lora_finqa_10 epoch: 1/1 iteration: 16/128 step: 5
[2025-12-23 17:29:30,074] m-LoRA: Adapter lora_finqa_11 epoch: 1/1 iteration: 16/128 step: 5
[2025-12-23 17:29:30,150] m-LoRA: Adapter lora_finqa_19 loss: 2.3395986557006836
[2025-12-23 17:29:34,002] m-LoRA: Adapter lora_finqa_20 loss: 1.474920630455017
[2025-12-23 17:29:34,077] m-LoRA: Adapter lora_finqa_13 epoch: 1/1 iteration: 16/128 step: 5
[2025-12-23 17:29:36,223] m-LoRA: Adapter lora_finqa_22 loss: 1.984501838684082
[2025-12-23 17:29:36,410] m-LoRA: Adapter lora_finqa_12 epoch: 1/1 iteration: 32/128 step: 5
[2025-12-23 17:29:37,640] m-LoRA: Adapter lora_finqa_21 loss: 2.5671586990356445
[2025-12-23 17:29:37,799] m-LoRA: Adapter lora_finqa_14 epoch: 1/1 iteration: 64/128 step: 5
[2025-12-23 17:29:38,316] m-LoRA: Adapter lora_finqa_23 loss: 1.4956820011138916
[2025-12-23 17:29:38,319] m-LoRA: Adapter lora_finqa_15 epoch: 1/1 iteration: 8/128 step: 5
[2025-12-23 17:29:42,756] m-LoRA: Adapter lora_finqa_16 epoch: 1/1 iteration: 8/128 step: 5
[2025-12-23 17:29:43,078] m-LoRA: Adapter lora_finqa_24 loss: 1.4821406602859497
[2025-12-23 17:29:43,445] m-LoRA: Adapter lora_finqa_25 loss: 1.9904842376708984
[2025-12-23 17:29:43,448] m-LoRA: Adapter lora_finqa_17 epoch: 1/1 iteration: 32/128 step: 5
[2025-12-23 17:29:44,201] m-LoRA: Adapter lora_finqa_26 loss: 2.5672199726104736
[2025-12-23 17:29:44,206] m-LoRA: Adapter lora_finqa_18 epoch: 1/1 iteration: 16/128 step: 5
[2025-12-23 17:29:45,236] m-LoRA: Adapter lora_finqa_27 loss: 1.484277606010437
[2025-12-23 17:29:45,364] m-LoRA: Adapter lora_finqa_19 epoch: 1/1 iteration: 32/128 step: 5
[2025-12-23 17:29:49,812] m-LoRA: Adapter lora_finqa_28 loss: 1.9946725368499756
[2025-12-23 17:29:50,191] m-LoRA: Adapter lora_finqa_20 epoch: 1/1 iteration: 64/128 step: 5
[2025-12-23 17:29:51,953] m-LoRA: Adapter lora_finqa_29 loss: 1.9814263582229614
[2025-12-23 17:29:52,141] m-LoRA: Adapter lora_finqa_22 epoch: 1/1 iteration: 32/128 step: 5
[2025-12-23 17:29:54,572] m-LoRA: Adapter lora_finqa_21 epoch: 1/1 iteration: 16/128 step: 5
[2025-12-23 17:29:54,651] m-LoRA: Adapter lora_finqa_30 loss: 1.4784560203552246
[2025-12-23 17:29:58,547] m-LoRA: Adapter lora_finqa_23 epoch: 1/1 iteration: 8/128 step: 5
[2025-12-23 17:29:58,732] m-LoRA: Adapter lora_finqa_31 loss: 1.4850398302078247
[2025-12-23 17:29:59,704] m-LoRA: Adapter lora_finqa_32 loss: 2.567150115966797
[2025-12-23 17:29:59,877] m-LoRA: Adapter lora_finqa_24 epoch: 1/1 iteration: 64/128 step: 5
[2025-12-23 17:30:00,269] m-LoRA: Adapter lora_finqa_25 epoch: 1/1 iteration: 8/128 step: 5
[2025-12-23 17:30:00,320] m-LoRA: Adapter lora_finqa_0 loss: 2.198071241378784
[2025-12-23 17:30:00,801] m-LoRA: Adapter lora_finqa_26 epoch: 1/1 iteration: 16/128 step: 5
[2025-12-23 17:30:00,874] m-LoRA: Adapter lora_finqa_3 loss: 2.2017838954925537
[2025-12-23 17:30:05,340] m-LoRA: Adapter lora_finqa_2 loss: 2.554952383041382
[2025-12-23 17:30:05,474] m-LoRA: Adapter lora_finqa_27 epoch: 1/1 iteration: 16/128 step: 5
[2025-12-23 17:30:05,895] m-LoRA: Adapter lora_finqa_1 loss: 2.199963092803955
[2025-12-23 17:30:06,070] m-LoRA: Adapter lora_finqa_28 epoch: 1/1 iteration: 64/128 step: 5
[2025-12-23 17:30:10,451] m-LoRA: Adapter lora_finqa_4 loss: 1.1641274690628052
[2025-12-23 17:30:10,550] m-LoRA: Adapter lora_finqa_29 epoch: 1/1 iteration: 32/128 step: 5
[2025-12-23 17:30:14,745] m-LoRA: Adapter lora_finqa_5 loss: 1.7126861810684204
[2025-12-23 17:30:14,852] m-LoRA: Adapter lora_finqa_30 epoch: 1/1 iteration: 32/128 step: 5
[2025-12-23 17:30:17,152] m-LoRA: Adapter lora_finqa_6 loss: 1.1816893815994263
[2025-12-23 17:30:17,350] m-LoRA: Adapter lora_finqa_31 epoch: 1/1 iteration: 64/128 step: 5
[2025-12-23 17:30:18,208] m-LoRA: Adapter lora_finqa_7 loss: 1.721218466758728
[2025-12-23 17:30:18,211] m-LoRA: Adapter lora_finqa_32 epoch: 1/1 iteration: 16/128 step: 5
[2025-12-23 17:30:18,793] m-LoRA: Adapter lora_finqa_0 epoch: 1/1 iteration: 10/128 step: 6
[2025-12-23 17:30:18,846] m-LoRA: Adapter lora_finqa_8 loss: 1.7252991199493408
[2025-12-23 17:30:21,155] m-LoRA: Adapter lora_finqa_3 epoch: 1/1 iteration: 10/128 step: 6
[2025-12-23 17:30:21,246] m-LoRA: Adapter lora_finqa_9 loss: 1.187051773071289
[2025-12-23 17:30:22,233] m-LoRA: Adapter lora_finqa_10 loss: 2.1984920501708984
[2025-12-23 17:30:22,389] m-LoRA: Adapter lora_finqa_2 epoch: 1/1 iteration: 80/128 step: 6
[2025-12-23 17:30:23,497] m-LoRA: Adapter lora_finqa_1 epoch: 1/1 iteration: 10/128 step: 6
[2025-12-23 17:30:23,556] m-LoRA: Adapter lora_finqa_11 loss: 2.199147939682007
[2025-12-23 17:30:24,799] m-LoRA: Adapter lora_finqa_13 loss: 1.7058384418487549
[2025-12-23 17:30:24,975] m-LoRA: Adapter lora_finqa_4 epoch: 1/1 iteration: 80/128 step: 6
[2025-12-23 17:30:26,946] m-LoRA: Adapter lora_finqa_12 loss: 1.7172040939331055
[2025-12-23 17:30:27,171] m-LoRA: Adapter lora_finqa_5 epoch: 1/1 iteration: 80/128 step: 6
[2025-12-23 17:30:31,018] m-LoRA: Adapter lora_finqa_14 loss: 2.1948249340057373
[2025-12-23 17:30:31,130] m-LoRA: Adapter lora_finqa_6 epoch: 1/1 iteration: 40/128 step: 6
[2025-12-23 17:30:31,721] m-LoRA: Adapter lora_finqa_15 loss: 1.188906192779541
[2025-12-23 17:30:31,724] m-LoRA: Adapter lora_finqa_7 epoch: 1/1 iteration: 10/128 step: 6
[2025-12-23 17:30:32,200] m-LoRA: Adapter lora_finqa_16 loss: 1.1723637580871582
[2025-12-23 17:30:32,203] m-LoRA: Adapter lora_finqa_8 epoch: 1/1 iteration: 10/128 step: 6
[2025-12-23 17:30:34,573] m-LoRA: Adapter lora_finqa_17 loss: 1.6972053050994873
[2025-12-23 17:30:34,770] m-LoRA: Adapter lora_finqa_9 epoch: 1/1 iteration: 40/128 step: 6
[2025-12-23 17:30:35,743] m-LoRA: Adapter lora_finqa_10 epoch: 1/1 iteration: 20/128 step: 6
[2025-12-23 17:30:35,816] m-LoRA: Adapter lora_finqa_18 loss: 1.702052116394043
[2025-12-23 17:30:37,935] m-LoRA: Adapter lora_finqa_11 epoch: 1/1 iteration: 20/128 step: 6
[2025-12-23 17:30:38,020] m-LoRA: Adapter lora_finqa_19 loss: 2.200303316116333
[2025-12-23 17:30:41,744] m-LoRA: Adapter lora_finqa_13 epoch: 1/1 iteration: 20/128 step: 6
[2025-12-23 17:30:41,953] m-LoRA: Adapter lora_finqa_20 loss: 1.1626499891281128
[2025-12-23 17:30:44,059] m-LoRA: Adapter lora_finqa_22 loss: 1.7010701894760132
[2025-12-23 17:30:44,253] m-LoRA: Adapter lora_finqa_12 epoch: 1/1 iteration: 40/128 step: 6
[2025-12-23 17:30:45,450] m-LoRA: Adapter lora_finqa_21 loss: 2.554504632949829
[2025-12-23 17:30:45,597] m-LoRA: Adapter lora_finqa_14 epoch: 1/1 iteration: 80/128 step: 6
[2025-12-23 17:30:46,079] m-LoRA: Adapter lora_finqa_15 epoch: 1/1 iteration: 10/128 step: 6
[2025-12-23 17:30:46,134] m-LoRA: Adapter lora_finqa_23 loss: 1.203488826751709
[2025-12-23 17:30:50,532] m-LoRA: Adapter lora_finqa_16 epoch: 1/1 iteration: 10/128 step: 6
[2025-12-23 17:30:50,736] m-LoRA: Adapter lora_finqa_24 loss: 1.1750514507293701
[2025-12-23 17:30:51,321] m-LoRA: Adapter lora_finqa_25 loss: 1.7112963199615479
[2025-12-23 17:30:51,402] m-LoRA: Adapter lora_finqa_17 epoch: 1/1 iteration: 40/128 step: 6
[2025-12-23 17:30:52,399] m-LoRA: Adapter lora_finqa_26 loss: 2.554415225982666
[2025-12-23 17:30:52,510] m-LoRA: Adapter lora_finqa_18 epoch: 1/1 iteration: 20/128 step: 6
[2025-12-23 17:30:53,813] m-LoRA: Adapter lora_finqa_27 loss: 1.1838655471801758
[2025-12-23 17:30:53,818] m-LoRA: Adapter lora_finqa_19 epoch: 1/1 iteration: 40/128 step: 6
[2025-12-23 17:30:58,433] m-LoRA: Adapter lora_finqa_28 loss: 1.7113202810287476
[2025-12-23 17:30:58,803] m-LoRA: Adapter lora_finqa_20 epoch: 1/1 iteration: 80/128 step: 6
[2025-12-23 17:31:00,187] m-LoRA: Adapter lora_finqa_29 loss: 1.6981016397476196
[2025-12-23 17:31:00,389] m-LoRA: Adapter lora_finqa_22 epoch: 1/1 iteration: 40/128 step: 6
[2025-12-23 17:31:02,523] m-LoRA: Adapter lora_finqa_21 epoch: 1/1 iteration: 20/128 step: 6
[2025-12-23 17:31:02,616] m-LoRA: Adapter lora_finqa_30 loss: 1.1813738346099854
[2025-12-23 17:31:06,955] m-LoRA: Adapter lora_finqa_23 epoch: 1/1 iteration: 10/128 step: 6
[2025-12-23 17:31:07,158] m-LoRA: Adapter lora_finqa_31 loss: 1.1886378526687622
[2025-12-23 17:31:08,125] m-LoRA: Adapter lora_finqa_32 loss: 2.5544638633728027
[2025-12-23 17:31:08,304] m-LoRA: Adapter lora_finqa_24 epoch: 1/1 iteration: 80/128 step: 6
[2025-12-23 17:31:08,765] m-LoRA: Adapter lora_finqa_0 loss: 2.0532357692718506
[2025-12-23 17:31:08,768] m-LoRA: Adapter lora_finqa_25 epoch: 1/1 iteration: 10/128 step: 6
[2025-12-23 17:31:09,297] m-LoRA: Adapter lora_finqa_3 loss: 2.0558812618255615
[2025-12-23 17:31:09,300] m-LoRA: Adapter lora_finqa_26 epoch: 1/1 iteration: 20/128 step: 6
[2025-12-23 17:31:13,608] m-LoRA: Adapter lora_finqa_27 epoch: 1/1 iteration: 20/128 step: 6
[2025-12-23 17:31:13,829] m-LoRA: Adapter lora_finqa_2 loss: 2.539116859436035
[2025-12-23 17:31:14,299] m-LoRA: Adapter lora_finqa_1 loss: 2.05277943611145
[2025-12-23 17:31:14,472] m-LoRA: Adapter lora_finqa_28 epoch: 1/1 iteration: 80/128 step: 6
[2025-12-23 17:31:18,865] m-LoRA: Adapter lora_finqa_4 loss: 0.7667357325553894
[2025-12-23 17:31:18,964] m-LoRA: Adapter lora_finqa_29 epoch: 1/1 iteration: 40/128 step: 6
[2025-12-23 17:31:23,245] m-LoRA: Adapter lora_finqa_5 loss: 1.3988447189331055
[2025-12-23 17:31:23,353] m-LoRA: Adapter lora_finqa_30 epoch: 1/1 iteration: 40/128 step: 6
[2025-12-23 17:31:25,653] m-LoRA: Adapter lora_finqa_6 loss: 0.7732948064804077
[2025-12-23 17:31:25,870] m-LoRA: Adapter lora_finqa_31 epoch: 1/1 iteration: 80/128 step: 6
[2025-12-23 17:31:26,541] m-LoRA: Adapter lora_finqa_7 loss: 1.4070419073104858
[2025-12-23 17:31:26,544] m-LoRA: Adapter lora_finqa_32 epoch: 1/1 iteration: 20/128 step: 6
[2025-12-23 17:31:27,295] m-LoRA: Adapter lora_finqa_8 loss: 1.4114335775375366
[2025-12-23 17:31:27,298] m-LoRA: Adapter lora_finqa_0 epoch: 1/1 iteration: 12/128 step: 7
[2025-12-23 17:31:29,605] m-LoRA: Adapter lora_finqa_3 epoch: 1/1 iteration: 12/128 step: 7
[2025-12-23 17:31:29,716] m-LoRA: Adapter lora_finqa_9 loss: 0.7793404459953308
[2025-12-23 17:31:30,750] m-LoRA: Adapter lora_finqa_10 loss: 2.052358627319336
[2025-12-23 17:31:30,913] m-LoRA: Adapter lora_finqa_2 epoch: 1/1 iteration: 96/128 step: 7
[2025-12-23 17:31:31,996] m-LoRA: Adapter lora_finqa_1 epoch: 1/1 iteration: 12/128 step: 7
[2025-12-23 17:31:32,052] m-LoRA: Adapter lora_finqa_11 loss: 2.0545005798339844
[2025-12-23 17:31:33,170] m-LoRA: Adapter lora_finqa_13 loss: 1.3952853679656982
[2025-12-23 17:31:33,342] m-LoRA: Adapter lora_finqa_4 epoch: 1/1 iteration: 96/128 step: 7
[2025-12-23 17:31:35,363] m-LoRA: Adapter lora_finqa_12 loss: 1.4060230255126953
[2025-12-23 17:31:35,568] m-LoRA: Adapter lora_finqa_5 epoch: 1/1 iteration: 96/128 step: 7
[2025-12-23 17:31:39,706] m-LoRA: Adapter lora_finqa_14 loss: 2.046719551086426
[2025-12-23 17:31:39,813] m-LoRA: Adapter lora_finqa_6 epoch: 1/1 iteration: 48/128 step: 7
[2025-12-23 17:31:40,345] m-LoRA: Adapter lora_finqa_15 loss: 0.7748854160308838
[2025-12-23 17:31:40,348] m-LoRA: Adapter lora_finqa_7 epoch: 1/1 iteration: 12/128 step: 7
[2025-12-23 17:31:40,849] m-LoRA: Adapter lora_finqa_8 epoch: 1/1 iteration: 12/128 step: 7
[2025-12-23 17:31:40,900] m-LoRA: Adapter lora_finqa_16 loss: 0.7848816514015198
[2025-12-23 17:31:43,231] m-LoRA: Adapter lora_finqa_17 loss: 1.3885583877563477
[2025-12-23 17:31:43,446] m-LoRA: Adapter lora_finqa_9 epoch: 1/1 iteration: 48/128 step: 7
[2025-12-23 17:31:44,409] m-LoRA: Adapter lora_finqa_10 epoch: 1/1 iteration: 24/128 step: 7
[2025-12-23 17:31:44,481] m-LoRA: Adapter lora_finqa_18 loss: 1.3909868001937866
[2025-12-23 17:31:46,822] m-LoRA: Adapter lora_finqa_19 loss: 2.053063154220581
[2025-12-23 17:31:46,909] m-LoRA: Adapter lora_finqa_11 epoch: 1/1 iteration: 24/128 step: 7
[2025-12-23 17:31:50,567] m-LoRA: Adapter lora_finqa_13 epoch: 1/1 iteration: 24/128 step: 7
[2025-12-23 17:31:50,788] m-LoRA: Adapter lora_finqa_20 loss: 0.7691023349761963
[2025-12-23 17:31:52,839] m-LoRA: Adapter lora_finqa_22 loss: 1.3887099027633667
[2025-12-23 17:31:53,041] m-LoRA: Adapter lora_finqa_12 epoch: 1/1 iteration: 48/128 step: 7
[2025-12-23 17:31:54,272] m-LoRA: Adapter lora_finqa_21 loss: 2.5401339530944824
[2025-12-23 17:31:54,426] m-LoRA: Adapter lora_finqa_14 epoch: 1/1 iteration: 96/128 step: 7
[2025-12-23 17:31:54,960] m-LoRA: Adapter lora_finqa_23 loss: 0.7906069159507751
[2025-12-23 17:31:54,963] m-LoRA: Adapter lora_finqa_15 epoch: 1/1 iteration: 12/128 step: 7
[2025-12-23 17:31:59,080] m-LoRA: Adapter lora_finqa_16 epoch: 1/1 iteration: 12/128 step: 7
[2025-12-23 17:31:59,295] m-LoRA: Adapter lora_finqa_24 loss: 0.7844236493110657
[2025-12-23 17:31:59,780] m-LoRA: Adapter lora_finqa_25 loss: 1.3968629837036133
[2025-12-23 17:31:59,872] m-LoRA: Adapter lora_finqa_17 epoch: 1/1 iteration: 48/128 step: 7
[2025-12-23 17:32:00,869] m-LoRA: Adapter lora_finqa_26 loss: 2.53872013092041
[2025-12-23 17:32:00,875] m-LoRA: Adapter lora_finqa_18 epoch: 1/1 iteration: 24/128 step: 7
[2025-12-23 17:32:01,885] m-LoRA: Adapter lora_finqa_27 loss: 0.7799528241157532
[2025-12-23 17:32:02,030] m-LoRA: Adapter lora_finqa_19 epoch: 1/1 iteration: 48/128 step: 7
[2025-12-23 17:32:06,724] m-LoRA: Adapter lora_finqa_28 loss: 1.3981589078903198
[2025-12-23 17:32:07,100] m-LoRA: Adapter lora_finqa_20 epoch: 1/1 iteration: 96/128 step: 7
[2025-12-23 17:32:08,892] m-LoRA: Adapter lora_finqa_29 loss: 1.3855150938034058
[2025-12-23 17:32:09,079] m-LoRA: Adapter lora_finqa_22 epoch: 1/1 iteration: 48/128 step: 7
[2025-12-23 17:32:11,512] m-LoRA: Adapter lora_finqa_21 epoch: 1/1 iteration: 24/128 step: 7
[2025-12-23 17:32:11,646] m-LoRA: Adapter lora_finqa_30 loss: 0.7791875600814819
[2025-12-23 17:32:15,517] m-LoRA: Adapter lora_finqa_23 epoch: 1/1 iteration: 12/128 step: 7
[2025-12-23 17:32:15,708] m-LoRA: Adapter lora_finqa_31 loss: 0.7776552438735962
[2025-12-23 17:32:16,143] m-LoRA: Adapter lora_finqa_32 loss: 2.5400965213775635
[2025-12-23 17:32:16,446] m-LoRA: Adapter lora_finqa_24 epoch: 1/1 iteration: 96/128 step: 7
[2025-12-23 17:32:16,836] m-LoRA: Adapter lora_finqa_0 loss: 1.9027705192565918
[2025-12-23 17:32:16,839] m-LoRA: Adapter lora_finqa_25 epoch: 1/1 iteration: 12/128 step: 7
[2025-12-23 17:32:17,127] m-LoRA: Adapter lora_finqa_3 loss: 1.9035208225250244
[2025-12-23 17:32:17,130] m-LoRA: Adapter lora_finqa_26 epoch: 1/1 iteration: 24/128 step: 7
[2025-12-23 17:32:21,664] m-LoRA: Adapter lora_finqa_2 loss: 2.5215914249420166
[2025-12-23 17:32:21,748] m-LoRA: Adapter lora_finqa_27 epoch: 1/1 iteration: 24/128 step: 7
[2025-12-23 17:32:22,204] m-LoRA: Adapter lora_finqa_1 loss: 1.902903437614441
[2025-12-23 17:32:22,379] m-LoRA: Adapter lora_finqa_28 epoch: 1/1 iteration: 96/128 step: 7
[2025-12-23 17:32:26,655] m-LoRA: Adapter lora_finqa_4 loss: 0.5120827555656433
[2025-12-23 17:32:26,754] m-LoRA: Adapter lora_finqa_29 epoch: 1/1 iteration: 48/128 step: 7
[2025-12-23 17:32:30,914] m-LoRA: Adapter lora_finqa_5 loss: 1.1095495223999023
[2025-12-23 17:32:31,021] m-LoRA: Adapter lora_finqa_30 epoch: 1/1 iteration: 48/128 step: 7
[2025-12-23 17:32:33,241] m-LoRA: Adapter lora_finqa_6 loss: 0.5202761292457581
[2025-12-23 17:32:33,438] m-LoRA: Adapter lora_finqa_31 epoch: 1/1 iteration: 96/128 step: 7
[2025-12-23 17:32:34,166] m-LoRA: Adapter lora_finqa_7 loss: 1.138929843902588
[2025-12-23 17:32:34,170] m-LoRA: Adapter lora_finqa_32 epoch: 1/1 iteration: 24/128 step: 7
[2025-12-23 17:32:34,733] m-LoRA: Adapter lora_finqa_8 loss: 1.1309219598770142
[2025-12-23 17:32:34,736] m-LoRA: Adapter lora_finqa_0 epoch: 1/1 iteration: 14/128 step: 8
[2025-12-23 17:32:37,301] m-LoRA: Adapter lora_finqa_3 epoch: 1/1 iteration: 14/128 step: 8
[2025-12-23 17:32:37,418] m-LoRA: Adapter lora_finqa_9 loss: 0.5246137976646423
[2025-12-23 17:32:38,483] m-LoRA: Adapter lora_finqa_10 loss: 1.8987741470336914
[2025-12-23 17:32:38,635] m-LoRA: Adapter lora_finqa_2 epoch: 1/1 iteration: 112/128 step: 8
[2025-12-23 17:32:39,752] m-LoRA: Adapter lora_finqa_1 epoch: 1/1 iteration: 14/128 step: 8
[2025-12-23 17:32:39,807] m-LoRA: Adapter lora_finqa_11 loss: 1.9016951322555542
[2025-12-23 17:32:40,881] m-LoRA: Adapter lora_finqa_13 loss: 1.0886327028274536
[2025-12-23 17:32:41,054] m-LoRA: Adapter lora_finqa_4 epoch: 1/1 iteration: 112/128 step: 8
[2025-12-23 17:32:43,043] m-LoRA: Adapter lora_finqa_12 loss: 1.1191269159317017
[2025-12-23 17:32:43,252] m-LoRA: Adapter lora_finqa_5 epoch: 1/1 iteration: 112/128 step: 8
[2025-12-23 17:32:47,172] m-LoRA: Adapter lora_finqa_14 loss: 1.8919140100479126
[2025-12-23 17:32:47,280] m-LoRA: Adapter lora_finqa_6 epoch: 1/1 iteration: 56/128 step: 8
[2025-12-23 17:32:47,766] m-LoRA: Adapter lora_finqa_7 epoch: 1/1 iteration: 14/128 step: 8
[2025-12-23 17:32:47,819] m-LoRA: Adapter lora_finqa_15 loss: 0.5254920721054077
[2025-12-23 17:32:48,391] m-LoRA: Adapter lora_finqa_16 loss: 0.5270752310752869
[2025-12-23 17:32:48,395] m-LoRA: Adapter lora_finqa_8 epoch: 1/1 iteration: 14/128 step: 8
[2025-12-23 17:32:50,864] m-LoRA: Adapter lora_finqa_17 loss: 1.0758675336837769
[2025-12-23 17:32:50,963] m-LoRA: Adapter lora_finqa_9 epoch: 1/1 iteration: 56/128 step: 8
[2025-12-23 17:32:52,037] m-LoRA: Adapter lora_finqa_10 epoch: 1/1 iteration: 28/128 step: 8
[2025-12-23 17:32:52,109] m-LoRA: Adapter lora_finqa_18 loss: 1.0817056894302368
[2025-12-23 17:32:54,359] m-LoRA: Adapter lora_finqa_11 epoch: 1/1 iteration: 28/128 step: 8
[2025-12-23 17:32:54,432] m-LoRA: Adapter lora_finqa_19 loss: 1.90133798122406
[2025-12-23 17:32:58,347] m-LoRA: Adapter lora_finqa_20 loss: 0.5116801857948303
[2025-12-23 17:32:58,441] m-LoRA: Adapter lora_finqa_13 epoch: 1/1 iteration: 28/128 step: 8
[2025-12-23 17:33:00,676] m-LoRA: Adapter lora_finqa_22 loss: 1.0820297002792358
[2025-12-23 17:33:00,864] m-LoRA: Adapter lora_finqa_12 epoch: 1/1 iteration: 56/128 step: 8
[2025-12-23 17:33:01,957] m-LoRA: Adapter lora_finqa_21 loss: 2.521080255508423
[2025-12-23 17:33:02,104] m-LoRA: Adapter lora_finqa_14 epoch: 1/1 iteration: 112/128 step: 8
[2025-12-23 17:33:02,649] m-LoRA: Adapter lora_finqa_23 loss: 0.5387968420982361
[2025-12-23 17:33:02,653] m-LoRA: Adapter lora_finqa_15 epoch: 1/1 iteration: 14/128 step: 8
[2025-12-23 17:33:06,633] m-LoRA: Adapter lora_finqa_16 epoch: 1/1 iteration: 14/128 step: 8
[2025-12-23 17:33:06,852] m-LoRA: Adapter lora_finqa_24 loss: 0.5254821181297302
[2025-12-23 17:33:07,385] m-LoRA: Adapter lora_finqa_25 loss: 1.100213885307312
[2025-12-23 17:33:07,467] m-LoRA: Adapter lora_finqa_17 epoch: 1/1 iteration: 56/128 step: 8
[2025-12-23 17:33:08,459] m-LoRA: Adapter lora_finqa_18 epoch: 1/1 iteration: 28/128 step: 8
[2025-12-23 17:33:08,534] m-LoRA: Adapter lora_finqa_26 loss: 2.5208187103271484
[2025-12-23 17:33:09,504] m-LoRA: Adapter lora_finqa_27 loss: 0.5327237844467163
[2025-12-23 17:33:09,648] m-LoRA: Adapter lora_finqa_19 epoch: 1/1 iteration: 56/128 step: 8
[2025-12-23 17:33:14,143] m-LoRA: Adapter lora_finqa_28 loss: 1.1081181764602661
[2025-12-23 17:33:14,519] m-LoRA: Adapter lora_finqa_20 epoch: 1/1 iteration: 112/128 step: 8
[2025-12-23 17:33:16,319] m-LoRA: Adapter lora_finqa_29 loss: 1.0768293142318726
[2025-12-23 17:33:16,512] m-LoRA: Adapter lora_finqa_22 epoch: 1/1 iteration: 56/128 step: 8
[2025-12-23 17:33:18,963] m-LoRA: Adapter lora_finqa_21 epoch: 1/1 iteration: 28/128 step: 8
[2025-12-23 17:33:19,073] m-LoRA: Adapter lora_finqa_30 loss: 0.5227212905883789
[2025-12-23 17:33:21,526] m-LoRA: Adapter lora_finqa_23 epoch: 1/1 iteration: 14/128 step: 8
[2025-12-23 17:33:21,700] m-LoRA: Adapter lora_finqa_31 loss: 0.5206953883171082
[2025-12-23 17:33:22,380] m-LoRA: Adapter lora_finqa_32 loss: 2.5219156742095947
[2025-12-23 17:33:22,553] m-LoRA: Adapter lora_finqa_24 epoch: 1/1 iteration: 112/128 step: 8
[2025-12-23 17:33:22,947] m-LoRA: Adapter lora_finqa_25 epoch: 1/1 iteration: 14/128 step: 8
[2025-12-23 17:33:22,977] m-LoRA: Adapter lora_finqa_0 loss: 1.7404632568359375
[2025-12-23 17:33:23,506] m-LoRA: Adapter lora_finqa_26 epoch: 1/1 iteration: 28/128 step: 8
[2025-12-23 17:33:23,585] m-LoRA: Adapter lora_finqa_3 loss: 1.7453221082687378
[2025-12-23 17:33:26,219] m-LoRA: Adapter lora_finqa_2 loss: 2.5009617805480957
[2025-12-23 17:33:26,237] m-LoRA: Adapter lora_finqa_27 epoch: 1/1 iteration: 28/128 step: 8
[2025-12-23 17:33:26,902] m-LoRA: Adapter lora_finqa_1 loss: 1.7364702224731445
[2025-12-23 17:33:27,093] m-LoRA: Adapter lora_finqa_28 epoch: 1/1 iteration: 112/128 step: 8
[2025-12-23 17:33:31,712] m-LoRA: Adapter lora_finqa_4 loss: 0.32199525833129883
[2025-12-23 17:33:31,809] m-LoRA: Adapter lora_finqa_29 epoch: 1/1 iteration: 56/128 step: 8
[2025-12-23 17:33:36,123] m-LoRA: Adapter lora_finqa_5 loss: 0.8169754147529602
[2025-12-23 17:33:36,234] m-LoRA: Adapter lora_finqa_30 epoch: 1/1 iteration: 56/128 step: 8
[2025-12-23 17:33:38,566] m-LoRA: Adapter lora_finqa_6 loss: 0.3281784951686859
[2025-12-23 17:33:38,767] m-LoRA: Adapter lora_finqa_31 epoch: 1/1 iteration: 112/128 step: 8
[2025-12-23 17:33:39,594] m-LoRA: Adapter lora_finqa_7 loss: 0.8337751626968384
[2025-12-23 17:33:39,597] m-LoRA: Adapter lora_finqa_32 epoch: 1/1 iteration: 28/128 step: 8
[2025-12-23 17:33:40,216] m-LoRA: Adapter lora_finqa_8 loss: 0.8330929279327393
[2025-12-23 17:33:40,219] m-LoRA: Adapter lora_finqa_0 epoch: 1/1 iteration: 16/128 step: 9
[2025-12-23 17:33:41,598] m-LoRA: Adapter lora_finqa_3 epoch: 1/1 iteration: 16/128 step: 9
[2025-12-23 17:33:41,687] m-LoRA: Adapter lora_finqa_9 loss: 0.3290597200393677
[2025-12-23 17:33:42,838] m-LoRA: Adapter lora_finqa_10 loss: 1.7340036630630493
[2025-12-23 17:33:42,992] m-LoRA: Finish and base model offload adapter - ['lora_finqa_2']
[2025-12-23 17:33:43,458] m-LoRA: Task to running, need to load adapters: ['lora_finqa_33']
[2025-12-23 17:33:43,555] m-LoRA: Adapter lora_finqa_33 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:33:43,813] m-LoRA: Adapter lora_finqa_11 loss: 1.7394988536834717
[2025-12-23 17:33:43,819] m-LoRA: Adapter lora_finqa_1 epoch: 1/1 iteration: 16/128 step: 9
[2025-12-23 17:33:44,149] m-LoRA: Adapter lora_finqa_13 loss: 0.7952935099601746
[2025-12-23 17:33:44,322] m-LoRA: Finish and base model offload adapter - ['lora_finqa_4']
[2025-12-23 17:33:45,085] m-LoRA: Task to running, need to load adapters: ['lora_finqa_34']
[2025-12-23 17:33:45,226] m-LoRA: Adapter lora_finqa_34 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:33:45,540] m-LoRA: Adapter lora_finqa_12 loss: 0.821618378162384
[2025-12-23 17:33:45,747] m-LoRA: Finish and base model offload adapter - ['lora_finqa_5']
[2025-12-23 17:33:46,278] m-LoRA: Task to running, need to load adapters: ['lora_finqa_35']
[2025-12-23 17:33:46,345] m-LoRA: Adapter lora_finqa_35 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:33:50,052] m-LoRA: Adapter lora_finqa_14 loss: 1.7270523309707642
[2025-12-23 17:33:50,160] m-LoRA: Adapter lora_finqa_6 epoch: 1/1 iteration: 64/128 step: 9
[2025-12-23 17:33:50,671] m-LoRA: Adapter lora_finqa_15 loss: 0.33289268612861633
[2025-12-23 17:33:50,674] m-LoRA: Adapter lora_finqa_7 epoch: 1/1 iteration: 16/128 step: 9
[2025-12-23 17:33:50,935] m-LoRA: Adapter lora_finqa_8 epoch: 1/1 iteration: 16/128 step: 9
[2025-12-23 17:33:50,990] m-LoRA: Adapter lora_finqa_16 loss: 0.33480608463287354
[2025-12-23 17:33:53,250] m-LoRA: Adapter lora_finqa_17 loss: 0.7797235250473022
[2025-12-23 17:33:53,447] m-LoRA: Adapter lora_finqa_9 epoch: 1/1 iteration: 64/128 step: 9
[2025-12-23 17:33:54,568] m-LoRA: Adapter lora_finqa_10 epoch: 1/1 iteration: 32/128 step: 9
[2025-12-23 17:33:54,638] m-LoRA: Adapter lora_finqa_18 loss: 0.7856079339981079
[2025-12-23 17:33:56,828] m-LoRA: Adapter lora_finqa_11 epoch: 1/1 iteration: 32/128 step: 9
[2025-12-23 17:33:56,903] m-LoRA: Adapter lora_finqa_19 loss: 1.7379698753356934
[2025-12-23 17:34:00,638] m-LoRA: Adapter lora_finqa_13 epoch: 1/1 iteration: 32/128 step: 9
[2025-12-23 17:34:00,832] m-LoRA: Adapter lora_finqa_20 loss: 0.3227916955947876
[2025-12-23 17:34:02,971] m-LoRA: Adapter lora_finqa_22 loss: 0.7898880243301392
[2025-12-23 17:34:03,159] m-LoRA: Adapter lora_finqa_12 epoch: 1/1 iteration: 64/128 step: 9
[2025-12-23 17:34:04,351] m-LoRA: Adapter lora_finqa_21 loss: 2.5003066062927246
[2025-12-23 17:34:04,496] m-LoRA: Finish and base model offload adapter - ['lora_finqa_14']
[2025-12-23 17:34:04,733] m-LoRA: Task to running, need to load adapters: ['lora_finqa_36']
[2025-12-23 17:34:04,771] m-LoRA: Adapter lora_finqa_36 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:34:05,003] m-LoRA: Adapter lora_finqa_23 loss: 0.34694868326187134
[2025-12-23 17:34:05,076] m-LoRA: Adapter lora_finqa_15 epoch: 1/1 iteration: 16/128 step: 9
[2025-12-23 17:34:08,914] m-LoRA: Adapter lora_finqa_16 epoch: 1/1 iteration: 16/128 step: 9
[2025-12-23 17:34:09,180] m-LoRA: Adapter lora_finqa_24 loss: 0.33279502391815186
[2025-12-23 17:34:09,649] m-LoRA: Adapter lora_finqa_25 loss: 0.8115355968475342
[2025-12-23 17:34:09,732] m-LoRA: Adapter lora_finqa_17 epoch: 1/1 iteration: 64/128 step: 9
[2025-12-23 17:34:10,718] m-LoRA: Adapter lora_finqa_18 epoch: 1/1 iteration: 32/128 step: 9
[2025-12-23 17:34:10,793] m-LoRA: Adapter lora_finqa_26 loss: 2.4999094009399414
[2025-12-23 17:34:11,759] m-LoRA: Adapter lora_finqa_27 loss: 0.3375619649887085
[2025-12-23 17:34:11,882] m-LoRA: Adapter lora_finqa_19 epoch: 1/1 iteration: 64/128 step: 9
[2025-12-23 17:34:14,598] m-LoRA: Adapter lora_finqa_28 loss: 0.8148131966590881
[2025-12-23 17:34:14,971] m-LoRA: Finish and base model offload adapter - ['lora_finqa_20']
[2025-12-23 17:34:15,819] m-LoRA: Adapter lora_finqa_29 loss: 0.782646119594574
[2025-12-23 17:34:15,829] m-LoRA: Task to running, need to load adapters: ['lora_finqa_37']
[2025-12-23 17:34:16,034] m-LoRA: Adapter lora_finqa_37 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:34:16,140] m-LoRA: Adapter lora_finqa_22 epoch: 1/1 iteration: 64/128 step: 9
[2025-12-23 17:34:16,858] m-LoRA: Adapter lora_finqa_21 epoch: 1/1 iteration: 32/128 step: 9
[2025-12-23 17:34:16,947] m-LoRA: Adapter lora_finqa_30 loss: 0.32812613248825073
[2025-12-23 17:34:21,637] m-LoRA: Adapter lora_finqa_23 epoch: 1/1 iteration: 16/128 step: 9
[2025-12-23 17:34:21,853] m-LoRA: Adapter lora_finqa_31 loss: 0.3304099142551422
[2025-12-23 17:34:22,887] m-LoRA: Adapter lora_finqa_32 loss: 2.4989216327667236
[2025-12-23 17:34:23,061] m-LoRA: Finish and base model offload adapter - ['lora_finqa_24']
[2025-12-23 17:34:23,716] m-LoRA: Adapter lora_finqa_0 loss: 1.5557098388671875
[2025-12-23 17:34:23,719] m-LoRA: Task to running, need to load adapters: ['lora_finqa_38']
[2025-12-23 17:34:23,822] m-LoRA: Adapter lora_finqa_38 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:34:24,108] m-LoRA: Adapter lora_finqa_3 loss: 1.5623027086257935
[2025-12-23 17:34:24,112] m-LoRA: Adapter lora_finqa_25 epoch: 1/1 iteration: 16/128 step: 9
[2025-12-23 17:34:24,299] m-LoRA: Adapter lora_finqa_26 epoch: 1/1 iteration: 32/128 step: 9
[2025-12-23 17:34:29,153] m-LoRA: Adapter lora_finqa_33 loss: 2.5885279178619385
[2025-12-23 17:34:29,259] m-LoRA: Adapter lora_finqa_1 loss: 1.556731104850769
[2025-12-23 17:34:29,263] m-LoRA: Adapter lora_finqa_27 epoch: 1/1 iteration: 32/128 step: 9
[2025-12-23 17:34:29,642] m-LoRA: Finish and base model offload adapter - ['lora_finqa_28']
[2025-12-23 17:34:30,197] m-LoRA: Task to running, need to load adapters: ['lora_finqa_39']
[2025-12-23 17:34:30,575] m-LoRA: Adapter lora_finqa_39 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:34:30,779] m-LoRA: Adapter lora_finqa_34 loss: 2.588528633117676
[2025-12-23 17:34:30,789] m-LoRA: Adapter lora_finqa_29 epoch: 1/1 iteration: 64/128 step: 9
[2025-12-23 17:34:31,031] m-LoRA: Adapter lora_finqa_35 loss: 2.5885279178619385
[2025-12-23 17:34:31,141] m-LoRA: Adapter lora_finqa_30 epoch: 1/1 iteration: 64/128 step: 9
[2025-12-23 17:34:32,275] m-LoRA: Adapter lora_finqa_6 loss: 0.21193160116672516
[2025-12-23 17:34:32,480] m-LoRA: Finish and base model offload adapter - ['lora_finqa_31']
[2025-12-23 17:34:33,012] m-LoRA: Adapter lora_finqa_7 loss: 0.5878480672836304
[2025-12-23 17:34:33,015] m-LoRA: Task to running, need to load adapters: ['lora_finqa_40']
[2025-12-23 17:34:33,098] m-LoRA: Adapter lora_finqa_40 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:34:33,234] m-LoRA: Adapter lora_finqa_32 epoch: 1/1 iteration: 32/128 step: 9
[2025-12-23 17:34:33,338] m-LoRA: Adapter lora_finqa_8 loss: 0.5856879353523254
[2025-12-23 17:34:33,341] m-LoRA: Adapter lora_finqa_0 epoch: 1/1 iteration: 18/128 step: 10
[2025-12-23 17:34:35,754] m-LoRA: Adapter lora_finqa_3 epoch: 1/1 iteration: 18/128 step: 10
[2025-12-23 17:34:35,859] m-LoRA: Adapter lora_finqa_9 loss: 0.20944887399673462
[2025-12-23 17:34:37,084] m-LoRA: Adapter lora_finqa_10 loss: 1.5514862537384033
[2025-12-23 17:34:37,246] m-LoRA: Adapter lora_finqa_33 epoch: 1/1 iteration: 16/128 step: 2
[2025-12-23 17:34:38,304] m-LoRA: Adapter lora_finqa_1 epoch: 1/1 iteration: 18/128 step: 10
[2025-12-23 17:34:38,340] m-LoRA: Adapter lora_finqa_11 loss: 1.5553603172302246
[2025-12-23 17:34:39,532] m-LoRA: Adapter lora_finqa_13 loss: 0.5497898459434509
[2025-12-23 17:34:39,659] m-LoRA: Adapter lora_finqa_34 epoch: 1/1 iteration: 8/128 step: 2
[2025-12-23 17:34:41,928] m-LoRA: Adapter lora_finqa_12 loss: 0.5719587802886963
[2025-12-23 17:34:41,990] m-LoRA: Adapter lora_finqa_35 epoch: 1/1 iteration: 4/128 step: 2
[2025-12-23 17:34:42,547] m-LoRA: Adapter lora_finqa_36 loss: 2.5885283946990967
[2025-12-23 17:34:42,655] m-LoRA: Adapter lora_finqa_6 epoch: 1/1 iteration: 72/128 step: 10
[2025-12-23 17:34:42,908] m-LoRA: Adapter lora_finqa_15 loss: 0.21421359479427338
[2025-12-23 17:34:42,911] m-LoRA: Adapter lora_finqa_7 epoch: 1/1 iteration: 18/128 step: 10
[2025-12-23 17:34:43,593] m-LoRA: Adapter lora_finqa_16 loss: 0.21635565161705017
[2025-12-23 17:34:43,596] m-LoRA: Adapter lora_finqa_8 epoch: 1/1 iteration: 18/128 step: 10
[2025-12-23 17:34:45,857] m-LoRA: Adapter lora_finqa_17 loss: 0.5393347144126892
[2025-12-23 17:34:45,956] m-LoRA: Adapter lora_finqa_9 epoch: 1/1 iteration: 72/128 step: 10
[2025-12-23 17:34:46,949] m-LoRA: Adapter lora_finqa_10 epoch: 1/1 iteration: 36/128 step: 10
[2025-12-23 17:34:47,021] m-LoRA: Adapter lora_finqa_18 loss: 0.5407055616378784
[2025-12-23 17:34:49,151] m-LoRA: Adapter lora_finqa_11 epoch: 1/1 iteration: 36/128 step: 10
[2025-12-23 17:34:49,257] m-LoRA: Adapter lora_finqa_19 loss: 1.5533941984176636
[2025-12-23 17:34:49,735] m-LoRA: Adapter lora_finqa_13 epoch: 1/1 iteration: 36/128 step: 10
[2025-12-23 17:34:49,808] m-LoRA: Adapter lora_finqa_37 loss: 2.5885283946990967
[2025-12-23 17:34:51,044] m-LoRA: Adapter lora_finqa_22 loss: 0.5418810844421387
[2025-12-23 17:34:51,054] m-LoRA: Adapter lora_finqa_12 epoch: 1/1 iteration: 72/128 step: 10
[2025-12-23 17:34:52,149] m-LoRA: Adapter lora_finqa_21 loss: 2.4788501262664795
[2025-12-23 17:34:52,154] m-LoRA: Adapter lora_finqa_36 epoch: 1/1 iteration: 2/128 step: 2
[2025-12-23 17:34:52,814] m-LoRA: Adapter lora_finqa_15 epoch: 1/1 iteration: 18/128 step: 10
[2025-12-23 17:34:52,847] m-LoRA: Adapter lora_finqa_23 loss: 0.22578752040863037
[2025-12-23 17:34:54,981] m-LoRA: Adapter lora_finqa_16 epoch: 1/1 iteration: 18/128 step: 10
[2025-12-23 17:34:55,198] m-LoRA: Adapter lora_finqa_38 loss: 2.5885279178619385
[2025-12-23 17:34:55,722] m-LoRA: Adapter lora_finqa_25 loss: 0.5618178248405457
[2025-12-23 17:34:55,806] m-LoRA: Adapter lora_finqa_17 epoch: 1/1 iteration: 72/128 step: 10
[2025-12-23 17:34:56,779] m-LoRA: Adapter lora_finqa_18 epoch: 1/1 iteration: 36/128 step: 10
[2025-12-23 17:34:56,857] m-LoRA: Adapter lora_finqa_26 loss: 2.478062868118286
[2025-12-23 17:34:57,372] m-LoRA: Adapter lora_finqa_27 loss: 0.21192865073680878
[2025-12-23 17:34:57,378] m-LoRA: Adapter lora_finqa_19 epoch: 1/1 iteration: 72/128 step: 10
[2025-12-23 17:34:58,699] m-LoRA: Adapter lora_finqa_37 epoch: 1/1 iteration: 2/128 step: 2
[2025-12-23 17:34:58,756] m-LoRA: Adapter lora_finqa_39 loss: 2.5885279178619385
[2025-12-23 17:35:01,091] m-LoRA: Adapter lora_finqa_29 loss: 0.539128839969635
[2025-12-23 17:35:01,287] m-LoRA: Adapter lora_finqa_22 epoch: 1/1 iteration: 72/128 step: 10
[2025-12-23 17:35:03,330] m-LoRA: Adapter lora_finqa_21 epoch: 1/1 iteration: 36/128 step: 10
[2025-12-23 17:35:03,432] m-LoRA: Adapter lora_finqa_30 loss: 0.20877960324287415
[2025-12-23 17:35:03,928] m-LoRA: Adapter lora_finqa_23 epoch: 1/1 iteration: 18/128 step: 10
[2025-12-23 17:35:03,980] m-LoRA: Adapter lora_finqa_40 loss: 2.5885283946990967
[2025-12-23 17:35:04,538] m-LoRA: Adapter lora_finqa_32 loss: 2.475773572921753
[2025-12-23 17:35:04,713] m-LoRA: Adapter lora_finqa_38 epoch: 1/1 iteration: 16/128 step: 2
[2025-12-23 17:35:05,329] m-LoRA: Adapter lora_finqa_25 epoch: 1/1 iteration: 18/128 step: 10
[2025-12-23 17:35:05,374] m-LoRA: Adapter lora_finqa_0 loss: 1.3914698362350464
[2025-12-23 17:35:05,699] m-LoRA: Adapter lora_finqa_3 loss: 1.4003260135650635
[2025-12-23 17:35:05,702] m-LoRA: Adapter lora_finqa_26 epoch: 1/1 iteration: 36/128 step: 10
[2025-12-23 17:35:07,887] m-LoRA: Adapter lora_finqa_27 epoch: 1/1 iteration: 36/128 step: 10
[2025-12-23 17:35:08,260] m-LoRA: Adapter lora_finqa_33 loss: 2.545323133468628
[2025-12-23 17:35:08,278] m-LoRA: Adapter lora_finqa_39 epoch: 1/1 iteration: 4/128 step: 2
[2025-12-23 17:35:08,370] m-LoRA: Adapter lora_finqa_1 loss: 1.3931834697723389
[2025-12-23 17:35:09,435] m-LoRA: Adapter lora_finqa_34 loss: 2.3146674633026123
[2025-12-23 17:35:09,635] m-LoRA: Adapter lora_finqa_29 epoch: 1/1 iteration: 72/128 step: 10
[2025-12-23 17:35:10,066] m-LoRA: Adapter lora_finqa_35 loss: 2.473938226699829
[2025-12-23 17:35:10,176] m-LoRA: Adapter lora_finqa_30 epoch: 1/1 iteration: 72/128 step: 10
[2025-12-23 17:35:11,302] m-LoRA: Adapter lora_finqa_40 epoch: 1/1 iteration: 2/128 step: 2
[2025-12-23 17:35:11,369] m-LoRA: Adapter lora_finqa_6 loss: 0.11150503903627396
[2025-12-23 17:35:11,865] m-LoRA: Adapter lora_finqa_7 loss: 0.4273461103439331
[2025-12-23 17:35:11,869] m-LoRA: Adapter lora_finqa_32 epoch: 1/1 iteration: 36/128 step: 10
[2025-12-23 17:35:12,214] m-LoRA: Adapter lora_finqa_8 loss: 0.4287242591381073
[2025-12-23 17:35:12,217] m-LoRA: Adapter lora_finqa_0 epoch: 1/1 iteration: 20/128 step: 11
[2025-12-23 17:35:13,423] m-LoRA: Adapter lora_finqa_9 loss: 0.1034083291888237
[2025-12-23 17:35:13,433] m-LoRA: Adapter lora_finqa_3 epoch: 1/1 iteration: 20/128 step: 11
[2025-12-23 17:35:14,076] m-LoRA: Adapter lora_finqa_10 loss: 1.3895947933197021
[2025-12-23 17:35:14,222] m-LoRA: Adapter lora_finqa_33 epoch: 1/1 iteration: 32/128 step: 3
[2025-12-23 17:35:14,633] m-LoRA: Adapter lora_finqa_1 epoch: 1/1 iteration: 20/128 step: 11
[2025-12-23 17:35:14,842] m-LoRA: Adapter lora_finqa_11 loss: 1.3953310251235962
[2025-12-23 17:35:15,431] m-LoRA: Adapter lora_finqa_13 loss: 0.3818841278553009
[2025-12-23 17:35:15,580] m-LoRA: Adapter lora_finqa_34 epoch: 1/1 iteration: 16/128 step: 3
[2025-12-23 17:35:16,716] m-LoRA: Adapter lora_finqa_35 epoch: 1/1 iteration: 8/128 step: 3
[2025-12-23 17:35:16,849] m-LoRA: Adapter lora_finqa_12 loss: 0.42140182852745056
[2025-12-23 17:35:17,205] m-LoRA: Adapter lora_finqa_36 loss: 2.542715311050415
[2025-12-23 17:35:17,312] m-LoRA: Adapter lora_finqa_6 epoch: 1/1 iteration: 80/128 step: 11
[2025-12-23 17:35:17,554] m-LoRA: Adapter lora_finqa_15 loss: 0.11375157535076141
[2025-12-23 17:35:17,557] m-LoRA: Adapter lora_finqa_7 epoch: 1/1 iteration: 20/128 step: 11
[2025-12-23 17:35:17,884] m-LoRA: Adapter lora_finqa_16 loss: 0.11036429554224014
[2025-12-23 17:35:17,887] m-LoRA: Adapter lora_finqa_8 epoch: 1/1 iteration: 20/128 step: 11
[2025-12-23 17:35:20,264] m-LoRA: Adapter lora_finqa_17 loss: 0.36997857689857483
[2025-12-23 17:35:20,515] m-LoRA: Adapter lora_finqa_9 epoch: 1/1 iteration: 80/128 step: 11
[2025-12-23 17:35:21,160] m-LoRA: Adapter lora_finqa_10 epoch: 1/1 iteration: 40/128 step: 11
[2025-12-23 17:35:21,245] m-LoRA: Adapter lora_finqa_18 loss: 0.3724234700202942
[2025-12-23 17:35:23,579] m-LoRA: Adapter lora_finqa_11 epoch: 1/1 iteration: 40/128 step: 11
[2025-12-23 17:35:23,786] m-LoRA: Adapter lora_finqa_19 loss: 1.393502116203308
[2025-12-23 17:35:23,796] m-LoRA: Adapter lora_finqa_13 epoch: 1/1 iteration: 40/128 step: 11
[2025-12-23 17:35:23,872] m-LoRA: Adapter lora_finqa_37 loss: 2.5451934337615967
[2025-12-23 17:35:24,977] m-LoRA: Adapter lora_finqa_22 loss: 0.38303205370903015
[2025-12-23 17:35:25,169] m-LoRA: Adapter lora_finqa_12 epoch: 1/1 iteration: 80/128 step: 11
[2025-12-23 17:35:25,706] m-LoRA: Adapter lora_finqa_21 loss: 2.4515979290008545
[2025-12-23 17:35:25,712] m-LoRA: Adapter lora_finqa_36 epoch: 1/1 iteration: 4/128 step: 3
[2025-12-23 17:35:26,127] m-LoRA: Adapter lora_finqa_23 loss: 0.11760476976633072
[2025-12-23 17:35:26,131] m-LoRA: Adapter lora_finqa_15 epoch: 1/1 iteration: 20/128 step: 11
[2025-12-23 17:35:30,200] m-LoRA: Adapter lora_finqa_16 epoch: 1/1 iteration: 20/128 step: 11
[2025-12-23 17:35:30,460] m-LoRA: Adapter lora_finqa_38 loss: 2.5848255157470703
[2025-12-23 17:35:30,655] m-LoRA: Adapter lora_finqa_25 loss: 0.4102102816104889
[2025-12-23 17:35:30,658] m-LoRA: Adapter lora_finqa_17 epoch: 1/1 iteration: 80/128 step: 11
[2025-12-23 17:35:31,251] m-LoRA: Adapter lora_finqa_26 loss: 2.449904203414917
[2025-12-23 17:35:31,257] m-LoRA: Adapter lora_finqa_18 epoch: 1/1 iteration: 40/128 step: 11
[2025-12-23 17:35:31,764] m-LoRA: Adapter lora_finqa_27 loss: 0.10948356240987778
[2025-12-23 17:35:31,898] m-LoRA: Adapter lora_finqa_19 epoch: 1/1 iteration: 80/128 step: 11
[2025-12-23 17:35:32,352] m-LoRA: Adapter lora_finqa_39 loss: 2.3154640197753906
[2025-12-23 17:35:32,357] m-LoRA: Adapter lora_finqa_37 epoch: 1/1 iteration: 4/128 step: 3
[2025-12-23 17:35:35,079] m-LoRA: Adapter lora_finqa_29 loss: 0.3764882981777191
[2025-12-23 17:35:35,269] m-LoRA: Adapter lora_finqa_22 epoch: 1/1 iteration: 80/128 step: 11
[2025-12-23 17:35:37,423] m-LoRA: Adapter lora_finqa_21 epoch: 1/1 iteration: 40/128 step: 11
[2025-12-23 17:35:37,520] m-LoRA: Adapter lora_finqa_30 loss: 0.1042419821023941
[2025-12-23 17:35:37,987] m-LoRA: Adapter lora_finqa_40 loss: 2.542480230331421
[2025-12-23 17:35:37,991] m-LoRA: Adapter lora_finqa_23 epoch: 1/1 iteration: 20/128 step: 11
[2025-12-23 17:35:39,086] m-LoRA: Adapter lora_finqa_32 loss: 2.4511799812316895
[2025-12-23 17:35:39,379] m-LoRA: Adapter lora_finqa_38 epoch: 1/1 iteration: 32/128 step: 3
[2025-12-23 17:35:39,917] m-LoRA: Adapter lora_finqa_0 loss: 1.203445553779602
[2025-12-23 17:35:39,921] m-LoRA: Adapter lora_finqa_25 epoch: 1/1 iteration: 20/128 step: 11
[2025-12-23 17:35:40,603] m-LoRA: Adapter lora_finqa_3 loss: 1.2144832611083984
[2025-12-23 17:35:40,606] m-LoRA: Adapter lora_finqa_26 epoch: 1/1 iteration: 40/128 step: 11
[2025-12-23 17:35:44,512] m-LoRA: Adapter lora_finqa_27 epoch: 1/1 iteration: 40/128 step: 11
[2025-12-23 17:35:44,706] m-LoRA: Adapter lora_finqa_33 loss: 2.4552016258239746
[2025-12-23 17:35:45,140] m-LoRA: Adapter lora_finqa_1 loss: 1.2049682140350342
[2025-12-23 17:35:45,243] m-LoRA: Adapter lora_finqa_39 epoch: 1/1 iteration: 8/128 step: 3
[2025-12-23 17:35:47,370] m-LoRA: Adapter lora_finqa_34 loss: 1.9173400402069092
[2025-12-23 17:35:47,736] m-LoRA: Adapter lora_finqa_29 epoch: 1/1 iteration: 80/128 step: 11
[2025-12-23 17:35:48,992] m-LoRA: Adapter lora_finqa_35 loss: 2.254678964614868
[2025-12-23 17:35:49,102] m-LoRA: Adapter lora_finqa_30 epoch: 1/1 iteration: 80/128 step: 11
[2025-12-23 17:35:50,293] m-LoRA: Adapter lora_finqa_40 epoch: 1/1 iteration: 4/128 step: 3
[2025-12-23 17:35:50,371] m-LoRA: Adapter lora_finqa_6 loss: 0.05925187095999718
[2025-12-23 17:35:50,942] m-LoRA: Adapter lora_finqa_7 loss: 0.2879070043563843
[2025-12-23 17:35:50,945] m-LoRA: Adapter lora_finqa_32 epoch: 1/1 iteration: 40/128 step: 11
[2025-12-23 17:35:51,471] m-LoRA: Adapter lora_finqa_8 loss: 0.287123441696167
[2025-12-23 17:35:51,474] m-LoRA: Adapter lora_finqa_0 epoch: 1/1 iteration: 22/128 step: 12
[2025-12-23 17:35:52,671] m-LoRA: Adapter lora_finqa_3 epoch: 1/1 iteration: 22/128 step: 12
[2025-12-23 17:35:52,754] m-LoRA: Adapter lora_finqa_9 loss: 0.055489569902420044
[2025-12-23 17:35:53,773] m-LoRA: Adapter lora_finqa_10 loss: 1.1973390579223633
[2025-12-23 17:35:53,928] m-LoRA: Adapter lora_finqa_33 epoch: 1/1 iteration: 48/128 step: 4
[2025-12-23 17:35:54,500] m-LoRA: Adapter lora_finqa_1 epoch: 1/1 iteration: 22/128 step: 12
[2025-12-23 17:35:54,558] m-LoRA: Adapter lora_finqa_11 loss: 1.2041715383529663
[2025-12-23 17:35:55,098] m-LoRA: Adapter lora_finqa_13 loss: 0.261308878660202
[2025-12-23 17:35:55,209] m-LoRA: Adapter lora_finqa_34 epoch: 1/1 iteration: 24/128 step: 4
[2025-12-23 17:35:56,440] m-LoRA: Adapter lora_finqa_35 epoch: 1/1 iteration: 12/128 step: 4
[2025-12-23 17:35:56,545] m-LoRA: Adapter lora_finqa_12 loss: 0.2769121825695038
[2025-12-23 17:35:57,205] m-LoRA: Adapter lora_finqa_36 loss: 2.4537973403930664
[2025-12-23 17:35:57,297] m-LoRA: Adapter lora_finqa_6 epoch: 1/1 iteration: 88/128 step: 12
[2025-12-23 17:35:57,784] m-LoRA: Adapter lora_finqa_7 epoch: 1/1 iteration: 22/128 step: 12
[2025-12-23 17:35:57,839] m-LoRA: Adapter lora_finqa_15 loss: 0.05875389650464058
[2025-12-23 17:35:58,516] m-LoRA: Adapter lora_finqa_16 loss: 0.06253907084465027
[2025-12-23 17:35:58,520] m-LoRA: Adapter lora_finqa_8 epoch: 1/1 iteration: 22/128 step: 12
[2025-12-23 17:35:59,736] m-LoRA: Adapter lora_finqa_17 loss: 0.2583696246147156
[2025-12-23 17:35:59,837] m-LoRA: Adapter lora_finqa_9 epoch: 1/1 iteration: 88/128 step: 12
[2025-12-23 17:36:00,806] m-LoRA: Adapter lora_finqa_10 epoch: 1/1 iteration: 44/128 step: 12
[2025-12-23 17:36:00,879] m-LoRA: Adapter lora_finqa_18 loss: 0.2586626708507538
[2025-12-23 17:36:02,128] m-LoRA: Adapter lora_finqa_11 epoch: 1/1 iteration: 44/128 step: 12
[2025-12-23 17:36:02,202] m-LoRA: Adapter lora_finqa_19 loss: 1.2040091753005981
[2025-12-23 17:36:02,795] m-LoRA: Adapter lora_finqa_37 loss: 2.453315496444702
[2025-12-23 17:36:02,799] m-LoRA: Adapter lora_finqa_13 epoch: 1/1 iteration: 44/128 step: 12
[2025-12-23 17:36:03,985] m-LoRA: Adapter lora_finqa_22 loss: 0.26041385531425476
[2025-12-23 17:36:04,194] m-LoRA: Adapter lora_finqa_12 epoch: 1/1 iteration: 88/128 step: 12
[2025-12-23 17:36:05,123] m-LoRA: Adapter lora_finqa_36 epoch: 1/1 iteration: 6/128 step: 4
[2025-12-23 17:36:05,176] m-LoRA: Adapter lora_finqa_21 loss: 2.4229118824005127
[2025-12-23 17:36:05,552] m-LoRA: Adapter lora_finqa_23 loss: 0.06280973553657532
[2025-12-23 17:36:05,555] m-LoRA: Adapter lora_finqa_15 epoch: 1/1 iteration: 22/128 step: 12
[2025-12-23 17:36:09,585] m-LoRA: Adapter lora_finqa_16 epoch: 1/1 iteration: 22/128 step: 12
[2025-12-23 17:36:09,806] m-LoRA: Adapter lora_finqa_38 loss: 2.577080011367798
[2025-12-23 17:36:09,991] m-LoRA: Adapter lora_finqa_25 loss: 0.26928257942199707
[2025-12-23 17:36:09,994] m-LoRA: Adapter lora_finqa_17 epoch: 1/1 iteration: 88/128 step: 12
[2025-12-23 17:36:10,564] m-LoRA: Adapter lora_finqa_26 loss: 2.4208030700683594
[2025-12-23 17:36:10,677] m-LoRA: Adapter lora_finqa_18 epoch: 1/1 iteration: 44/128 step: 12
[2025-12-23 17:36:11,202] m-LoRA: Adapter lora_finqa_27 loss: 0.054267313331365585
[2025-12-23 17:36:11,208] m-LoRA: Adapter lora_finqa_19 epoch: 1/1 iteration: 88/128 step: 12
[2025-12-23 17:36:11,670] m-LoRA: Adapter lora_finqa_39 loss: 1.915016531944275
[2025-12-23 17:36:11,675] m-LoRA: Adapter lora_finqa_37 epoch: 1/1 iteration: 6/128 step: 4
[2025-12-23 17:36:13,063] m-LoRA: Adapter lora_finqa_29 loss: 0.25594210624694824
[2025-12-23 17:36:13,179] m-LoRA: Adapter lora_finqa_22 epoch: 1/1 iteration: 88/128 step: 12
[2025-12-23 17:36:14,681] m-LoRA: Adapter lora_finqa_30 loss: 0.0554572269320488
[2025-12-23 17:36:14,691] m-LoRA: Adapter lora_finqa_21 epoch: 1/1 iteration: 44/128 step: 12
[2025-12-23 17:36:14,928] m-LoRA: Adapter lora_finqa_40 loss: 2.4603590965270996
[2025-12-23 17:36:14,932] m-LoRA: Adapter lora_finqa_23 epoch: 1/1 iteration: 22/128 step: 12
[2025-12-23 17:36:15,570] m-LoRA: Adapter lora_finqa_32 loss: 2.4221901893615723
[2025-12-23 17:36:15,722] m-LoRA: Adapter lora_finqa_38 epoch: 1/1 iteration: 48/128 step: 4
[2025-12-23 17:36:16,087] m-LoRA: Adapter lora_finqa_0 loss: 1.0074942111968994
[2025-12-23 17:36:16,090] m-LoRA: Adapter lora_finqa_25 epoch: 1/1 iteration: 22/128 step: 12
[2025-12-23 17:36:16,269] m-LoRA: Adapter lora_finqa_3 loss: 1.0163302421569824
[2025-12-23 17:36:16,272] m-LoRA: Adapter lora_finqa_26 epoch: 1/1 iteration: 44/128 step: 12
[2025-12-23 17:36:18,592] m-LoRA: Adapter lora_finqa_27 epoch: 1/1 iteration: 44/128 step: 12
[2025-12-23 17:36:18,846] m-LoRA: Adapter lora_finqa_33 loss: 2.338522434234619
[2025-12-23 17:36:19,461] m-LoRA: Adapter lora_finqa_1 loss: 1.009840965270996
[2025-12-23 17:36:19,465] m-LoRA: Adapter lora_finqa_39 epoch: 1/1 iteration: 12/128 step: 4
[2025-12-23 17:36:21,612] m-LoRA: Adapter lora_finqa_34 loss: 1.4841458797454834
[2025-12-23 17:36:21,797] m-LoRA: Adapter lora_finqa_29 epoch: 1/1 iteration: 88/128 step: 12
[2025-12-23 17:36:22,732] m-LoRA: Adapter lora_finqa_35 loss: 1.9908123016357422
[2025-12-23 17:36:22,855] m-LoRA: Adapter lora_finqa_30 epoch: 1/1 iteration: 88/128 step: 12
[2025-12-23 17:36:25,561] m-LoRA: Adapter lora_finqa_40 epoch: 1/1 iteration: 6/128 step: 4
[2025-12-23 17:36:25,631] m-LoRA: Adapter lora_finqa_6 loss: 0.03720787912607193
[2025-12-23 17:36:26,040] m-LoRA: Adapter lora_finqa_7 loss: 0.20052875578403473
[2025-12-23 17:36:26,043] m-LoRA: Adapter lora_finqa_32 epoch: 1/1 iteration: 44/128 step: 12
[2025-12-23 17:36:26,297] m-LoRA: Adapter lora_finqa_8 loss: 0.200047105550766
[2025-12-23 17:36:26,300] m-LoRA: Adapter lora_finqa_0 epoch: 1/1 iteration: 24/128 step: 13
[2025-12-23 17:36:28,513] m-LoRA: Adapter lora_finqa_3 epoch: 1/1 iteration: 24/128 step: 13
[2025-12-23 17:36:28,623] m-LoRA: Adapter lora_finqa_9 loss: 0.03644457086920738
[2025-12-23 17:36:29,135] m-LoRA: Adapter lora_finqa_10 loss: 1.0014768838882446
[2025-12-23 17:36:29,280] m-LoRA: Adapter lora_finqa_33 epoch: 1/1 iteration: 64/128 step: 5
[2025-12-23 17:36:30,284] m-LoRA: Adapter lora_finqa_1 epoch: 1/1 iteration: 24/128 step: 13
[2025-12-23 17:36:30,336] m-LoRA: Adapter lora_finqa_11 loss: 1.0108619928359985
[2025-12-23 17:36:31,888] m-LoRA: Adapter lora_finqa_13 loss: 0.18623754382133484
[2025-12-23 17:36:31,893] m-LoRA: Adapter lora_finqa_34 epoch: 1/1 iteration: 32/128 step: 5
[2025-12-23 17:36:33,054] m-LoRA: Adapter lora_finqa_35 epoch: 1/1 iteration: 16/128 step: 5
[2025-12-23 17:36:33,150] m-LoRA: Adapter lora_finqa_12 loss: 0.19347292184829712
[2025-12-23 17:36:33,503] m-LoRA: Adapter lora_finqa_36 loss: 2.336376190185547
[2025-12-23 17:36:33,594] m-LoRA: Adapter lora_finqa_6 epoch: 1/1 iteration: 96/128 step: 13
[2025-12-23 17:36:33,898] m-LoRA: Adapter lora_finqa_15 loss: 0.03806145861744881
[2025-12-23 17:36:33,902] m-LoRA: Adapter lora_finqa_7 epoch: 1/1 iteration: 24/128 step: 13
[2025-12-23 17:36:34,166] m-LoRA: Adapter lora_finqa_16 loss: 0.0409369021654129
[2025-12-23 17:36:34,169] m-LoRA: Adapter lora_finqa_8 epoch: 1/1 iteration: 24/128 step: 13
[2025-12-23 17:36:36,523] m-LoRA: Adapter lora_finqa_9 epoch: 1/1 iteration: 96/128 step: 13
[2025-12-23 17:36:36,677] m-LoRA: Adapter lora_finqa_17 loss: 0.18223623931407928
[2025-12-23 17:36:37,014] m-LoRA: Adapter lora_finqa_10 epoch: 1/1 iteration: 48/128 step: 13
[2025-12-23 17:36:37,085] m-LoRA: Adapter lora_finqa_18 loss: 0.1856936663389206
[2025-12-23 17:36:38,121] m-LoRA: Adapter lora_finqa_19 loss: 1.0068663358688354
[2025-12-23 17:36:38,131] m-LoRA: Adapter lora_finqa_11 epoch: 1/1 iteration: 48/128 step: 13
[2025-12-23 17:36:38,881] m-LoRA: Adapter lora_finqa_37 loss: 2.3361687660217285
[2025-12-23 17:36:38,884] m-LoRA: Adapter lora_finqa_13 epoch: 1/1 iteration: 48/128 step: 13
[2025-12-23 17:36:41,279] m-LoRA: Adapter lora_finqa_22 loss: 0.1866695135831833
[2025-12-23 17:36:41,379] m-LoRA: Adapter lora_finqa_12 epoch: 1/1 iteration: 96/128 step: 13
[2025-12-23 17:36:42,412] m-LoRA: Adapter lora_finqa_36 epoch: 1/1 iteration: 8/128 step: 5
[2025-12-23 17:36:42,469] m-LoRA: Adapter lora_finqa_21 loss: 2.3941524028778076
[2025-12-23 17:36:43,179] m-LoRA: Adapter lora_finqa_23 loss: 0.043781623244285583
[2025-12-23 17:36:43,182] m-LoRA: Adapter lora_finqa_15 epoch: 1/1 iteration: 24/128 step: 13
[2025-12-23 17:36:46,495] m-LoRA: Adapter lora_finqa_16 epoch: 1/1 iteration: 24/128 step: 13
[2025-12-23 17:36:46,712] m-LoRA: Adapter lora_finqa_38 loss: 2.567796468734741
[2025-12-23 17:36:47,330] m-LoRA: Adapter lora_finqa_25 loss: 0.1890222281217575
[2025-12-23 17:36:47,333] m-LoRA: Adapter lora_finqa_17 epoch: 1/1 iteration: 96/128 step: 13
[2025-12-23 17:36:48,310] m-LoRA: Adapter lora_finqa_26 loss: 2.390381336212158
[2025-12-23 17:36:48,424] m-LoRA: Adapter lora_finqa_18 epoch: 1/1 iteration: 48/128 step: 13
[2025-12-23 17:36:49,383] m-LoRA: Adapter lora_finqa_27 loss: 0.036137886345386505
[2025-12-23 17:36:49,541] m-LoRA: Adapter lora_finqa_19 epoch: 1/1 iteration: 96/128 step: 13
[2025-12-23 17:36:51,017] m-LoRA: Adapter lora_finqa_37 epoch: 1/1 iteration: 8/128 step: 5
[2025-12-23 17:36:51,058] m-LoRA: Adapter lora_finqa_39 loss: 1.4834705591201782
[2025-12-23 17:36:52,199] m-LoRA: Adapter lora_finqa_29 loss: 0.18151789903640747
[2025-12-23 17:36:52,290] m-LoRA: Adapter lora_finqa_22 epoch: 1/1 iteration: 96/128 step: 13
[2025-12-23 17:36:53,302] m-LoRA: Adapter lora_finqa_21 epoch: 1/1 iteration: 48/128 step: 13
[2025-12-23 17:36:53,397] m-LoRA: Adapter lora_finqa_30 loss: 0.0350288525223732
[2025-12-23 17:36:54,048] m-LoRA: Adapter lora_finqa_40 loss: 2.3379831314086914
[2025-12-23 17:36:54,052] m-LoRA: Adapter lora_finqa_23 epoch: 1/1 iteration: 24/128 step: 13
[2025-12-23 17:36:54,625] m-LoRA: Adapter lora_finqa_32 loss: 2.390577554702759
[2025-12-23 17:36:54,778] m-LoRA: Adapter lora_finqa_38 epoch: 1/1 iteration: 64/128 step: 5
[2025-12-23 17:36:55,366] m-LoRA: Adapter lora_finqa_25 epoch: 1/1 iteration: 24/128 step: 13
[2025-12-23 17:36:55,420] m-LoRA: Adapter lora_finqa_0 loss: 0.8302161693572998
[2025-12-23 17:36:55,953] m-LoRA: Adapter lora_finqa_26 epoch: 1/1 iteration: 48/128 step: 13
[2025-12-23 17:36:56,027] m-LoRA: Adapter lora_finqa_3 loss: 0.8391693234443665
[2025-12-23 17:36:58,151] m-LoRA: Adapter lora_finqa_27 epoch: 1/1 iteration: 48/128 step: 13
[2025-12-23 17:36:58,345] m-LoRA: Adapter lora_finqa_33 loss: 2.199889659881592
[2025-12-23 17:36:58,875] m-LoRA: Adapter lora_finqa_1 loss: 0.8355712294578552
[2025-12-23 17:36:58,878] m-LoRA: Adapter lora_finqa_39 epoch: 1/1 iteration: 16/128 step: 5
[2025-12-23 17:37:00,037] m-LoRA: Adapter lora_finqa_34 loss: 1.1874783039093018
[2025-12-23 17:37:00,227] m-LoRA: Adapter lora_finqa_29 epoch: 1/1 iteration: 96/128 step: 13
[2025-12-23 17:37:00,606] m-LoRA: Adapter lora_finqa_35 loss: 1.707090973854065
[2025-12-23 17:37:00,715] m-LoRA: Adapter lora_finqa_30 epoch: 1/1 iteration: 96/128 step: 13
[2025-12-23 17:37:02,009] m-LoRA: Adapter lora_finqa_40 epoch: 1/1 iteration: 8/128 step: 5
[2025-12-23 17:37:02,138] m-LoRA: Adapter lora_finqa_6 loss: 0.026417342945933342
[2025-12-23 17:37:02,738] m-LoRA: Adapter lora_finqa_7 loss: 0.1365792453289032
[2025-12-23 17:37:02,742] m-LoRA: Adapter lora_finqa_32 epoch: 1/1 iteration: 48/128 step: 13
[2025-12-23 17:37:03,453] m-LoRA: Adapter lora_finqa_0 epoch: 1/1 iteration: 26/128 step: 14
[2025-12-23 17:37:03,508] m-LoRA: Adapter lora_finqa_8 loss: 0.1345614194869995
[2025-12-23 17:37:04,787] m-LoRA: Adapter lora_finqa_3 epoch: 1/1 iteration: 26/128 step: 14
[2025-12-23 17:37:04,865] m-LoRA: Adapter lora_finqa_9 loss: 0.026582021266222
[2025-12-23 17:37:05,363] m-LoRA: Adapter lora_finqa_10 loss: 0.825186550617218
[2025-12-23 17:37:05,509] m-LoRA: Adapter lora_finqa_33 epoch: 1/1 iteration: 80/128 step: 6
[2025-12-23 17:37:06,079] m-LoRA: Adapter lora_finqa_1 epoch: 1/1 iteration: 26/128 step: 14
[2025-12-23 17:37:06,127] m-LoRA: Adapter lora_finqa_11 loss: 0.8341648578643799
[2025-12-23 17:37:07,452] m-LoRA: Adapter lora_finqa_13 loss: 0.11688917875289917
[2025-12-23 17:37:07,604] m-LoRA: Adapter lora_finqa_34 epoch: 1/1 iteration: 40/128 step: 6
[2025-12-23 17:37:08,714] m-LoRA: Adapter lora_finqa_35 epoch: 1/1 iteration: 20/128 step: 6
[2025-12-23 17:37:08,790] m-LoRA: Adapter lora_finqa_12 loss: 0.13104023039340973
[2025-12-23 17:37:08,991] m-LoRA: Adapter lora_finqa_36 loss: 2.198352336883545
[2025-12-23 17:37:09,084] m-LoRA: Adapter lora_finqa_6 epoch: 1/1 iteration: 104/128 step: 14
[2025-12-23 17:37:09,354] m-LoRA: Adapter lora_finqa_15 loss: 0.0280398428440094
[2025-12-23 17:37:09,358] m-LoRA: Adapter lora_finqa_7 epoch: 1/1 iteration: 26/128 step: 14
[2025-12-23 17:37:09,821] m-LoRA: Adapter lora_finqa_16 loss: 0.029453711584210396
[2025-12-23 17:37:09,824] m-LoRA: Adapter lora_finqa_8 epoch: 1/1 iteration: 26/128 step: 14
[2025-12-23 17:37:11,209] m-LoRA: Adapter lora_finqa_17 loss: 0.11360903084278107
[2025-12-23 17:37:11,308] m-LoRA: Adapter lora_finqa_9 epoch: 1/1 iteration: 104/128 step: 14
[2025-12-23 17:37:11,854] m-LoRA: Adapter lora_finqa_10 epoch: 1/1 iteration: 52/128 step: 14
[2025-12-23 17:37:11,926] m-LoRA: Adapter lora_finqa_18 loss: 0.11479806900024414
[2025-12-23 17:37:13,041] m-LoRA: Adapter lora_finqa_11 epoch: 1/1 iteration: 52/128 step: 14
[2025-12-23 17:37:13,164] m-LoRA: Adapter lora_finqa_19 loss: 0.8304691910743713
[2025-12-23 17:37:13,484] m-LoRA: Adapter lora_finqa_37 loss: 2.198490858078003
[2025-12-23 17:37:13,557] m-LoRA: Adapter lora_finqa_13 epoch: 1/1 iteration: 52/128 step: 14
[2025-12-23 17:37:14,855] m-LoRA: Adapter lora_finqa_22 loss: 0.11553898453712463
[2025-12-23 17:37:15,053] m-LoRA: Adapter lora_finqa_12 epoch: 1/1 iteration: 104/128 step: 14
[2025-12-23 17:37:15,480] m-LoRA: Adapter lora_finqa_36 epoch: 1/1 iteration: 10/128 step: 6
[2025-12-23 17:37:15,533] m-LoRA: Adapter lora_finqa_21 loss: 2.3593595027923584
[2025-12-23 17:37:16,212] m-LoRA: Adapter lora_finqa_15 epoch: 1/1 iteration: 26/128 step: 14
[2025-12-23 17:37:16,267] m-LoRA: Adapter lora_finqa_23 loss: 0.030590172857046127
[2025-12-23 17:37:20,918] m-LoRA: Adapter lora_finqa_16 epoch: 1/1 iteration: 26/128 step: 14
[2025-12-23 17:37:21,148] m-LoRA: Adapter lora_finqa_38 loss: 2.555441379547119
[2025-12-23 17:37:21,330] m-LoRA: Adapter lora_finqa_25 loss: 0.12443690001964569
[2025-12-23 17:37:21,333] m-LoRA: Adapter lora_finqa_17 epoch: 1/1 iteration: 104/128 step: 14
[2025-12-23 17:37:22,344] m-LoRA: Adapter lora_finqa_18 epoch: 1/1 iteration: 52/128 step: 14
[2025-12-23 17:37:22,418] m-LoRA: Adapter lora_finqa_26 loss: 2.35599684715271
[2025-12-23 17:37:23,428] m-LoRA: Adapter lora_finqa_19 epoch: 1/1 iteration: 104/128 step: 14
[2025-12-23 17:37:23,556] m-LoRA: Adapter lora_finqa_27 loss: 0.02633628249168396
[2025-12-23 17:37:24,915] m-LoRA: Adapter lora_finqa_37 epoch: 1/1 iteration: 10/128 step: 6
[2025-12-23 17:37:24,979] m-LoRA: Adapter lora_finqa_39 loss: 1.1987786293029785
[2025-12-23 17:37:27,306] m-LoRA: Adapter lora_finqa_29 loss: 0.11244786530733109
[2025-12-23 17:37:27,502] m-LoRA: Adapter lora_finqa_22 epoch: 1/1 iteration: 104/128 step: 14
[2025-12-23 17:37:29,586] m-LoRA: Adapter lora_finqa_21 epoch: 1/1 iteration: 52/128 step: 14
[2025-12-23 17:37:29,667] m-LoRA: Adapter lora_finqa_30 loss: 0.026011217385530472
[2025-12-23 17:37:30,215] m-LoRA: Adapter lora_finqa_40 loss: 2.2025206089019775
[2025-12-23 17:37:30,218] m-LoRA: Adapter lora_finqa_23 epoch: 1/1 iteration: 26/128 step: 14
[2025-12-23 17:37:31,430] m-LoRA: Adapter lora_finqa_32 loss: 2.358164072036743
[2025-12-23 17:37:31,585] m-LoRA: Adapter lora_finqa_38 epoch: 1/1 iteration: 80/128 step: 6
[2025-12-23 17:37:32,122] m-LoRA: Adapter lora_finqa_0 loss: 0.664489209651947
[2025-12-23 17:37:32,126] m-LoRA: Adapter lora_finqa_25 epoch: 1/1 iteration: 26/128 step: 14
[2025-12-23 17:37:32,849] m-LoRA: Adapter lora_finqa_3 loss: 0.6681474447250366
[2025-12-23 17:37:32,852] m-LoRA: Adapter lora_finqa_26 epoch: 1/1 iteration: 52/128 step: 14
[2025-12-23 17:37:34,910] m-LoRA: Adapter lora_finqa_27 epoch: 1/1 iteration: 52/128 step: 14
[2025-12-23 17:37:35,111] m-LoRA: Adapter lora_finqa_33 loss: 2.0522968769073486
[2025-12-23 17:37:35,678] m-LoRA: Adapter lora_finqa_1 loss: 0.664443850517273
[2025-12-23 17:37:35,681] m-LoRA: Adapter lora_finqa_39 epoch: 1/1 iteration: 20/128 step: 6
[2025-12-23 17:37:37,841] m-LoRA: Adapter lora_finqa_34 loss: 0.7825416922569275
[2025-12-23 17:37:38,362] m-LoRA: Adapter lora_finqa_29 epoch: 1/1 iteration: 104/128 step: 14
[2025-12-23 17:37:39,510] m-LoRA: Adapter lora_finqa_35 loss: 1.3974164724349976
[2025-12-23 17:37:39,630] m-LoRA: Adapter lora_finqa_30 epoch: 1/1 iteration: 104/128 step: 14
[2025-12-23 17:37:41,964] m-LoRA: Adapter lora_finqa_40 epoch: 1/1 iteration: 10/128 step: 6
[2025-12-23 17:37:42,032] m-LoRA: Adapter lora_finqa_6 loss: 0.02000064216554165
[2025-12-23 17:37:42,555] m-LoRA: Adapter lora_finqa_7 loss: 0.08135458081960678
[2025-12-23 17:37:42,559] m-LoRA: Adapter lora_finqa_32 epoch: 1/1 iteration: 52/128 step: 14
[2025-12-23 17:37:43,151] m-LoRA: Adapter lora_finqa_8 loss: 0.0789596438407898
[2025-12-23 17:37:43,154] m-LoRA: Adapter lora_finqa_0 epoch: 1/1 iteration: 28/128 step: 15
[2025-12-23 17:37:45,291] m-LoRA: Adapter lora_finqa_3 epoch: 1/1 iteration: 28/128 step: 15
[2025-12-23 17:37:45,389] m-LoRA: Adapter lora_finqa_9 loss: 0.01950104534626007
[2025-12-23 17:37:46,503] m-LoRA: Adapter lora_finqa_10 loss: 0.6605949401855469
[2025-12-23 17:37:46,649] m-LoRA: Adapter lora_finqa_33 epoch: 1/1 iteration: 96/128 step: 7
[2025-12-23 17:37:48,061] m-LoRA: Adapter lora_finqa_1 epoch: 1/1 iteration: 28/128 step: 15
[2025-12-23 17:37:48,117] m-LoRA: Adapter lora_finqa_11 loss: 0.6682998538017273
[2025-12-23 17:37:49,363] m-LoRA: Adapter lora_finqa_13 loss: 0.06691747158765793
[2025-12-23 17:37:49,515] m-LoRA: Adapter lora_finqa_34 epoch: 1/1 iteration: 48/128 step: 7
[2025-12-23 17:37:51,554] m-LoRA: Adapter lora_finqa_35 epoch: 1/1 iteration: 24/128 step: 7
[2025-12-23 17:37:51,631] m-LoRA: Adapter lora_finqa_12 loss: 0.07743857055902481
[2025-12-23 17:37:52,129] m-LoRA: Adapter lora_finqa_36 loss: 2.0525920391082764
[2025-12-23 17:37:52,220] m-LoRA: Adapter lora_finqa_6 epoch: 1/1 iteration: 112/128 step: 15
[2025-12-23 17:37:52,772] m-LoRA: Adapter lora_finqa_15 loss: 0.02033243514597416
[2025-12-23 17:37:52,776] m-LoRA: Adapter lora_finqa_7 epoch: 1/1 iteration: 28/128 step: 15
[2025-12-23 17:37:53,561] m-LoRA: Adapter lora_finqa_16 loss: 0.021863922476768494
[2025-12-23 17:37:53,565] m-LoRA: Adapter lora_finqa_8 epoch: 1/1 iteration: 28/128 step: 15
[2025-12-23 17:37:55,621] m-LoRA: Adapter lora_finqa_9 epoch: 1/1 iteration: 112/128 step: 15
[2025-12-23 17:37:55,773] m-LoRA: Adapter lora_finqa_17 loss: 0.06531066447496414
[2025-12-23 17:37:56,640] m-LoRA: Adapter lora_finqa_10 epoch: 1/1 iteration: 56/128 step: 15
[2025-12-23 17:37:56,713] m-LoRA: Adapter lora_finqa_18 loss: 0.06606525182723999
[2025-12-23 17:37:59,027] m-LoRA: Adapter lora_finqa_11 epoch: 1/1 iteration: 56/128 step: 15
[2025-12-23 17:37:59,105] m-LoRA: Adapter lora_finqa_19 loss: 0.6646221876144409
[2025-12-23 17:37:59,614] m-LoRA: Adapter lora_finqa_13 epoch: 1/1 iteration: 56/128 step: 15
[2025-12-23 17:37:59,687] m-LoRA: Adapter lora_finqa_37 loss: 2.0592544078826904
[2025-12-23 17:38:01,945] m-LoRA: Adapter lora_finqa_22 loss: 0.06606385856866837
[2025-12-23 17:38:02,146] m-LoRA: Adapter lora_finqa_12 epoch: 1/1 iteration: 112/128 step: 15
[2025-12-23 17:38:03,047] m-LoRA: Adapter lora_finqa_21 loss: 2.321840524673462
[2025-12-23 17:38:03,053] m-LoRA: Adapter lora_finqa_36 epoch: 1/1 iteration: 12/128 step: 7
[2025-12-23 17:38:03,765] m-LoRA: Adapter lora_finqa_23 loss: 0.021656742319464684
[2025-12-23 17:38:03,860] m-LoRA: Adapter lora_finqa_15 epoch: 1/1 iteration: 28/128 step: 15
[2025-12-23 17:38:07,579] m-LoRA: Adapter lora_finqa_16 epoch: 1/1 iteration: 28/128 step: 15
[2025-12-23 17:38:07,774] m-LoRA: Adapter lora_finqa_38 loss: 2.539337635040283
[2025-12-23 17:38:08,337] m-LoRA: Adapter lora_finqa_25 loss: 0.07110071927309036
[2025-12-23 17:38:08,341] m-LoRA: Adapter lora_finqa_17 epoch: 1/1 iteration: 112/128 step: 15
[2025-12-23 17:38:09,226] m-LoRA: Adapter lora_finqa_18 epoch: 1/1 iteration: 56/128 step: 15
[2025-12-23 17:38:09,299] m-LoRA: Adapter lora_finqa_26 loss: 2.320246934890747
[2025-12-23 17:38:10,255] m-LoRA: Adapter lora_finqa_27 loss: 0.019453424960374832
[2025-12-23 17:38:10,391] m-LoRA: Adapter lora_finqa_19 epoch: 1/1 iteration: 112/128 step: 15
[2025-12-23 17:38:11,931] m-LoRA: Adapter lora_finqa_39 loss: 0.7749598026275635
[2025-12-23 17:38:11,936] m-LoRA: Adapter lora_finqa_37 epoch: 1/1 iteration: 12/128 step: 7
[2025-12-23 17:38:14,063] m-LoRA: Adapter lora_finqa_29 loss: 0.06402464956045151
[2025-12-23 17:38:14,157] m-LoRA: Adapter lora_finqa_22 epoch: 1/1 iteration: 112/128 step: 15
[2025-12-23 17:38:15,174] m-LoRA: Adapter lora_finqa_21 epoch: 1/1 iteration: 56/128 step: 15
[2025-12-23 17:38:15,272] m-LoRA: Adapter lora_finqa_30 loss: 0.019854584708809853
[2025-12-23 17:38:15,931] m-LoRA: Adapter lora_finqa_40 loss: 2.056955575942993
[2025-12-23 17:38:15,935] m-LoRA: Adapter lora_finqa_23 epoch: 1/1 iteration: 28/128 step: 15
[2025-12-23 17:38:17,146] m-LoRA: Adapter lora_finqa_32 loss: 2.3197414875030518
[2025-12-23 17:38:17,303] m-LoRA: Adapter lora_finqa_38 epoch: 1/1 iteration: 96/128 step: 7
[2025-12-23 17:38:17,775] m-LoRA: Adapter lora_finqa_25 epoch: 1/1 iteration: 28/128 step: 15
[2025-12-23 17:38:17,834] m-LoRA: Adapter lora_finqa_0 loss: 0.5284088253974915
[2025-12-23 17:38:18,422] m-LoRA: Adapter lora_finqa_3 loss: 0.5348089337348938
[2025-12-23 17:38:18,426] m-LoRA: Adapter lora_finqa_26 epoch: 1/1 iteration: 56/128 step: 15
[2025-12-23 17:38:22,176] m-LoRA: Adapter lora_finqa_27 epoch: 1/1 iteration: 56/128 step: 15
[2025-12-23 17:38:22,380] m-LoRA: Adapter lora_finqa_33 loss: 1.898063063621521
[2025-12-23 17:38:22,887] m-LoRA: Adapter lora_finqa_1 loss: 0.5309021472930908
[2025-12-23 17:38:22,890] m-LoRA: Adapter lora_finqa_39 epoch: 1/1 iteration: 24/128 step: 7
[2025-12-23 17:38:24,816] m-LoRA: Adapter lora_finqa_34 loss: 0.5328071713447571
[2025-12-23 17:38:25,004] m-LoRA: Adapter lora_finqa_29 epoch: 1/1 iteration: 112/128 step: 15
[2025-12-23 17:38:26,453] m-LoRA: Adapter lora_finqa_35 loss: 1.0976041555404663
[2025-12-23 17:38:26,565] m-LoRA: Adapter lora_finqa_30 epoch: 1/1 iteration: 112/128 step: 15
[2025-12-23 17:38:28,746] m-LoRA: Adapter lora_finqa_40 epoch: 1/1 iteration: 12/128 step: 7
[2025-12-23 17:38:28,830] m-LoRA: Adapter lora_finqa_6 loss: 0.016097526997327805
[2025-12-23 17:38:29,100] m-LoRA: Adapter lora_finqa_7 loss: 0.053063102066516876
[2025-12-23 17:38:29,103] m-LoRA: Adapter lora_finqa_32 epoch: 1/1 iteration: 56/128 step: 15
[2025-12-23 17:38:29,558] m-LoRA: Adapter lora_finqa_8 loss: 0.05053155496716499
[2025-12-23 17:38:29,561] m-LoRA: Adapter lora_finqa_0 epoch: 1/1 iteration: 30/128 step: 16
[2025-12-23 17:38:31,681] m-LoRA: Adapter lora_finqa_3 epoch: 1/1 iteration: 30/128 step: 16
[2025-12-23 17:38:31,767] m-LoRA: Adapter lora_finqa_9 loss: 0.0153913339599967
[2025-12-23 17:38:32,250] m-LoRA: Adapter lora_finqa_10 loss: 0.529534637928009
[2025-12-23 17:38:32,395] m-LoRA: Adapter lora_finqa_33 epoch: 1/1 iteration: 112/128 step: 8
[2025-12-23 17:38:33,391] m-LoRA: Adapter lora_finqa_1 epoch: 1/1 iteration: 30/128 step: 16
[2025-12-23 17:38:33,451] m-LoRA: Adapter lora_finqa_11 loss: 0.5323365330696106
[2025-12-23 17:38:34,858] m-LoRA: Adapter lora_finqa_13 loss: 0.04429403692483902
[2025-12-23 17:38:34,864] m-LoRA: Adapter lora_finqa_34 epoch: 1/1 iteration: 56/128 step: 8
[2025-12-23 17:38:36,929] m-LoRA: Adapter lora_finqa_12 loss: 0.05196463316679001
[2025-12-23 17:38:37,015] m-LoRA: Adapter lora_finqa_35 epoch: 1/1 iteration: 28/128 step: 8
[2025-12-23 17:38:37,540] m-LoRA: Adapter lora_finqa_36 loss: 1.9064452648162842
[2025-12-23 17:38:37,649] m-LoRA: Adapter lora_finqa_6 epoch: 1/1 iteration: 120/128 step: 16
[2025-12-23 17:38:38,138] m-LoRA: Adapter lora_finqa_15 loss: 0.016195278614759445
[2025-12-23 17:38:38,141] m-LoRA: Adapter lora_finqa_7 epoch: 1/1 iteration: 30/128 step: 16
[2025-12-23 17:38:38,817] m-LoRA: Adapter lora_finqa_16 loss: 0.016844842582941055
[2025-12-23 17:38:38,821] m-LoRA: Adapter lora_finqa_8 epoch: 1/1 iteration: 30/128 step: 16
[2025-12-23 17:38:40,980] m-LoRA: Adapter lora_finqa_17 loss: 0.0446273572742939
[2025-12-23 17:38:41,078] m-LoRA: Adapter lora_finqa_9 epoch: 1/1 iteration: 120/128 step: 16
[2025-12-23 17:38:42,039] m-LoRA: Adapter lora_finqa_10 epoch: 1/1 iteration: 60/128 step: 16
[2025-12-23 17:38:42,110] m-LoRA: Adapter lora_finqa_18 loss: 0.04263952001929283
[2025-12-23 17:38:44,171] m-LoRA: Adapter lora_finqa_11 epoch: 1/1 iteration: 60/128 step: 16
[2025-12-23 17:38:44,244] m-LoRA: Adapter lora_finqa_19 loss: 0.5304480791091919
[2025-12-23 17:38:44,728] m-LoRA: Adapter lora_finqa_37 loss: 1.9044109582901
[2025-12-23 17:38:44,731] m-LoRA: Adapter lora_finqa_13 epoch: 1/1 iteration: 60/128 step: 16
[2025-12-23 17:38:46,963] m-LoRA: Adapter lora_finqa_22 loss: 0.044560085982084274
[2025-12-23 17:38:47,159] m-LoRA: Adapter lora_finqa_12 epoch: 1/1 iteration: 120/128 step: 16
[2025-12-23 17:38:48,027] m-LoRA: Adapter lora_finqa_36 epoch: 1/1 iteration: 14/128 step: 8
[2025-12-23 17:38:48,084] m-LoRA: Adapter lora_finqa_21 loss: 2.2823750972747803
[2025-12-23 17:38:48,783] m-LoRA: Adapter lora_finqa_23 loss: 0.016286708414554596
[2025-12-23 17:38:48,787] m-LoRA: Adapter lora_finqa_15 epoch: 1/1 iteration: 30/128 step: 16
[2025-12-23 17:38:50,855] m-LoRA: Adapter lora_finqa_16 epoch: 1/1 iteration: 30/128 step: 16
[2025-12-23 17:38:51,066] m-LoRA: Adapter lora_finqa_38 loss: 2.520650863647461
[2025-12-23 17:38:51,645] m-LoRA: Adapter lora_finqa_25 loss: 0.0467558279633522
[2025-12-23 17:38:51,648] m-LoRA: Adapter lora_finqa_17 epoch: 1/1 iteration: 120/128 step: 16
[2025-12-23 17:38:52,610] m-LoRA: Adapter lora_finqa_26 loss: 2.2799301147460938
[2025-12-23 17:38:52,713] m-LoRA: Adapter lora_finqa_18 epoch: 1/1 iteration: 60/128 step: 16
[2025-12-23 17:38:53,210] m-LoRA: Adapter lora_finqa_27 loss: 0.015874022617936134
[2025-12-23 17:38:53,318] m-LoRA: Adapter lora_finqa_19 epoch: 1/1 iteration: 120/128 step: 16
[2025-12-23 17:38:54,764] m-LoRA: Adapter lora_finqa_37 epoch: 1/1 iteration: 14/128 step: 8
[2025-12-23 17:38:54,819] m-LoRA: Adapter lora_finqa_39 loss: 0.5274855494499207
[2025-12-23 17:38:57,184] m-LoRA: Adapter lora_finqa_29 loss: 0.043202560395002365
[2025-12-23 17:38:57,273] m-LoRA: Adapter lora_finqa_22 epoch: 1/1 iteration: 120/128 step: 16
[2025-12-23 17:38:59,357] m-LoRA: Adapter lora_finqa_21 epoch: 1/1 iteration: 60/128 step: 16
[2025-12-23 17:38:59,465] m-LoRA: Adapter lora_finqa_30 loss: 0.016216326504945755
[2025-12-23 17:38:59,986] m-LoRA: Adapter lora_finqa_40 loss: 1.9036864042282104
[2025-12-23 17:38:59,989] m-LoRA: Adapter lora_finqa_23 epoch: 1/1 iteration: 30/128 step: 16
[2025-12-23 17:39:01,216] m-LoRA: Adapter lora_finqa_32 loss: 2.2823596000671387
[2025-12-23 17:39:01,369] m-LoRA: Adapter lora_finqa_38 epoch: 1/1 iteration: 112/128 step: 8
[2025-12-23 17:39:01,887] m-LoRA: Adapter lora_finqa_25 epoch: 1/1 iteration: 30/128 step: 16
[2025-12-23 17:39:01,938] m-LoRA: Adapter lora_finqa_0 loss: 0.4181221127510071
[2025-12-23 17:39:02,599] m-LoRA: Adapter lora_finqa_3 loss: 0.4213297665119171
[2025-12-23 17:39:02,602] m-LoRA: Adapter lora_finqa_26 epoch: 1/1 iteration: 60/128 step: 16
[2025-12-23 17:39:06,295] m-LoRA: Adapter lora_finqa_27 epoch: 1/1 iteration: 60/128 step: 16
[2025-12-23 17:39:06,644] m-LoRA: Adapter lora_finqa_33 loss: 1.7344998121261597
[2025-12-23 17:39:06,661] m-LoRA: Adapter lora_finqa_39 epoch: 1/1 iteration: 28/128 step: 8
[2025-12-23 17:39:06,760] m-LoRA: Adapter lora_finqa_1 loss: 0.42063695192337036
[2025-12-23 17:39:08,776] m-LoRA: Adapter lora_finqa_34 loss: 0.33836400508880615
[2025-12-23 17:39:08,863] m-LoRA: Adapter lora_finqa_29 epoch: 1/1 iteration: 120/128 step: 16
[2025-12-23 17:39:09,803] m-LoRA: Adapter lora_finqa_35 loss: 0.8045871257781982
[2025-12-23 17:39:09,808] m-LoRA: Adapter lora_finqa_30 epoch: 1/1 iteration: 120/128 step: 16
[2025-12-23 17:39:12,287] m-LoRA: Adapter lora_finqa_40 epoch: 1/1 iteration: 14/128 step: 8
[2025-12-23 17:39:12,368] m-LoRA: Adapter lora_finqa_6 loss: 0.013661927543580532
[2025-12-23 17:39:12,836] m-LoRA: Adapter lora_finqa_32 epoch: 1/1 iteration: 60/128 step: 16
[2025-12-23 17:39:12,911] m-LoRA: Adapter lora_finqa_7 loss: 0.03914353623986244
[2025-12-23 17:39:13,146] m-LoRA: Adapter lora_finqa_8 loss: 0.03746440261602402
[2025-12-23 17:39:13,149] m-LoRA: Adapter lora_finqa_0 epoch: 1/1 iteration: 32/128 step: 17
[2025-12-23 17:39:15,379] m-LoRA: Adapter lora_finqa_3 epoch: 1/1 iteration: 32/128 step: 17
[2025-12-23 17:39:15,477] m-LoRA: Adapter lora_finqa_9 loss: 0.013209408149123192
[2025-12-23 17:39:16,516] m-LoRA: Adapter lora_finqa_10 loss: 0.415151447057724
[2025-12-23 17:39:16,661] m-LoRA: Finish and base model offload adapter - ['lora_finqa_33']
[2025-12-23 17:39:16,935] m-LoRA: Task to running, need to load adapters: ['lora_finqa_41']
[2025-12-23 17:39:16,993] m-LoRA: Adapter lora_finqa_41 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:39:17,772] m-LoRA: Adapter lora_finqa_1 epoch: 1/1 iteration: 32/128 step: 17
[2025-12-23 17:39:17,825] m-LoRA: Adapter lora_finqa_11 loss: 0.42076626420021057
[2025-12-23 17:39:19,098] m-LoRA: Adapter lora_finqa_13 loss: 0.03458087518811226
[2025-12-23 17:39:19,103] m-LoRA: Adapter lora_finqa_34 epoch: 1/1 iteration: 64/128 step: 9
[2025-12-23 17:39:21,078] m-LoRA: Adapter lora_finqa_35 epoch: 1/1 iteration: 32/128 step: 9
[2025-12-23 17:39:21,165] m-LoRA: Adapter lora_finqa_12 loss: 0.037251897156238556
[2025-12-23 17:39:21,629] m-LoRA: Adapter lora_finqa_36 loss: 1.7390881776809692
[2025-12-23 17:39:21,721] m-LoRA: Finish and base model offload adapter - ['lora_finqa_6']
[2025-12-23 17:39:22,412] m-LoRA: Adapter lora_finqa_15 loss: 0.013727418147027493
[2025-12-23 17:39:22,415] m-LoRA: Task to running, need to load adapters: ['lora_finqa_42']
[2025-12-23 17:39:22,602] m-LoRA: Adapter lora_finqa_42 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:39:22,708] m-LoRA: Adapter lora_finqa_7 epoch: 1/1 iteration: 32/128 step: 17
[2025-12-23 17:39:22,965] m-LoRA: Adapter lora_finqa_16 loss: 0.013849196024239063
[2025-12-23 17:39:22,968] m-LoRA: Adapter lora_finqa_8 epoch: 1/1 iteration: 32/128 step: 17
[2025-12-23 17:39:25,285] m-LoRA: Adapter lora_finqa_17 loss: 0.03487880527973175
[2025-12-23 17:39:25,492] m-LoRA: Finish and base model offload adapter - ['lora_finqa_9']
[2025-12-23 17:39:25,974] m-LoRA: Task to running, need to load adapters: ['lora_finqa_43']
[2025-12-23 17:39:26,045] m-LoRA: Adapter lora_finqa_43 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:39:26,480] m-LoRA: Adapter lora_finqa_10 epoch: 1/1 iteration: 64/128 step: 17
[2025-12-23 17:39:26,552] m-LoRA: Adapter lora_finqa_18 loss: 0.03450833633542061
[2025-12-23 17:39:28,814] m-LoRA: Adapter lora_finqa_11 epoch: 1/1 iteration: 64/128 step: 17
[2025-12-23 17:39:28,923] m-LoRA: Adapter lora_finqa_19 loss: 0.4199264943599701
[2025-12-23 17:39:29,431] m-LoRA: Adapter lora_finqa_13 epoch: 1/1 iteration: 64/128 step: 17
[2025-12-23 17:39:29,503] m-LoRA: Adapter lora_finqa_37 loss: 1.7431493997573853
[2025-12-23 17:39:30,700] m-LoRA: Adapter lora_finqa_22 loss: 0.03415847569704056
[2025-12-23 17:39:30,799] m-LoRA: Finish and base model offload adapter - ['lora_finqa_12']
[2025-12-23 17:39:31,410] m-LoRA: Task to running, need to load adapters: ['lora_finqa_44']
[2025-12-23 17:39:31,538] m-LoRA: Adapter lora_finqa_44 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:39:31,889] m-LoRA: Adapter lora_finqa_36 epoch: 1/1 iteration: 16/128 step: 9
[2025-12-23 17:39:31,943] m-LoRA: Adapter lora_finqa_21 loss: 2.2408814430236816
[2025-12-23 17:39:32,657] m-LoRA: Adapter lora_finqa_23 loss: 0.013163555413484573
[2025-12-23 17:39:32,660] m-LoRA: Adapter lora_finqa_15 epoch: 1/1 iteration: 32/128 step: 17
[2025-12-23 17:39:34,841] m-LoRA: Adapter lora_finqa_16 epoch: 1/1 iteration: 32/128 step: 17
[2025-12-23 17:39:35,053] m-LoRA: Adapter lora_finqa_38 loss: 2.5001380443573
[2025-12-23 17:39:35,528] m-LoRA: Adapter lora_finqa_25 loss: 0.03578997030854225
[2025-12-23 17:39:35,622] m-LoRA: Finish and base model offload adapter - ['lora_finqa_17']
[2025-12-23 17:39:35,959] m-LoRA: Task to running, need to load adapters: ['lora_finqa_45']
[2025-12-23 17:39:36,024] m-LoRA: Adapter lora_finqa_45 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:39:36,703] m-LoRA: Adapter lora_finqa_18 epoch: 1/1 iteration: 64/128 step: 17
[2025-12-23 17:39:36,774] m-LoRA: Adapter lora_finqa_26 loss: 2.239490270614624
[2025-12-23 17:39:37,754] m-LoRA: Adapter lora_finqa_27 loss: 0.013801127672195435
[2025-12-23 17:39:37,910] m-LoRA: Finish and base model offload adapter - ['lora_finqa_19']
[2025-12-23 17:39:38,054] m-LoRA: Task to running, need to load adapters: ['lora_finqa_46']
[2025-12-23 17:39:38,134] m-LoRA: Adapter lora_finqa_46 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:39:38,627] m-LoRA: Adapter lora_finqa_37 epoch: 1/1 iteration: 16/128 step: 9
[2025-12-23 17:39:38,660] m-LoRA: Adapter lora_finqa_39 loss: 0.3352505564689636
[2025-12-23 17:39:41,046] m-LoRA: Adapter lora_finqa_29 loss: 0.03413109481334686
[2025-12-23 17:39:41,135] m-LoRA: Finish and base model offload adapter - ['lora_finqa_22']
[2025-12-23 17:39:41,512] m-LoRA: Task to running, need to load adapters: ['lora_finqa_47']
[2025-12-23 17:39:41,650] m-LoRA: Adapter lora_finqa_47 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:39:42,146] m-LoRA: Adapter lora_finqa_21 epoch: 1/1 iteration: 64/128 step: 17
[2025-12-23 17:39:42,244] m-LoRA: Adapter lora_finqa_30 loss: 0.013831467367708683
[2025-12-23 17:39:42,874] m-LoRA: Adapter lora_finqa_23 epoch: 1/1 iteration: 32/128 step: 17
[2025-12-23 17:39:42,910] m-LoRA: Adapter lora_finqa_40 loss: 1.7422527074813843
[2025-12-23 17:39:43,625] m-LoRA: Adapter lora_finqa_32 loss: 2.2396116256713867
[2025-12-23 17:39:43,779] m-LoRA: Finish and base model offload adapter - ['lora_finqa_38']
[2025-12-23 17:39:44,152] m-LoRA: Adapter lora_finqa_0 loss: 0.33114030957221985
[2025-12-23 17:39:44,155] m-LoRA: Task to running, need to load adapters: ['lora_finqa_48']
[2025-12-23 17:39:44,339] m-LoRA: Adapter lora_finqa_48 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:39:44,484] m-LoRA: Adapter lora_finqa_3 loss: 0.33425840735435486
[2025-12-23 17:39:44,487] m-LoRA: Adapter lora_finqa_25 epoch: 1/1 iteration: 32/128 step: 17
[2025-12-23 17:39:44,620] m-LoRA: Adapter lora_finqa_26 epoch: 1/1 iteration: 64/128 step: 17
[2025-12-23 17:39:45,086] m-LoRA: Adapter lora_finqa_27 epoch: 1/1 iteration: 64/128 step: 17
[2025-12-23 17:39:45,167] m-LoRA: Adapter lora_finqa_41 loss: 2.5885279178619385
[2025-12-23 17:39:45,515] m-LoRA: Adapter lora_finqa_1 loss: 0.332697331905365
[2025-12-23 17:39:45,519] m-LoRA: Adapter lora_finqa_39 epoch: 1/1 iteration: 32/128 step: 9
[2025-12-23 17:39:46,757] m-LoRA: Adapter lora_finqa_34 loss: 0.21748429536819458
[2025-12-23 17:39:46,946] m-LoRA: Finish and base model offload adapter - ['lora_finqa_29']
[2025-12-23 17:39:47,322] m-LoRA: Task to running, need to load adapters: ['lora_finqa_49']
[2025-12-23 17:39:47,584] m-LoRA: Adapter lora_finqa_49 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:39:47,887] m-LoRA: Finish and base model offload adapter - ['lora_finqa_30']
[2025-12-23 17:39:48,563] m-LoRA: Adapter lora_finqa_35 loss: 0.5550366044044495
[2025-12-23 17:39:48,569] m-LoRA: Task to running, need to load adapters: ['lora_finqa_50']
[2025-12-23 17:39:48,789] m-LoRA: Adapter lora_finqa_50 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:39:49,131] m-LoRA: Adapter lora_finqa_42 loss: 2.5885283946990967
[2025-12-23 17:39:49,134] m-LoRA: Adapter lora_finqa_40 epoch: 1/1 iteration: 16/128 step: 9
[2025-12-23 17:39:49,285] m-LoRA: Adapter lora_finqa_7 loss: 0.032435547560453415
[2025-12-23 17:39:49,288] m-LoRA: Adapter lora_finqa_32 epoch: 1/1 iteration: 64/128 step: 17
[2025-12-23 17:39:49,408] m-LoRA: Adapter lora_finqa_8 loss: 0.03045906499028206
[2025-12-23 17:39:49,411] m-LoRA: Adapter lora_finqa_0 epoch: 1/1 iteration: 34/128 step: 18
[2025-12-23 17:39:49,520] m-LoRA: Adapter lora_finqa_10 loss: 0.3296419084072113
[2025-12-23 17:39:49,525] m-LoRA: Adapter lora_finqa_3 epoch: 1/1 iteration: 34/128 step: 18
[2025-12-23 17:39:53,582] m-LoRA: Adapter lora_finqa_41 epoch: 1/1 iteration: 4/128 step: 2
[2025-12-23 17:39:53,798] m-LoRA: Adapter lora_finqa_43 loss: 2.5885279178619385
[2025-12-23 17:39:54,797] m-LoRA: Adapter lora_finqa_11 loss: 0.3312565088272095
[2025-12-23 17:39:54,802] m-LoRA: Adapter lora_finqa_1 epoch: 1/1 iteration: 34/128 step: 18
[2025-12-23 17:39:55,847] m-LoRA: Adapter lora_finqa_13 loss: 0.028532277792692184
[2025-12-23 17:39:55,955] m-LoRA: Adapter lora_finqa_34 epoch: 1/1 iteration: 72/128 step: 10
[2025-12-23 17:40:00,178] m-LoRA: Adapter lora_finqa_35 epoch: 1/1 iteration: 36/128 step: 10
[2025-12-23 17:40:00,382] m-LoRA: Adapter lora_finqa_44 loss: 2.5885279178619385
[2025-12-23 17:40:00,897] m-LoRA: Adapter lora_finqa_42 epoch: 1/1 iteration: 2/128 step: 2
[2025-12-23 17:40:00,953] m-LoRA: Adapter lora_finqa_36 loss: 1.5598779916763306
[2025-12-23 17:40:01,417] m-LoRA: Adapter lora_finqa_7 epoch: 1/1 iteration: 34/128 step: 18
[2025-12-23 17:40:01,452] m-LoRA: Adapter lora_finqa_15 loss: 0.0124633414670825
[2025-12-23 17:40:02,003] m-LoRA: Adapter lora_finqa_16 loss: 0.012736452743411064
[2025-12-23 17:40:02,006] m-LoRA: Adapter lora_finqa_8 epoch: 1/1 iteration: 34/128 step: 18
[2025-12-23 17:40:03,129] m-LoRA: Adapter lora_finqa_45 loss: 2.5885279178619385
[2025-12-23 17:40:03,135] m-LoRA: Adapter lora_finqa_10 epoch: 1/1 iteration: 68/128 step: 18
[2025-12-23 17:40:04,759] m-LoRA: Adapter lora_finqa_18 loss: 0.028713054955005646
[2025-12-23 17:40:04,930] m-LoRA: Adapter lora_finqa_43 epoch: 1/1 iteration: 16/128 step: 2
[2025-12-23 17:40:05,461] m-LoRA: Adapter lora_finqa_11 epoch: 1/1 iteration: 68/128 step: 18
[2025-12-23 17:40:05,534] m-LoRA: Adapter lora_finqa_46 loss: 2.5885283946990967
[2025-12-23 17:40:06,189] m-LoRA: Adapter lora_finqa_37 loss: 1.5579487085342407
[2025-12-23 17:40:06,193] m-LoRA: Adapter lora_finqa_13 epoch: 1/1 iteration: 68/128 step: 18
[2025-12-23 17:40:06,934] m-LoRA: Adapter lora_finqa_47 loss: 2.5885283946990967
[2025-12-23 17:40:07,131] m-LoRA: Adapter lora_finqa_44 epoch: 1/1 iteration: 16/128 step: 2
[2025-12-23 17:40:08,046] m-LoRA: Adapter lora_finqa_36 epoch: 1/1 iteration: 18/128 step: 10
[2025-12-23 17:40:08,100] m-LoRA: Adapter lora_finqa_21 loss: 2.1988422870635986
[2025-12-23 17:40:08,776] m-LoRA: Adapter lora_finqa_23 loss: 0.011406629346311092
[2025-12-23 17:40:08,780] m-LoRA: Adapter lora_finqa_15 epoch: 1/1 iteration: 34/128 step: 18
[2025-12-23 17:40:09,375] m-LoRA: Adapter lora_finqa_48 loss: 2.5885283946990967
[2025-12-23 17:40:09,379] m-LoRA: Adapter lora_finqa_16 epoch: 1/1 iteration: 34/128 step: 18
[2025-12-23 17:40:10,058] m-LoRA: Adapter lora_finqa_25 loss: 0.030864689499139786
[2025-12-23 17:40:10,062] m-LoRA: Adapter lora_finqa_45 epoch: 1/1 iteration: 4/128 step: 2
[2025-12-23 17:40:11,121] m-LoRA: Adapter lora_finqa_18 epoch: 1/1 iteration: 68/128 step: 18
[2025-12-23 17:40:11,197] m-LoRA: Adapter lora_finqa_26 loss: 2.1965901851654053
[2025-12-23 17:40:12,299] m-LoRA: Adapter lora_finqa_27 loss: 0.012099819257855415
[2025-12-23 17:40:12,305] m-LoRA: Adapter lora_finqa_46 epoch: 1/1 iteration: 2/128 step: 2
[2025-12-23 17:40:13,469] m-LoRA: Adapter lora_finqa_39 loss: 0.21896839141845703
[2025-12-23 17:40:13,474] m-LoRA: Adapter lora_finqa_37 epoch: 1/1 iteration: 18/128 step: 10
[2025-12-23 17:40:15,588] m-LoRA: Adapter lora_finqa_47 epoch: 1/1 iteration: 2/128 step: 2
[2025-12-23 17:40:15,800] m-LoRA: Adapter lora_finqa_49 loss: 2.5885279178619385
[2025-12-23 17:40:17,692] m-LoRA: Adapter lora_finqa_21 epoch: 1/1 iteration: 68/128 step: 18
[2025-12-23 17:40:17,882] m-LoRA: Adapter lora_finqa_50 loss: 2.5885279178619385
[2025-12-23 17:40:18,338] m-LoRA: Adapter lora_finqa_23 epoch: 1/1 iteration: 34/128 step: 18
[2025-12-23 17:40:18,373] m-LoRA: Adapter lora_finqa_40 loss: 1.5630313158035278
[2025-12-23 17:40:19,692] m-LoRA: Adapter lora_finqa_48 epoch: 1/1 iteration: 2/128 step: 2
[2025-12-23 17:40:19,754] m-LoRA: Adapter lora_finqa_32 loss: 2.197334051132202
[2025-12-23 17:40:20,260] m-LoRA: Adapter lora_finqa_25 epoch: 1/1 iteration: 34/128 step: 18
[2025-12-23 17:40:20,313] m-LoRA: Adapter lora_finqa_0 loss: 0.2604924738407135
[2025-12-23 17:40:20,855] m-LoRA: Adapter lora_finqa_3 loss: 0.261542946100235
[2025-12-23 17:40:20,858] m-LoRA: Adapter lora_finqa_26 epoch: 1/1 iteration: 68/128 step: 18
[2025-12-23 17:40:21,683] m-LoRA: Adapter lora_finqa_27 epoch: 1/1 iteration: 68/128 step: 18
[2025-12-23 17:40:21,770] m-LoRA: Adapter lora_finqa_41 loss: 2.5419492721557617
[2025-12-23 17:40:22,028] m-LoRA: Adapter lora_finqa_1 loss: 0.2631818652153015
[2025-12-23 17:40:22,031] m-LoRA: Adapter lora_finqa_39 epoch: 1/1 iteration: 36/128 step: 10
[2025-12-23 17:40:23,321] m-LoRA: Adapter lora_finqa_34 loss: 0.11247320473194122
[2025-12-23 17:40:23,535] m-LoRA: Adapter lora_finqa_49 epoch: 1/1 iteration: 16/128 step: 2
[2025-12-23 17:40:23,990] m-LoRA: Adapter lora_finqa_35 loss: 0.39277681708335876
[2025-12-23 17:40:24,160] m-LoRA: Adapter lora_finqa_50 epoch: 1/1 iteration: 16/128 step: 2
[2025-12-23 17:40:24,445] m-LoRA: Adapter lora_finqa_42 loss: 2.478895902633667
[2025-12-23 17:40:24,448] m-LoRA: Adapter lora_finqa_40 epoch: 1/1 iteration: 18/128 step: 10
[2025-12-23 17:40:24,665] m-LoRA: Adapter lora_finqa_7 loss: 0.026549775153398514
[2025-12-23 17:40:24,668] m-LoRA: Adapter lora_finqa_32 epoch: 1/1 iteration: 68/128 step: 18
[2025-12-23 17:40:24,897] m-LoRA: Adapter lora_finqa_8 loss: 0.02525532804429531
[2025-12-23 17:40:25,007] m-LoRA: Adapter lora_finqa_0 epoch: 1/1 iteration: 36/128 step: 19
[2025-12-23 17:40:25,672] m-LoRA: Adapter lora_finqa_3 epoch: 1/1 iteration: 36/128 step: 19
[2025-12-23 17:40:25,731] m-LoRA: Adapter lora_finqa_10 loss: 0.2602000832557678
[2025-12-23 17:40:29,713] m-LoRA: Adapter lora_finqa_41 epoch: 1/1 iteration: 8/128 step: 3
[2025-12-23 17:40:29,906] m-LoRA: Adapter lora_finqa_43 loss: 2.4731345176696777
[2025-12-23 17:40:30,361] m-LoRA: Adapter lora_finqa_11 loss: 0.2599208652973175
[2025-12-23 17:40:30,366] m-LoRA: Adapter lora_finqa_1 epoch: 1/1 iteration: 36/128 step: 19
[2025-12-23 17:40:31,014] m-LoRA: Adapter lora_finqa_13 loss: 0.023579835891723633
[2025-12-23 17:40:31,019] m-LoRA: Adapter lora_finqa_34 epoch: 1/1 iteration: 80/128 step: 11
[2025-12-23 17:40:35,537] m-LoRA: Adapter lora_finqa_44 loss: 2.314901113510132
[2025-12-23 17:40:35,611] m-LoRA: Adapter lora_finqa_35 epoch: 1/1 iteration: 40/128 step: 11
[2025-12-23 17:40:36,067] m-LoRA: Adapter lora_finqa_36 loss: 1.3958442211151123
[2025-12-23 17:40:36,070] m-LoRA: Adapter lora_finqa_42 epoch: 1/1 iteration: 4/128 step: 3
[2025-12-23 17:40:36,250] m-LoRA: Adapter lora_finqa_15 loss: 0.011543171480298042
[2025-12-23 17:40:36,253] m-LoRA: Adapter lora_finqa_7 epoch: 1/1 iteration: 36/128 step: 19
[2025-12-23 17:40:36,457] m-LoRA: Adapter lora_finqa_16 loss: 0.011482547037303448
[2025-12-23 17:40:36,461] m-LoRA: Adapter lora_finqa_8 epoch: 1/1 iteration: 36/128 step: 19
[2025-12-23 17:40:37,025] m-LoRA: Adapter lora_finqa_45 loss: 2.5833182334899902
[2025-12-23 17:40:37,031] m-LoRA: Adapter lora_finqa_10 epoch: 1/1 iteration: 72/128 step: 19
[2025-12-23 17:40:37,551] m-LoRA: Adapter lora_finqa_18 loss: 0.023355288431048393
[2025-12-23 17:40:37,705] m-LoRA: Adapter lora_finqa_43 epoch: 1/1 iteration: 32/128 step: 3
[2025-12-23 17:40:38,040] m-LoRA: Adapter lora_finqa_46 loss: 2.4727046489715576
[2025-12-23 17:40:38,044] m-LoRA: Adapter lora_finqa_11 epoch: 1/1 iteration: 72/128 step: 19
[2025-12-23 17:40:38,226] m-LoRA: Adapter lora_finqa_37 loss: 1.3995457887649536
[2025-12-23 17:40:38,229] m-LoRA: Adapter lora_finqa_13 epoch: 1/1 iteration: 72/128 step: 19
[2025-12-23 17:40:38,965] m-LoRA: Adapter lora_finqa_47 loss: 2.321500778198242
[2025-12-23 17:40:39,711] m-LoRA: Adapter lora_finqa_21 loss: 2.1547935009002686
[2025-12-23 17:40:40,068] m-LoRA: Adapter lora_finqa_23 loss: 0.010570336133241653
[2025-12-23 17:40:40,377] m-LoRA: Adapter lora_finqa_48 loss: 2.4778056144714355
[2025-12-23 17:40:40,555] m-LoRA: Adapter lora_finqa_44 epoch: 1/1 iteration: 32/128 step: 3
[2025-12-23 17:40:40,888] m-LoRA: Adapter lora_finqa_25 loss: 0.024867910891771317
[2025-12-23 17:40:40,891] m-LoRA: Adapter lora_finqa_36 epoch: 1/1 iteration: 20/128 step: 11
[2025-12-23 17:40:42,169] m-LoRA: Adapter lora_finqa_15 epoch: 1/1 iteration: 36/128 step: 19
[2025-12-23 17:40:42,203] m-LoRA: Adapter lora_finqa_26 loss: 2.15095591545105
[2025-12-23 17:40:43,552] m-LoRA: Adapter lora_finqa_27 loss: 0.010731056332588196
[2025-12-23 17:40:43,558] m-LoRA: Adapter lora_finqa_16 epoch: 1/1 iteration: 36/128 step: 19
[2025-12-23 17:40:44,728] m-LoRA: Adapter lora_finqa_45 epoch: 1/1 iteration: 8/128 step: 3
[2025-12-23 17:40:44,804] m-LoRA: Adapter lora_finqa_39 loss: 0.11394186317920685
[2025-12-23 17:40:48,786] m-LoRA: Adapter lora_finqa_18 epoch: 1/1 iteration: 72/128 step: 19
[2025-12-23 17:40:49,028] m-LoRA: Adapter lora_finqa_49 loss: 2.4785873889923096
[2025-12-23 17:40:50,931] m-LoRA: Adapter lora_finqa_46 epoch: 1/1 iteration: 4/128 step: 3
[2025-12-23 17:40:51,205] m-LoRA: Adapter lora_finqa_50 loss: 2.585253953933716
[2025-12-23 17:40:51,683] m-LoRA: Adapter lora_finqa_37 epoch: 1/1 iteration: 20/128 step: 11
[2025-12-23 17:40:51,740] m-LoRA: Adapter lora_finqa_40 loss: 1.3984419107437134
[2025-12-23 17:40:53,247] m-LoRA: Adapter lora_finqa_32 loss: 2.1536941528320312
[2025-12-23 17:40:53,253] m-LoRA: Adapter lora_finqa_47 epoch: 1/1 iteration: 4/128 step: 3
[2025-12-23 17:40:53,809] m-LoRA: Adapter lora_finqa_0 loss: 0.20423345267772675
[2025-12-23 17:40:53,813] m-LoRA: Adapter lora_finqa_21 epoch: 1/1 iteration: 72/128 step: 19
[2025-12-23 17:40:54,357] m-LoRA: Adapter lora_finqa_3 loss: 0.2052137851715088
[2025-12-23 17:40:54,361] m-LoRA: Adapter lora_finqa_23 epoch: 1/1 iteration: 36/128 step: 19
[2025-12-23 17:40:56,211] m-LoRA: Adapter lora_finqa_48 epoch: 1/1 iteration: 4/128 step: 3
[2025-12-23 17:40:56,276] m-LoRA: Adapter lora_finqa_41 loss: 2.455524444580078
[2025-12-23 17:40:56,942] m-LoRA: Adapter lora_finqa_1 loss: 0.20674003660678864
[2025-12-23 17:40:56,945] m-LoRA: Adapter lora_finqa_25 epoch: 1/1 iteration: 36/128 step: 19
[2025-12-23 17:40:58,051] m-LoRA: Adapter lora_finqa_26 epoch: 1/1 iteration: 72/128 step: 19
[2025-12-23 17:40:58,155] m-LoRA: Adapter lora_finqa_34 loss: 0.05750250071287155
[2025-12-23 17:40:59,227] m-LoRA: Adapter lora_finqa_27 epoch: 1/1 iteration: 72/128 step: 19
[2025-12-23 17:40:59,304] m-LoRA: Adapter lora_finqa_35 loss: 0.2619491517543793
[2025-12-23 17:40:59,983] m-LoRA: Adapter lora_finqa_42 loss: 2.265685796737671
[2025-12-23 17:41:00,056] m-LoRA: Adapter lora_finqa_39 epoch: 1/1 iteration: 40/128 step: 11
[2025-12-23 17:41:00,748] m-LoRA: Adapter lora_finqa_7 loss: 0.021608784794807434
[2025-12-23 17:41:00,927] m-LoRA: Adapter lora_finqa_49 epoch: 1/1 iteration: 32/128 step: 3
[2025-12-23 17:41:01,442] m-LoRA: Adapter lora_finqa_8 loss: 0.02080322988331318
[2025-12-23 17:41:01,601] m-LoRA: Adapter lora_finqa_50 epoch: 1/1 iteration: 32/128 step: 3
[2025-12-23 17:41:02,760] m-LoRA: Adapter lora_finqa_40 epoch: 1/1 iteration: 20/128 step: 11
[2025-12-23 17:41:02,828] m-LoRA: Adapter lora_finqa_10 loss: 0.20483310520648956
[2025-12-23 17:41:04,911] m-LoRA: Adapter lora_finqa_32 epoch: 1/1 iteration: 72/128 step: 19
[2025-12-23 17:41:05,127] m-LoRA: Adapter lora_finqa_43 loss: 2.2522990703582764
[2025-12-23 17:41:06,119] m-LoRA: Adapter lora_finqa_0 epoch: 1/1 iteration: 38/128 step: 20
[2025-12-23 17:41:06,170] m-LoRA: Adapter lora_finqa_11 loss: 0.2018580138683319
[2025-12-23 17:41:07,280] m-LoRA: Adapter lora_finqa_13 loss: 0.019512034952640533
[2025-12-23 17:41:07,285] m-LoRA: Adapter lora_finqa_3 epoch: 1/1 iteration: 38/128 step: 20
[2025-12-23 17:41:09,615] m-LoRA: Adapter lora_finqa_41 epoch: 1/1 iteration: 12/128 step: 4
[2025-12-23 17:41:09,863] m-LoRA: Adapter lora_finqa_44 loss: 1.9158614873886108
[2025-12-23 17:41:10,348] m-LoRA: Adapter lora_finqa_36 loss: 1.208784818649292
[2025-12-23 17:41:10,419] m-LoRA: Adapter lora_finqa_1 epoch: 1/1 iteration: 38/128 step: 20
[2025-12-23 17:41:11,091] m-LoRA: Adapter lora_finqa_15 loss: 0.009629634208977222
[2025-12-23 17:41:11,095] m-LoRA: Adapter lora_finqa_34 epoch: 1/1 iteration: 88/128 step: 12
[2025-12-23 17:41:11,572] m-LoRA: Adapter lora_finqa_16 loss: 0.009569098241627216
[2025-12-23 17:41:11,695] m-LoRA: Adapter lora_finqa_35 epoch: 1/1 iteration: 44/128 step: 12
[2025-12-23 17:41:12,153] m-LoRA: Adapter lora_finqa_42 epoch: 1/1 iteration: 6/128 step: 4
[2025-12-23 17:41:12,202] m-LoRA: Adapter lora_finqa_45 loss: 2.578066110610962
[2025-12-23 17:41:12,917] m-LoRA: Adapter lora_finqa_18 loss: 0.023560905829072
[2025-12-23 17:41:12,923] m-LoRA: Adapter lora_finqa_7 epoch: 1/1 iteration: 38/128 step: 20
[2025-12-23 17:41:13,363] m-LoRA: Adapter lora_finqa_46 loss: 2.2521049976348877
[2025-12-23 17:41:13,366] m-LoRA: Adapter lora_finqa_8 epoch: 1/1 iteration: 38/128 step: 20
[2025-12-23 17:41:13,705] m-LoRA: Adapter lora_finqa_37 loss: 1.2086410522460938
[2025-12-23 17:41:13,708] m-LoRA: Adapter lora_finqa_10 epoch: 1/1 iteration: 76/128 step: 20
[2025-12-23 17:41:14,039] m-LoRA: Adapter lora_finqa_47 loss: 1.921860694885254
[2025-12-23 17:41:14,197] m-LoRA: Adapter lora_finqa_43 epoch: 1/1 iteration: 48/128 step: 4
[2025-12-23 17:41:14,705] m-LoRA: Adapter lora_finqa_11 epoch: 1/1 iteration: 76/128 step: 20
[2025-12-23 17:41:14,785] m-LoRA: Adapter lora_finqa_21 loss: 2.1109797954559326
[2025-12-23 17:41:15,010] m-LoRA: Adapter lora_finqa_23 loss: 0.008892713114619255
[2025-12-23 17:41:15,206] m-LoRA: Adapter lora_finqa_13 epoch: 1/1 iteration: 76/128 step: 20
[2025-12-23 17:41:15,761] m-LoRA: Adapter lora_finqa_48 loss: 2.2665302753448486
[2025-12-23 17:41:15,765] m-LoRA: Adapter lora_finqa_44 epoch: 1/1 iteration: 48/128 step: 4
[2025-12-23 17:41:16,107] m-LoRA: Adapter lora_finqa_25 loss: 0.020426597446203232
[2025-12-23 17:41:16,110] m-LoRA: Adapter lora_finqa_36 epoch: 1/1 iteration: 22/128 step: 12
[2025-12-23 17:41:16,532] m-LoRA: Adapter lora_finqa_15 epoch: 1/1 iteration: 38/128 step: 20
[2025-12-23 17:41:16,589] m-LoRA: Adapter lora_finqa_26 loss: 2.1040492057800293
[2025-12-23 17:41:17,289] m-LoRA: Adapter lora_finqa_27 loss: 0.009545245207846165
[2025-12-23 17:41:17,294] m-LoRA: Adapter lora_finqa_16 epoch: 1/1 iteration: 38/128 step: 20
[2025-12-23 17:41:18,037] m-LoRA: Adapter lora_finqa_39 loss: 0.06136874854564667
[2025-12-23 17:41:18,042] m-LoRA: Adapter lora_finqa_45 epoch: 1/1 iteration: 12/128 step: 4
[2025-12-23 17:41:20,296] m-LoRA: Adapter lora_finqa_18 epoch: 1/1 iteration: 76/128 step: 20
[2025-12-23 17:41:20,490] m-LoRA: Adapter lora_finqa_49 loss: 2.262003183364868
[2025-12-23 17:41:24,443] m-LoRA: Adapter lora_finqa_46 epoch: 1/1 iteration: 6/128 step: 4
[2025-12-23 17:41:24,742] m-LoRA: Adapter lora_finqa_50 loss: 2.5787456035614014
[2025-12-23 17:41:24,760] m-LoRA: Adapter lora_finqa_37 epoch: 1/1 iteration: 22/128 step: 12
[2025-12-23 17:41:24,799] m-LoRA: Adapter lora_finqa_40 loss: 1.212424874305725
[2025-12-23 17:41:25,531] m-LoRA: Adapter lora_finqa_47 epoch: 1/1 iteration: 6/128 step: 4
[2025-12-23 17:41:25,577] m-LoRA: Adapter lora_finqa_32 loss: 2.1082065105438232
[2025-12-23 17:41:25,826] m-LoRA: Adapter lora_finqa_0 loss: 0.15682215988636017
[2025-12-23 17:41:25,829] m-LoRA: Adapter lora_finqa_21 epoch: 1/1 iteration: 76/128 step: 20
[2025-12-23 17:41:26,106] m-LoRA: Adapter lora_finqa_3 loss: 0.15808016061782837
[2025-12-23 17:41:26,109] m-LoRA: Adapter lora_finqa_23 epoch: 1/1 iteration: 38/128 step: 20
[2025-12-23 17:41:26,649] m-LoRA: Adapter lora_finqa_48 epoch: 1/1 iteration: 6/128 step: 4
[2025-12-23 17:41:26,703] m-LoRA: Adapter lora_finqa_41 loss: 2.3375425338745117
[2025-12-23 17:41:26,974] m-LoRA: Adapter lora_finqa_1 loss: 0.15721918642520905
[2025-12-23 17:41:26,977] m-LoRA: Adapter lora_finqa_25 epoch: 1/1 iteration: 38/128 step: 20
[2025-12-23 17:41:29,714] m-LoRA: Adapter lora_finqa_26 epoch: 1/1 iteration: 76/128 step: 20
[2025-12-23 17:41:29,845] m-LoRA: Adapter lora_finqa_34 loss: 0.03722261264920235
[2025-12-23 17:41:31,157] m-LoRA: Adapter lora_finqa_27 epoch: 1/1 iteration: 76/128 step: 20
[2025-12-23 17:41:31,235] m-LoRA: Adapter lora_finqa_35 loss: 0.1864638328552246
[2025-12-23 17:41:31,504] m-LoRA: Adapter lora_finqa_42 loss: 2.000976085662842
[2025-12-23 17:41:31,508] m-LoRA: Adapter lora_finqa_39 epoch: 1/1 iteration: 44/128 step: 12
[2025-12-23 17:41:31,785] m-LoRA: Adapter lora_finqa_7 loss: 0.018205678090453148
[2025-12-23 17:41:31,961] m-LoRA: Adapter lora_finqa_49 epoch: 1/1 iteration: 48/128 step: 4
[2025-12-23 17:41:32,562] m-LoRA: Adapter lora_finqa_8 loss: 0.017598941922187805
[2025-12-23 17:41:32,566] m-LoRA: Adapter lora_finqa_50 epoch: 1/1 iteration: 48/128 step: 4
[2025-12-23 17:41:33,706] m-LoRA: Adapter lora_finqa_10 loss: 0.1577433943748474
[2025-12-23 17:41:33,711] m-LoRA: Adapter lora_finqa_40 epoch: 1/1 iteration: 22/128 step: 12
[2025-12-23 17:41:35,969] m-LoRA: Adapter lora_finqa_32 epoch: 1/1 iteration: 76/128 step: 20
[2025-12-23 17:41:36,169] m-LoRA: Adapter lora_finqa_43 loss: 1.9878615140914917
[2025-12-23 17:41:37,201] m-LoRA: Adapter lora_finqa_0 epoch: 1/1 iteration: 40/128 step: 21
[2025-12-23 17:41:37,255] m-LoRA: Adapter lora_finqa_11 loss: 0.15280982851982117
[2025-12-23 17:41:38,318] m-LoRA: Adapter lora_finqa_3 epoch: 1/1 iteration: 40/128 step: 21
[2025-12-23 17:41:38,360] m-LoRA: Adapter lora_finqa_13 loss: 0.01656978577375412
[2025-12-23 17:41:40,660] m-LoRA: Adapter lora_finqa_41 epoch: 1/1 iteration: 16/128 step: 5
[2025-12-23 17:41:40,866] m-LoRA: Adapter lora_finqa_44 loss: 1.4814985990524292
[2025-12-23 17:41:41,318] m-LoRA: Adapter lora_finqa_36 loss: 1.013433814048767
[2025-12-23 17:41:41,322] m-LoRA: Adapter lora_finqa_1 epoch: 1/1 iteration: 40/128 step: 21
[2025-12-23 17:41:41,853] m-LoRA: Adapter lora_finqa_15 loss: 0.00905606895685196
[2025-12-23 17:41:41,945] m-LoRA: Adapter lora_finqa_34 epoch: 1/1 iteration: 96/128 step: 13
[2025-12-23 17:41:42,442] m-LoRA: Adapter lora_finqa_35 epoch: 1/1 iteration: 48/128 step: 13
[2025-12-23 17:41:42,515] m-LoRA: Adapter lora_finqa_16 loss: 0.00894434005022049
[2025-12-23 17:41:43,511] m-LoRA: Adapter lora_finqa_45 loss: 2.566775321960449
[2025-12-23 17:41:43,516] m-LoRA: Adapter lora_finqa_42 epoch: 1/1 iteration: 8/128 step: 5
[2025-12-23 17:41:45,208] m-LoRA: Adapter lora_finqa_7 epoch: 1/1 iteration: 40/128 step: 21
[2025-12-23 17:41:45,263] m-LoRA: Adapter lora_finqa_18 loss: 0.017323963344097137
[2025-12-23 17:41:45,930] m-LoRA: Adapter lora_finqa_46 loss: 1.9911293983459473
[2025-12-23 17:41:45,934] m-LoRA: Adapter lora_finqa_8 epoch: 1/1 iteration: 40/128 step: 21
[2025-12-23 17:41:46,613] m-LoRA: Adapter lora_finqa_37 loss: 1.013442039489746
[2025-12-23 17:41:46,617] m-LoRA: Adapter lora_finqa_10 epoch: 1/1 iteration: 80/128 step: 21
[2025-12-23 17:41:47,317] m-LoRA: Adapter lora_finqa_47 loss: 1.4870532751083374
[2025-12-23 17:41:47,472] m-LoRA: Adapter lora_finqa_43 epoch: 1/1 iteration: 64/128 step: 5
[2025-12-23 17:41:47,940] m-LoRA: Adapter lora_finqa_11 epoch: 1/1 iteration: 80/128 step: 21
[2025-12-23 17:41:48,015] m-LoRA: Adapter lora_finqa_21 loss: 2.0633952617645264
[2025-12-23 17:41:48,611] m-LoRA: Adapter lora_finqa_23 loss: 0.00845514889806509
[2025-12-23 17:41:48,614] m-LoRA: Adapter lora_finqa_13 epoch: 1/1 iteration: 80/128 step: 21
[2025-12-23 17:41:49,399] m-LoRA: Adapter lora_finqa_48 loss: 2.0041556358337402
[2025-12-23 17:41:49,574] m-LoRA: Adapter lora_finqa_44 epoch: 1/1 iteration: 64/128 step: 5
[2025-12-23 17:41:50,091] m-LoRA: Adapter lora_finqa_36 epoch: 1/1 iteration: 24/128 step: 13
[2025-12-23 17:41:50,148] m-LoRA: Adapter lora_finqa_25 loss: 0.017078042030334473
[2025-12-23 17:41:50,704] m-LoRA: Adapter lora_finqa_15 epoch: 1/1 iteration: 40/128 step: 21
[2025-12-23 17:41:50,760] m-LoRA: Adapter lora_finqa_26 loss: 2.056583881378174
[2025-12-23 17:41:51,447] m-LoRA: Adapter lora_finqa_16 epoch: 1/1 iteration: 40/128 step: 21
[2025-12-23 17:41:51,502] m-LoRA: Adapter lora_finqa_27 loss: 0.008614101447165012
[2025-12-23 17:41:52,158] m-LoRA: Adapter lora_finqa_39 loss: 0.03820030763745308
[2025-12-23 17:41:52,164] m-LoRA: Adapter lora_finqa_45 epoch: 1/1 iteration: 16/128 step: 5
[2025-12-23 17:41:54,205] m-LoRA: Adapter lora_finqa_18 epoch: 1/1 iteration: 80/128 step: 21
[2025-12-23 17:41:54,405] m-LoRA: Adapter lora_finqa_49 loss: 1.9972928762435913
[2025-12-23 17:41:56,231] m-LoRA: Adapter lora_finqa_46 epoch: 1/1 iteration: 8/128 step: 5
[2025-12-23 17:41:56,469] m-LoRA: Adapter lora_finqa_50 loss: 2.5681495666503906
[2025-12-23 17:41:56,934] m-LoRA: Adapter lora_finqa_37 epoch: 1/1 iteration: 24/128 step: 13
[2025-12-23 17:41:56,979] m-LoRA: Adapter lora_finqa_40 loss: 1.0164823532104492
[2025-12-23 17:41:57,933] m-LoRA: Adapter lora_finqa_32 loss: 2.0599753856658936
[2025-12-23 17:41:57,939] m-LoRA: Adapter lora_finqa_47 epoch: 1/1 iteration: 8/128 step: 5
[2025-12-23 17:41:58,230] m-LoRA: Adapter lora_finqa_0 loss: 0.11248313635587692
[2025-12-23 17:41:58,233] m-LoRA: Adapter lora_finqa_21 epoch: 1/1 iteration: 80/128 step: 21
[2025-12-23 17:41:58,516] m-LoRA: Adapter lora_finqa_3 loss: 0.11398983746767044
[2025-12-23 17:41:58,519] m-LoRA: Adapter lora_finqa_23 epoch: 1/1 iteration: 40/128 step: 21
[2025-12-23 17:41:59,067] m-LoRA: Adapter lora_finqa_48 epoch: 1/1 iteration: 8/128 step: 5
[2025-12-23 17:41:59,103] m-LoRA: Adapter lora_finqa_41 loss: 2.1990997791290283
[2025-12-23 17:41:59,385] m-LoRA: Adapter lora_finqa_1 loss: 0.11198142915964127
[2025-12-23 17:41:59,389] m-LoRA: Adapter lora_finqa_25 epoch: 1/1 iteration: 40/128 step: 21
[2025-12-23 17:42:00,763] m-LoRA: Adapter lora_finqa_26 epoch: 1/1 iteration: 80/128 step: 21
[2025-12-23 17:42:00,863] m-LoRA: Adapter lora_finqa_34 loss: 0.027171801775693893
[2025-12-23 17:42:01,599] m-LoRA: Adapter lora_finqa_35 loss: 0.12070933729410172
[2025-12-23 17:42:01,605] m-LoRA: Adapter lora_finqa_27 epoch: 1/1 iteration: 80/128 step: 21
[2025-12-23 17:42:01,885] m-LoRA: Adapter lora_finqa_42 loss: 1.7242711782455444
[2025-12-23 17:42:01,889] m-LoRA: Adapter lora_finqa_39 epoch: 1/1 iteration: 48/128 step: 13
[2025-12-23 17:42:02,241] m-LoRA: Adapter lora_finqa_7 loss: 0.015855951234698296
[2025-12-23 17:42:02,418] m-LoRA: Adapter lora_finqa_49 epoch: 1/1 iteration: 64/128 step: 5
[2025-12-23 17:42:03,011] m-LoRA: Adapter lora_finqa_8 loss: 0.015199875459074974
[2025-12-23 17:42:03,014] m-LoRA: Adapter lora_finqa_50 epoch: 1/1 iteration: 64/128 step: 5
[2025-12-23 17:42:03,360] m-LoRA: Adapter lora_finqa_10 loss: 0.11320670694112778
[2025-12-23 17:42:03,366] m-LoRA: Adapter lora_finqa_40 epoch: 1/1 iteration: 24/128 step: 13
[2025-12-23 17:42:05,998] m-LoRA: Adapter lora_finqa_32 epoch: 1/1 iteration: 80/128 step: 21
[2025-12-23 17:42:06,227] m-LoRA: Adapter lora_finqa_43 loss: 1.7015645503997803
[2025-12-23 17:42:06,739] m-LoRA: Adapter lora_finqa_11 loss: 0.11116848140954971
[2025-12-23 17:42:06,745] m-LoRA: Adapter lora_finqa_0 epoch: 1/1 iteration: 42/128 step: 22
[2025-12-23 17:42:07,277] m-LoRA: Adapter lora_finqa_3 epoch: 1/1 iteration: 42/128 step: 22
[2025-12-23 17:42:07,321] m-LoRA: Adapter lora_finqa_13 loss: 0.014618167653679848
[2025-12-23 17:42:12,034] m-LoRA: Adapter lora_finqa_41 epoch: 1/1 iteration: 20/128 step: 6
[2025-12-23 17:42:12,392] m-LoRA: Adapter lora_finqa_44 loss: 1.1747462749481201
[2025-12-23 17:42:12,409] m-LoRA: Adapter lora_finqa_1 epoch: 1/1 iteration: 42/128 step: 22
[2025-12-23 17:42:12,450] m-LoRA: Adapter lora_finqa_36 loss: 0.8369771242141724
[2025-12-23 17:42:12,969] m-LoRA: Adapter lora_finqa_15 loss: 0.008256557397544384
[2025-12-23 17:42:12,973] m-LoRA: Adapter lora_finqa_34 epoch: 1/1 iteration: 104/128 step: 14
[2025-12-23 17:42:13,222] m-LoRA: Adapter lora_finqa_16 loss: 0.007762832101434469
[2025-12-23 17:42:13,225] m-LoRA: Adapter lora_finqa_35 epoch: 1/1 iteration: 52/128 step: 14
[2025-12-23 17:42:13,633] m-LoRA: Adapter lora_finqa_42 epoch: 1/1 iteration: 10/128 step: 6
[2025-12-23 17:42:13,690] m-LoRA: Adapter lora_finqa_45 loss: 2.554852247238159
[2025-12-23 17:42:14,151] m-LoRA: Adapter lora_finqa_7 epoch: 1/1 iteration: 42/128 step: 22
[2025-12-23 17:42:14,208] m-LoRA: Adapter lora_finqa_18 loss: 0.015866506844758987
[2025-12-23 17:42:14,437] m-LoRA: Adapter lora_finqa_8 epoch: 1/1 iteration: 42/128 step: 22
[2025-12-23 17:42:14,492] m-LoRA: Adapter lora_finqa_46 loss: 1.7083685398101807
[2025-12-23 17:42:14,759] m-LoRA: Adapter lora_finqa_10 epoch: 1/1 iteration: 84/128 step: 22
[2025-12-23 17:42:14,836] m-LoRA: Adapter lora_finqa_37 loss: 0.8350617289543152
[2025-12-23 17:42:15,384] m-LoRA: Adapter lora_finqa_47 loss: 1.1827492713928223
[2025-12-23 17:42:15,540] m-LoRA: Adapter lora_finqa_43 epoch: 1/1 iteration: 80/128 step: 6
[2025-12-23 17:42:16,413] m-LoRA: Adapter lora_finqa_21 loss: 2.013477087020874
[2025-12-23 17:42:16,418] m-LoRA: Adapter lora_finqa_11 epoch: 1/1 iteration: 84/128 step: 22
[2025-12-23 17:42:16,746] m-LoRA: Adapter lora_finqa_23 loss: 0.006312655750662088
[2025-12-23 17:42:16,750] m-LoRA: Adapter lora_finqa_13 epoch: 1/1 iteration: 84/128 step: 22
[2025-12-23 17:42:17,424] m-LoRA: Adapter lora_finqa_48 loss: 1.7311898469924927
[2025-12-23 17:42:17,603] m-LoRA: Adapter lora_finqa_44 epoch: 1/1 iteration: 80/128 step: 6
[2025-12-23 17:42:18,125] m-LoRA: Adapter lora_finqa_36 epoch: 1/1 iteration: 26/128 step: 14
[2025-12-23 17:42:18,185] m-LoRA: Adapter lora_finqa_25 loss: 0.015183351933956146
[2025-12-23 17:42:19,632] m-LoRA: Adapter lora_finqa_15 epoch: 1/1 iteration: 42/128 step: 22
[2025-12-23 17:42:19,693] m-LoRA: Adapter lora_finqa_26 loss: 2.007997751235962
[2025-12-23 17:42:20,916] m-LoRA: Adapter lora_finqa_16 epoch: 1/1 iteration: 42/128 step: 22
[2025-12-23 17:42:20,999] m-LoRA: Adapter lora_finqa_27 loss: 0.007726296316832304
[2025-12-23 17:42:22,449] m-LoRA: Adapter lora_finqa_39 loss: 0.03007986769080162
[2025-12-23 17:42:22,455] m-LoRA: Adapter lora_finqa_45 epoch: 1/1 iteration: 20/128 step: 6
[2025-12-23 17:42:26,666] m-LoRA: Adapter lora_finqa_18 epoch: 1/1 iteration: 84/128 step: 22
[2025-12-23 17:42:26,907] m-LoRA: Adapter lora_finqa_49 loss: 1.7149505615234375
[2025-12-23 17:42:28,870] m-LoRA: Adapter lora_finqa_46 epoch: 1/1 iteration: 10/128 step: 6
[2025-12-23 17:42:29,136] m-LoRA: Adapter lora_finqa_50 loss: 2.5555434226989746
[2025-12-23 17:42:29,644] m-LoRA: Adapter lora_finqa_40 loss: 0.8384681344032288
[2025-12-23 17:42:29,648] m-LoRA: Adapter lora_finqa_37 epoch: 1/1 iteration: 26/128 step: 14
[2025-12-23 17:42:30,927] m-LoRA: Adapter lora_finqa_47 epoch: 1/1 iteration: 10/128 step: 6
[2025-12-23 17:42:30,983] m-LoRA: Adapter lora_finqa_32 loss: 2.0121445655822754
[2025-12-23 17:42:31,541] m-LoRA: Adapter lora_finqa_0 loss: 0.08431199938058853
[2025-12-23 17:42:31,544] m-LoRA: Adapter lora_finqa_21 epoch: 1/1 iteration: 84/128 step: 22
[2025-12-23 17:42:32,085] m-LoRA: Adapter lora_finqa_3 loss: 0.08637534081935883
[2025-12-23 17:42:32,089] m-LoRA: Adapter lora_finqa_23 epoch: 1/1 iteration: 42/128 step: 22
[2025-12-23 17:42:33,576] m-LoRA: Adapter lora_finqa_48 epoch: 1/1 iteration: 10/128 step: 6
[2025-12-23 17:42:33,632] m-LoRA: Adapter lora_finqa_41 loss: 2.05312442779541
[2025-12-23 17:42:34,344] m-LoRA: Adapter lora_finqa_1 loss: 0.08153653144836426
[2025-12-23 17:42:34,348] m-LoRA: Adapter lora_finqa_25 epoch: 1/1 iteration: 42/128 step: 22
[2025-12-23 17:42:36,594] m-LoRA: Adapter lora_finqa_26 epoch: 1/1 iteration: 84/128 step: 22
[2025-12-23 17:42:36,680] m-LoRA: Adapter lora_finqa_34 loss: 0.020345650613307953
[2025-12-23 17:42:37,762] m-LoRA: Adapter lora_finqa_27 epoch: 1/1 iteration: 84/128 step: 22
[2025-12-23 17:42:37,843] m-LoRA: Adapter lora_finqa_35 loss: 0.06853950768709183
[2025-12-23 17:42:38,538] m-LoRA: Adapter lora_finqa_39 epoch: 1/1 iteration: 52/128 step: 14
[2025-12-23 17:42:38,616] m-LoRA: Adapter lora_finqa_42 loss: 1.4121061563491821
[2025-12-23 17:42:39,286] m-LoRA: Adapter lora_finqa_7 loss: 0.01414475031197071
[2025-12-23 17:42:39,464] m-LoRA: Adapter lora_finqa_49 epoch: 1/1 iteration: 80/128 step: 6
[2025-12-23 17:42:39,933] m-LoRA: Adapter lora_finqa_8 loss: 0.013738501816987991
[2025-12-23 17:42:40,091] m-LoRA: Adapter lora_finqa_50 epoch: 1/1 iteration: 80/128 step: 6
[2025-12-23 17:42:40,591] m-LoRA: Adapter lora_finqa_40 epoch: 1/1 iteration: 26/128 step: 14
[2025-12-23 17:42:40,670] m-LoRA: Adapter lora_finqa_10 loss: 0.0838455855846405
[2025-12-23 17:42:42,838] m-LoRA: Adapter lora_finqa_32 epoch: 1/1 iteration: 84/128 step: 22
[2025-12-23 17:42:43,087] m-LoRA: Adapter lora_finqa_43 loss: 1.3907885551452637
[2025-12-23 17:42:43,557] m-LoRA: Adapter lora_finqa_11 loss: 0.08326892554759979
[2025-12-23 17:42:43,563] m-LoRA: Adapter lora_finqa_0 epoch: 1/1 iteration: 44/128 step: 23
[2025-12-23 17:42:44,053] m-LoRA: Adapter lora_finqa_3 epoch: 1/1 iteration: 44/128 step: 23
[2025-12-23 17:42:44,110] m-LoRA: Adapter lora_finqa_13 loss: 0.013434563763439655
[2025-12-23 17:42:46,317] m-LoRA: Adapter lora_finqa_41 epoch: 1/1 iteration: 24/128 step: 7
[2025-12-23 17:42:46,582] m-LoRA: Adapter lora_finqa_44 loss: 0.7784731984138489
[2025-12-23 17:42:47,158] m-LoRA: Adapter lora_finqa_36 loss: 0.6660100221633911
[2025-12-23 17:42:47,162] m-LoRA: Adapter lora_finqa_1 epoch: 1/1 iteration: 44/128 step: 23
[2025-12-23 17:42:47,452] m-LoRA: Adapter lora_finqa_15 loss: 0.006158835254609585
[2025-12-23 17:42:47,456] m-LoRA: Adapter lora_finqa_34 epoch: 1/1 iteration: 112/128 step: 15
[2025-12-23 17:42:47,737] m-LoRA: Adapter lora_finqa_16 loss: 0.005985756404697895
[2025-12-23 17:42:47,740] m-LoRA: Adapter lora_finqa_35 epoch: 1/1 iteration: 56/128 step: 15
[2025-12-23 17:42:48,267] m-LoRA: Adapter lora_finqa_42 epoch: 1/1 iteration: 12/128 step: 7
[2025-12-23 17:42:48,324] m-LoRA: Adapter lora_finqa_45 loss: 2.5380756855010986
[2025-12-23 17:42:48,833] m-LoRA: Adapter lora_finqa_18 loss: 0.013624152168631554
[2025-12-23 17:42:48,840] m-LoRA: Adapter lora_finqa_7 epoch: 1/1 iteration: 44/128 step: 23
[2025-12-23 17:42:49,105] m-LoRA: Adapter lora_finqa_46 loss: 1.397370457649231
[2025-12-23 17:42:49,109] m-LoRA: Adapter lora_finqa_8 epoch: 1/1 iteration: 44/128 step: 23
[2025-12-23 17:42:49,408] m-LoRA: Adapter lora_finqa_37 loss: 0.6668433547019958
[2025-12-23 17:42:49,412] m-LoRA: Adapter lora_finqa_10 epoch: 1/1 iteration: 88/128 step: 23
[2025-12-23 17:42:50,135] m-LoRA: Adapter lora_finqa_47 loss: 0.7859748005867004
[2025-12-23 17:42:50,292] m-LoRA: Adapter lora_finqa_43 epoch: 1/1 iteration: 96/128 step: 7
[2025-12-23 17:42:50,959] m-LoRA: Adapter lora_finqa_21 loss: 1.9628857374191284
[2025-12-23 17:42:50,965] m-LoRA: Adapter lora_finqa_11 epoch: 1/1 iteration: 88/128 step: 23
[2025-12-23 17:42:51,273] m-LoRA: Adapter lora_finqa_13 epoch: 1/1 iteration: 88/128 step: 23
[2025-12-23 17:42:51,347] m-LoRA: Adapter lora_finqa_23 loss: 0.005485905800014734
[2025-12-23 17:42:51,647] m-LoRA: Adapter lora_finqa_48 loss: 1.4313204288482666
[2025-12-23 17:42:51,833] m-LoRA: Adapter lora_finqa_44 epoch: 1/1 iteration: 96/128 step: 7
[2025-12-23 17:42:52,166] m-LoRA: Adapter lora_finqa_25 loss: 0.014253298752009869
[2025-12-23 17:42:52,170] m-LoRA: Adapter lora_finqa_36 epoch: 1/1 iteration: 28/128 step: 15
[2025-12-23 17:42:52,708] m-LoRA: Adapter lora_finqa_15 epoch: 1/1 iteration: 44/128 step: 23
[2025-12-23 17:42:52,766] m-LoRA: Adapter lora_finqa_26 loss: 1.9560344219207764
[2025-12-23 17:42:53,525] m-LoRA: Adapter lora_finqa_16 epoch: 1/1 iteration: 44/128 step: 23
[2025-12-23 17:42:53,569] m-LoRA: Adapter lora_finqa_27 loss: 0.0064889430068433285
[2025-12-23 17:42:54,247] m-LoRA: Adapter lora_finqa_39 loss: 0.022152846679091454
[2025-12-23 17:42:54,252] m-LoRA: Adapter lora_finqa_45 epoch: 1/1 iteration: 24/128 step: 7
[2025-12-23 17:42:56,637] m-LoRA: Adapter lora_finqa_18 epoch: 1/1 iteration: 88/128 step: 23
[2025-12-23 17:42:56,875] m-LoRA: Adapter lora_finqa_49 loss: 1.4006062746047974
[2025-12-23 17:42:58,960] m-LoRA: Adapter lora_finqa_46 epoch: 1/1 iteration: 12/128 step: 7
[2025-12-23 17:42:59,209] m-LoRA: Adapter lora_finqa_50 loss: 2.5405068397521973
[2025-12-23 17:42:59,278] m-LoRA: Adapter lora_finqa_40 loss: 0.6709911823272705
[2025-12-23 17:42:59,281] m-LoRA: Adapter lora_finqa_37 epoch: 1/1 iteration: 28/128 step: 15
[2025-12-23 17:42:59,970] m-LoRA: Adapter lora_finqa_32 loss: 1.9608204364776611
[2025-12-23 17:42:59,975] m-LoRA: Adapter lora_finqa_47 epoch: 1/1 iteration: 12/128 step: 7
[2025-12-23 17:43:00,744] m-LoRA: Adapter lora_finqa_21 epoch: 1/1 iteration: 88/128 step: 23
[2025-12-23 17:43:00,817] m-LoRA: Adapter lora_finqa_0 loss: 0.0664571225643158
[2025-12-23 17:43:01,085] m-LoRA: Adapter lora_finqa_3 loss: 0.06787630915641785
[2025-12-23 17:43:01,088] m-LoRA: Adapter lora_finqa_23 epoch: 1/1 iteration: 44/128 step: 23
[2025-12-23 17:43:01,642] m-LoRA: Adapter lora_finqa_48 epoch: 1/1 iteration: 12/128 step: 7
[2025-12-23 17:43:01,676] m-LoRA: Adapter lora_finqa_41 loss: 1.902582049369812
[2025-12-23 17:43:01,950] m-LoRA: Adapter lora_finqa_1 loss: 0.06490981578826904
[2025-12-23 17:43:01,953] m-LoRA: Adapter lora_finqa_25 epoch: 1/1 iteration: 44/128 step: 23
[2025-12-23 17:43:03,262] m-LoRA: Adapter lora_finqa_26 epoch: 1/1 iteration: 88/128 step: 23
[2025-12-23 17:43:03,390] m-LoRA: Adapter lora_finqa_34 loss: 0.01684666983783245
[2025-12-23 17:43:03,983] m-LoRA: Adapter lora_finqa_27 epoch: 1/1 iteration: 88/128 step: 23
[2025-12-23 17:43:04,065] m-LoRA: Adapter lora_finqa_35 loss: 0.045208584517240524
[2025-12-23 17:43:04,319] m-LoRA: Adapter lora_finqa_42 loss: 1.1326147317886353
[2025-12-23 17:43:04,428] m-LoRA: Adapter lora_finqa_39 epoch: 1/1 iteration: 56/128 step: 15
[2025-12-23 17:43:04,698] m-LoRA: Adapter lora_finqa_7 loss: 0.013148060999810696
[2025-12-23 17:43:04,874] m-LoRA: Adapter lora_finqa_49 epoch: 1/1 iteration: 96/128 step: 7
[2025-12-23 17:43:05,457] m-LoRA: Adapter lora_finqa_8 loss: 0.012922050431370735
[2025-12-23 17:43:05,460] m-LoRA: Adapter lora_finqa_50 epoch: 1/1 iteration: 96/128 step: 7
[2025-12-23 17:43:05,810] m-LoRA: Adapter lora_finqa_40 epoch: 1/1 iteration: 28/128 step: 15
[2025-12-23 17:43:05,846] m-LoRA: Adapter lora_finqa_10 loss: 0.06507962942123413
[2025-12-23 17:43:10,444] m-LoRA: Adapter lora_finqa_32 epoch: 1/1 iteration: 88/128 step: 23
[2025-12-23 17:43:10,680] m-LoRA: Adapter lora_finqa_43 loss: 1.0892399549484253
[2025-12-23 17:43:11,602] m-LoRA: Adapter lora_finqa_0 epoch: 1/1 iteration: 46/128 step: 24
[2025-12-23 17:43:11,665] m-LoRA: Adapter lora_finqa_11 loss: 0.06399177759885788
[2025-12-23 17:43:12,723] m-LoRA: Adapter lora_finqa_3 epoch: 1/1 iteration: 46/128 step: 24
[2025-12-23 17:43:12,754] m-LoRA: Adapter lora_finqa_13 loss: 0.012488075532019138
[2025-12-23 17:43:15,227] m-LoRA: Adapter lora_finqa_41 epoch: 1/1 iteration: 28/128 step: 8
[2025-12-23 17:43:15,539] m-LoRA: Adapter lora_finqa_44 loss: 0.5208836197853088
[2025-12-23 17:43:15,556] m-LoRA: Adapter lora_finqa_1 epoch: 1/1 iteration: 46/128 step: 24
[2025-12-23 17:43:15,592] m-LoRA: Adapter lora_finqa_36 loss: 0.5327914953231812
[2025-12-23 17:43:16,146] m-LoRA: Adapter lora_finqa_15 loss: 0.0048367599956691265
[2025-12-23 17:43:16,150] m-LoRA: Adapter lora_finqa_34 epoch: 1/1 iteration: 120/128 step: 16
[2025-12-23 17:43:16,494] m-LoRA: Adapter lora_finqa_16 loss: 0.005632326006889343
[2025-12-23 17:43:16,604] m-LoRA: Adapter lora_finqa_35 epoch: 1/1 iteration: 60/128 step: 16
[2025-12-23 17:43:17,658] m-LoRA: Adapter lora_finqa_45 loss: 2.5214178562164307
[2025-12-23 17:43:17,664] m-LoRA: Adapter lora_finqa_42 epoch: 1/1 iteration: 14/128 step: 8
[2025-12-23 17:43:18,941] m-LoRA: Adapter lora_finqa_18 loss: 0.012543747201561928
[2025-12-23 17:43:18,947] m-LoRA: Adapter lora_finqa_7 epoch: 1/1 iteration: 46/128 step: 24
[2025-12-23 17:43:19,774] m-LoRA: Adapter lora_finqa_46 loss: 1.1031049489974976
[2025-12-23 17:43:19,777] m-LoRA: Adapter lora_finqa_8 epoch: 1/1 iteration: 46/128 step: 24
[2025-12-23 17:43:20,428] m-LoRA: Adapter lora_finqa_37 loss: 0.5326747298240662
[2025-12-23 17:43:20,432] m-LoRA: Adapter lora_finqa_10 epoch: 1/1 iteration: 92/128 step: 24
[2025-12-23 17:43:21,055] m-LoRA: Adapter lora_finqa_47 loss: 0.5314875245094299
[2025-12-23 17:43:21,207] m-LoRA: Adapter lora_finqa_43 epoch: 1/1 iteration: 112/128 step: 8
[2025-12-23 17:43:22,403] m-LoRA: Adapter lora_finqa_11 epoch: 1/1 iteration: 92/128 step: 24
[2025-12-23 17:43:22,479] m-LoRA: Adapter lora_finqa_21 loss: 1.9099829196929932
[2025-12-23 17:43:23,259] m-LoRA: Adapter lora_finqa_23 loss: 0.0038946515414863825
[2025-12-23 17:43:23,262] m-LoRA: Adapter lora_finqa_13 epoch: 1/1 iteration: 92/128 step: 24
[2025-12-23 17:43:23,802] m-LoRA: Adapter lora_finqa_48 loss: 1.1794874668121338
[2025-12-23 17:43:23,977] m-LoRA: Adapter lora_finqa_44 epoch: 1/1 iteration: 112/128 step: 8
[2025-12-23 17:43:24,456] m-LoRA: Adapter lora_finqa_36 epoch: 1/1 iteration: 30/128 step: 16
[2025-12-23 17:43:24,512] m-LoRA: Adapter lora_finqa_25 loss: 0.013250823132693768
[2025-12-23 17:43:25,642] m-LoRA: Adapter lora_finqa_15 epoch: 1/1 iteration: 46/128 step: 24
[2025-12-23 17:43:25,704] m-LoRA: Adapter lora_finqa_26 loss: 1.902261734008789
[2025-12-23 17:43:26,218] m-LoRA: Adapter lora_finqa_16 epoch: 1/1 iteration: 46/128 step: 24
[2025-12-23 17:43:26,273] m-LoRA: Adapter lora_finqa_27 loss: 0.005482462700456381
[2025-12-23 17:43:27,382] m-LoRA: Adapter lora_finqa_45 epoch: 1/1 iteration: 28/128 step: 8
[2025-12-23 17:43:27,461] m-LoRA: Adapter lora_finqa_39 loss: 0.016977090388536453
[2025-12-23 17:43:29,445] m-LoRA: Adapter lora_finqa_18 epoch: 1/1 iteration: 92/128 step: 24
[2025-12-23 17:43:29,628] m-LoRA: Adapter lora_finqa_49 loss: 1.1175754070281982
[2025-12-23 17:43:31,501] m-LoRA: Adapter lora_finqa_46 epoch: 1/1 iteration: 14/128 step: 8
[2025-12-23 17:43:31,729] m-LoRA: Adapter lora_finqa_50 loss: 2.523000478744507
[2025-12-23 17:43:32,230] m-LoRA: Adapter lora_finqa_37 epoch: 1/1 iteration: 30/128 step: 16
[2025-12-23 17:43:32,282] m-LoRA: Adapter lora_finqa_40 loss: 0.5392388701438904
[2025-12-23 17:43:33,214] m-LoRA: Adapter lora_finqa_47 epoch: 1/1 iteration: 14/128 step: 8
[2025-12-23 17:43:33,270] m-LoRA: Adapter lora_finqa_32 loss: 1.9057203531265259
[2025-12-23 17:43:33,543] m-LoRA: Adapter lora_finqa_0 loss: 0.05486873909831047
[2025-12-23 17:43:33,546] m-LoRA: Adapter lora_finqa_21 epoch: 1/1 iteration: 92/128 step: 24
[2025-12-23 17:43:33,802] m-LoRA: Adapter lora_finqa_23 epoch: 1/1 iteration: 46/128 step: 24
[2025-12-23 17:43:33,847] m-LoRA: Adapter lora_finqa_3 loss: 0.05454434081912041
[2025-12-23 17:43:34,430] m-LoRA: Adapter lora_finqa_41 loss: 1.738473892211914
[2025-12-23 17:43:34,435] m-LoRA: Adapter lora_finqa_48 epoch: 1/1 iteration: 14/128 step: 8
[2025-12-23 17:43:35,198] m-LoRA: Adapter lora_finqa_1 loss: 0.05309870466589928
[2025-12-23 17:43:35,201] m-LoRA: Adapter lora_finqa_25 epoch: 1/1 iteration: 46/128 step: 24
[2025-12-23 17:43:36,578] m-LoRA: Adapter lora_finqa_26 epoch: 1/1 iteration: 92/128 step: 24
[2025-12-23 17:43:36,734] m-LoRA: Adapter lora_finqa_34 loss: 0.014161946251988411
[2025-12-23 17:43:37,248] m-LoRA: Adapter lora_finqa_35 loss: 0.03464043140411377
[2025-12-23 17:43:37,254] m-LoRA: Adapter lora_finqa_27 epoch: 1/1 iteration: 92/128 step: 24
[2025-12-23 17:43:37,557] m-LoRA: Adapter lora_finqa_42 loss: 0.8376167416572571
[2025-12-23 17:43:37,664] m-LoRA: Adapter lora_finqa_39 epoch: 1/1 iteration: 60/128 step: 16
[2025-12-23 17:43:37,971] m-LoRA: Adapter lora_finqa_7 loss: 0.012730853632092476
[2025-12-23 17:43:38,146] m-LoRA: Adapter lora_finqa_49 epoch: 1/1 iteration: 112/128 step: 8
[2025-12-23 17:43:38,749] m-LoRA: Adapter lora_finqa_8 loss: 0.011968138627707958
[2025-12-23 17:43:38,752] m-LoRA: Adapter lora_finqa_50 epoch: 1/1 iteration: 112/128 step: 8
[2025-12-23 17:43:39,115] m-LoRA: Adapter lora_finqa_10 loss: 0.053050678223371506
[2025-12-23 17:43:39,120] m-LoRA: Adapter lora_finqa_40 epoch: 1/1 iteration: 30/128 step: 16
[2025-12-23 17:43:41,607] m-LoRA: Adapter lora_finqa_32 epoch: 1/1 iteration: 92/128 step: 24
[2025-12-23 17:43:41,838] m-LoRA: Adapter lora_finqa_43 loss: 0.7975122928619385
[2025-12-23 17:43:42,602] m-LoRA: Adapter lora_finqa_11 loss: 0.051827143877744675
[2025-12-23 17:43:42,607] m-LoRA: Adapter lora_finqa_0 epoch: 1/1 iteration: 48/128 step: 25
[2025-12-23 17:43:43,118] m-LoRA: Adapter lora_finqa_3 epoch: 1/1 iteration: 48/128 step: 25
[2025-12-23 17:43:43,175] m-LoRA: Adapter lora_finqa_13 loss: 0.011548830196261406
[2025-12-23 17:43:46,198] m-LoRA: Adapter lora_finqa_44 loss: 0.32788193225860596
[2025-12-23 17:43:46,224] m-LoRA: Adapter lora_finqa_41 epoch: 1/1 iteration: 32/128 step: 9
[2025-12-23 17:43:46,361] m-LoRA: Adapter lora_finqa_36 loss: 0.42386335134506226
[2025-12-23 17:43:46,364] m-LoRA: Adapter lora_finqa_1 epoch: 1/1 iteration: 48/128 step: 25
[2025-12-23 17:43:46,771] m-LoRA: Finish and base model offload adapter - ['lora_finqa_34']
[2025-12-23 17:43:47,560] m-LoRA: Adapter lora_finqa_15 loss: 0.0042227283120155334
[2025-12-23 17:43:47,611] m-LoRA: Task to running, need to load adapters: ['lora_finqa_51']
[2025-12-23 17:43:47,827] m-LoRA: Adapter lora_finqa_51 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:43:47,940] m-LoRA: Adapter lora_finqa_16 loss: 0.003511331044137478
[2025-12-23 17:43:47,943] m-LoRA: Adapter lora_finqa_35 epoch: 1/1 iteration: 64/128 step: 17
[2025-12-23 17:43:48,175] m-LoRA: Adapter lora_finqa_45 loss: 2.5001368522644043
[2025-12-23 17:43:48,180] m-LoRA: Adapter lora_finqa_42 epoch: 1/1 iteration: 16/128 step: 9
[2025-12-23 17:43:48,417] m-LoRA: Adapter lora_finqa_18 loss: 0.01171840075403452
[2025-12-23 17:43:48,422] m-LoRA: Adapter lora_finqa_7 epoch: 1/1 iteration: 48/128 step: 25
[2025-12-23 17:43:48,581] m-LoRA: Adapter lora_finqa_46 loss: 0.8129981160163879
[2025-12-23 17:43:48,585] m-LoRA: Adapter lora_finqa_8 epoch: 1/1 iteration: 48/128 step: 25
[2025-12-23 17:43:48,769] m-LoRA: Adapter lora_finqa_37 loss: 0.42237693071365356
[2025-12-23 17:43:48,773] m-LoRA: Adapter lora_finqa_10 epoch: 1/1 iteration: 96/128 step: 25
[2025-12-23 17:43:49,337] m-LoRA: Adapter lora_finqa_47 loss: 0.33728668093681335
[2025-12-23 17:43:49,492] m-LoRA: Finish and base model offload adapter - ['lora_finqa_43']
[2025-12-23 17:43:49,919] m-LoRA: Task to running, need to load adapters: ['lora_finqa_52']
[2025-12-23 17:43:50,138] m-LoRA: Adapter lora_finqa_52 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:43:50,320] m-LoRA: Adapter lora_finqa_21 loss: 1.8524062633514404
[2025-12-23 17:43:50,325] m-LoRA: Adapter lora_finqa_11 epoch: 1/1 iteration: 96/128 step: 25
[2025-12-23 17:43:50,544] m-LoRA: Adapter lora_finqa_23 loss: 0.0029468571301549673
[2025-12-23 17:43:50,547] m-LoRA: Adapter lora_finqa_13 epoch: 1/1 iteration: 96/128 step: 25
[2025-12-23 17:43:50,877] m-LoRA: Adapter lora_finqa_48 loss: 0.8625462055206299
[2025-12-23 17:43:51,297] m-LoRA: Adapter lora_finqa_25 loss: 0.012314784340560436
[2025-12-23 17:43:51,468] m-LoRA: Finish and base model offload adapter - ['lora_finqa_44']
[2025-12-23 17:43:52,060] m-LoRA: Task to running, need to load adapters: ['lora_finqa_53']
[2025-12-23 17:43:52,124] m-LoRA: Adapter lora_finqa_53 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:43:52,378] m-LoRA: Adapter lora_finqa_26 loss: 1.8441065549850464
[2025-12-23 17:43:52,383] m-LoRA: Adapter lora_finqa_36 epoch: 1/1 iteration: 32/128 step: 17
[2025-12-23 17:43:52,696] m-LoRA: Adapter lora_finqa_15 epoch: 1/1 iteration: 48/128 step: 25
[2025-12-23 17:43:52,729] m-LoRA: Adapter lora_finqa_27 loss: 0.004917285405099392
[2025-12-23 17:43:53,427] m-LoRA: Adapter lora_finqa_16 epoch: 1/1 iteration: 48/128 step: 25
[2025-12-23 17:43:53,463] m-LoRA: Adapter lora_finqa_39 loss: 0.014044512994587421
[2025-12-23 17:43:57,874] m-LoRA: Adapter lora_finqa_45 epoch: 1/1 iteration: 32/128 step: 9
[2025-12-23 17:43:58,085] m-LoRA: Adapter lora_finqa_49 loss: 0.8221392035484314
[2025-12-23 17:44:02,162] m-LoRA: Adapter lora_finqa_18 epoch: 1/1 iteration: 96/128 step: 25
[2025-12-23 17:44:02,375] m-LoRA: Adapter lora_finqa_50 loss: 2.50144362449646
[2025-12-23 17:44:02,486] m-LoRA: Adapter lora_finqa_40 loss: 0.42503178119659424
[2025-12-23 17:44:02,490] m-LoRA: Adapter lora_finqa_46 epoch: 1/1 iteration: 16/128 step: 9
[2025-12-23 17:44:03,597] m-LoRA: Adapter lora_finqa_37 epoch: 1/1 iteration: 32/128 step: 17
[2025-12-23 17:44:03,651] m-LoRA: Adapter lora_finqa_32 loss: 1.8483589887619019
[2025-12-23 17:44:03,936] m-LoRA: Adapter lora_finqa_0 loss: 0.045618411153554916
[2025-12-23 17:44:03,939] m-LoRA: Adapter lora_finqa_47 epoch: 1/1 iteration: 16/128 step: 9
[2025-12-23 17:44:04,231] m-LoRA: Adapter lora_finqa_3 loss: 0.045570261776447296
[2025-12-23 17:44:04,234] m-LoRA: Adapter lora_finqa_21 epoch: 1/1 iteration: 96/128 step: 25
[2025-12-23 17:44:05,663] m-LoRA: Adapter lora_finqa_41 loss: 1.554892897605896
[2025-12-23 17:44:05,713] m-LoRA: Adapter lora_finqa_23 epoch: 1/1 iteration: 48/128 step: 25
[2025-12-23 17:44:05,981] m-LoRA: Adapter lora_finqa_1 loss: 0.044622961431741714
[2025-12-23 17:44:05,984] m-LoRA: Adapter lora_finqa_48 epoch: 1/1 iteration: 16/128 step: 9
[2025-12-23 17:44:06,344] m-LoRA: Adapter lora_finqa_25 epoch: 1/1 iteration: 48/128 step: 25
[2025-12-23 17:44:06,407] m-LoRA: Adapter lora_finqa_51 loss: 2.5885283946990967
[2025-12-23 17:44:07,203] m-LoRA: Adapter lora_finqa_35 loss: 0.02924143150448799
[2025-12-23 17:44:07,208] m-LoRA: Adapter lora_finqa_26 epoch: 1/1 iteration: 96/128 step: 25
[2025-12-23 17:44:07,486] m-LoRA: Adapter lora_finqa_42 loss: 0.5889829993247986
[2025-12-23 17:44:07,489] m-LoRA: Adapter lora_finqa_27 epoch: 1/1 iteration: 96/128 step: 25
[2025-12-23 17:44:07,697] m-LoRA: Adapter lora_finqa_7 loss: 0.011974024586379528
[2025-12-23 17:44:07,701] m-LoRA: Adapter lora_finqa_39 epoch: 1/1 iteration: 64/128 step: 17
[2025-12-23 17:44:08,329] m-LoRA: Adapter lora_finqa_8 loss: 0.011211891658604145
[2025-12-23 17:44:08,501] m-LoRA: Finish and base model offload adapter - ['lora_finqa_49']
[2025-12-23 17:44:09,218] m-LoRA: Task to running, need to load adapters: ['lora_finqa_54']
[2025-12-23 17:44:09,383] m-LoRA: Adapter lora_finqa_54 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:44:09,677] m-LoRA: Adapter lora_finqa_10 loss: 0.04474068433046341
[2025-12-23 17:44:09,833] m-LoRA: Finish and base model offload adapter - ['lora_finqa_50']
[2025-12-23 17:44:10,229] m-LoRA: Task to running, need to load adapters: ['lora_finqa_55']
[2025-12-23 17:44:10,335] m-LoRA: Adapter lora_finqa_55 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:44:12,217] m-LoRA: Adapter lora_finqa_40 epoch: 1/1 iteration: 32/128 step: 17
[2025-12-23 17:44:12,331] m-LoRA: Adapter lora_finqa_52 loss: 2.588528633117676
[2025-12-23 17:44:13,526] m-LoRA: Adapter lora_finqa_32 epoch: 1/1 iteration: 96/128 step: 25
[2025-12-23 17:44:13,606] m-LoRA: Adapter lora_finqa_11 loss: 0.043923940509557724
[2025-12-23 17:44:14,790] m-LoRA: Adapter lora_finqa_13 loss: 0.010943129658699036
[2025-12-23 17:44:14,895] m-LoRA: Adapter lora_finqa_0 epoch: 1/1 iteration: 50/128 step: 26
[2025-12-23 17:44:16,950] m-LoRA: Adapter lora_finqa_3 epoch: 1/1 iteration: 50/128 step: 26
[2025-12-23 17:44:17,147] m-LoRA: Adapter lora_finqa_53 loss: 2.5885279178619385
[2025-12-23 17:44:17,647] m-LoRA: Adapter lora_finqa_41 epoch: 1/1 iteration: 36/128 step: 10
[2025-12-23 17:44:17,717] m-LoRA: Adapter lora_finqa_36 loss: 0.33726242184638977
[2025-12-23 17:44:18,222] m-LoRA: Adapter lora_finqa_15 loss: 0.003360475180670619
[2025-12-23 17:44:18,225] m-LoRA: Adapter lora_finqa_1 epoch: 1/1 iteration: 50/128 step: 26
[2025-12-23 17:44:18,741] m-LoRA: Adapter lora_finqa_16 loss: 0.0024008620530366898
[2025-12-23 17:44:18,745] m-LoRA: Adapter lora_finqa_51 epoch: 1/1 iteration: 2/128 step: 2
[2025-12-23 17:44:19,291] m-LoRA: Adapter lora_finqa_45 loss: 2.4758880138397217
[2025-12-23 17:44:19,424] m-LoRA: Adapter lora_finqa_35 epoch: 1/1 iteration: 68/128 step: 18
[2025-12-23 17:44:20,167] m-LoRA: Adapter lora_finqa_18 loss: 0.011927583254873753
[2025-12-23 17:44:20,172] m-LoRA: Adapter lora_finqa_42 epoch: 1/1 iteration: 18/128 step: 10
[2025-12-23 17:44:20,985] m-LoRA: Adapter lora_finqa_46 loss: 0.5607665777206421
[2025-12-23 17:44:20,988] m-LoRA: Adapter lora_finqa_7 epoch: 1/1 iteration: 50/128 step: 26
[2025-12-23 17:44:21,616] m-LoRA: Adapter lora_finqa_37 loss: 0.33354076743125916
[2025-12-23 17:44:21,619] m-LoRA: Adapter lora_finqa_8 epoch: 1/1 iteration: 50/128 step: 26
[2025-12-23 17:44:22,250] m-LoRA: Adapter lora_finqa_47 loss: 0.2152073085308075
[2025-12-23 17:44:22,254] m-LoRA: Adapter lora_finqa_10 epoch: 1/1 iteration: 100/128 step: 26
[2025-12-23 17:44:22,918] m-LoRA: Adapter lora_finqa_21 loss: 1.7937743663787842
[2025-12-23 17:44:23,091] m-LoRA: Adapter lora_finqa_52 epoch: 1/1 iteration: 8/128 step: 2
[2025-12-23 17:44:23,669] m-LoRA: Adapter lora_finqa_23 loss: 0.001927827252075076
[2025-12-23 17:44:23,672] m-LoRA: Adapter lora_finqa_11 epoch: 1/1 iteration: 100/128 step: 26
[2025-12-23 17:44:24,341] m-LoRA: Adapter lora_finqa_48 loss: 0.617107093334198
[2025-12-23 17:44:24,345] m-LoRA: Adapter lora_finqa_13 epoch: 1/1 iteration: 100/128 step: 26
[2025-12-23 17:44:25,018] m-LoRA: Adapter lora_finqa_25 loss: 0.011442531831562519
[2025-12-23 17:44:25,181] m-LoRA: Adapter lora_finqa_53 epoch: 1/1 iteration: 16/128 step: 2
[2025-12-23 17:44:25,655] m-LoRA: Adapter lora_finqa_36 epoch: 1/1 iteration: 34/128 step: 18
[2025-12-23 17:44:25,711] m-LoRA: Adapter lora_finqa_26 loss: 1.7861686944961548
[2025-12-23 17:44:26,849] m-LoRA: Adapter lora_finqa_15 epoch: 1/1 iteration: 50/128 step: 26
[2025-12-23 17:44:26,895] m-LoRA: Adapter lora_finqa_27 loss: 0.0028745541349053383
[2025-12-23 17:44:27,456] m-LoRA: Adapter lora_finqa_16 epoch: 1/1 iteration: 50/128 step: 26
[2025-12-23 17:44:27,508] m-LoRA: Adapter lora_finqa_39 loss: 0.012049754150211811
[2025-12-23 17:44:29,672] m-LoRA: Adapter lora_finqa_54 loss: 2.5885279178619385
[2025-12-23 17:44:29,692] m-LoRA: Adapter lora_finqa_45 epoch: 1/1 iteration: 36/128 step: 10
[2025-12-23 17:44:30,131] m-LoRA: Adapter lora_finqa_55 loss: 2.5885283946990967
[2025-12-23 17:44:30,134] m-LoRA: Adapter lora_finqa_18 epoch: 1/1 iteration: 100/128 step: 26
[2025-12-23 17:44:30,290] m-LoRA: Adapter lora_finqa_40 loss: 0.3378555476665497
[2025-12-23 17:44:30,293] m-LoRA: Adapter lora_finqa_46 epoch: 1/1 iteration: 18/128 step: 10
[2025-12-23 17:44:30,757] m-LoRA: Adapter lora_finqa_37 epoch: 1/1 iteration: 34/128 step: 18
[2025-12-23 17:44:30,797] m-LoRA: Adapter lora_finqa_32 loss: 1.7909306287765503
[2025-12-23 17:44:31,069] m-LoRA: Adapter lora_finqa_0 loss: 0.040053486824035645
[2025-12-23 17:44:31,072] m-LoRA: Adapter lora_finqa_47 epoch: 1/1 iteration: 18/128 step: 10
[2025-12-23 17:44:31,369] m-LoRA: Adapter lora_finqa_3 loss: 0.040032513439655304
[2025-12-23 17:44:31,372] m-LoRA: Adapter lora_finqa_21 epoch: 1/1 iteration: 100/128 step: 26
[2025-12-23 17:44:31,898] m-LoRA: Adapter lora_finqa_23 epoch: 1/1 iteration: 50/128 step: 26
[2025-12-23 17:44:31,931] m-LoRA: Adapter lora_finqa_41 loss: 1.3919373750686646
[2025-12-23 17:44:32,193] m-LoRA: Adapter lora_finqa_1 loss: 0.03866557404398918
[2025-12-23 17:44:32,196] m-LoRA: Adapter lora_finqa_48 epoch: 1/1 iteration: 18/128 step: 10
[2025-12-23 17:44:32,888] m-LoRA: Adapter lora_finqa_51 loss: 2.478745460510254
[2025-12-23 17:44:32,892] m-LoRA: Adapter lora_finqa_25 epoch: 1/1 iteration: 50/128 step: 26
[2025-12-23 17:44:33,533] m-LoRA: Adapter lora_finqa_26 epoch: 1/1 iteration: 100/128 step: 26
[2025-12-23 17:44:33,607] m-LoRA: Adapter lora_finqa_35 loss: 0.02351129800081253
[2025-12-23 17:44:33,801] m-LoRA: Adapter lora_finqa_42 loss: 0.4310033321380615
[2025-12-23 17:44:33,898] m-LoRA: Adapter lora_finqa_27 epoch: 1/1 iteration: 100/128 step: 26
[2025-12-23 17:44:34,245] m-LoRA: Adapter lora_finqa_7 loss: 0.010868005454540253
[2025-12-23 17:44:34,248] m-LoRA: Adapter lora_finqa_39 epoch: 1/1 iteration: 68/128 step: 18
[2025-12-23 17:44:34,530] m-LoRA: Adapter lora_finqa_8 loss: 0.011893837712705135
[2025-12-23 17:44:34,726] m-LoRA: Adapter lora_finqa_54 epoch: 1/1 iteration: 16/128 step: 2
[2025-12-23 17:44:35,245] m-LoRA: Adapter lora_finqa_10 loss: 0.03942763805389404
[2025-12-23 17:44:35,251] m-LoRA: Adapter lora_finqa_55 epoch: 1/1 iteration: 2/128 step: 2
[2025-12-23 17:44:36,526] m-LoRA: Adapter lora_finqa_52 loss: 2.472529172897339
[2025-12-23 17:44:36,536] m-LoRA: Adapter lora_finqa_40 epoch: 1/1 iteration: 34/128 step: 18
[2025-12-23 17:44:37,178] m-LoRA: Adapter lora_finqa_11 loss: 0.03936176374554634
[2025-12-23 17:44:37,184] m-LoRA: Adapter lora_finqa_32 epoch: 1/1 iteration: 100/128 step: 26
[2025-12-23 17:44:37,854] m-LoRA: Adapter lora_finqa_0 epoch: 1/1 iteration: 52/128 step: 27
[2025-12-23 17:44:37,887] m-LoRA: Adapter lora_finqa_13 loss: 0.010411405935883522
[2025-12-23 17:44:38,168] m-LoRA: Adapter lora_finqa_36 loss: 0.2672778367996216
[2025-12-23 17:44:38,172] m-LoRA: Adapter lora_finqa_3 epoch: 1/1 iteration: 52/128 step: 27
[2025-12-23 17:44:40,411] m-LoRA: Adapter lora_finqa_41 epoch: 1/1 iteration: 40/128 step: 11
[2025-12-23 17:44:40,626] m-LoRA: Adapter lora_finqa_53 loss: 2.5445849895477295
[2025-12-23 17:44:41,087] m-LoRA: Adapter lora_finqa_15 loss: 0.00221938150934875
[2025-12-23 17:44:41,090] m-LoRA: Adapter lora_finqa_1 epoch: 1/1 iteration: 52/128 step: 27
[2025-12-23 17:44:41,351] m-LoRA: Adapter lora_finqa_16 loss: 0.0020131992641836405
[2025-12-23 17:44:41,354] m-LoRA: Adapter lora_finqa_51 epoch: 1/1 iteration: 4/128 step: 3
[2025-12-23 17:44:41,936] m-LoRA: Adapter lora_finqa_45 loss: 2.4498162269592285
[2025-12-23 17:44:41,942] m-LoRA: Adapter lora_finqa_35 epoch: 1/1 iteration: 72/128 step: 19
[2025-12-23 17:44:42,462] m-LoRA: Adapter lora_finqa_42 epoch: 1/1 iteration: 20/128 step: 11
[2025-12-23 17:44:42,519] m-LoRA: Adapter lora_finqa_18 loss: 0.01045688334852457
[2025-12-23 17:44:42,742] m-LoRA: Adapter lora_finqa_46 loss: 0.4100998044013977
[2025-12-23 17:44:42,746] m-LoRA: Adapter lora_finqa_7 epoch: 1/1 iteration: 52/128 step: 27
[2025-12-23 17:44:43,016] m-LoRA: Adapter lora_finqa_37 loss: 0.26516249775886536
[2025-12-23 17:44:43,019] m-LoRA: Adapter lora_finqa_8 epoch: 1/1 iteration: 52/128 step: 27
[2025-12-23 17:44:43,297] m-LoRA: Adapter lora_finqa_10 epoch: 1/1 iteration: 104/128 step: 27
[2025-12-23 17:44:43,370] m-LoRA: Adapter lora_finqa_47 loss: 0.1214478388428688
[2025-12-23 17:44:43,993] m-LoRA: Adapter lora_finqa_52 epoch: 1/1 iteration: 16/128 step: 3
[2025-12-23 17:44:44,125] m-LoRA: Adapter lora_finqa_21 loss: 1.7328507900238037
[2025-12-23 17:44:44,471] m-LoRA: Adapter lora_finqa_23 loss: 0.0019508369732648134
[2025-12-23 17:44:44,474] m-LoRA: Adapter lora_finqa_11 epoch: 1/1 iteration: 104/128 step: 27
[2025-12-23 17:44:44,854] m-LoRA: Adapter lora_finqa_48 loss: 0.4431138336658478
[2025-12-23 17:44:44,858] m-LoRA: Adapter lora_finqa_13 epoch: 1/1 iteration: 104/128 step: 27
[2025-12-23 17:44:45,124] m-LoRA: Adapter lora_finqa_25 loss: 0.01066306047141552
[2025-12-23 17:44:45,265] m-LoRA: Adapter lora_finqa_36 epoch: 1/1 iteration: 36/128 step: 19
[2025-12-23 17:44:45,818] m-LoRA: Adapter lora_finqa_26 loss: 1.7237732410430908
[2025-12-23 17:44:46,049] m-LoRA: Adapter lora_finqa_53 epoch: 1/1 iteration: 32/128 step: 3
[2025-12-23 17:44:46,631] m-LoRA: Adapter lora_finqa_27 loss: 0.0021435560192912817
[2025-12-23 17:44:46,637] m-LoRA: Adapter lora_finqa_15 epoch: 1/1 iteration: 52/128 step: 27
[2025-12-23 17:44:47,262] m-LoRA: Adapter lora_finqa_16 epoch: 1/1 iteration: 52/128 step: 27
[2025-12-23 17:44:47,316] m-LoRA: Adapter lora_finqa_39 loss: 0.011394881643354893
[2025-12-23 17:44:52,150] m-LoRA: Adapter lora_finqa_54 loss: 2.4765303134918213
[2025-12-23 17:44:52,168] m-LoRA: Adapter lora_finqa_45 epoch: 1/1 iteration: 40/128 step: 11
[2025-12-23 17:44:52,626] m-LoRA: Adapter lora_finqa_55 loss: 2.584073543548584
[2025-12-23 17:44:52,681] m-LoRA: Adapter lora_finqa_18 epoch: 1/1 iteration: 104/128 step: 27
[2025-12-23 17:44:52,835] m-LoRA: Adapter lora_finqa_40 loss: 0.27046722173690796
[2025-12-23 17:44:52,838] m-LoRA: Adapter lora_finqa_46 epoch: 1/1 iteration: 20/128 step: 11
[2025-12-23 17:44:53,467] m-LoRA: Adapter lora_finqa_37 epoch: 1/1 iteration: 36/128 step: 19
[2025-12-23 17:44:53,522] m-LoRA: Adapter lora_finqa_32 loss: 1.728074073791504
[2025-12-23 17:44:53,759] m-LoRA: Adapter lora_finqa_0 loss: 0.036333177238702774
[2025-12-23 17:44:53,762] m-LoRA: Adapter lora_finqa_47 epoch: 1/1 iteration: 20/128 step: 11
[2025-12-23 17:44:54,150] m-LoRA: Adapter lora_finqa_3 loss: 0.03623238205909729
[2025-12-23 17:44:54,153] m-LoRA: Adapter lora_finqa_21 epoch: 1/1 iteration: 104/128 step: 27
[2025-12-23 17:44:55,596] m-LoRA: Adapter lora_finqa_41 loss: 1.2025890350341797
[2025-12-23 17:44:55,602] m-LoRA: Adapter lora_finqa_23 epoch: 1/1 iteration: 52/128 step: 27
[2025-12-23 17:44:55,912] m-LoRA: Adapter lora_finqa_1 loss: 0.03545764833688736
[2025-12-23 17:44:55,915] m-LoRA: Adapter lora_finqa_48 epoch: 1/1 iteration: 20/128 step: 11
[2025-12-23 17:44:56,293] m-LoRA: Adapter lora_finqa_25 epoch: 1/1 iteration: 52/128 step: 27
[2025-12-23 17:44:56,345] m-LoRA: Adapter lora_finqa_51 loss: 2.2623507976531982
[2025-12-23 17:44:56,998] m-LoRA: Adapter lora_finqa_35 loss: 0.01958278752863407
[2025-12-23 17:44:57,003] m-LoRA: Adapter lora_finqa_26 epoch: 1/1 iteration: 104/128 step: 27
[2025-12-23 17:44:57,337] m-LoRA: Adapter lora_finqa_42 loss: 0.2883482277393341
[2025-12-23 17:44:57,340] m-LoRA: Adapter lora_finqa_27 epoch: 1/1 iteration: 104/128 step: 27
[2025-12-23 17:44:57,611] m-LoRA: Adapter lora_finqa_7 loss: 0.010685299523174763
[2025-12-23 17:44:57,701] m-LoRA: Adapter lora_finqa_39 epoch: 1/1 iteration: 72/128 step: 19
[2025-12-23 17:44:57,959] m-LoRA: Adapter lora_finqa_8 loss: 0.009610538370907307
[2025-12-23 17:44:58,234] m-LoRA: Adapter lora_finqa_54 epoch: 1/1 iteration: 32/128 step: 3
[2025-12-23 17:44:58,861] m-LoRA: Adapter lora_finqa_10 loss: 0.03542713075876236
[2025-12-23 17:44:58,867] m-LoRA: Adapter lora_finqa_55 epoch: 1/1 iteration: 4/128 step: 3
[2025-12-23 17:45:00,025] m-LoRA: Adapter lora_finqa_40 epoch: 1/1 iteration: 36/128 step: 19
[2025-12-23 17:45:00,132] m-LoRA: Adapter lora_finqa_52 loss: 2.251256227493286
[2025-12-23 17:45:01,484] m-LoRA: Adapter lora_finqa_32 epoch: 1/1 iteration: 104/128 step: 27
[2025-12-23 17:45:01,559] m-LoRA: Adapter lora_finqa_11 loss: 0.03555992245674133
[2025-12-23 17:45:02,871] m-LoRA: Adapter lora_finqa_0 epoch: 1/1 iteration: 54/128 step: 28
[2025-12-23 17:45:02,921] m-LoRA: Adapter lora_finqa_13 loss: 0.009240034967660904
[2025-12-23 17:45:03,517] m-LoRA: Adapter lora_finqa_36 loss: 0.2105075865983963
[2025-12-23 17:45:03,521] m-LoRA: Adapter lora_finqa_3 epoch: 1/1 iteration: 54/128 step: 28
[2025-12-23 17:45:05,738] m-LoRA: Adapter lora_finqa_41 epoch: 1/1 iteration: 44/128 step: 12
[2025-12-23 17:45:05,953] m-LoRA: Adapter lora_finqa_53 loss: 2.4559381008148193
[2025-12-23 17:45:06,458] m-LoRA: Adapter lora_finqa_15 loss: 0.001173846423625946
[2025-12-23 17:45:06,462] m-LoRA: Adapter lora_finqa_1 epoch: 1/1 iteration: 54/128 step: 28
[2025-12-23 17:45:07,002] m-LoRA: Adapter lora_finqa_16 loss: 0.0010311913210898638
[2025-12-23 17:45:07,005] m-LoRA: Adapter lora_finqa_51 epoch: 1/1 iteration: 6/128 step: 4
[2025-12-23 17:45:08,043] m-LoRA: Adapter lora_finqa_45 loss: 2.4214065074920654
[2025-12-23 17:45:08,048] m-LoRA: Adapter lora_finqa_35 epoch: 1/1 iteration: 76/128 step: 20
[2025-12-23 17:45:08,610] m-LoRA: Adapter lora_finqa_18 loss: 0.009207808412611485
[2025-12-23 17:45:08,615] m-LoRA: Adapter lora_finqa_42 epoch: 1/1 iteration: 22/128 step: 12
[2025-12-23 17:45:09,369] m-LoRA: Adapter lora_finqa_46 loss: 0.2720203697681427
[2025-12-23 17:45:09,372] m-LoRA: Adapter lora_finqa_7 epoch: 1/1 iteration: 54/128 step: 28
[2025-12-23 17:45:10,066] m-LoRA: Adapter lora_finqa_37 loss: 0.2108667641878128
[2025-12-23 17:45:10,151] m-LoRA: Adapter lora_finqa_8 epoch: 1/1 iteration: 54/128 step: 28
[2025-12-23 17:45:10,441] m-LoRA: Adapter lora_finqa_47 loss: 0.06048647314310074
[2025-12-23 17:45:10,444] m-LoRA: Adapter lora_finqa_10 epoch: 1/1 iteration: 108/128 step: 28
[2025-12-23 17:45:11,211] m-LoRA: Adapter lora_finqa_21 loss: 1.6632639169692993
[2025-12-23 17:45:11,217] m-LoRA: Adapter lora_finqa_52 epoch: 1/1 iteration: 24/128 step: 4
[2025-12-23 17:45:11,932] m-LoRA: Adapter lora_finqa_23 loss: 0.0012311663012951612
[2025-12-23 17:45:11,935] m-LoRA: Adapter lora_finqa_11 epoch: 1/1 iteration: 108/128 step: 28
[2025-12-23 17:45:12,638] m-LoRA: Adapter lora_finqa_48 loss: 0.30415499210357666
[2025-12-23 17:45:12,641] m-LoRA: Adapter lora_finqa_13 epoch: 1/1 iteration: 108/128 step: 28
[2025-12-23 17:45:13,339] m-LoRA: Adapter lora_finqa_25 loss: 0.009838838130235672
[2025-12-23 17:45:13,342] m-LoRA: Adapter lora_finqa_36 epoch: 1/1 iteration: 38/128 step: 20
[2025-12-23 17:45:14,421] m-LoRA: Adapter lora_finqa_26 loss: 1.6569452285766602
[2025-12-23 17:45:14,585] m-LoRA: Adapter lora_finqa_53 epoch: 1/1 iteration: 48/128 step: 4
[2025-12-23 17:45:15,622] m-LoRA: Adapter lora_finqa_15 epoch: 1/1 iteration: 54/128 step: 28
[2025-12-23 17:45:15,678] m-LoRA: Adapter lora_finqa_27 loss: 0.0011777112958952785
[2025-12-23 17:45:16,321] m-LoRA: Adapter lora_finqa_39 loss: 0.009687116369605064
[2025-12-23 17:45:16,365] m-LoRA: Adapter lora_finqa_16 epoch: 1/1 iteration: 54/128 step: 28
[2025-12-23 17:45:18,313] m-LoRA: Adapter lora_finqa_45 epoch: 1/1 iteration: 44/128 step: 12
[2025-12-23 17:45:18,531] m-LoRA: Adapter lora_finqa_54 loss: 2.2592179775238037
[2025-12-23 17:45:19,061] m-LoRA: Adapter lora_finqa_18 epoch: 1/1 iteration: 108/128 step: 28
[2025-12-23 17:45:19,133] m-LoRA: Adapter lora_finqa_55 loss: 2.5774855613708496
[2025-12-23 17:45:19,385] m-LoRA: Adapter lora_finqa_40 loss: 0.2124006599187851
[2025-12-23 17:45:19,388] m-LoRA: Adapter lora_finqa_46 epoch: 1/1 iteration: 22/128 step: 12
[2025-12-23 17:45:19,921] m-LoRA: Adapter lora_finqa_37 epoch: 1/1 iteration: 38/128 step: 20
[2025-12-23 17:45:19,976] m-LoRA: Adapter lora_finqa_32 loss: 1.6607639789581299
[2025-12-23 17:45:20,161] m-LoRA: Adapter lora_finqa_47 epoch: 1/1 iteration: 22/128 step: 12
[2025-12-23 17:45:20,217] m-LoRA: Adapter lora_finqa_0 loss: 0.03316818177700043
[2025-12-23 17:45:20,463] m-LoRA: Adapter lora_finqa_21 epoch: 1/1 iteration: 108/128 step: 28
[2025-12-23 17:45:20,536] m-LoRA: Adapter lora_finqa_3 loss: 0.033403366804122925
[2025-12-23 17:45:21,097] m-LoRA: Adapter lora_finqa_41 loss: 1.009007453918457
[2025-12-23 17:45:21,323] m-LoRA: Adapter lora_finqa_23 epoch: 1/1 iteration: 54/128 step: 28
[2025-12-23 17:45:21,641] m-LoRA: Adapter lora_finqa_48 epoch: 1/1 iteration: 22/128 step: 12
[2025-12-23 17:45:21,695] m-LoRA: Adapter lora_finqa_1 loss: 0.03211553394794464
[2025-12-23 17:45:22,011] m-LoRA: Adapter lora_finqa_51 loss: 2.0069470405578613
[2025-12-23 17:45:22,014] m-LoRA: Adapter lora_finqa_25 epoch: 1/1 iteration: 54/128 step: 28
[2025-12-23 17:45:22,661] m-LoRA: Adapter lora_finqa_35 loss: 0.016334805637598038
[2025-12-23 17:45:22,666] m-LoRA: Adapter lora_finqa_26 epoch: 1/1 iteration: 108/128 step: 28
[2025-12-23 17:45:23,002] m-LoRA: Adapter lora_finqa_42 loss: 0.20012067258358002
[2025-12-23 17:45:23,005] m-LoRA: Adapter lora_finqa_27 epoch: 1/1 iteration: 108/128 step: 28
[2025-12-23 17:45:23,309] m-LoRA: Adapter lora_finqa_7 loss: 0.009384731762111187
[2025-12-23 17:45:23,313] m-LoRA: Adapter lora_finqa_39 epoch: 1/1 iteration: 76/128 step: 20
[2025-12-23 17:45:23,601] m-LoRA: Adapter lora_finqa_8 loss: 0.008532971143722534
[2025-12-23 17:45:23,780] m-LoRA: Adapter lora_finqa_54 epoch: 1/1 iteration: 48/128 step: 4
[2025-12-23 17:45:24,313] m-LoRA: Adapter lora_finqa_10 loss: 0.03195543587207794
[2025-12-23 17:45:24,319] m-LoRA: Adapter lora_finqa_55 epoch: 1/1 iteration: 6/128 step: 4
[2025-12-23 17:45:25,464] m-LoRA: Adapter lora_finqa_40 epoch: 1/1 iteration: 38/128 step: 20
[2025-12-23 17:45:25,577] m-LoRA: Adapter lora_finqa_52 loss: 1.9835206270217896
[2025-12-23 17:45:26,334] m-LoRA: Adapter lora_finqa_11 loss: 0.03204924240708351
[2025-12-23 17:45:26,340] m-LoRA: Adapter lora_finqa_32 epoch: 1/1 iteration: 108/128 step: 28
[2025-12-23 17:45:26,937] m-LoRA: Adapter lora_finqa_0 epoch: 1/1 iteration: 56/128 step: 29
[2025-12-23 17:45:26,991] m-LoRA: Adapter lora_finqa_13 loss: 0.009635185822844505
[2025-12-23 17:45:27,286] m-LoRA: Adapter lora_finqa_36 loss: 0.16294585168361664
[2025-12-23 17:45:27,289] m-LoRA: Adapter lora_finqa_3 epoch: 1/1 iteration: 56/128 step: 29
[2025-12-23 17:45:30,022] m-LoRA: Adapter lora_finqa_53 loss: 2.3377063274383545
[2025-12-23 17:45:30,040] m-LoRA: Adapter lora_finqa_41 epoch: 1/1 iteration: 48/128 step: 13
[2025-12-23 17:45:30,191] m-LoRA: Adapter lora_finqa_15 loss: 0.0007523880922235548
[2025-12-23 17:45:30,194] m-LoRA: Adapter lora_finqa_1 epoch: 1/1 iteration: 56/128 step: 29
[2025-12-23 17:45:30,598] m-LoRA: Adapter lora_finqa_16 loss: 0.0009069297229871154
[2025-12-23 17:45:30,601] m-LoRA: Adapter lora_finqa_51 epoch: 1/1 iteration: 8/128 step: 5
[2025-12-23 17:45:31,100] m-LoRA: Adapter lora_finqa_35 epoch: 1/1 iteration: 80/128 step: 21
[2025-12-23 17:45:31,174] m-LoRA: Adapter lora_finqa_45 loss: 2.3895320892333984
[2025-12-23 17:45:31,652] m-LoRA: Adapter lora_finqa_18 loss: 0.008506839163601398
[2025-12-23 17:45:31,657] m-LoRA: Adapter lora_finqa_42 epoch: 1/1 iteration: 24/128 step: 13
[2025-12-23 17:45:31,903] m-LoRA: Adapter lora_finqa_46 loss: 0.19101785123348236
[2025-12-23 17:45:31,907] m-LoRA: Adapter lora_finqa_7 epoch: 1/1 iteration: 56/128 step: 29
[2025-12-23 17:45:32,197] m-LoRA: Adapter lora_finqa_37 loss: 0.16099542379379272
[2025-12-23 17:45:32,200] m-LoRA: Adapter lora_finqa_8 epoch: 1/1 iteration: 56/128 step: 29
[2025-12-23 17:45:32,488] m-LoRA: Adapter lora_finqa_47 loss: 0.03855591267347336
[2025-12-23 17:45:32,492] m-LoRA: Adapter lora_finqa_10 epoch: 1/1 iteration: 112/128 step: 29
[2025-12-23 17:45:33,304] m-LoRA: Adapter lora_finqa_21 loss: 1.5968841314315796
[2025-12-23 17:45:33,439] m-LoRA: Adapter lora_finqa_52 epoch: 1/1 iteration: 32/128 step: 5
[2025-12-23 17:45:33,744] m-LoRA: Adapter lora_finqa_23 loss: 0.0006779965478926897
[2025-12-23 17:45:33,747] m-LoRA: Adapter lora_finqa_11 epoch: 1/1 iteration: 112/128 step: 29
[2025-12-23 17:45:34,055] m-LoRA: Adapter lora_finqa_48 loss: 0.20887376368045807
[2025-12-23 17:45:34,058] m-LoRA: Adapter lora_finqa_13 epoch: 1/1 iteration: 112/128 step: 29
[2025-12-23 17:45:34,391] m-LoRA: Adapter lora_finqa_25 loss: 0.010084915906190872
[2025-12-23 17:45:34,394] m-LoRA: Adapter lora_finqa_36 epoch: 1/1 iteration: 40/128 step: 21
[2025-12-23 17:45:34,960] m-LoRA: Adapter lora_finqa_26 loss: 1.591713309288025
[2025-12-23 17:45:35,115] m-LoRA: Adapter lora_finqa_53 epoch: 1/1 iteration: 64/128 step: 5
[2025-12-23 17:45:35,701] m-LoRA: Adapter lora_finqa_27 loss: 0.0008114780066534877
[2025-12-23 17:45:35,706] m-LoRA: Adapter lora_finqa_15 epoch: 1/1 iteration: 56/128 step: 29
[2025-12-23 17:45:36,322] m-LoRA: Adapter lora_finqa_16 epoch: 1/1 iteration: 56/128 step: 29
[2025-12-23 17:45:36,355] m-LoRA: Adapter lora_finqa_39 loss: 0.009544962085783482
[2025-12-23 17:45:40,392] m-LoRA: Adapter lora_finqa_45 epoch: 1/1 iteration: 48/128 step: 13
[2025-12-23 17:45:40,729] m-LoRA: Adapter lora_finqa_54 loss: 1.9937965869903564
[2025-12-23 17:45:40,746] m-LoRA: Adapter lora_finqa_18 epoch: 1/1 iteration: 112/128 step: 29
[2025-12-23 17:45:40,807] m-LoRA: Adapter lora_finqa_55 loss: 2.568802833557129
[2025-12-23 17:45:41,196] m-LoRA: Adapter lora_finqa_40 loss: 0.16501857340335846
[2025-12-23 17:45:41,199] m-LoRA: Adapter lora_finqa_46 epoch: 1/1 iteration: 24/128 step: 13
[2025-12-23 17:45:41,800] m-LoRA: Adapter lora_finqa_37 epoch: 1/1 iteration: 40/128 step: 21
[2025-12-23 17:45:41,833] m-LoRA: Adapter lora_finqa_32 loss: 1.5947301387786865
[2025-12-23 17:45:42,105] m-LoRA: Adapter lora_finqa_0 loss: 0.03011443093419075
[2025-12-23 17:45:42,108] m-LoRA: Adapter lora_finqa_47 epoch: 1/1 iteration: 24/128 step: 13
[2025-12-23 17:45:42,667] m-LoRA: Adapter lora_finqa_3 loss: 0.0306368637830019
[2025-12-23 17:45:42,670] m-LoRA: Adapter lora_finqa_21 epoch: 1/1 iteration: 112/128 step: 29
[2025-12-23 17:45:44,012] m-LoRA: Adapter lora_finqa_23 epoch: 1/1 iteration: 56/128 step: 29
[2025-12-23 17:45:44,045] m-LoRA: Adapter lora_finqa_41 loss: 0.8290694355964661
[2025-12-23 17:45:44,374] m-LoRA: Adapter lora_finqa_1 loss: 0.02914601005613804
[2025-12-23 17:45:44,378] m-LoRA: Adapter lora_finqa_48 epoch: 1/1 iteration: 24/128 step: 13
[2025-12-23 17:45:44,716] m-LoRA: Adapter lora_finqa_51 loss: 1.7267251014709473
[2025-12-23 17:45:44,720] m-LoRA: Adapter lora_finqa_25 epoch: 1/1 iteration: 56/128 step: 29
[2025-12-23 17:45:45,358] m-LoRA: Adapter lora_finqa_26 epoch: 1/1 iteration: 112/128 step: 29
[2025-12-23 17:45:45,434] m-LoRA: Adapter lora_finqa_35 loss: 0.014617180451750755
[2025-12-23 17:45:45,726] m-LoRA: Adapter lora_finqa_42 loss: 0.1367783546447754
[2025-12-23 17:45:45,730] m-LoRA: Adapter lora_finqa_27 epoch: 1/1 iteration: 112/128 step: 29
[2025-12-23 17:45:46,043] m-LoRA: Adapter lora_finqa_7 loss: 0.008447526022791862
[2025-12-23 17:45:46,047] m-LoRA: Adapter lora_finqa_39 epoch: 1/1 iteration: 80/128 step: 21
[2025-12-23 17:45:46,421] m-LoRA: Adapter lora_finqa_8 loss: 0.007735442370176315
[2025-12-23 17:45:46,598] m-LoRA: Adapter lora_finqa_54 epoch: 1/1 iteration: 64/128 step: 5
[2025-12-23 17:45:47,102] m-LoRA: Adapter lora_finqa_55 epoch: 1/1 iteration: 8/128 step: 5
[2025-12-23 17:45:47,153] m-LoRA: Adapter lora_finqa_10 loss: 0.029278066009283066
[2025-12-23 17:45:49,686] m-LoRA: Adapter lora_finqa_40 epoch: 1/1 iteration: 40/128 step: 21
[2025-12-23 17:45:49,774] m-LoRA: Adapter lora_finqa_52 loss: 1.6985677480697632
[2025-12-23 17:45:50,928] m-LoRA: Adapter lora_finqa_32 epoch: 1/1 iteration: 112/128 step: 29
[2025-12-23 17:45:51,002] m-LoRA: Adapter lora_finqa_11 loss: 0.029534177854657173
[2025-12-23 17:45:52,242] m-LoRA: Adapter lora_finqa_13 loss: 0.007162677124142647
[2025-12-23 17:45:52,247] m-LoRA: Adapter lora_finqa_0 epoch: 1/1 iteration: 58/128 step: 30
[2025-12-23 17:45:52,825] m-LoRA: Adapter lora_finqa_36 loss: 0.11547241359949112
[2025-12-23 17:45:52,828] m-LoRA: Adapter lora_finqa_3 epoch: 1/1 iteration: 58/128 step: 30
[2025-12-23 17:45:54,788] m-LoRA: Adapter lora_finqa_41 epoch: 1/1 iteration: 52/128 step: 14
[2025-12-23 17:45:54,999] m-LoRA: Adapter lora_finqa_53 loss: 2.198920488357544
[2025-12-23 17:45:55,533] m-LoRA: Adapter lora_finqa_15 loss: 0.0006477842107415199
[2025-12-23 17:45:55,536] m-LoRA: Adapter lora_finqa_1 epoch: 1/1 iteration: 58/128 step: 30
[2025-12-23 17:45:56,073] m-LoRA: Adapter lora_finqa_16 loss: 0.00048154417891055346
[2025-12-23 17:45:56,076] m-LoRA: Adapter lora_finqa_51 epoch: 1/1 iteration: 10/128 step: 6
[2025-12-23 17:45:56,580] m-LoRA: Adapter lora_finqa_35 epoch: 1/1 iteration: 84/128 step: 22
[2025-12-23 17:45:56,653] m-LoRA: Adapter lora_finqa_45 loss: 2.356720447540283
[2025-12-23 17:45:57,181] m-LoRA: Adapter lora_finqa_18 loss: 0.007925234735012054
[2025-12-23 17:45:57,187] m-LoRA: Adapter lora_finqa_42 epoch: 1/1 iteration: 26/128 step: 14
[2025-12-23 17:45:57,468] m-LoRA: Adapter lora_finqa_46 loss: 0.12598557770252228
[2025-12-23 17:45:57,471] m-LoRA: Adapter lora_finqa_7 epoch: 1/1 iteration: 58/128 step: 30
[2025-12-23 17:45:58,354] m-LoRA: Adapter lora_finqa_37 loss: 0.11566036939620972
[2025-12-23 17:45:58,357] m-LoRA: Adapter lora_finqa_8 epoch: 1/1 iteration: 58/128 step: 30
[2025-12-23 17:45:59,064] m-LoRA: Adapter lora_finqa_47 loss: 0.028420524671673775
[2025-12-23 17:45:59,067] m-LoRA: Adapter lora_finqa_10 epoch: 1/1 iteration: 116/128 step: 30
[2025-12-23 17:45:59,681] m-LoRA: Adapter lora_finqa_21 loss: 1.5356301069259644
[2025-12-23 17:45:59,804] m-LoRA: Adapter lora_finqa_52 epoch: 1/1 iteration: 40/128 step: 6
[2025-12-23 17:46:00,478] m-LoRA: Adapter lora_finqa_23 loss: 0.00039601928438059986
[2025-12-23 17:46:00,482] m-LoRA: Adapter lora_finqa_11 epoch: 1/1 iteration: 116/128 step: 30
[2025-12-23 17:46:00,831] m-LoRA: Adapter lora_finqa_48 loss: 0.1403433382511139
[2025-12-23 17:46:00,835] m-LoRA: Adapter lora_finqa_13 epoch: 1/1 iteration: 116/128 step: 30
[2025-12-23 17:46:01,530] m-LoRA: Adapter lora_finqa_25 loss: 0.008176032453775406
[2025-12-23 17:46:01,533] m-LoRA: Adapter lora_finqa_36 epoch: 1/1 iteration: 42/128 step: 22
[2025-12-23 17:46:03,106] m-LoRA: Adapter lora_finqa_26 loss: 1.529402494430542
[2025-12-23 17:46:03,112] m-LoRA: Adapter lora_finqa_53 epoch: 1/1 iteration: 80/128 step: 6
[2025-12-23 17:46:03,532] m-LoRA: Adapter lora_finqa_27 loss: 0.0010429617250338197
[2025-12-23 17:46:03,538] m-LoRA: Adapter lora_finqa_15 epoch: 1/1 iteration: 58/128 step: 30
[2025-12-23 17:46:04,830] m-LoRA: Adapter lora_finqa_39 loss: 0.007508986629545689
[2025-12-23 17:46:04,836] m-LoRA: Adapter lora_finqa_16 epoch: 1/1 iteration: 58/128 step: 30
[2025-12-23 17:46:06,894] m-LoRA: Adapter lora_finqa_45 epoch: 1/1 iteration: 52/128 step: 14
[2025-12-23 17:46:07,095] m-LoRA: Adapter lora_finqa_54 loss: 1.710898995399475
[2025-12-23 17:46:07,597] m-LoRA: Adapter lora_finqa_18 epoch: 1/1 iteration: 116/128 step: 30
[2025-12-23 17:46:07,670] m-LoRA: Adapter lora_finqa_55 loss: 2.5568313598632812
[2025-12-23 17:46:08,187] m-LoRA: Adapter lora_finqa_40 loss: 0.11517079919576645
[2025-12-23 17:46:08,191] m-LoRA: Adapter lora_finqa_46 epoch: 1/1 iteration: 26/128 step: 14
[2025-12-23 17:46:08,732] m-LoRA: Adapter lora_finqa_37 epoch: 1/1 iteration: 42/128 step: 22
[2025-12-23 17:46:08,763] m-LoRA: Adapter lora_finqa_32 loss: 1.5334720611572266
[2025-12-23 17:46:09,042] m-LoRA: Adapter lora_finqa_0 loss: 0.027462776750326157
[2025-12-23 17:46:09,045] m-LoRA: Adapter lora_finqa_47 epoch: 1/1 iteration: 26/128 step: 14
[2025-12-23 17:46:09,329] m-LoRA: Adapter lora_finqa_3 loss: 0.028710493817925453
[2025-12-23 17:46:09,332] m-LoRA: Adapter lora_finqa_21 epoch: 1/1 iteration: 116/128 step: 30
[2025-12-23 17:46:10,016] m-LoRA: Adapter lora_finqa_23 epoch: 1/1 iteration: 58/128 step: 30
[2025-12-23 17:46:10,071] m-LoRA: Adapter lora_finqa_41 loss: 0.6634346842765808
[2025-12-23 17:46:10,486] m-LoRA: Adapter lora_finqa_1 loss: 0.02727126143872738
[2025-12-23 17:46:10,489] m-LoRA: Adapter lora_finqa_48 epoch: 1/1 iteration: 26/128 step: 14
[2025-12-23 17:46:10,848] m-LoRA: Adapter lora_finqa_51 loss: 1.4126408100128174
[2025-12-23 17:46:10,852] m-LoRA: Adapter lora_finqa_25 epoch: 1/1 iteration: 58/128 step: 30
[2025-12-23 17:46:11,543] m-LoRA: Adapter lora_finqa_35 loss: 0.013567357324063778
[2025-12-23 17:46:11,548] m-LoRA: Adapter lora_finqa_26 epoch: 1/1 iteration: 116/128 step: 30
[2025-12-23 17:46:11,850] m-LoRA: Adapter lora_finqa_42 loss: 0.08100638538599014
[2025-12-23 17:46:11,853] m-LoRA: Adapter lora_finqa_27 epoch: 1/1 iteration: 116/128 step: 30
[2025-12-23 17:46:12,168] m-LoRA: Adapter lora_finqa_7 loss: 0.008192447014153004
[2025-12-23 17:46:12,172] m-LoRA: Adapter lora_finqa_39 epoch: 1/1 iteration: 84/128 step: 22
[2025-12-23 17:46:12,497] m-LoRA: Adapter lora_finqa_8 loss: 0.006820023525506258
[2025-12-23 17:46:12,676] m-LoRA: Adapter lora_finqa_54 epoch: 1/1 iteration: 80/128 step: 6
[2025-12-23 17:46:13,205] m-LoRA: Adapter lora_finqa_10 loss: 0.02655002847313881
[2025-12-23 17:46:13,211] m-LoRA: Adapter lora_finqa_55 epoch: 1/1 iteration: 10/128 step: 6
[2025-12-23 17:46:14,396] m-LoRA: Adapter lora_finqa_40 epoch: 1/1 iteration: 42/128 step: 22
[2025-12-23 17:46:14,508] m-LoRA: Adapter lora_finqa_52 loss: 1.3876341581344604
[2025-12-23 17:46:15,073] m-LoRA: Adapter lora_finqa_32 epoch: 1/1 iteration: 116/128 step: 30
[2025-12-23 17:46:15,149] m-LoRA: Adapter lora_finqa_11 loss: 0.026490703225135803
[2025-12-23 17:46:15,695] m-LoRA: Adapter lora_finqa_0 epoch: 1/1 iteration: 60/128 step: 31
[2025-12-23 17:46:15,752] m-LoRA: Adapter lora_finqa_13 loss: 0.006301927380263805
[2025-12-23 17:46:16,028] m-LoRA: Adapter lora_finqa_36 loss: 0.08650711923837662
[2025-12-23 17:46:16,031] m-LoRA: Adapter lora_finqa_3 epoch: 1/1 iteration: 60/128 step: 31
[2025-12-23 17:46:18,517] m-LoRA: Adapter lora_finqa_53 loss: 2.0499939918518066
[2025-12-23 17:46:18,535] m-LoRA: Adapter lora_finqa_41 epoch: 1/1 iteration: 56/128 step: 15
[2025-12-23 17:46:18,653] m-LoRA: Adapter lora_finqa_15 loss: 0.0005088271573185921
[2025-12-23 17:46:18,656] m-LoRA: Adapter lora_finqa_1 epoch: 1/1 iteration: 60/128 step: 31
[2025-12-23 17:46:18,968] m-LoRA: Adapter lora_finqa_16 loss: 0.00037571616121567786
[2025-12-23 17:46:19,095] m-LoRA: Adapter lora_finqa_51 epoch: 1/1 iteration: 12/128 step: 7
[2025-12-23 17:46:19,532] m-LoRA: Adapter lora_finqa_35 epoch: 1/1 iteration: 88/128 step: 23
[2025-12-23 17:46:19,606] m-LoRA: Adapter lora_finqa_45 loss: 2.320216655731201
[2025-12-23 17:46:20,099] m-LoRA: Adapter lora_finqa_42 epoch: 1/1 iteration: 28/128 step: 15
[2025-12-23 17:46:20,145] m-LoRA: Adapter lora_finqa_18 loss: 0.007388439495116472
[2025-12-23 17:46:20,430] m-LoRA: Adapter lora_finqa_46 loss: 0.07398822903633118
[2025-12-23 17:46:20,433] m-LoRA: Adapter lora_finqa_7 epoch: 1/1 iteration: 60/128 step: 31
[2025-12-23 17:46:20,718] m-LoRA: Adapter lora_finqa_37 loss: 0.08546236157417297
[2025-12-23 17:46:20,721] m-LoRA: Adapter lora_finqa_8 epoch: 1/1 iteration: 60/128 step: 31
[2025-12-23 17:46:20,997] m-LoRA: Adapter lora_finqa_47 loss: 0.02112736366689205
[2025-12-23 17:46:21,000] m-LoRA: Adapter lora_finqa_10 epoch: 1/1 iteration: 120/128 step: 31
[2025-12-23 17:46:21,853] m-LoRA: Adapter lora_finqa_21 loss: 1.47361159324646
[2025-12-23 17:46:21,989] m-LoRA: Adapter lora_finqa_52 epoch: 1/1 iteration: 48/128 step: 7
[2025-12-23 17:46:22,261] m-LoRA: Adapter lora_finqa_23 loss: 0.00042468419997021556
[2025-12-23 17:46:22,265] m-LoRA: Adapter lora_finqa_11 epoch: 1/1 iteration: 120/128 step: 31
[2025-12-23 17:46:22,537] m-LoRA: Adapter lora_finqa_48 loss: 0.08752176910638809
[2025-12-23 17:46:22,653] m-LoRA: Adapter lora_finqa_13 epoch: 1/1 iteration: 120/128 step: 31
[2025-12-23 17:46:22,952] m-LoRA: Adapter lora_finqa_25 loss: 0.00794893503189087
[2025-12-23 17:46:22,955] m-LoRA: Adapter lora_finqa_36 epoch: 1/1 iteration: 44/128 step: 23
[2025-12-23 17:46:23,584] m-LoRA: Adapter lora_finqa_26 loss: 1.4641227722167969
[2025-12-23 17:46:23,730] m-LoRA: Adapter lora_finqa_53 epoch: 1/1 iteration: 96/128 step: 7
[2025-12-23 17:46:24,260] m-LoRA: Adapter lora_finqa_15 epoch: 1/1 iteration: 60/128 step: 31
[2025-12-23 17:46:24,313] m-LoRA: Adapter lora_finqa_27 loss: 0.00047766900388523936
[2025-12-23 17:46:24,901] m-LoRA: Adapter lora_finqa_39 loss: 0.006473264656960964
[2025-12-23 17:46:24,907] m-LoRA: Adapter lora_finqa_16 epoch: 1/1 iteration: 60/128 step: 31
[2025-12-23 17:46:27,138] m-LoRA: Adapter lora_finqa_45 epoch: 1/1 iteration: 56/128 step: 15
[2025-12-23 17:46:27,583] m-LoRA: Adapter lora_finqa_54 loss: 1.397774338722229
[2025-12-23 17:46:27,601] m-LoRA: Adapter lora_finqa_18 epoch: 1/1 iteration: 120/128 step: 31
[2025-12-23 17:46:27,678] m-LoRA: Adapter lora_finqa_55 loss: 2.540584087371826
[2025-12-23 17:46:28,052] m-LoRA: Adapter lora_finqa_40 loss: 0.08529578894376755
[2025-12-23 17:46:28,055] m-LoRA: Adapter lora_finqa_46 epoch: 1/1 iteration: 28/128 step: 15
[2025-12-23 17:46:28,573] m-LoRA: Adapter lora_finqa_37 epoch: 1/1 iteration: 44/128 step: 23
[2025-12-23 17:46:28,631] m-LoRA: Adapter lora_finqa_32 loss: 1.4698617458343506
[2025-12-23 17:46:28,901] m-LoRA: Adapter lora_finqa_0 loss: 0.024636317044496536
[2025-12-23 17:46:28,904] m-LoRA: Adapter lora_finqa_47 epoch: 1/1 iteration: 28/128 step: 15
[2025-12-23 17:46:29,171] m-LoRA: Adapter lora_finqa_3 loss: 0.025760270655155182
[2025-12-23 17:46:29,175] m-LoRA: Adapter lora_finqa_21 epoch: 1/1 iteration: 120/128 step: 31
[2025-12-23 17:46:29,702] m-LoRA: Adapter lora_finqa_23 epoch: 1/1 iteration: 60/128 step: 31
[2025-12-23 17:46:29,757] m-LoRA: Adapter lora_finqa_41 loss: 0.5272790789604187
[2025-12-23 17:46:29,982] m-LoRA: Adapter lora_finqa_1 loss: 0.023807693272829056
[2025-12-23 17:46:29,985] m-LoRA: Adapter lora_finqa_48 epoch: 1/1 iteration: 28/128 step: 15
[2025-12-23 17:46:30,571] m-LoRA: Adapter lora_finqa_51 loss: 1.1478252410888672
[2025-12-23 17:46:30,575] m-LoRA: Adapter lora_finqa_25 epoch: 1/1 iteration: 60/128 step: 31
[2025-12-23 17:46:31,328] m-LoRA: Adapter lora_finqa_26 epoch: 1/1 iteration: 120/128 step: 31
[2025-12-23 17:46:31,404] m-LoRA: Adapter lora_finqa_35 loss: 0.012566833756864071
[2025-12-23 17:46:31,681] m-LoRA: Adapter lora_finqa_42 loss: 0.05327586084604263
[2025-12-23 17:46:31,685] m-LoRA: Adapter lora_finqa_27 epoch: 1/1 iteration: 120/128 step: 31
[2025-12-23 17:46:32,083] m-LoRA: Adapter lora_finqa_7 loss: 0.006782097741961479
[2025-12-23 17:46:32,086] m-LoRA: Adapter lora_finqa_39 epoch: 1/1 iteration: 88/128 step: 23
[2025-12-23 17:46:32,411] m-LoRA: Adapter lora_finqa_8 loss: 0.005871248431503773
[2025-12-23 17:46:32,585] m-LoRA: Adapter lora_finqa_54 epoch: 1/1 iteration: 96/128 step: 7
[2025-12-23 17:46:33,052] m-LoRA: Adapter lora_finqa_55 epoch: 1/1 iteration: 12/128 step: 7
[2025-12-23 17:46:33,107] m-LoRA: Adapter lora_finqa_10 loss: 0.023756926879286766
[2025-12-23 17:46:36,039] m-LoRA: Adapter lora_finqa_40 epoch: 1/1 iteration: 44/128 step: 23
[2025-12-23 17:46:36,111] m-LoRA: Adapter lora_finqa_52 loss: 1.0858144760131836
[2025-12-23 17:46:36,526] m-LoRA: Adapter lora_finqa_32 epoch: 1/1 iteration: 120/128 step: 31
[2025-12-23 17:46:36,601] m-LoRA: Adapter lora_finqa_11 loss: 0.023985326290130615
[2025-12-23 17:46:37,131] m-LoRA: Adapter lora_finqa_13 loss: 0.0052422829903662205
[2025-12-23 17:46:37,136] m-LoRA: Adapter lora_finqa_0 epoch: 1/1 iteration: 62/128 step: 32
[2025-12-23 17:46:37,382] m-LoRA: Adapter lora_finqa_36 loss: 0.0688183382153511
[2025-12-23 17:46:37,385] m-LoRA: Adapter lora_finqa_3 epoch: 1/1 iteration: 62/128 step: 32
[2025-12-23 17:46:41,663] m-LoRA: Adapter lora_finqa_41 epoch: 1/1 iteration: 60/128 step: 16
[2025-12-23 17:46:42,018] m-LoRA: Adapter lora_finqa_53 loss: 1.895823359489441
[2025-12-23 17:46:42,035] m-LoRA: Adapter lora_finqa_1 epoch: 1/1 iteration: 62/128 step: 32
[2025-12-23 17:46:42,068] m-LoRA: Adapter lora_finqa_15 loss: 0.00030853154021315277
[2025-12-23 17:46:42,478] m-LoRA: Adapter lora_finqa_16 loss: 0.00030348970904015005
[2025-12-23 17:46:42,481] m-LoRA: Adapter lora_finqa_51 epoch: 1/1 iteration: 14/128 step: 8
[2025-12-23 17:46:43,416] m-LoRA: Adapter lora_finqa_35 epoch: 1/1 iteration: 92/128 step: 24
[2025-12-23 17:46:43,491] m-LoRA: Adapter lora_finqa_45 loss: 2.280160427093506
[2025-12-23 17:46:44,573] m-LoRA: Adapter lora_finqa_42 epoch: 1/1 iteration: 30/128 step: 16
[2025-12-23 17:46:44,628] m-LoRA: Adapter lora_finqa_18 loss: 0.005973148625344038
[2025-12-23 17:46:45,234] m-LoRA: Adapter lora_finqa_7 epoch: 1/1 iteration: 62/128 step: 32
[2025-12-23 17:46:45,278] m-LoRA: Adapter lora_finqa_46 loss: 0.04752065986394882
[2025-12-23 17:46:45,573] m-LoRA: Adapter lora_finqa_8 epoch: 1/1 iteration: 62/128 step: 32
[2025-12-23 17:46:45,610] m-LoRA: Adapter lora_finqa_37 loss: 0.0656840056180954
[2025-12-23 17:46:45,963] m-LoRA: Adapter lora_finqa_47 loss: 0.0159880630671978
[2025-12-23 17:46:45,966] m-LoRA: Adapter lora_finqa_10 epoch: 1/1 iteration: 124/128 step: 32
[2025-12-23 17:46:46,579] m-LoRA: Adapter lora_finqa_21 loss: 1.4003546237945557
[2025-12-23 17:46:46,718] m-LoRA: Adapter lora_finqa_52 epoch: 1/1 iteration: 56/128 step: 8
[2025-12-23 17:46:46,953] m-LoRA: Adapter lora_finqa_23 loss: 0.0002695273142307997
[2025-12-23 17:46:46,956] m-LoRA: Adapter lora_finqa_11 epoch: 1/1 iteration: 124/128 step: 32
[2025-12-23 17:46:47,369] m-LoRA: Adapter lora_finqa_48 loss: 0.0581967793405056
[2025-12-23 17:46:47,372] m-LoRA: Adapter lora_finqa_13 epoch: 1/1 iteration: 124/128 step: 32
[2025-12-23 17:46:47,716] m-LoRA: Adapter lora_finqa_25 loss: 0.006604103371500969
[2025-12-23 17:46:47,719] m-LoRA: Adapter lora_finqa_36 epoch: 1/1 iteration: 46/128 step: 24
[2025-12-23 17:46:48,995] m-LoRA: Adapter lora_finqa_26 loss: 1.3925237655639648
[2025-12-23 17:46:49,158] m-LoRA: Adapter lora_finqa_53 epoch: 1/1 iteration: 112/128 step: 8
[2025-12-23 17:46:50,248] m-LoRA: Adapter lora_finqa_15 epoch: 1/1 iteration: 62/128 step: 32
[2025-12-23 17:46:50,302] m-LoRA: Adapter lora_finqa_27 loss: 0.000313063821522519
[2025-12-23 17:46:51,600] m-LoRA: Adapter lora_finqa_16 epoch: 1/1 iteration: 62/128 step: 32
[2025-12-23 17:46:51,649] m-LoRA: Adapter lora_finqa_39 loss: 0.005298747215420008
[2025-12-23 17:46:53,605] m-LoRA: Adapter lora_finqa_45 epoch: 1/1 iteration: 60/128 step: 16
[2025-12-23 17:46:53,801] m-LoRA: Adapter lora_finqa_54 loss: 1.1025397777557373
[2025-12-23 17:46:54,344] m-LoRA: Adapter lora_finqa_55 loss: 2.523479461669922
[2025-12-23 17:46:54,348] m-LoRA: Adapter lora_finqa_18 epoch: 1/1 iteration: 124/128 step: 32
[2025-12-23 17:46:54,891] m-LoRA: Adapter lora_finqa_40 loss: 0.06733927875757217
[2025-12-23 17:46:54,894] m-LoRA: Adapter lora_finqa_46 epoch: 1/1 iteration: 30/128 step: 16
[2025-12-23 17:46:55,982] m-LoRA: Adapter lora_finqa_37 epoch: 1/1 iteration: 46/128 step: 24
[2025-12-23 17:46:56,038] m-LoRA: Adapter lora_finqa_32 loss: 1.396574854850769
[2025-12-23 17:46:56,784] m-LoRA: Adapter lora_finqa_0 loss: 0.02220664545893669
[2025-12-23 17:46:56,787] m-LoRA: Adapter lora_finqa_47 epoch: 1/1 iteration: 30/128 step: 16
[2025-12-23 17:46:57,642] m-LoRA: Adapter lora_finqa_3 loss: 0.023139065131545067
[2025-12-23 17:46:57,646] m-LoRA: Adapter lora_finqa_21 epoch: 1/1 iteration: 124/128 step: 32
[2025-12-23 17:46:58,895] m-LoRA: Adapter lora_finqa_23 epoch: 1/1 iteration: 62/128 step: 32
[2025-12-23 17:46:58,951] m-LoRA: Adapter lora_finqa_41 loss: 0.41548341512680054
[2025-12-23 17:46:59,465] m-LoRA: Adapter lora_finqa_1 loss: 0.021234910935163498
[2025-12-23 17:46:59,468] m-LoRA: Adapter lora_finqa_48 epoch: 1/1 iteration: 30/128 step: 16
[2025-12-23 17:46:59,785] m-LoRA: Adapter lora_finqa_51 loss: 0.8403279185295105
[2025-12-23 17:46:59,789] m-LoRA: Adapter lora_finqa_25 epoch: 1/1 iteration: 62/128 step: 32
[2025-12-23 17:47:00,481] m-LoRA: Adapter lora_finqa_35 loss: 0.011898775584995747
[2025-12-23 17:47:00,487] m-LoRA: Adapter lora_finqa_26 epoch: 1/1 iteration: 124/128 step: 32
[2025-12-23 17:47:01,102] m-LoRA: Adapter lora_finqa_42 loss: 0.03779714182019234
[2025-12-23 17:47:01,106] m-LoRA: Adapter lora_finqa_27 epoch: 1/1 iteration: 124/128 step: 32
[2025-12-23 17:47:01,788] m-LoRA: Adapter lora_finqa_7 loss: 0.005909973755478859
[2025-12-23 17:47:01,791] m-LoRA: Adapter lora_finqa_39 epoch: 1/1 iteration: 92/128 step: 24
[2025-12-23 17:47:02,460] m-LoRA: Adapter lora_finqa_8 loss: 0.005841229110956192
[2025-12-23 17:47:02,639] m-LoRA: Adapter lora_finqa_54 epoch: 1/1 iteration: 112/128 step: 8
[2025-12-23 17:47:03,550] m-LoRA: Adapter lora_finqa_55 epoch: 1/1 iteration: 14/128 step: 8
[2025-12-23 17:47:03,607] m-LoRA: Adapter lora_finqa_10 loss: 0.02164377272129059
[2025-12-23 17:47:04,738] m-LoRA: Adapter lora_finqa_40 epoch: 1/1 iteration: 46/128 step: 24
[2025-12-23 17:47:04,803] m-LoRA: Adapter lora_finqa_52 loss: 0.795539379119873
[2025-12-23 17:47:05,287] m-LoRA: Adapter lora_finqa_32 epoch: 1/1 iteration: 124/128 step: 32
[2025-12-23 17:47:05,342] m-LoRA: Adapter lora_finqa_11 loss: 0.021124539896845818
[2025-12-23 17:47:05,844] m-LoRA: Adapter lora_finqa_0 epoch: 1/1 iteration: 64/128 step: 33
[2025-12-23 17:47:05,898] m-LoRA: Adapter lora_finqa_13 loss: 0.004419710952788591
[2025-12-23 17:47:06,540] m-LoRA: Adapter lora_finqa_3 epoch: 1/1 iteration: 64/128 step: 33
[2025-12-23 17:47:06,595] m-LoRA: Adapter lora_finqa_36 loss: 0.05595330148935318
[2025-12-23 17:47:08,687] m-LoRA: Adapter lora_finqa_41 epoch: 1/1 iteration: 64/128 step: 17
[2025-12-23 17:47:08,895] m-LoRA: Adapter lora_finqa_53 loss: 1.7316937446594238
[2025-12-23 17:47:09,384] m-LoRA: Adapter lora_finqa_15 loss: 0.00037729606265202165
[2025-12-23 17:47:09,387] m-LoRA: Adapter lora_finqa_1 epoch: 1/1 iteration: 64/128 step: 33
[2025-12-23 17:47:09,906] m-LoRA: Adapter lora_finqa_16 loss: 0.00024991531972773373
[2025-12-23 17:47:09,991] m-LoRA: Adapter lora_finqa_51 epoch: 1/1 iteration: 16/128 step: 9
[2025-12-23 17:47:10,489] m-LoRA: Adapter lora_finqa_35 epoch: 1/1 iteration: 96/128 step: 25
[2025-12-23 17:47:10,562] m-LoRA: Adapter lora_finqa_45 loss: 2.237898111343384
[2025-12-23 17:47:11,068] m-LoRA: Adapter lora_finqa_18 loss: 0.004727387800812721
[2025-12-23 17:47:11,074] m-LoRA: Adapter lora_finqa_42 epoch: 1/1 iteration: 32/128 step: 17
[2025-12-23 17:47:11,328] m-LoRA: Adapter lora_finqa_46 loss: 0.036920953541994095
[2025-12-23 17:47:11,331] m-LoRA: Adapter lora_finqa_7 epoch: 1/1 iteration: 64/128 step: 33
[2025-12-23 17:47:11,849] m-LoRA: Adapter lora_finqa_37 loss: 0.05390245467424393
[2025-12-23 17:47:11,852] m-LoRA: Adapter lora_finqa_8 epoch: 1/1 iteration: 64/128 step: 33
[2025-12-23 17:47:12,251] m-LoRA: Finish and base model offload adapter - ['lora_finqa_10']
[2025-12-23 17:47:12,443] m-LoRA: Adapter lora_finqa_47 loss: 0.012802153825759888
[2025-12-23 17:47:12,446] m-LoRA: Task to running, need to load adapters: ['lora_finqa_56']
[2025-12-23 17:47:12,639] m-LoRA: Adapter lora_finqa_56 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:47:12,945] m-LoRA: Adapter lora_finqa_21 loss: 1.3213316202163696
[2025-12-23 17:47:13,142] m-LoRA: Adapter lora_finqa_52 epoch: 1/1 iteration: 64/128 step: 9
[2025-12-23 17:47:13,385] m-LoRA: Finish and base model offload adapter - ['lora_finqa_11']
[2025-12-23 17:47:13,532] m-LoRA: Adapter lora_finqa_23 loss: 0.0002303618093719706
[2025-12-23 17:47:13,535] m-LoRA: Task to running, need to load adapters: ['lora_finqa_57']
[2025-12-23 17:47:13,647] m-LoRA: Adapter lora_finqa_57 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:47:13,807] m-LoRA: Finish and base model offload adapter - ['lora_finqa_13']
[2025-12-23 17:47:14,126] m-LoRA: Adapter lora_finqa_48 loss: 0.04345521703362465
[2025-12-23 17:47:14,130] m-LoRA: Task to running, need to load adapters: ['lora_finqa_58']
[2025-12-23 17:47:14,403] m-LoRA: Adapter lora_finqa_58 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:47:14,585] m-LoRA: Adapter lora_finqa_25 loss: 0.005448797717690468
[2025-12-23 17:47:14,588] m-LoRA: Adapter lora_finqa_36 epoch: 1/1 iteration: 48/128 step: 25
[2025-12-23 17:47:14,940] m-LoRA: Adapter lora_finqa_26 loss: 1.310987949371338
[2025-12-23 17:47:15,088] m-LoRA: Finish and base model offload adapter - ['lora_finqa_53']
[2025-12-23 17:47:15,314] m-LoRA: Task to running, need to load adapters: ['lora_finqa_59']
[2025-12-23 17:47:15,530] m-LoRA: Adapter lora_finqa_59 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:47:15,854] m-LoRA: Adapter lora_finqa_27 loss: 0.00026479855296202004
[2025-12-23 17:47:15,860] m-LoRA: Adapter lora_finqa_15 epoch: 1/1 iteration: 64/128 step: 33
[2025-12-23 17:47:16,297] m-LoRA: Adapter lora_finqa_16 epoch: 1/1 iteration: 64/128 step: 33
[2025-12-23 17:47:16,332] m-LoRA: Adapter lora_finqa_39 loss: 0.004074539989233017
[2025-12-23 17:47:18,838] m-LoRA: Adapter lora_finqa_54 loss: 0.8113221526145935
[2025-12-23 17:47:18,856] m-LoRA: Adapter lora_finqa_45 epoch: 1/1 iteration: 64/128 step: 17
[2025-12-23 17:47:19,001] m-LoRA: Finish and base model offload adapter - ['lora_finqa_18']
[2025-12-23 17:47:19,446] m-LoRA: Adapter lora_finqa_55 loss: 2.5005180835723877
[2025-12-23 17:47:19,450] m-LoRA: Task to running, need to load adapters: ['lora_finqa_60']
[2025-12-23 17:47:19,539] m-LoRA: Adapter lora_finqa_60 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:47:19,644] m-LoRA: Adapter lora_finqa_40 loss: 0.05400397256016731
[2025-12-23 17:47:19,647] m-LoRA: Adapter lora_finqa_46 epoch: 1/1 iteration: 32/128 step: 17
[2025-12-23 17:47:19,833] m-LoRA: Adapter lora_finqa_37 epoch: 1/1 iteration: 48/128 step: 25
[2025-12-23 17:47:19,888] m-LoRA: Adapter lora_finqa_32 loss: 1.3162202835083008
[2025-12-23 17:47:20,128] m-LoRA: Adapter lora_finqa_0 loss: 0.0198939461261034
[2025-12-23 17:47:20,131] m-LoRA: Adapter lora_finqa_47 epoch: 1/1 iteration: 32/128 step: 17
[2025-12-23 17:47:20,387] m-LoRA: Finish and base model offload adapter - ['lora_finqa_21']
[2025-12-23 17:47:20,648] m-LoRA: Adapter lora_finqa_3 loss: 0.020618245005607605
[2025-12-23 17:47:20,652] m-LoRA: Task to running, need to load adapters: ['lora_finqa_61']
[2025-12-23 17:47:20,909] m-LoRA: Adapter lora_finqa_61 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:47:21,045] m-LoRA: Adapter lora_finqa_41 loss: 0.3283236026763916
[2025-12-23 17:47:21,050] m-LoRA: Adapter lora_finqa_23 epoch: 1/1 iteration: 64/128 step: 33
[2025-12-23 17:47:21,293] m-LoRA: Adapter lora_finqa_1 loss: 0.019516438245773315
[2025-12-23 17:47:21,297] m-LoRA: Adapter lora_finqa_48 epoch: 1/1 iteration: 32/128 step: 17
[2025-12-23 17:47:21,869] m-LoRA: Adapter lora_finqa_51 loss: 0.5975849032402039
[2025-12-23 17:47:21,873] m-LoRA: Adapter lora_finqa_25 epoch: 1/1 iteration: 64/128 step: 33
[2025-12-23 17:47:22,598] m-LoRA: Finish and base model offload adapter - ['lora_finqa_26']
[2025-12-23 17:47:22,857] m-LoRA: Adapter lora_finqa_35 loss: 0.011268547736108303
[2025-12-23 17:47:22,862] m-LoRA: Task to running, need to load adapters: ['lora_finqa_62']
[2025-12-23 17:47:23,124] m-LoRA: Adapter lora_finqa_62 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:47:23,230] m-LoRA: Finish and base model offload adapter - ['lora_finqa_27']
[2025-12-23 17:47:24,028] m-LoRA: Adapter lora_finqa_42 loss: 0.03205903246998787
[2025-12-23 17:47:24,032] m-LoRA: Task to running, need to load adapters: ['lora_finqa_63']
[2025-12-23 17:47:24,293] m-LoRA: Adapter lora_finqa_63 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:47:24,437] m-LoRA: Adapter lora_finqa_7 loss: 0.0051173800602555275
[2025-12-23 17:47:24,440] m-LoRA: Adapter lora_finqa_39 epoch: 1/1 iteration: 96/128 step: 25
[2025-12-23 17:47:24,674] m-LoRA: Finish and base model offload adapter - ['lora_finqa_54']
[2025-12-23 17:47:25,255] m-LoRA: Adapter lora_finqa_8 loss: 0.005207084119319916
[2025-12-23 17:47:25,366] m-LoRA: Task to running, need to load adapters: ['lora_finqa_64']
[2025-12-23 17:47:25,575] m-LoRA: Adapter lora_finqa_64 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:47:25,714] m-LoRA: Adapter lora_finqa_56 loss: 2.588528633117676
[2025-12-23 17:47:25,723] m-LoRA: Adapter lora_finqa_55 epoch: 1/1 iteration: 16/128 step: 9
[2025-12-23 17:47:26,558] m-LoRA: Adapter lora_finqa_40 epoch: 1/1 iteration: 48/128 step: 25
[2025-12-23 17:47:26,644] m-LoRA: Adapter lora_finqa_52 loss: 0.5460751056671143
[2025-12-23 17:47:26,929] m-LoRA: Finish and base model offload adapter - ['lora_finqa_32']
[2025-12-23 17:47:27,179] m-LoRA: Adapter lora_finqa_57 loss: 2.5885283946990967
[2025-12-23 17:47:27,182] m-LoRA: Task to running, need to load adapters: ['lora_finqa_65']
[2025-12-23 17:47:27,305] m-LoRA: Adapter lora_finqa_65 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:47:28,061] m-LoRA: Adapter lora_finqa_0 epoch: 1/1 iteration: 66/128 step: 34
[2025-12-23 17:47:28,171] m-LoRA: Adapter lora_finqa_58 loss: 2.588528633117676
[2025-12-23 17:47:28,412] m-LoRA: Adapter lora_finqa_36 loss: 0.04647182300686836
[2025-12-23 17:47:28,416] m-LoRA: Adapter lora_finqa_3 epoch: 1/1 iteration: 66/128 step: 34
[2025-12-23 17:47:32,858] m-LoRA: Adapter lora_finqa_41 epoch: 1/1 iteration: 68/128 step: 18
[2025-12-23 17:47:33,239] m-LoRA: Adapter lora_finqa_59 loss: 2.5885279178619385
[2025-12-23 17:47:33,257] m-LoRA: Adapter lora_finqa_1 epoch: 1/1 iteration: 66/128 step: 34
[2025-12-23 17:47:33,291] m-LoRA: Adapter lora_finqa_15 loss: 0.00021072693925816566
[2025-12-23 17:47:33,840] m-LoRA: Adapter lora_finqa_16 loss: 0.00024264081730507314
[2025-12-23 17:47:33,843] m-LoRA: Adapter lora_finqa_51 epoch: 1/1 iteration: 18/128 step: 10
[2025-12-23 17:47:34,402] m-LoRA: Adapter lora_finqa_35 epoch: 1/1 iteration: 100/128 step: 26
[2025-12-23 17:47:34,476] m-LoRA: Adapter lora_finqa_45 loss: 2.196009874343872
[2025-12-23 17:47:34,682] m-LoRA: Adapter lora_finqa_60 loss: 2.5885283946990967
[2025-12-23 17:47:34,686] m-LoRA: Adapter lora_finqa_42 epoch: 1/1 iteration: 34/128 step: 18
[2025-12-23 17:47:34,946] m-LoRA: Adapter lora_finqa_46 loss: 0.03123016282916069
[2025-12-23 17:47:34,950] m-LoRA: Adapter lora_finqa_7 epoch: 1/1 iteration: 66/128 step: 34
[2025-12-23 17:47:35,218] m-LoRA: Adapter lora_finqa_8 epoch: 1/1 iteration: 66/128 step: 34
[2025-12-23 17:47:35,271] m-LoRA: Adapter lora_finqa_37 loss: 0.04583016782999039
[2025-12-23 17:47:35,521] m-LoRA: Adapter lora_finqa_47 loss: 0.011481798253953457
[2025-12-23 17:47:35,657] m-LoRA: Adapter lora_finqa_56 epoch: 1/1 iteration: 8/128 step: 2
[2025-12-23 17:47:36,165] m-LoRA: Adapter lora_finqa_61 loss: 2.5885283946990967
[2025-12-23 17:47:36,264] m-LoRA: Adapter lora_finqa_52 epoch: 1/1 iteration: 72/128 step: 10
[2025-12-23 17:47:36,586] m-LoRA: Adapter lora_finqa_57 epoch: 1/1 iteration: 2/128 step: 2
[2025-12-23 17:47:36,638] m-LoRA: Adapter lora_finqa_23 loss: 0.00021301298693288118
[2025-12-23 17:47:36,967] m-LoRA: Adapter lora_finqa_48 loss: 0.037693221122026443
[2025-12-23 17:47:37,083] m-LoRA: Adapter lora_finqa_58 epoch: 1/1 iteration: 8/128 step: 2
[2025-12-23 17:47:37,321] m-LoRA: Adapter lora_finqa_25 loss: 0.004748050589114428
[2025-12-23 17:47:37,324] m-LoRA: Adapter lora_finqa_36 epoch: 1/1 iteration: 50/128 step: 26
[2025-12-23 17:47:38,678] m-LoRA: Adapter lora_finqa_62 loss: 2.5885279178619385
[2025-12-23 17:47:38,886] m-LoRA: Adapter lora_finqa_59 epoch: 1/1 iteration: 16/128 step: 2
[2025-12-23 17:47:40,039] m-LoRA: Adapter lora_finqa_63 loss: 2.5885279178619385
[2025-12-23 17:47:40,044] m-LoRA: Adapter lora_finqa_15 epoch: 1/1 iteration: 66/128 step: 34
[2025-12-23 17:47:41,349] m-LoRA: Adapter lora_finqa_39 loss: 0.002933697309345007
[2025-12-23 17:47:41,355] m-LoRA: Adapter lora_finqa_16 epoch: 1/1 iteration: 66/128 step: 34
[2025-12-23 17:47:42,472] m-LoRA: Adapter lora_finqa_64 loss: 2.5885279178619385
[2025-12-23 17:47:42,477] m-LoRA: Adapter lora_finqa_45 epoch: 1/1 iteration: 68/128 step: 18
[2025-12-23 17:47:43,135] m-LoRA: Adapter lora_finqa_55 loss: 2.4782042503356934
[2025-12-23 17:47:43,138] m-LoRA: Adapter lora_finqa_60 epoch: 1/1 iteration: 2/128 step: 2
[2025-12-23 17:47:43,799] m-LoRA: Adapter lora_finqa_40 loss: 0.04582669958472252
[2025-12-23 17:47:43,803] m-LoRA: Adapter lora_finqa_46 epoch: 1/1 iteration: 34/128 step: 18
[2025-12-23 17:47:44,368] m-LoRA: Adapter lora_finqa_37 epoch: 1/1 iteration: 50/128 step: 26
[2025-12-23 17:47:44,429] m-LoRA: Adapter lora_finqa_65 loss: 2.5885279178619385
[2025-12-23 17:47:44,665] m-LoRA: Adapter lora_finqa_0 loss: 0.017709389328956604
[2025-12-23 17:47:44,668] m-LoRA: Adapter lora_finqa_47 epoch: 1/1 iteration: 34/128 step: 18
[2025-12-23 17:47:44,954] m-LoRA: Adapter lora_finqa_3 loss: 0.018565161153674126
[2025-12-23 17:47:44,958] m-LoRA: Adapter lora_finqa_61 epoch: 1/1 iteration: 2/128 step: 2
[2025-12-23 17:47:45,593] m-LoRA: Adapter lora_finqa_41 loss: 0.2582952082157135
[2025-12-23 17:47:45,599] m-LoRA: Adapter lora_finqa_23 epoch: 1/1 iteration: 66/128 step: 34
[2025-12-23 17:47:46,244] m-LoRA: Adapter lora_finqa_1 loss: 0.017674198374152184
[2025-12-23 17:47:46,248] m-LoRA: Adapter lora_finqa_48 epoch: 1/1 iteration: 34/128 step: 18
[2025-12-23 17:47:46,940] m-LoRA: Adapter lora_finqa_51 loss: 0.4328996539115906
[2025-12-23 17:47:46,943] m-LoRA: Adapter lora_finqa_25 epoch: 1/1 iteration: 66/128 step: 34
[2025-12-23 17:47:48,004] m-LoRA: Adapter lora_finqa_62 epoch: 1/1 iteration: 4/128 step: 2
[2025-12-23 17:47:48,080] m-LoRA: Adapter lora_finqa_35 loss: 0.010569710284471512
[2025-12-23 17:47:48,628] m-LoRA: Adapter lora_finqa_42 loss: 0.026167677715420723
[2025-12-23 17:47:48,631] m-LoRA: Adapter lora_finqa_63 epoch: 1/1 iteration: 4/128 step: 2
[2025-12-23 17:47:49,315] m-LoRA: Adapter lora_finqa_7 loss: 0.004671679809689522
[2025-12-23 17:47:49,319] m-LoRA: Adapter lora_finqa_39 epoch: 1/1 iteration: 100/128 step: 26
[2025-12-23 17:47:49,915] m-LoRA: Adapter lora_finqa_8 loss: 0.003896439913660288
[2025-12-23 17:47:49,918] m-LoRA: Adapter lora_finqa_64 epoch: 1/1 iteration: 4/128 step: 2
[2025-12-23 17:47:51,012] m-LoRA: Adapter lora_finqa_55 epoch: 1/1 iteration: 18/128 step: 10
[2025-12-23 17:47:51,077] m-LoRA: Adapter lora_finqa_56 loss: 2.315152406692505
[2025-12-23 17:47:52,060] m-LoRA: Adapter lora_finqa_40 epoch: 1/1 iteration: 50/128 step: 26
[2025-12-23 17:47:52,122] m-LoRA: Adapter lora_finqa_52 loss: 0.3925025463104248
[2025-12-23 17:47:52,800] m-LoRA: Adapter lora_finqa_57 loss: 2.5417633056640625
[2025-12-23 17:47:52,803] m-LoRA: Adapter lora_finqa_65 epoch: 1/1 iteration: 4/128 step: 2
[2025-12-23 17:47:53,976] m-LoRA: Adapter lora_finqa_0 epoch: 1/1 iteration: 68/128 step: 35
[2025-12-23 17:47:54,087] m-LoRA: Adapter lora_finqa_58 loss: 2.3128726482391357
[2025-12-23 17:47:54,675] m-LoRA: Adapter lora_finqa_36 loss: 0.04031704366207123
[2025-12-23 17:47:54,768] m-LoRA: Adapter lora_finqa_3 epoch: 1/1 iteration: 68/128 step: 35
[2025-12-23 17:47:56,833] m-LoRA: Adapter lora_finqa_41 epoch: 1/1 iteration: 72/128 step: 19
[2025-12-23 17:47:57,041] m-LoRA: Adapter lora_finqa_59 loss: 2.4767348766326904
[2025-12-23 17:47:57,534] m-LoRA: Adapter lora_finqa_15 loss: 0.0001991869939956814
[2025-12-23 17:47:57,537] m-LoRA: Adapter lora_finqa_1 epoch: 1/1 iteration: 68/128 step: 35
[2025-12-23 17:47:57,817] m-LoRA: Adapter lora_finqa_16 loss: 0.0001944085379363969
[2025-12-23 17:47:57,820] m-LoRA: Adapter lora_finqa_51 epoch: 1/1 iteration: 20/128 step: 11
[2025-12-23 17:47:58,355] m-LoRA: Adapter lora_finqa_35 epoch: 1/1 iteration: 104/128 step: 27
[2025-12-23 17:47:58,410] m-LoRA: Adapter lora_finqa_45 loss: 2.1496195793151855
[2025-12-23 17:47:58,633] m-LoRA: Adapter lora_finqa_60 loss: 2.5401113033294678
[2025-12-23 17:47:58,636] m-LoRA: Adapter lora_finqa_42 epoch: 1/1 iteration: 36/128 step: 19
[2025-12-23 17:47:58,880] m-LoRA: Adapter lora_finqa_46 loss: 0.025814631953835487
[2025-12-23 17:47:58,883] m-LoRA: Adapter lora_finqa_7 epoch: 1/1 iteration: 68/128 step: 35
[2025-12-23 17:47:59,127] m-LoRA: Adapter lora_finqa_8 epoch: 1/1 iteration: 68/128 step: 35
[2025-12-23 17:47:59,171] m-LoRA: Adapter lora_finqa_37 loss: 0.03998637944459915
[2025-12-23 17:47:59,435] m-LoRA: Adapter lora_finqa_47 loss: 0.010459516197443008
[2025-12-23 17:47:59,557] m-LoRA: Adapter lora_finqa_56 epoch: 1/1 iteration: 16/128 step: 3
[2025-12-23 17:48:00,022] m-LoRA: Adapter lora_finqa_61 loss: 2.4801549911499023
[2025-12-23 17:48:00,123] m-LoRA: Adapter lora_finqa_52 epoch: 1/1 iteration: 80/128 step: 11
[2025-12-23 17:48:00,357] m-LoRA: Adapter lora_finqa_57 epoch: 1/1 iteration: 4/128 step: 3
[2025-12-23 17:48:00,407] m-LoRA: Adapter lora_finqa_23 loss: 0.00017798630869947374
[2025-12-23 17:48:00,768] m-LoRA: Adapter lora_finqa_48 loss: 0.028727227821946144
[2025-12-23 17:48:00,860] m-LoRA: Adapter lora_finqa_58 epoch: 1/1 iteration: 16/128 step: 3
[2025-12-23 17:48:01,151] m-LoRA: Adapter lora_finqa_25 loss: 0.004159858915954828
[2025-12-23 17:48:01,154] m-LoRA: Adapter lora_finqa_36 epoch: 1/1 iteration: 52/128 step: 27
[2025-12-23 17:48:01,778] m-LoRA: Adapter lora_finqa_62 loss: 2.585732936859131
[2025-12-23 17:48:01,979] m-LoRA: Adapter lora_finqa_59 epoch: 1/1 iteration: 32/128 step: 3
[2025-12-23 17:48:02,578] m-LoRA: Adapter lora_finqa_63 loss: 2.471679210662842
[2025-12-23 17:48:02,584] m-LoRA: Adapter lora_finqa_15 epoch: 1/1 iteration: 68/128 step: 35
[2025-12-23 17:48:03,239] m-LoRA: Adapter lora_finqa_39 loss: 0.001901236828416586
[2025-12-23 17:48:03,245] m-LoRA: Adapter lora_finqa_16 epoch: 1/1 iteration: 68/128 step: 35
[2025-12-23 17:48:03,856] m-LoRA: Adapter lora_finqa_64 loss: 2.478114366531372
[2025-12-23 17:48:03,862] m-LoRA: Adapter lora_finqa_45 epoch: 1/1 iteration: 72/128 step: 19
[2025-12-23 17:48:04,142] m-LoRA: Adapter lora_finqa_55 loss: 2.4521632194519043
[2025-12-23 17:48:04,145] m-LoRA: Adapter lora_finqa_60 epoch: 1/1 iteration: 4/128 step: 3
[2025-12-23 17:48:04,458] m-LoRA: Adapter lora_finqa_40 loss: 0.039504364132881165
[2025-12-23 17:48:04,461] m-LoRA: Adapter lora_finqa_46 epoch: 1/1 iteration: 36/128 step: 19
[2025-12-23 17:48:05,050] m-LoRA: Adapter lora_finqa_37 epoch: 1/1 iteration: 52/128 step: 27
[2025-12-23 17:48:05,103] m-LoRA: Adapter lora_finqa_65 loss: 2.4701223373413086
[2025-12-23 17:48:05,381] m-LoRA: Adapter lora_finqa_0 loss: 0.016493212431669235
[2025-12-23 17:48:05,385] m-LoRA: Adapter lora_finqa_47 epoch: 1/1 iteration: 36/128 step: 19
[2025-12-23 17:48:05,735] m-LoRA: Adapter lora_finqa_3 loss: 0.016900328919291496
[2025-12-23 17:48:05,739] m-LoRA: Adapter lora_finqa_61 epoch: 1/1 iteration: 4/128 step: 3
[2025-12-23 17:48:06,335] m-LoRA: Adapter lora_finqa_23 epoch: 1/1 iteration: 68/128 step: 35
[2025-12-23 17:48:06,388] m-LoRA: Adapter lora_finqa_41 loss: 0.20231503248214722
[2025-12-23 17:48:06,698] m-LoRA: Adapter lora_finqa_1 loss: 0.01571357250213623
[2025-12-23 17:48:06,701] m-LoRA: Adapter lora_finqa_48 epoch: 1/1 iteration: 36/128 step: 19
[2025-12-23 17:48:07,084] m-LoRA: Adapter lora_finqa_51 loss: 0.2954410910606384
[2025-12-23 17:48:07,087] m-LoRA: Adapter lora_finqa_25 epoch: 1/1 iteration: 68/128 step: 35
[2025-12-23 17:48:07,665] m-LoRA: Adapter lora_finqa_62 epoch: 1/1 iteration: 8/128 step: 3
[2025-12-23 17:48:07,741] m-LoRA: Adapter lora_finqa_35 loss: 0.009462099522352219
[2025-12-23 17:48:08,055] m-LoRA: Adapter lora_finqa_42 loss: 0.0216175876557827
[2025-12-23 17:48:08,059] m-LoRA: Adapter lora_finqa_63 epoch: 1/1 iteration: 8/128 step: 3
[2025-12-23 17:48:08,382] m-LoRA: Adapter lora_finqa_7 loss: 0.003142015542834997
[2025-12-23 17:48:08,385] m-LoRA: Adapter lora_finqa_39 epoch: 1/1 iteration: 104/128 step: 27
[2025-12-23 17:48:08,699] m-LoRA: Adapter lora_finqa_8 loss: 0.002451085252687335
[2025-12-23 17:48:08,703] m-LoRA: Adapter lora_finqa_64 epoch: 1/1 iteration: 8/128 step: 3
[2025-12-23 17:48:09,830] m-LoRA: Adapter lora_finqa_55 epoch: 1/1 iteration: 20/128 step: 11
[2025-12-23 17:48:09,919] m-LoRA: Adapter lora_finqa_56 loss: 1.9118717908859253
[2025-12-23 17:48:11,241] m-LoRA: Adapter lora_finqa_52 loss: 0.260678768157959
[2025-12-23 17:48:11,251] m-LoRA: Adapter lora_finqa_40 epoch: 1/1 iteration: 52/128 step: 27
[2025-12-23 17:48:11,522] m-LoRA: Adapter lora_finqa_57 loss: 2.4537010192871094
[2025-12-23 17:48:11,525] m-LoRA: Adapter lora_finqa_65 epoch: 1/1 iteration: 8/128 step: 3
[2025-12-23 17:48:12,643] m-LoRA: Adapter lora_finqa_58 loss: 1.912534236907959
[2025-12-23 17:48:12,653] m-LoRA: Adapter lora_finqa_0 epoch: 1/1 iteration: 70/128 step: 36
[2025-12-23 17:48:13,032] m-LoRA: Adapter lora_finqa_36 loss: 0.03617573529481888
[2025-12-23 17:48:13,035] m-LoRA: Adapter lora_finqa_3 epoch: 1/1 iteration: 70/128 step: 36
[2025-12-23 17:48:15,203] m-LoRA: Adapter lora_finqa_41 epoch: 1/1 iteration: 76/128 step: 20
[2025-12-23 17:48:15,526] m-LoRA: Adapter lora_finqa_59 loss: 2.2594809532165527
[2025-12-23 17:48:15,543] m-LoRA: Adapter lora_finqa_1 epoch: 1/1 iteration: 70/128 step: 36
[2025-12-23 17:48:15,665] m-LoRA: Adapter lora_finqa_15 loss: 0.0001710244978312403
[2025-12-23 17:48:16,073] m-LoRA: Adapter lora_finqa_16 loss: 0.00015347283624578267
[2025-12-23 17:48:16,076] m-LoRA: Adapter lora_finqa_51 epoch: 1/1 iteration: 22/128 step: 12
[2025-12-23 17:48:16,631] m-LoRA: Adapter lora_finqa_35 epoch: 1/1 iteration: 108/128 step: 28
[2025-12-23 17:48:16,708] m-LoRA: Adapter lora_finqa_45 loss: 2.103893280029297
[2025-12-23 17:48:16,952] m-LoRA: Adapter lora_finqa_60 loss: 2.4537792205810547
[2025-12-23 17:48:16,955] m-LoRA: Adapter lora_finqa_42 epoch: 1/1 iteration: 38/128 step: 20
[2025-12-23 17:48:17,228] m-LoRA: Adapter lora_finqa_46 loss: 0.021075569093227386
[2025-12-23 17:48:17,231] m-LoRA: Adapter lora_finqa_7 epoch: 1/1 iteration: 70/128 step: 36
[2025-12-23 17:48:17,504] m-LoRA: Adapter lora_finqa_37 loss: 0.03585443273186684
[2025-12-23 17:48:17,508] m-LoRA: Adapter lora_finqa_8 epoch: 1/1 iteration: 70/128 step: 36
[2025-12-23 17:48:17,738] m-LoRA: Adapter lora_finqa_47 loss: 0.008609844371676445
[2025-12-23 17:48:17,861] m-LoRA: Adapter lora_finqa_56 epoch: 1/1 iteration: 24/128 step: 4
[2025-12-23 17:48:18,077] m-LoRA: Adapter lora_finqa_61 loss: 2.2680485248565674
[2025-12-23 17:48:18,216] m-LoRA: Adapter lora_finqa_52 epoch: 1/1 iteration: 88/128 step: 12
[2025-12-23 17:48:18,460] m-LoRA: Adapter lora_finqa_23 loss: 0.0001704911410342902
[2025-12-23 17:48:18,464] m-LoRA: Adapter lora_finqa_57 epoch: 1/1 iteration: 6/128 step: 4
[2025-12-23 17:48:19,148] m-LoRA: Adapter lora_finqa_48 loss: 0.022918792441487312
[2025-12-23 17:48:19,267] m-LoRA: Adapter lora_finqa_58 epoch: 1/1 iteration: 24/128 step: 4
[2025-12-23 17:48:19,602] m-LoRA: Adapter lora_finqa_25 loss: 0.002824146766215563
[2025-12-23 17:48:19,606] m-LoRA: Adapter lora_finqa_36 epoch: 1/1 iteration: 54/128 step: 28
[2025-12-23 17:48:20,251] m-LoRA: Adapter lora_finqa_62 loss: 2.578152894973755
[2025-12-23 17:48:20,899] m-LoRA: Adapter lora_finqa_63 loss: 2.252821207046509
[2025-12-23 17:48:21,071] m-LoRA: Adapter lora_finqa_59 epoch: 1/1 iteration: 48/128 step: 4
[2025-12-23 17:48:22,335] m-LoRA: Adapter lora_finqa_15 epoch: 1/1 iteration: 70/128 step: 36
[2025-12-23 17:48:22,393] m-LoRA: Adapter lora_finqa_39 loss: 0.0022035136353224516
[2025-12-23 17:48:23,638] m-LoRA: Adapter lora_finqa_64 loss: 2.2632358074188232
[2025-12-23 17:48:23,644] m-LoRA: Adapter lora_finqa_16 epoch: 1/1 iteration: 70/128 step: 36
[2025-12-23 17:48:24,094] m-LoRA: Adapter lora_finqa_55 loss: 2.424286127090454
[2025-12-23 17:48:24,097] m-LoRA: Adapter lora_finqa_45 epoch: 1/1 iteration: 76/128 step: 20
[2025-12-23 17:48:24,518] m-LoRA: Adapter lora_finqa_60 epoch: 1/1 iteration: 6/128 step: 4
[2025-12-23 17:48:24,549] m-LoRA: Adapter lora_finqa_40 loss: 0.03553104028105736
[2025-12-23 17:48:25,700] m-LoRA: Adapter lora_finqa_46 epoch: 1/1 iteration: 38/128 step: 20
[2025-12-23 17:48:25,752] m-LoRA: Adapter lora_finqa_65 loss: 2.246422529220581
[2025-12-23 17:48:26,128] m-LoRA: Adapter lora_finqa_0 loss: 0.015276871621608734
[2025-12-23 17:48:26,131] m-LoRA: Adapter lora_finqa_37 epoch: 1/1 iteration: 54/128 step: 28
[2025-12-23 17:48:26,792] m-LoRA: Adapter lora_finqa_3 loss: 0.015345611609518528
[2025-12-23 17:48:26,795] m-LoRA: Adapter lora_finqa_47 epoch: 1/1 iteration: 38/128 step: 20
[2025-12-23 17:48:27,432] m-LoRA: Adapter lora_finqa_61 epoch: 1/1 iteration: 6/128 step: 4
[2025-12-23 17:48:27,481] m-LoRA: Adapter lora_finqa_41 loss: 0.15302972495555878
[2025-12-23 17:48:27,708] m-LoRA: Adapter lora_finqa_1 loss: 0.01496092602610588
[2025-12-23 17:48:27,711] m-LoRA: Adapter lora_finqa_23 epoch: 1/1 iteration: 70/128 step: 36
[2025-12-23 17:48:28,135] m-LoRA: Adapter lora_finqa_51 loss: 0.20079578459262848
[2025-12-23 17:48:28,138] m-LoRA: Adapter lora_finqa_48 epoch: 1/1 iteration: 38/128 step: 20
[2025-12-23 17:48:29,429] m-LoRA: Adapter lora_finqa_25 epoch: 1/1 iteration: 70/128 step: 36
[2025-12-23 17:48:29,485] m-LoRA: Adapter lora_finqa_35 loss: 0.008394907228648663
[2025-12-23 17:48:30,079] m-LoRA: Adapter lora_finqa_42 loss: 0.018261028453707695
[2025-12-23 17:48:30,083] m-LoRA: Adapter lora_finqa_62 epoch: 1/1 iteration: 12/128 step: 4
[2025-12-23 17:48:30,696] m-LoRA: Adapter lora_finqa_7 loss: 0.002716250717639923
[2025-12-23 17:48:30,699] m-LoRA: Adapter lora_finqa_63 epoch: 1/1 iteration: 12/128 step: 4
[2025-12-23 17:48:31,411] m-LoRA: Adapter lora_finqa_8 loss: 0.001643480616621673
[2025-12-23 17:48:31,415] m-LoRA: Adapter lora_finqa_39 epoch: 1/1 iteration: 108/128 step: 28
[2025-12-23 17:48:32,432] m-LoRA: Adapter lora_finqa_64 epoch: 1/1 iteration: 12/128 step: 4
[2025-12-23 17:48:32,516] m-LoRA: Adapter lora_finqa_56 loss: 1.4776631593704224
[2025-12-23 17:48:33,441] m-LoRA: Adapter lora_finqa_55 epoch: 1/1 iteration: 22/128 step: 12
[2025-12-23 17:48:33,543] m-LoRA: Adapter lora_finqa_52 loss: 0.18457411229610443
[2025-12-23 17:48:34,188] m-LoRA: Adapter lora_finqa_40 epoch: 1/1 iteration: 54/128 step: 28
[2025-12-23 17:48:34,244] m-LoRA: Adapter lora_finqa_57 loss: 2.337524652481079
[2025-12-23 17:48:35,453] m-LoRA: Adapter lora_finqa_58 loss: 1.4761593341827393
[2025-12-23 17:48:35,463] m-LoRA: Adapter lora_finqa_65 epoch: 1/1 iteration: 12/128 step: 4
[2025-12-23 17:48:35,758] m-LoRA: Adapter lora_finqa_36 loss: 0.032951679080724716
[2025-12-23 17:48:35,835] m-LoRA: Adapter lora_finqa_0 epoch: 1/1 iteration: 72/128 step: 37
[2025-12-23 17:48:37,882] m-LoRA: Adapter lora_finqa_3 epoch: 1/1 iteration: 72/128 step: 37
[2025-12-23 17:48:38,081] m-LoRA: Adapter lora_finqa_59 loss: 1.9930764436721802
[2025-12-23 17:48:38,569] m-LoRA: Adapter lora_finqa_15 loss: 0.00014516022929456085
[2025-12-23 17:48:38,572] m-LoRA: Adapter lora_finqa_41 epoch: 1/1 iteration: 80/128 step: 21
[2025-12-23 17:48:38,810] m-LoRA: Adapter lora_finqa_1 epoch: 1/1 iteration: 72/128 step: 37
[2025-12-23 17:48:38,864] m-LoRA: Adapter lora_finqa_16 loss: 0.00013859149476047605
[2025-12-23 17:48:39,375] m-LoRA: Adapter lora_finqa_51 epoch: 1/1 iteration: 24/128 step: 13
[2025-12-23 17:48:39,430] m-LoRA: Adapter lora_finqa_45 loss: 2.0573513507843018
[2025-12-23 17:48:39,681] m-LoRA: Adapter lora_finqa_35 epoch: 1/1 iteration: 112/128 step: 29
[2025-12-23 17:48:39,758] m-LoRA: Adapter lora_finqa_60 loss: 2.3360350131988525
[2025-12-23 17:48:40,242] m-LoRA: Adapter lora_finqa_42 epoch: 1/1 iteration: 40/128 step: 21
[2025-12-23 17:48:40,298] m-LoRA: Adapter lora_finqa_46 loss: 0.017640110105276108
[2025-12-23 17:48:40,573] m-LoRA: Adapter lora_finqa_37 loss: 0.0327414907515049
[2025-12-23 17:48:40,577] m-LoRA: Adapter lora_finqa_7 epoch: 1/1 iteration: 72/128 step: 37
[2025-12-23 17:48:41,674] m-LoRA: Adapter lora_finqa_47 loss: 0.007229357026517391
[2025-12-23 17:48:41,677] m-LoRA: Adapter lora_finqa_8 epoch: 1/1 iteration: 72/128 step: 37
[2025-12-23 17:48:41,988] m-LoRA: Adapter lora_finqa_61 loss: 2.004990816116333
[2025-12-23 17:48:42,082] m-LoRA: Adapter lora_finqa_56 epoch: 1/1 iteration: 32/128 step: 5
[2025-12-23 17:48:42,696] m-LoRA: Adapter lora_finqa_23 loss: 0.00014298911264631897
[2025-12-23 17:48:42,820] m-LoRA: Adapter lora_finqa_52 epoch: 1/1 iteration: 96/128 step: 13
[2025-12-23 17:48:43,143] m-LoRA: Adapter lora_finqa_48 loss: 0.019021090120077133
[2025-12-23 17:48:43,147] m-LoRA: Adapter lora_finqa_57 epoch: 1/1 iteration: 8/128 step: 5
[2025-12-23 17:48:43,540] m-LoRA: Adapter lora_finqa_25 loss: 0.0020956688094884157
[2025-12-23 17:48:43,544] m-LoRA: Adapter lora_finqa_58 epoch: 1/1 iteration: 32/128 step: 5
[2025-12-23 17:48:44,171] m-LoRA: Adapter lora_finqa_62 loss: 2.567513942718506
[2025-12-23 17:48:44,184] m-LoRA: Adapter lora_finqa_36 epoch: 1/1 iteration: 56/128 step: 29
[2025-12-23 17:48:44,806] m-LoRA: Adapter lora_finqa_63 loss: 1.9886338710784912
[2025-12-23 17:48:44,979] m-LoRA: Adapter lora_finqa_59 epoch: 1/1 iteration: 64/128 step: 5
[2025-12-23 17:48:45,491] m-LoRA: Adapter lora_finqa_15 epoch: 1/1 iteration: 72/128 step: 37
[2025-12-23 17:48:45,545] m-LoRA: Adapter lora_finqa_39 loss: 0.0009899704018607736
[2025-12-23 17:48:46,139] m-LoRA: Adapter lora_finqa_64 loss: 2.0009748935699463
[2025-12-23 17:48:46,144] m-LoRA: Adapter lora_finqa_16 epoch: 1/1 iteration: 72/128 step: 37
[2025-12-23 17:48:46,473] m-LoRA: Adapter lora_finqa_55 loss: 2.3952698707580566
[2025-12-23 17:48:46,476] m-LoRA: Adapter lora_finqa_45 epoch: 1/1 iteration: 80/128 step: 21
[2025-12-23 17:48:46,796] m-LoRA: Adapter lora_finqa_40 loss: 0.032734259963035583
[2025-12-23 17:48:46,799] m-LoRA: Adapter lora_finqa_60 epoch: 1/1 iteration: 8/128 step: 5
[2025-12-23 17:48:47,382] m-LoRA: Adapter lora_finqa_46 epoch: 1/1 iteration: 40/128 step: 21
[2025-12-23 17:48:47,447] m-LoRA: Adapter lora_finqa_65 loss: 1.9822731018066406
[2025-12-23 17:48:47,693] m-LoRA: Adapter lora_finqa_0 loss: 0.014762124046683311
[2025-12-23 17:48:47,696] m-LoRA: Adapter lora_finqa_37 epoch: 1/1 iteration: 56/128 step: 29
[2025-12-23 17:48:48,033] m-LoRA: Adapter lora_finqa_3 loss: 0.014619522728025913
[2025-12-23 17:48:48,037] m-LoRA: Adapter lora_finqa_47 epoch: 1/1 iteration: 40/128 step: 21
[2025-12-23 17:48:48,652] m-LoRA: Adapter lora_finqa_61 epoch: 1/1 iteration: 8/128 step: 5
[2025-12-23 17:48:48,708] m-LoRA: Adapter lora_finqa_41 loss: 0.11088357120752335
[2025-12-23 17:48:48,966] m-LoRA: Adapter lora_finqa_1 loss: 0.014945263043045998
[2025-12-23 17:48:48,969] m-LoRA: Adapter lora_finqa_23 epoch: 1/1 iteration: 72/128 step: 37
[2025-12-23 17:48:49,347] m-LoRA: Adapter lora_finqa_51 loss: 0.1383252888917923
[2025-12-23 17:48:49,350] m-LoRA: Adapter lora_finqa_48 epoch: 1/1 iteration: 40/128 step: 21
[2025-12-23 17:48:50,021] m-LoRA: Adapter lora_finqa_35 loss: 0.0077406843192875385
[2025-12-23 17:48:50,026] m-LoRA: Adapter lora_finqa_25 epoch: 1/1 iteration: 72/128 step: 37
[2025-12-23 17:48:50,307] m-LoRA: Adapter lora_finqa_42 loss: 0.01574808545410633
[2025-12-23 17:48:50,310] m-LoRA: Adapter lora_finqa_62 epoch: 1/1 iteration: 16/128 step: 5
[2025-12-23 17:48:50,705] m-LoRA: Adapter lora_finqa_7 loss: 0.0016196737997233868
[2025-12-23 17:48:50,708] m-LoRA: Adapter lora_finqa_63 epoch: 1/1 iteration: 16/128 step: 5
[2025-12-23 17:48:51,044] m-LoRA: Adapter lora_finqa_8 loss: 0.0016404204070568085
[2025-12-23 17:48:51,047] m-LoRA: Adapter lora_finqa_39 epoch: 1/1 iteration: 112/128 step: 29
[2025-12-23 17:48:52,296] m-LoRA: Adapter lora_finqa_56 loss: 1.1929036378860474
[2025-12-23 17:48:52,306] m-LoRA: Adapter lora_finqa_64 epoch: 1/1 iteration: 16/128 step: 5
[2025-12-23 17:48:53,440] m-LoRA: Adapter lora_finqa_55 epoch: 1/1 iteration: 24/128 step: 13
[2025-12-23 17:48:53,506] m-LoRA: Adapter lora_finqa_52 loss: 0.1183868944644928
[2025-12-23 17:48:53,739] m-LoRA: Adapter lora_finqa_57 loss: 2.1981964111328125
[2025-12-23 17:48:53,743] m-LoRA: Adapter lora_finqa_40 epoch: 1/1 iteration: 56/128 step: 29
[2025-12-23 17:48:55,033] m-LoRA: Adapter lora_finqa_58 loss: 1.1801722049713135
[2025-12-23 17:48:55,043] m-LoRA: Adapter lora_finqa_65 epoch: 1/1 iteration: 16/128 step: 5
[2025-12-23 17:48:55,417] m-LoRA: Adapter lora_finqa_0 epoch: 1/1 iteration: 74/128 step: 38
[2025-12-23 17:48:55,448] m-LoRA: Adapter lora_finqa_36 loss: 0.02986341528594494
[2025-12-23 17:48:57,573] m-LoRA: Adapter lora_finqa_3 epoch: 1/1 iteration: 74/128 step: 38
[2025-12-23 17:48:57,787] m-LoRA: Adapter lora_finqa_59 loss: 1.7122849225997925
[2025-12-23 17:48:57,911] m-LoRA: Adapter lora_finqa_15 loss: 0.00014201592421159148
[2025-12-23 17:48:57,915] m-LoRA: Adapter lora_finqa_41 epoch: 1/1 iteration: 84/128 step: 22
[2025-12-23 17:48:58,305] m-LoRA: Adapter lora_finqa_16 loss: 0.00012857785623054951
[2025-12-23 17:48:58,308] m-LoRA: Adapter lora_finqa_1 epoch: 1/1 iteration: 74/128 step: 38
[2025-12-23 17:48:58,867] m-LoRA: Adapter lora_finqa_51 epoch: 1/1 iteration: 26/128 step: 14
[2025-12-23 17:48:58,909] m-LoRA: Adapter lora_finqa_45 loss: 2.0080831050872803
[2025-12-23 17:48:59,160] m-LoRA: Adapter lora_finqa_60 loss: 2.2009096145629883
[2025-12-23 17:48:59,164] m-LoRA: Adapter lora_finqa_35 epoch: 1/1 iteration: 116/128 step: 30
[2025-12-23 17:48:59,414] m-LoRA: Adapter lora_finqa_46 loss: 0.0158259067684412
[2025-12-23 17:48:59,417] m-LoRA: Adapter lora_finqa_42 epoch: 1/1 iteration: 42/128 step: 22
[2025-12-23 17:48:59,692] m-LoRA: Adapter lora_finqa_37 loss: 0.029754148796200752
[2025-12-23 17:48:59,695] m-LoRA: Adapter lora_finqa_7 epoch: 1/1 iteration: 74/128 step: 38
[2025-12-23 17:48:59,971] m-LoRA: Adapter lora_finqa_47 loss: 0.0062540690414607525
[2025-12-23 17:48:59,974] m-LoRA: Adapter lora_finqa_8 epoch: 1/1 iteration: 74/128 step: 38
[2025-12-23 17:49:00,221] m-LoRA: Adapter lora_finqa_61 loss: 1.726075291633606
[2025-12-23 17:49:00,337] m-LoRA: Adapter lora_finqa_56 epoch: 1/1 iteration: 40/128 step: 6
[2025-12-23 17:49:00,563] m-LoRA: Adapter lora_finqa_23 loss: 0.00012858655827585608
[2025-12-23 17:49:00,985] m-LoRA: Adapter lora_finqa_52 epoch: 1/1 iteration: 104/128 step: 14
[2025-12-23 17:49:01,393] m-LoRA: Adapter lora_finqa_48 loss: 0.016752414405345917
[2025-12-23 17:49:01,396] m-LoRA: Adapter lora_finqa_57 epoch: 1/1 iteration: 10/128 step: 6
[2025-12-23 17:49:01,751] m-LoRA: Adapter lora_finqa_25 loss: 0.0016202310798689723
[2025-12-23 17:49:01,843] m-LoRA: Adapter lora_finqa_58 epoch: 1/1 iteration: 40/128 step: 6
[2025-12-23 17:49:02,322] m-LoRA: Adapter lora_finqa_62 loss: 2.556908130645752
[2025-12-23 17:49:02,327] m-LoRA: Adapter lora_finqa_36 epoch: 1/1 iteration: 58/128 step: 30
[2025-12-23 17:49:03,008] m-LoRA: Adapter lora_finqa_63 loss: 1.7056690454483032
[2025-12-23 17:49:03,180] m-LoRA: Adapter lora_finqa_59 epoch: 1/1 iteration: 80/128 step: 6
[2025-12-23 17:49:03,732] m-LoRA: Adapter lora_finqa_15 epoch: 1/1 iteration: 74/128 step: 38
[2025-12-23 17:49:03,815] m-LoRA: Adapter lora_finqa_39 loss: 0.000700793752912432
[2025-12-23 17:49:04,483] m-LoRA: Adapter lora_finqa_64 loss: 1.7225395441055298
[2025-12-23 17:49:04,488] m-LoRA: Adapter lora_finqa_16 epoch: 1/1 iteration: 74/128 step: 38
[2025-12-23 17:49:04,770] m-LoRA: Adapter lora_finqa_45 epoch: 1/1 iteration: 84/128 step: 22
[2025-12-23 17:49:04,831] m-LoRA: Adapter lora_finqa_55 loss: 2.3606367111206055
[2025-12-23 17:49:05,171] m-LoRA: Adapter lora_finqa_40 loss: 0.029392369091510773
[2025-12-23 17:49:05,174] m-LoRA: Adapter lora_finqa_60 epoch: 1/1 iteration: 10/128 step: 6
[2025-12-23 17:49:06,558] m-LoRA: Adapter lora_finqa_65 loss: 1.6968461275100708
[2025-12-23 17:49:06,563] m-LoRA: Adapter lora_finqa_46 epoch: 1/1 iteration: 42/128 step: 22
[2025-12-23 17:49:06,856] m-LoRA: Adapter lora_finqa_0 loss: 0.013916912488639355
[2025-12-23 17:49:06,859] m-LoRA: Adapter lora_finqa_37 epoch: 1/1 iteration: 58/128 step: 30
[2025-12-23 17:49:07,176] m-LoRA: Adapter lora_finqa_3 loss: 0.013938112184405327
[2025-12-23 17:49:07,179] m-LoRA: Adapter lora_finqa_47 epoch: 1/1 iteration: 42/128 step: 22
[2025-12-23 17:49:07,788] m-LoRA: Adapter lora_finqa_41 loss: 0.08319893479347229
[2025-12-23 17:49:07,793] m-LoRA: Adapter lora_finqa_61 epoch: 1/1 iteration: 10/128 step: 6
[2025-12-23 17:49:08,058] m-LoRA: Adapter lora_finqa_1 loss: 0.013614901341497898
[2025-12-23 17:49:08,061] m-LoRA: Adapter lora_finqa_23 epoch: 1/1 iteration: 74/128 step: 38
[2025-12-23 17:49:08,395] m-LoRA: Adapter lora_finqa_51 loss: 0.08241736143827438
[2025-12-23 17:49:08,399] m-LoRA: Adapter lora_finqa_48 epoch: 1/1 iteration: 42/128 step: 22
[2025-12-23 17:49:09,034] m-LoRA: Adapter lora_finqa_25 epoch: 1/1 iteration: 74/128 step: 38
[2025-12-23 17:49:09,071] m-LoRA: Adapter lora_finqa_35 loss: 0.007269797846674919
[2025-12-23 17:49:09,427] m-LoRA: Adapter lora_finqa_42 loss: 0.014485303312540054
[2025-12-23 17:49:09,430] m-LoRA: Adapter lora_finqa_62 epoch: 1/1 iteration: 20/128 step: 6
[2025-12-23 17:49:09,730] m-LoRA: Adapter lora_finqa_7 loss: 0.0015642745420336723
[2025-12-23 17:49:09,733] m-LoRA: Adapter lora_finqa_63 epoch: 1/1 iteration: 20/128 step: 6
[2025-12-23 17:49:10,059] m-LoRA: Adapter lora_finqa_8 loss: 0.0013138479553163052
[2025-12-23 17:49:10,063] m-LoRA: Adapter lora_finqa_39 epoch: 1/1 iteration: 116/128 step: 30
[2025-12-23 17:49:11,295] m-LoRA: Adapter lora_finqa_64 epoch: 1/1 iteration: 20/128 step: 6
[2025-12-23 17:49:11,375] m-LoRA: Adapter lora_finqa_56 loss: 0.7751239538192749
[2025-12-23 17:49:14,020] m-LoRA: Adapter lora_finqa_52 loss: 0.07049659639596939
[2025-12-23 17:49:14,029] m-LoRA: Adapter lora_finqa_55 epoch: 1/1 iteration: 26/128 step: 14
[2025-12-23 17:49:14,301] m-LoRA: Adapter lora_finqa_40 epoch: 1/1 iteration: 58/128 step: 30
[2025-12-23 17:49:14,360] m-LoRA: Adapter lora_finqa_57 loss: 2.0527307987213135
[2025-12-23 17:49:16,575] m-LoRA: Adapter lora_finqa_65 epoch: 1/1 iteration: 20/128 step: 6
[2025-12-23 17:49:16,656] m-LoRA: Adapter lora_finqa_58 loss: 0.7675229907035828
[2025-12-23 17:49:17,041] m-LoRA: Adapter lora_finqa_36 loss: 0.027111155912280083
[2025-12-23 17:49:17,044] m-LoRA: Adapter lora_finqa_0 epoch: 1/1 iteration: 76/128 step: 39
[2025-12-23 17:49:19,155] m-LoRA: Adapter lora_finqa_3 epoch: 1/1 iteration: 76/128 step: 39
[2025-12-23 17:49:19,411] m-LoRA: Adapter lora_finqa_59 loss: 1.3997714519500732
[2025-12-23 17:49:19,507] m-LoRA: Adapter lora_finqa_15 loss: 0.00015243787493091077
[2025-12-23 17:49:19,511] m-LoRA: Adapter lora_finqa_41 epoch: 1/1 iteration: 88/128 step: 23
[2025-12-23 17:49:20,120] m-LoRA: Adapter lora_finqa_1 epoch: 1/1 iteration: 76/128 step: 39
[2025-12-23 17:49:20,149] m-LoRA: Adapter lora_finqa_16 loss: 0.00011590510985115543
[2025-12-23 17:49:21,234] m-LoRA: Adapter lora_finqa_51 epoch: 1/1 iteration: 28/128 step: 15
[2025-12-23 17:49:21,288] m-LoRA: Adapter lora_finqa_45 loss: 1.9566218852996826
[2025-12-23 17:49:21,513] m-LoRA: Adapter lora_finqa_35 epoch: 1/1 iteration: 120/128 step: 31
[2025-12-23 17:49:21,585] m-LoRA: Adapter lora_finqa_60 loss: 2.051743745803833
[2025-12-23 17:49:21,842] m-LoRA: Adapter lora_finqa_46 loss: 0.015196460299193859
[2025-12-23 17:49:21,845] m-LoRA: Adapter lora_finqa_42 epoch: 1/1 iteration: 44/128 step: 23
[2025-12-23 17:49:22,395] m-LoRA: Adapter lora_finqa_37 loss: 0.026969129219651222
[2025-12-23 17:49:22,398] m-LoRA: Adapter lora_finqa_7 epoch: 1/1 iteration: 76/128 step: 39
[2025-12-23 17:49:23,260] m-LoRA: Adapter lora_finqa_47 loss: 0.005822485778480768
[2025-12-23 17:49:23,263] m-LoRA: Adapter lora_finqa_8 epoch: 1/1 iteration: 76/128 step: 39
[2025-12-23 17:49:23,932] m-LoRA: Adapter lora_finqa_61 loss: 1.4161325693130493
[2025-12-23 17:49:23,936] m-LoRA: Adapter lora_finqa_56 epoch: 1/1 iteration: 48/128 step: 7
[2025-12-23 17:49:24,467] m-LoRA: Adapter lora_finqa_23 loss: 0.0001232530048582703
[2025-12-23 17:49:24,562] m-LoRA: Adapter lora_finqa_52 epoch: 1/1 iteration: 112/128 step: 15
[2025-12-23 17:49:25,276] m-LoRA: Adapter lora_finqa_48 loss: 0.014748265035450459
[2025-12-23 17:49:25,279] m-LoRA: Adapter lora_finqa_57 epoch: 1/1 iteration: 12/128 step: 7
[2025-12-23 17:49:26,007] m-LoRA: Adapter lora_finqa_25 loss: 0.0009743797709234059
[2025-12-23 17:49:26,010] m-LoRA: Adapter lora_finqa_58 epoch: 1/1 iteration: 48/128 step: 7
[2025-12-23 17:49:26,534] m-LoRA: Adapter lora_finqa_62 loss: 2.541506290435791
[2025-12-23 17:49:26,539] m-LoRA: Adapter lora_finqa_36 epoch: 1/1 iteration: 60/128 step: 31
[2025-12-23 17:49:27,174] m-LoRA: Adapter lora_finqa_63 loss: 1.3943663835525513
[2025-12-23 17:49:27,347] m-LoRA: Adapter lora_finqa_59 epoch: 1/1 iteration: 96/128 step: 7
[2025-12-23 17:49:27,856] m-LoRA: Adapter lora_finqa_15 epoch: 1/1 iteration: 76/128 step: 39
[2025-12-23 17:49:27,890] m-LoRA: Adapter lora_finqa_39 loss: 0.00035985279828310013
[2025-12-23 17:49:28,454] m-LoRA: Adapter lora_finqa_16 epoch: 1/1 iteration: 76/128 step: 39
[2025-12-23 17:49:28,511] m-LoRA: Adapter lora_finqa_64 loss: 1.4088698625564575
[2025-12-23 17:49:29,090] m-LoRA: Adapter lora_finqa_45 epoch: 1/1 iteration: 88/128 step: 23
[2025-12-23 17:49:29,158] m-LoRA: Adapter lora_finqa_55 loss: 2.3333942890167236
[2025-12-23 17:49:29,491] m-LoRA: Adapter lora_finqa_40 loss: 0.026604337617754936
[2025-12-23 17:49:29,494] m-LoRA: Adapter lora_finqa_60 epoch: 1/1 iteration: 12/128 step: 7
[2025-12-23 17:49:30,138] m-LoRA: Adapter lora_finqa_65 loss: 1.3869037628173828
[2025-12-23 17:49:30,144] m-LoRA: Adapter lora_finqa_46 epoch: 1/1 iteration: 44/128 step: 23
[2025-12-23 17:49:30,464] m-LoRA: Adapter lora_finqa_0 loss: 0.013438140973448753
[2025-12-23 17:49:30,468] m-LoRA: Adapter lora_finqa_37 epoch: 1/1 iteration: 60/128 step: 31
[2025-12-23 17:49:31,085] m-LoRA: Adapter lora_finqa_3 loss: 0.013542584143579006
[2025-12-23 17:49:31,088] m-LoRA: Adapter lora_finqa_47 epoch: 1/1 iteration: 44/128 step: 23
[2025-12-23 17:49:31,649] m-LoRA: Adapter lora_finqa_61 epoch: 1/1 iteration: 12/128 step: 7
[2025-12-23 17:49:31,709] m-LoRA: Adapter lora_finqa_41 loss: 0.06427224725484848
[2025-12-23 17:49:32,091] m-LoRA: Adapter lora_finqa_1 loss: 0.0137845603749156
[2025-12-23 17:49:32,094] m-LoRA: Adapter lora_finqa_23 epoch: 1/1 iteration: 76/128 step: 39
[2025-12-23 17:49:32,717] m-LoRA: Adapter lora_finqa_51 loss: 0.055860113352537155
[2025-12-23 17:49:32,721] m-LoRA: Adapter lora_finqa_48 epoch: 1/1 iteration: 44/128 step: 23
[2025-12-23 17:49:33,344] m-LoRA: Adapter lora_finqa_25 epoch: 1/1 iteration: 76/128 step: 39
[2025-12-23 17:49:33,406] m-LoRA: Adapter lora_finqa_35 loss: 0.006007724907249212
[2025-12-23 17:49:33,701] m-LoRA: Adapter lora_finqa_42 loss: 0.01307625137269497
[2025-12-23 17:49:33,704] m-LoRA: Adapter lora_finqa_62 epoch: 1/1 iteration: 24/128 step: 7
[2025-12-23 17:49:34,359] m-LoRA: Adapter lora_finqa_7 loss: 0.0008164238533936441
[2025-12-23 17:49:34,363] m-LoRA: Adapter lora_finqa_63 epoch: 1/1 iteration: 24/128 step: 7
[2025-12-23 17:49:34,754] m-LoRA: Adapter lora_finqa_8 loss: 0.001160918502137065
[2025-12-23 17:49:34,758] m-LoRA: Adapter lora_finqa_39 epoch: 1/1 iteration: 120/128 step: 31
[2025-12-23 17:49:35,869] m-LoRA: Adapter lora_finqa_64 epoch: 1/1 iteration: 24/128 step: 7
[2025-12-23 17:49:35,947] m-LoRA: Adapter lora_finqa_56 loss: 0.5264499187469482
[2025-12-23 17:49:36,897] m-LoRA: Adapter lora_finqa_55 epoch: 1/1 iteration: 28/128 step: 15
[2025-12-23 17:49:36,997] m-LoRA: Adapter lora_finqa_52 loss: 0.047120600938797
[2025-12-23 17:49:37,231] m-LoRA: Adapter lora_finqa_57 loss: 1.899757981300354
[2025-12-23 17:49:37,234] m-LoRA: Adapter lora_finqa_40 epoch: 1/1 iteration: 60/128 step: 31
[2025-12-23 17:49:38,456] m-LoRA: Adapter lora_finqa_65 epoch: 1/1 iteration: 24/128 step: 7
[2025-12-23 17:49:38,614] m-LoRA: Adapter lora_finqa_58 loss: 0.5175951719284058
[2025-12-23 17:49:38,965] m-LoRA: Adapter lora_finqa_36 loss: 0.02448984794318676
[2025-12-23 17:49:38,968] m-LoRA: Adapter lora_finqa_0 epoch: 1/1 iteration: 78/128 step: 40
[2025-12-23 17:49:43,081] m-LoRA: Adapter lora_finqa_3 epoch: 1/1 iteration: 78/128 step: 40
[2025-12-23 17:49:43,316] m-LoRA: Adapter lora_finqa_59 loss: 1.1081304550170898
[2025-12-23 17:49:43,447] m-LoRA: Adapter lora_finqa_15 loss: 0.00012208658154122531
[2025-12-23 17:49:43,450] m-LoRA: Adapter lora_finqa_41 epoch: 1/1 iteration: 92/128 step: 24
[2025-12-23 17:49:43,852] m-LoRA: Adapter lora_finqa_16 loss: 0.0001066864060703665
[2025-12-23 17:49:43,855] m-LoRA: Adapter lora_finqa_1 epoch: 1/1 iteration: 78/128 step: 40
[2025-12-23 17:49:44,372] m-LoRA: Adapter lora_finqa_51 epoch: 1/1 iteration: 30/128 step: 16
[2025-12-23 17:49:44,411] m-LoRA: Adapter lora_finqa_45 loss: 1.9022306203842163
[2025-12-23 17:49:44,686] m-LoRA: Adapter lora_finqa_60 loss: 1.9001144170761108
[2025-12-23 17:49:44,689] m-LoRA: Adapter lora_finqa_35 epoch: 1/1 iteration: 124/128 step: 32
[2025-12-23 17:49:45,248] m-LoRA: Adapter lora_finqa_46 loss: 0.013713721185922623
[2025-12-23 17:49:45,251] m-LoRA: Adapter lora_finqa_42 epoch: 1/1 iteration: 46/128 step: 24
[2025-12-23 17:49:45,526] m-LoRA: Adapter lora_finqa_37 loss: 0.024366654455661774
[2025-12-23 17:49:45,529] m-LoRA: Adapter lora_finqa_7 epoch: 1/1 iteration: 78/128 step: 40
[2025-12-23 17:49:46,396] m-LoRA: Adapter lora_finqa_47 loss: 0.0035333270207047462
[2025-12-23 17:49:46,400] m-LoRA: Adapter lora_finqa_8 epoch: 1/1 iteration: 78/128 step: 40
[2025-12-23 17:49:47,330] m-LoRA: Adapter lora_finqa_61 loss: 1.135066032409668
[2025-12-23 17:49:47,333] m-LoRA: Adapter lora_finqa_56 epoch: 1/1 iteration: 56/128 step: 8
[2025-12-23 17:49:47,945] m-LoRA: Adapter lora_finqa_23 loss: 0.00010752342495834455
[2025-12-23 17:49:48,030] m-LoRA: Adapter lora_finqa_52 epoch: 1/1 iteration: 120/128 step: 16
[2025-12-23 17:49:48,297] m-LoRA: Adapter lora_finqa_57 epoch: 1/1 iteration: 14/128 step: 8
[2025-12-23 17:49:48,329] m-LoRA: Adapter lora_finqa_48 loss: 0.014191986992955208
[2025-12-23 17:49:49,058] m-LoRA: Adapter lora_finqa_25 loss: 0.0006540328031405807
[2025-12-23 17:49:49,226] m-LoRA: Adapter lora_finqa_58 epoch: 1/1 iteration: 56/128 step: 8
[2025-12-23 17:49:50,563] m-LoRA: Adapter lora_finqa_62 loss: 2.5218682289123535
[2025-12-23 17:49:50,568] m-LoRA: Adapter lora_finqa_36 epoch: 1/1 iteration: 62/128 step: 32
[2025-12-23 17:49:51,773] m-LoRA: Adapter lora_finqa_63 loss: 1.097407341003418
[2025-12-23 17:49:51,946] m-LoRA: Adapter lora_finqa_59 epoch: 1/1 iteration: 112/128 step: 8
[2025-12-23 17:49:52,941] m-LoRA: Adapter lora_finqa_15 epoch: 1/1 iteration: 78/128 step: 40
[2025-12-23 17:49:52,996] m-LoRA: Adapter lora_finqa_39 loss: 0.0003509237722028047
[2025-12-23 17:49:54,160] m-LoRA: Adapter lora_finqa_64 loss: 1.1338776350021362
[2025-12-23 17:49:54,165] m-LoRA: Adapter lora_finqa_16 epoch: 1/1 iteration: 78/128 step: 40
[2025-12-23 17:49:54,711] m-LoRA: Adapter lora_finqa_45 epoch: 1/1 iteration: 92/128 step: 24
[2025-12-23 17:49:54,785] m-LoRA: Adapter lora_finqa_55 loss: 2.2842307090759277
[2025-12-23 17:49:55,404] m-LoRA: Adapter lora_finqa_40 loss: 0.024128954857587814
[2025-12-23 17:49:55,407] m-LoRA: Adapter lora_finqa_60 epoch: 1/1 iteration: 14/128 step: 8
[2025-12-23 17:49:56,545] m-LoRA: Adapter lora_finqa_46 epoch: 1/1 iteration: 46/128 step: 24
[2025-12-23 17:49:56,599] m-LoRA: Adapter lora_finqa_65 loss: 1.081357717514038
[2025-12-23 17:49:57,114] m-LoRA: Adapter lora_finqa_37 epoch: 1/1 iteration: 62/128 step: 32
[2025-12-23 17:49:57,161] m-LoRA: Adapter lora_finqa_0 loss: 0.013031363487243652
[2025-12-23 17:49:57,819] m-LoRA: Adapter lora_finqa_3 loss: 0.013304974883794785
[2025-12-23 17:49:57,822] m-LoRA: Adapter lora_finqa_47 epoch: 1/1 iteration: 46/128 step: 24
[2025-12-23 17:49:58,938] m-LoRA: Adapter lora_finqa_61 epoch: 1/1 iteration: 14/128 step: 8
[2025-12-23 17:49:58,994] m-LoRA: Adapter lora_finqa_41 loss: 0.052203837782144547
[2025-12-23 17:49:59,236] m-LoRA: Adapter lora_finqa_23 epoch: 1/1 iteration: 78/128 step: 40
[2025-12-23 17:49:59,290] m-LoRA: Adapter lora_finqa_1 loss: 0.012702650390565395
[2025-12-23 17:49:59,905] m-LoRA: Adapter lora_finqa_51 loss: 0.041951023042201996
[2025-12-23 17:49:59,909] m-LoRA: Adapter lora_finqa_48 epoch: 1/1 iteration: 46/128 step: 24
[2025-12-23 17:50:00,513] m-LoRA: Adapter lora_finqa_25 epoch: 1/1 iteration: 78/128 step: 40
[2025-12-23 17:50:00,573] m-LoRA: Adapter lora_finqa_35 loss: 0.004895981401205063
[2025-12-23 17:50:00,871] m-LoRA: Adapter lora_finqa_42 loss: 0.012727940455079079
[2025-12-23 17:50:00,874] m-LoRA: Adapter lora_finqa_62 epoch: 1/1 iteration: 28/128 step: 8
[2025-12-23 17:50:01,175] m-LoRA: Adapter lora_finqa_7 loss: 0.0009904755279421806
[2025-12-23 17:50:01,300] m-LoRA: Adapter lora_finqa_63 epoch: 1/1 iteration: 28/128 step: 8
[2025-12-23 17:50:01,981] m-LoRA: Adapter lora_finqa_8 loss: 0.00040221060044132173
[2025-12-23 17:50:01,985] m-LoRA: Adapter lora_finqa_39 epoch: 1/1 iteration: 124/128 step: 32
[2025-12-23 17:50:03,129] m-LoRA: Adapter lora_finqa_64 epoch: 1/1 iteration: 28/128 step: 8
[2025-12-23 17:50:03,211] m-LoRA: Adapter lora_finqa_56 loss: 0.33464157581329346
[2025-12-23 17:50:04,203] m-LoRA: Adapter lora_finqa_55 epoch: 1/1 iteration: 30/128 step: 16
[2025-12-23 17:50:04,267] m-LoRA: Adapter lora_finqa_52 loss: 0.03586193919181824
[2025-12-23 17:50:04,528] m-LoRA: Adapter lora_finqa_57 loss: 1.7355599403381348
[2025-12-23 17:50:04,532] m-LoRA: Adapter lora_finqa_40 epoch: 1/1 iteration: 62/128 step: 32
[2025-12-23 17:50:05,764] m-LoRA: Adapter lora_finqa_58 loss: 0.33030426502227783
[2025-12-23 17:50:05,775] m-LoRA: Adapter lora_finqa_65 epoch: 1/1 iteration: 28/128 step: 8
[2025-12-23 17:50:06,165] m-LoRA: Adapter lora_finqa_0 epoch: 1/1 iteration: 80/128 step: 41
[2025-12-23 17:50:06,220] m-LoRA: Adapter lora_finqa_36 loss: 0.021980199962854385
[2025-12-23 17:50:10,217] m-LoRA: Adapter lora_finqa_3 epoch: 1/1 iteration: 80/128 step: 41
[2025-12-23 17:50:10,550] m-LoRA: Adapter lora_finqa_59 loss: 0.8177871108055115
[2025-12-23 17:50:10,568] m-LoRA: Adapter lora_finqa_41 epoch: 1/1 iteration: 96/128 step: 25
[2025-12-23 17:50:10,626] m-LoRA: Adapter lora_finqa_15 loss: 0.00010599946836009622
[2025-12-23 17:50:11,024] m-LoRA: Adapter lora_finqa_16 loss: 0.00010632329940563068
[2025-12-23 17:50:11,027] m-LoRA: Adapter lora_finqa_1 epoch: 1/1 iteration: 80/128 step: 41
[2025-12-23 17:50:12,004] m-LoRA: Adapter lora_finqa_51 epoch: 1/1 iteration: 32/128 step: 17
[2025-12-23 17:50:12,038] m-LoRA: Adapter lora_finqa_45 loss: 1.8463866710662842
[2025-12-23 17:50:12,307] m-LoRA: Finish and base model offload adapter - ['lora_finqa_35']
[2025-12-23 17:50:12,641] m-LoRA: Adapter lora_finqa_60 loss: 1.7404669523239136
[2025-12-23 17:50:12,645] m-LoRA: Task to running, need to load adapters: ['lora_finqa_66']
[2025-12-23 17:50:12,879] m-LoRA: Adapter lora_finqa_66 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:50:13,026] m-LoRA: Adapter lora_finqa_46 loss: 0.01281687244772911
[2025-12-23 17:50:13,029] m-LoRA: Adapter lora_finqa_42 epoch: 1/1 iteration: 48/128 step: 25
[2025-12-23 17:50:13,224] m-LoRA: Adapter lora_finqa_37 loss: 0.02199948951601982
[2025-12-23 17:50:13,227] m-LoRA: Adapter lora_finqa_7 epoch: 1/1 iteration: 80/128 step: 41
[2025-12-23 17:50:13,652] m-LoRA: Adapter lora_finqa_47 loss: 0.002568300813436508
[2025-12-23 17:50:13,656] m-LoRA: Adapter lora_finqa_8 epoch: 1/1 iteration: 80/128 step: 41
[2025-12-23 17:50:13,990] m-LoRA: Adapter lora_finqa_61 loss: 0.8396191596984863
[2025-12-23 17:50:13,994] m-LoRA: Adapter lora_finqa_56 epoch: 1/1 iteration: 64/128 step: 9
[2025-12-23 17:50:14,263] m-LoRA: Adapter lora_finqa_23 loss: 0.00017980246047955006
[2025-12-23 17:50:14,394] m-LoRA: Finish and base model offload adapter - ['lora_finqa_52']
[2025-12-23 17:50:14,646] m-LoRA: Task to running, need to load adapters: ['lora_finqa_67']
[2025-12-23 17:50:14,693] m-LoRA: Adapter lora_finqa_67 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:50:14,867] m-LoRA: Adapter lora_finqa_48 loss: 0.01300469134002924
[2025-12-23 17:50:14,870] m-LoRA: Adapter lora_finqa_57 epoch: 1/1 iteration: 16/128 step: 9
[2025-12-23 17:50:15,407] m-LoRA: Adapter lora_finqa_25 loss: 0.0004740488075185567
[2025-12-23 17:50:15,563] m-LoRA: Adapter lora_finqa_58 epoch: 1/1 iteration: 64/128 step: 9
[2025-12-23 17:50:16,846] m-LoRA: Adapter lora_finqa_36 epoch: 1/1 iteration: 64/128 step: 33
[2025-12-23 17:50:16,908] m-LoRA: Adapter lora_finqa_62 loss: 2.504162311553955
[2025-12-23 17:50:18,296] m-LoRA: Adapter lora_finqa_63 loss: 0.8055793642997742
[2025-12-23 17:50:18,469] m-LoRA: Finish and base model offload adapter - ['lora_finqa_59']
[2025-12-23 17:50:19,238] m-LoRA: Task to running, need to load adapters: ['lora_finqa_68']
[2025-12-23 17:50:19,376] m-LoRA: Adapter lora_finqa_68 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:50:19,691] m-LoRA: Adapter lora_finqa_39 loss: 0.00032595923403277993
[2025-12-23 17:50:19,696] m-LoRA: Adapter lora_finqa_15 epoch: 1/1 iteration: 80/128 step: 41
[2025-12-23 17:50:20,756] m-LoRA: Adapter lora_finqa_16 epoch: 1/1 iteration: 80/128 step: 41
[2025-12-23 17:50:20,790] m-LoRA: Adapter lora_finqa_64 loss: 0.8360999226570129
[2025-12-23 17:50:21,475] m-LoRA: Adapter lora_finqa_55 loss: 2.2443225383758545
[2025-12-23 17:50:21,478] m-LoRA: Adapter lora_finqa_45 epoch: 1/1 iteration: 96/128 step: 25
[2025-12-23 17:50:22,103] m-LoRA: Adapter lora_finqa_60 epoch: 1/1 iteration: 16/128 step: 9
[2025-12-23 17:50:22,132] m-LoRA: Adapter lora_finqa_40 loss: 0.021836142987012863
[2025-12-23 17:50:23,208] m-LoRA: Adapter lora_finqa_46 epoch: 1/1 iteration: 48/128 step: 25
[2025-12-23 17:50:23,270] m-LoRA: Adapter lora_finqa_65 loss: 0.7877458333969116
[2025-12-23 17:50:23,802] m-LoRA: Adapter lora_finqa_0 loss: 0.012595390900969505
[2025-12-23 17:50:23,805] m-LoRA: Adapter lora_finqa_37 epoch: 1/1 iteration: 64/128 step: 33
[2025-12-23 17:50:24,486] m-LoRA: Adapter lora_finqa_3 loss: 0.012632349506020546
[2025-12-23 17:50:24,489] m-LoRA: Adapter lora_finqa_47 epoch: 1/1 iteration: 48/128 step: 25
[2025-12-23 17:50:25,575] m-LoRA: Adapter lora_finqa_61 epoch: 1/1 iteration: 16/128 step: 9
[2025-12-23 17:50:25,630] m-LoRA: Adapter lora_finqa_41 loss: 0.043919697403907776
[2025-12-23 17:50:26,195] m-LoRA: Adapter lora_finqa_1 loss: 0.012186978943645954
[2025-12-23 17:50:26,198] m-LoRA: Adapter lora_finqa_23 epoch: 1/1 iteration: 80/128 step: 41
[2025-12-23 17:50:26,856] m-LoRA: Adapter lora_finqa_51 loss: 0.03504160791635513
[2025-12-23 17:50:26,859] m-LoRA: Adapter lora_finqa_48 epoch: 1/1 iteration: 48/128 step: 25
[2025-12-23 17:50:27,518] m-LoRA: Adapter lora_finqa_25 epoch: 1/1 iteration: 80/128 step: 41
[2025-12-23 17:50:27,574] m-LoRA: Adapter lora_finqa_66 loss: 2.5885279178619385
[2025-12-23 17:50:28,141] m-LoRA: Adapter lora_finqa_42 loss: 0.011767346411943436
[2025-12-23 17:50:28,145] m-LoRA: Adapter lora_finqa_62 epoch: 1/1 iteration: 32/128 step: 9
[2025-12-23 17:50:28,781] m-LoRA: Adapter lora_finqa_7 loss: 0.00042126778862439096
[2025-12-23 17:50:28,784] m-LoRA: Adapter lora_finqa_63 epoch: 1/1 iteration: 32/128 step: 9
[2025-12-23 17:50:29,086] m-LoRA: Finish and base model offload adapter - ['lora_finqa_39']
[2025-12-23 17:50:29,565] m-LoRA: Adapter lora_finqa_8 loss: 0.00036736991023644805
[2025-12-23 17:50:29,568] m-LoRA: Task to running, need to load adapters: ['lora_finqa_69']
[2025-12-23 17:50:29,720] m-LoRA: Adapter lora_finqa_69 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:50:30,210] m-LoRA: Adapter lora_finqa_64 epoch: 1/1 iteration: 32/128 step: 9
[2025-12-23 17:50:30,306] m-LoRA: Adapter lora_finqa_56 loss: 0.21803325414657593
[2025-12-23 17:50:31,307] m-LoRA: Adapter lora_finqa_55 epoch: 1/1 iteration: 32/128 step: 17
[2025-12-23 17:50:31,374] m-LoRA: Adapter lora_finqa_67 loss: 2.588528633117676
[2025-12-23 17:50:31,605] m-LoRA: Adapter lora_finqa_57 loss: 1.5524529218673706
[2025-12-23 17:50:31,608] m-LoRA: Adapter lora_finqa_40 epoch: 1/1 iteration: 64/128 step: 33
[2025-12-23 17:50:32,696] m-LoRA: Adapter lora_finqa_65 epoch: 1/1 iteration: 32/128 step: 9
[2025-12-23 17:50:32,793] m-LoRA: Adapter lora_finqa_58 loss: 0.2107512354850769
[2025-12-23 17:50:33,219] m-LoRA: Adapter lora_finqa_36 loss: 0.019883593544363976
[2025-12-23 17:50:33,223] m-LoRA: Adapter lora_finqa_0 epoch: 1/1 iteration: 82/128 step: 42
[2025-12-23 17:50:33,483] m-LoRA: Adapter lora_finqa_15 loss: 0.00010140458471141756
[2025-12-23 17:50:33,487] m-LoRA: Adapter lora_finqa_3 epoch: 1/1 iteration: 82/128 step: 42
[2025-12-23 17:50:35,625] m-LoRA: Adapter lora_finqa_41 epoch: 1/1 iteration: 100/128 step: 26
[2025-12-23 17:50:35,975] m-LoRA: Adapter lora_finqa_68 loss: 2.5885279178619385
[2025-12-23 17:50:35,993] m-LoRA: Adapter lora_finqa_1 epoch: 1/1 iteration: 82/128 step: 42
[2025-12-23 17:50:36,051] m-LoRA: Adapter lora_finqa_16 loss: 0.0001828063977882266
[2025-12-23 17:50:36,565] m-LoRA: Adapter lora_finqa_51 epoch: 1/1 iteration: 34/128 step: 18
[2025-12-23 17:50:36,619] m-LoRA: Adapter lora_finqa_45 loss: 1.7869311571121216
[2025-12-23 17:50:36,897] m-LoRA: Adapter lora_finqa_60 loss: 1.5570966005325317
[2025-12-23 17:50:36,900] m-LoRA: Adapter lora_finqa_66 epoch: 1/1 iteration: 4/128 step: 2
[2025-12-23 17:50:37,172] m-LoRA: Adapter lora_finqa_46 loss: 0.012144382111728191
[2025-12-23 17:50:37,175] m-LoRA: Adapter lora_finqa_42 epoch: 1/1 iteration: 50/128 step: 26
[2025-12-23 17:50:37,452] m-LoRA: Adapter lora_finqa_37 loss: 0.019668014720082283
[2025-12-23 17:50:37,455] m-LoRA: Adapter lora_finqa_7 epoch: 1/1 iteration: 82/128 step: 42
[2025-12-23 17:50:37,728] m-LoRA: Adapter lora_finqa_47 loss: 0.0015136821893975139
[2025-12-23 17:50:37,732] m-LoRA: Adapter lora_finqa_8 epoch: 1/1 iteration: 82/128 step: 42
[2025-12-23 17:50:38,116] m-LoRA: Adapter lora_finqa_61 loss: 0.5861371159553528
[2025-12-23 17:50:38,120] m-LoRA: Adapter lora_finqa_56 epoch: 1/1 iteration: 72/128 step: 10
[2025-12-23 17:50:38,313] m-LoRA: Adapter lora_finqa_23 loss: 9.340464748675004e-05
[2025-12-23 17:50:38,446] m-LoRA: Adapter lora_finqa_67 epoch: 1/1 iteration: 8/128 step: 2
[2025-12-23 17:50:39,052] m-LoRA: Adapter lora_finqa_48 loss: 0.011948327533900738
[2025-12-23 17:50:39,056] m-LoRA: Adapter lora_finqa_57 epoch: 1/1 iteration: 18/128 step: 10
[2025-12-23 17:50:39,354] m-LoRA: Adapter lora_finqa_25 loss: 0.0012254860484972596
[2025-12-23 17:50:39,475] m-LoRA: Adapter lora_finqa_58 epoch: 1/1 iteration: 72/128 step: 10
[2025-12-23 17:50:40,631] m-LoRA: Adapter lora_finqa_36 epoch: 1/1 iteration: 66/128 step: 34
[2025-12-23 17:50:40,689] m-LoRA: Adapter lora_finqa_62 loss: 2.4786739349365234
[2025-12-23 17:50:42,010] m-LoRA: Adapter lora_finqa_15 epoch: 1/1 iteration: 82/128 step: 42
[2025-12-23 17:50:42,043] m-LoRA: Adapter lora_finqa_63 loss: 0.5548309683799744
[2025-12-23 17:50:46,117] m-LoRA: Adapter lora_finqa_69 loss: 2.5885279178619385
[2025-12-23 17:50:46,497] m-LoRA: Adapter lora_finqa_68 epoch: 1/1 iteration: 16/128 step: 2
[2025-12-23 17:50:47,188] m-LoRA: Adapter lora_finqa_16 epoch: 1/1 iteration: 82/128 step: 42
[2025-12-23 17:50:47,244] m-LoRA: Adapter lora_finqa_64 loss: 0.5889388918876648
[2025-12-23 17:50:47,773] m-LoRA: Adapter lora_finqa_55 loss: 2.203801393508911
[2025-12-23 17:50:47,776] m-LoRA: Adapter lora_finqa_45 epoch: 1/1 iteration: 100/128 step: 26
[2025-12-23 17:50:48,293] m-LoRA: Adapter lora_finqa_40 loss: 0.01952970400452614
[2025-12-23 17:50:48,296] m-LoRA: Adapter lora_finqa_60 epoch: 1/1 iteration: 18/128 step: 10
[2025-12-23 17:50:49,704] m-LoRA: Adapter lora_finqa_65 loss: 0.5418680310249329
[2025-12-23 17:50:49,709] m-LoRA: Adapter lora_finqa_46 epoch: 1/1 iteration: 50/128 step: 26
[2025-12-23 17:50:50,414] m-LoRA: Adapter lora_finqa_0 loss: 0.012455546297132969
[2025-12-23 17:50:50,417] m-LoRA: Adapter lora_finqa_37 epoch: 1/1 iteration: 66/128 step: 34
[2025-12-23 17:50:51,018] m-LoRA: Adapter lora_finqa_47 epoch: 1/1 iteration: 50/128 step: 26
[2025-12-23 17:50:51,076] m-LoRA: Adapter lora_finqa_3 loss: 0.01187449786812067
[2025-12-23 17:50:51,695] m-LoRA: Adapter lora_finqa_41 loss: 0.03905544430017471
[2025-12-23 17:50:51,701] m-LoRA: Adapter lora_finqa_61 epoch: 1/1 iteration: 18/128 step: 10
[2025-12-23 17:50:52,312] m-LoRA: Adapter lora_finqa_1 loss: 0.011798490770161152
[2025-12-23 17:50:52,315] m-LoRA: Adapter lora_finqa_23 epoch: 1/1 iteration: 82/128 step: 42
[2025-12-23 17:50:52,999] m-LoRA: Adapter lora_finqa_48 epoch: 1/1 iteration: 50/128 step: 26
[2025-12-23 17:50:53,050] m-LoRA: Adapter lora_finqa_51 loss: 0.027702441439032555
[2025-12-23 17:50:54,138] m-LoRA: Adapter lora_finqa_66 loss: 2.314467668533325
[2025-12-23 17:50:54,144] m-LoRA: Adapter lora_finqa_25 epoch: 1/1 iteration: 82/128 step: 42
[2025-12-23 17:50:54,505] m-LoRA: Adapter lora_finqa_42 loss: 0.01112846564501524
[2025-12-23 17:50:54,508] m-LoRA: Adapter lora_finqa_62 epoch: 1/1 iteration: 36/128 step: 10
[2025-12-23 17:50:55,117] m-LoRA: Adapter lora_finqa_7 loss: 0.00031628352007828653
[2025-12-23 17:50:55,120] m-LoRA: Adapter lora_finqa_63 epoch: 1/1 iteration: 36/128 step: 10
[2025-12-23 17:50:55,478] m-LoRA: Adapter lora_finqa_8 loss: 0.00024347906582988799
[2025-12-23 17:50:55,651] m-LoRA: Adapter lora_finqa_69 epoch: 1/1 iteration: 16/128 step: 2
[2025-12-23 17:50:56,613] m-LoRA: Adapter lora_finqa_64 epoch: 1/1 iteration: 36/128 step: 10
[2025-12-23 17:50:56,724] m-LoRA: Adapter lora_finqa_56 loss: 0.11229164898395538
[2025-12-23 17:50:57,775] m-LoRA: Adapter lora_finqa_55 epoch: 1/1 iteration: 34/128 step: 18
[2025-12-23 17:50:57,872] m-LoRA: Adapter lora_finqa_67 loss: 2.542140007019043
[2025-12-23 17:50:58,521] m-LoRA: Adapter lora_finqa_57 loss: 1.3890819549560547
[2025-12-23 17:50:58,525] m-LoRA: Adapter lora_finqa_40 epoch: 1/1 iteration: 66/128 step: 34
[2025-12-23 17:50:59,736] m-LoRA: Adapter lora_finqa_58 loss: 0.11421550065279007
[2025-12-23 17:50:59,746] m-LoRA: Adapter lora_finqa_65 epoch: 1/1 iteration: 36/128 step: 10
[2025-12-23 17:51:00,020] m-LoRA: Adapter lora_finqa_0 epoch: 1/1 iteration: 84/128 step: 43
[2025-12-23 17:51:00,053] m-LoRA: Adapter lora_finqa_36 loss: 0.01818668469786644
[2025-12-23 17:51:00,350] m-LoRA: Adapter lora_finqa_15 loss: 0.00011464918497949839
[2025-12-23 17:51:00,353] m-LoRA: Adapter lora_finqa_3 epoch: 1/1 iteration: 84/128 step: 43
[2025-12-23 17:51:02,548] m-LoRA: Adapter lora_finqa_41 epoch: 1/1 iteration: 104/128 step: 27
[2025-12-23 17:51:02,876] m-LoRA: Adapter lora_finqa_68 loss: 2.4779627323150635
[2025-12-23 17:51:02,894] m-LoRA: Adapter lora_finqa_1 epoch: 1/1 iteration: 84/128 step: 43
[2025-12-23 17:51:02,944] m-LoRA: Adapter lora_finqa_16 loss: 8.879359666025266e-05
[2025-12-23 17:51:03,499] m-LoRA: Adapter lora_finqa_51 epoch: 1/1 iteration: 36/128 step: 19
[2025-12-23 17:51:03,538] m-LoRA: Adapter lora_finqa_45 loss: 1.722609281539917
[2025-12-23 17:51:03,810] m-LoRA: Adapter lora_finqa_60 loss: 1.3964626789093018
[2025-12-23 17:51:03,814] m-LoRA: Adapter lora_finqa_66 epoch: 1/1 iteration: 8/128 step: 3
[2025-12-23 17:51:04,064] m-LoRA: Adapter lora_finqa_46 loss: 0.012340005487203598
[2025-12-23 17:51:04,067] m-LoRA: Adapter lora_finqa_42 epoch: 1/1 iteration: 52/128 step: 27
[2025-12-23 17:51:04,345] m-LoRA: Adapter lora_finqa_37 loss: 0.018113896250724792
[2025-12-23 17:51:04,349] m-LoRA: Adapter lora_finqa_7 epoch: 1/1 iteration: 84/128 step: 43
[2025-12-23 17:51:04,594] m-LoRA: Adapter lora_finqa_47 loss: 0.0009727099095471203
[2025-12-23 17:51:04,598] m-LoRA: Adapter lora_finqa_8 epoch: 1/1 iteration: 84/128 step: 43
[2025-12-23 17:51:04,850] m-LoRA: Adapter lora_finqa_61 loss: 0.4316366910934448
[2025-12-23 17:51:04,970] m-LoRA: Adapter lora_finqa_56 epoch: 1/1 iteration: 80/128 step: 11
[2025-12-23 17:51:05,291] m-LoRA: Adapter lora_finqa_23 loss: 9.027510532177985e-05
[2025-12-23 17:51:05,295] m-LoRA: Adapter lora_finqa_67 epoch: 1/1 iteration: 16/128 step: 3
[2025-12-23 17:51:05,544] m-LoRA: Adapter lora_finqa_48 loss: 0.010890036821365356
[2025-12-23 17:51:05,548] m-LoRA: Adapter lora_finqa_57 epoch: 1/1 iteration: 20/128 step: 11
[2025-12-23 17:51:06,229] m-LoRA: Adapter lora_finqa_25 loss: 0.00041396860615350306
[2025-12-23 17:51:06,362] m-LoRA: Adapter lora_finqa_58 epoch: 1/1 iteration: 80/128 step: 11
[2025-12-23 17:51:06,986] m-LoRA: Adapter lora_finqa_62 loss: 2.452306032180786
[2025-12-23 17:51:06,991] m-LoRA: Adapter lora_finqa_36 epoch: 1/1 iteration: 68/128 step: 35
[2025-12-23 17:51:07,620] m-LoRA: Adapter lora_finqa_63 loss: 0.4056052565574646
[2025-12-23 17:51:07,625] m-LoRA: Adapter lora_finqa_15 epoch: 1/1 iteration: 84/128 step: 43
[2025-12-23 17:51:12,398] m-LoRA: Adapter lora_finqa_69 loss: 2.47363543510437
[2025-12-23 17:51:12,823] m-LoRA: Adapter lora_finqa_68 epoch: 1/1 iteration: 32/128 step: 3
[2025-12-23 17:51:13,201] m-LoRA: Adapter lora_finqa_64 loss: 0.42698919773101807
[2025-12-23 17:51:13,237] m-LoRA: Adapter lora_finqa_16 epoch: 1/1 iteration: 84/128 step: 43
[2025-12-23 17:51:13,426] m-LoRA: Adapter lora_finqa_55 loss: 2.1572835445404053
[2025-12-23 17:51:13,430] m-LoRA: Adapter lora_finqa_45 epoch: 1/1 iteration: 104/128 step: 27
[2025-12-23 17:51:13,604] m-LoRA: Adapter lora_finqa_40 loss: 0.01756468415260315
[2025-12-23 17:51:13,608] m-LoRA: Adapter lora_finqa_60 epoch: 1/1 iteration: 20/128 step: 11
[2025-12-23 17:51:14,126] m-LoRA: Adapter lora_finqa_46 epoch: 1/1 iteration: 52/128 step: 27
[2025-12-23 17:51:14,182] m-LoRA: Adapter lora_finqa_65 loss: 0.3790590763092041
[2025-12-23 17:51:14,446] m-LoRA: Adapter lora_finqa_0 loss: 0.011673270724713802
[2025-12-23 17:51:14,449] m-LoRA: Adapter lora_finqa_37 epoch: 1/1 iteration: 68/128 step: 35
[2025-12-23 17:51:14,703] m-LoRA: Adapter lora_finqa_3 loss: 0.011845618486404419
[2025-12-23 17:51:14,706] m-LoRA: Adapter lora_finqa_47 epoch: 1/1 iteration: 52/128 step: 27
[2025-12-23 17:51:15,521] m-LoRA: Adapter lora_finqa_41 loss: 0.03566569462418556
[2025-12-23 17:51:15,526] m-LoRA: Adapter lora_finqa_61 epoch: 1/1 iteration: 20/128 step: 11
[2025-12-23 17:51:15,904] m-LoRA: Adapter lora_finqa_1 loss: 0.01194676011800766
[2025-12-23 17:51:15,907] m-LoRA: Adapter lora_finqa_23 epoch: 1/1 iteration: 84/128 step: 43
[2025-12-23 17:51:16,291] m-LoRA: Adapter lora_finqa_48 epoch: 1/1 iteration: 52/128 step: 27
[2025-12-23 17:51:16,344] m-LoRA: Adapter lora_finqa_51 loss: 0.022561844438314438
[2025-12-23 17:51:16,925] m-LoRA: Adapter lora_finqa_25 epoch: 1/1 iteration: 84/128 step: 43
[2025-12-23 17:51:16,983] m-LoRA: Adapter lora_finqa_66 loss: 1.9150736331939697
[2025-12-23 17:51:17,278] m-LoRA: Adapter lora_finqa_42 loss: 0.010000010952353477
[2025-12-23 17:51:17,281] m-LoRA: Adapter lora_finqa_62 epoch: 1/1 iteration: 40/128 step: 11
[2025-12-23 17:51:17,666] m-LoRA: Adapter lora_finqa_7 loss: 0.0005255421274341643
[2025-12-23 17:51:17,670] m-LoRA: Adapter lora_finqa_63 epoch: 1/1 iteration: 40/128 step: 11
[2025-12-23 17:51:17,948] m-LoRA: Adapter lora_finqa_8 loss: 0.0002586662885732949
[2025-12-23 17:51:18,106] m-LoRA: Adapter lora_finqa_69 epoch: 1/1 iteration: 32/128 step: 3
[2025-12-23 17:51:20,265] m-LoRA: Adapter lora_finqa_64 epoch: 1/1 iteration: 40/128 step: 11
[2025-12-23 17:51:20,419] m-LoRA: Adapter lora_finqa_56 loss: 0.0563955157995224
[2025-12-23 17:51:22,549] m-LoRA: Adapter lora_finqa_55 epoch: 1/1 iteration: 36/128 step: 19
[2025-12-23 17:51:22,612] m-LoRA: Adapter lora_finqa_67 loss: 2.4535868167877197
[2025-12-23 17:51:23,233] m-LoRA: Adapter lora_finqa_40 epoch: 1/1 iteration: 68/128 step: 35
[2025-12-23 17:51:23,290] m-LoRA: Adapter lora_finqa_57 loss: 1.2008298635482788
[2025-12-23 17:51:25,256] m-LoRA: Adapter lora_finqa_65 epoch: 1/1 iteration: 40/128 step: 11
[2025-12-23 17:51:25,342] m-LoRA: Adapter lora_finqa_58 loss: 0.05852824077010155
[2025-12-23 17:51:25,771] m-LoRA: Adapter lora_finqa_0 epoch: 1/1 iteration: 86/128 step: 44
[2025-12-23 17:51:25,826] m-LoRA: Adapter lora_finqa_36 loss: 0.017155859619379044
[2025-12-23 17:51:26,339] m-LoRA: Adapter lora_finqa_15 loss: 8.875814091879874e-05
[2025-12-23 17:51:26,342] m-LoRA: Adapter lora_finqa_3 epoch: 1/1 iteration: 86/128 step: 44
[2025-12-23 17:51:28,508] m-LoRA: Adapter lora_finqa_41 epoch: 1/1 iteration: 108/128 step: 28
[2025-12-23 17:51:28,721] m-LoRA: Adapter lora_finqa_68 loss: 2.260807752609253
[2025-12-23 17:51:29,191] m-LoRA: Adapter lora_finqa_1 epoch: 1/1 iteration: 86/128 step: 44
[2025-12-23 17:51:29,221] m-LoRA: Adapter lora_finqa_16 loss: 8.343208173755556e-05
[2025-12-23 17:51:30,134] m-LoRA: Adapter lora_finqa_51 epoch: 1/1 iteration: 38/128 step: 20
[2025-12-23 17:51:30,187] m-LoRA: Adapter lora_finqa_45 loss: 1.656899333000183
[2025-12-23 17:51:30,678] m-LoRA: Adapter lora_finqa_60 loss: 1.2109358310699463
[2025-12-23 17:51:30,681] m-LoRA: Adapter lora_finqa_66 epoch: 1/1 iteration: 12/128 step: 4
[2025-12-23 17:51:31,202] m-LoRA: Adapter lora_finqa_46 loss: 0.010955428704619408
[2025-12-23 17:51:31,205] m-LoRA: Adapter lora_finqa_42 epoch: 1/1 iteration: 54/128 step: 28
[2025-12-23 17:51:32,020] m-LoRA: Adapter lora_finqa_37 loss: 0.016514357179403305
[2025-12-23 17:51:32,024] m-LoRA: Adapter lora_finqa_7 epoch: 1/1 iteration: 86/128 step: 44
[2025-12-23 17:51:32,669] m-LoRA: Adapter lora_finqa_47 loss: 0.0006381940911523998
[2025-12-23 17:51:32,673] m-LoRA: Adapter lora_finqa_8 epoch: 1/1 iteration: 86/128 step: 44
[2025-12-23 17:51:33,347] m-LoRA: Adapter lora_finqa_61 loss: 0.28673478960990906
[2025-12-23 17:51:33,459] m-LoRA: Adapter lora_finqa_56 epoch: 1/1 iteration: 88/128 step: 12
[2025-12-23 17:51:34,060] m-LoRA: Adapter lora_finqa_23 loss: 8.392871677642688e-05
[2025-12-23 17:51:34,191] m-LoRA: Adapter lora_finqa_67 epoch: 1/1 iteration: 24/128 step: 4
[2025-12-23 17:51:34,492] m-LoRA: Adapter lora_finqa_48 loss: 0.010456378571689129
[2025-12-23 17:51:34,616] m-LoRA: Adapter lora_finqa_57 epoch: 1/1 iteration: 22/128 step: 12
[2025-12-23 17:51:34,870] m-LoRA: Adapter lora_finqa_25 loss: 0.00023351515119429678
[2025-12-23 17:51:35,043] m-LoRA: Adapter lora_finqa_58 epoch: 1/1 iteration: 88/128 step: 12
[2025-12-23 17:51:35,662] m-LoRA: Adapter lora_finqa_62 loss: 2.426743268966675
[2025-12-23 17:51:35,667] m-LoRA: Adapter lora_finqa_36 epoch: 1/1 iteration: 70/128 step: 36
[2025-12-23 17:51:36,261] m-LoRA: Adapter lora_finqa_15 epoch: 1/1 iteration: 86/128 step: 44
[2025-12-23 17:51:36,300] m-LoRA: Adapter lora_finqa_63 loss: 0.2675323486328125
[2025-12-23 17:51:38,453] m-LoRA: Adapter lora_finqa_69 loss: 2.25266170501709
[2025-12-23 17:51:38,842] m-LoRA: Adapter lora_finqa_68 epoch: 1/1 iteration: 48/128 step: 4
[2025-12-23 17:51:39,168] m-LoRA: Adapter lora_finqa_64 loss: 0.2870970666408539
[2025-12-23 17:51:39,198] m-LoRA: Adapter lora_finqa_16 epoch: 1/1 iteration: 86/128 step: 44
[2025-12-23 17:51:39,404] m-LoRA: Adapter lora_finqa_55 loss: 2.11309552192688
[2025-12-23 17:51:39,408] m-LoRA: Adapter lora_finqa_45 epoch: 1/1 iteration: 108/128 step: 28
[2025-12-23 17:51:39,599] m-LoRA: Adapter lora_finqa_60 epoch: 1/1 iteration: 22/128 step: 12
[2025-12-23 17:51:39,631] m-LoRA: Adapter lora_finqa_40 loss: 0.016529016196727753
[2025-12-23 17:51:40,126] m-LoRA: Adapter lora_finqa_46 epoch: 1/1 iteration: 54/128 step: 28
[2025-12-23 17:51:40,184] m-LoRA: Adapter lora_finqa_65 loss: 0.262553334236145
[2025-12-23 17:51:40,421] m-LoRA: Adapter lora_finqa_37 epoch: 1/1 iteration: 70/128 step: 36
[2025-12-23 17:51:40,478] m-LoRA: Adapter lora_finqa_0 loss: 0.011175230145454407
[2025-12-23 17:51:40,708] m-LoRA: Adapter lora_finqa_3 loss: 0.011004522442817688
[2025-12-23 17:51:40,712] m-LoRA: Adapter lora_finqa_47 epoch: 1/1 iteration: 54/128 step: 28
[2025-12-23 17:51:41,466] m-LoRA: Adapter lora_finqa_61 epoch: 1/1 iteration: 22/128 step: 12
[2025-12-23 17:51:41,523] m-LoRA: Adapter lora_finqa_41 loss: 0.0330687016248703
[2025-12-23 17:51:41,888] m-LoRA: Adapter lora_finqa_1 loss: 0.010863319039344788
[2025-12-23 17:51:41,892] m-LoRA: Adapter lora_finqa_23 epoch: 1/1 iteration: 86/128 step: 44
[2025-12-23 17:51:42,260] m-LoRA: Adapter lora_finqa_51 loss: 0.018772920593619347
[2025-12-23 17:51:42,264] m-LoRA: Adapter lora_finqa_48 epoch: 1/1 iteration: 54/128 step: 28
[2025-12-23 17:51:42,896] m-LoRA: Adapter lora_finqa_25 epoch: 1/1 iteration: 86/128 step: 44
[2025-12-23 17:51:42,948] m-LoRA: Adapter lora_finqa_66 loss: 1.4816378355026245
[2025-12-23 17:51:43,196] m-LoRA: Adapter lora_finqa_62 epoch: 1/1 iteration: 44/128 step: 12
[2025-12-23 17:51:43,272] m-LoRA: Adapter lora_finqa_42 loss: 0.009099867194890976
[2025-12-23 17:51:43,589] m-LoRA: Adapter lora_finqa_7 loss: 0.00020885610138066113
[2025-12-23 17:51:43,593] m-LoRA: Adapter lora_finqa_63 epoch: 1/1 iteration: 44/128 step: 12
[2025-12-23 17:51:43,941] m-LoRA: Adapter lora_finqa_8 loss: 0.00021641394414473325
[2025-12-23 17:51:44,107] m-LoRA: Adapter lora_finqa_69 epoch: 1/1 iteration: 48/128 step: 4
[2025-12-23 17:51:45,309] m-LoRA: Adapter lora_finqa_64 epoch: 1/1 iteration: 44/128 step: 12
[2025-12-23 17:51:45,437] m-LoRA: Adapter lora_finqa_56 loss: 0.03600113093852997
[2025-12-23 17:51:46,600] m-LoRA: Adapter lora_finqa_55 epoch: 1/1 iteration: 38/128 step: 20
[2025-12-23 17:51:46,693] m-LoRA: Adapter lora_finqa_67 loss: 2.3365132808685303
[2025-12-23 17:51:46,965] m-LoRA: Adapter lora_finqa_57 loss: 1.0058680772781372
[2025-12-23 17:51:46,969] m-LoRA: Adapter lora_finqa_40 epoch: 1/1 iteration: 70/128 step: 36
[2025-12-23 17:51:48,198] m-LoRA: Adapter lora_finqa_65 epoch: 1/1 iteration: 44/128 step: 12
[2025-12-23 17:51:48,293] m-LoRA: Adapter lora_finqa_58 loss: 0.036297086626291275
[2025-12-23 17:51:48,565] m-LoRA: Adapter lora_finqa_36 loss: 0.01591765321791172
[2025-12-23 17:51:48,568] m-LoRA: Adapter lora_finqa_0 epoch: 1/1 iteration: 88/128 step: 45
[2025-12-23 17:51:48,826] m-LoRA: Adapter lora_finqa_15 loss: 8.11497593531385e-05
[2025-12-23 17:51:48,829] m-LoRA: Adapter lora_finqa_3 epoch: 1/1 iteration: 88/128 step: 45
[2025-12-23 17:51:53,721] m-LoRA: Adapter lora_finqa_41 epoch: 1/1 iteration: 112/128 step: 29
[2025-12-23 17:51:54,068] m-LoRA: Adapter lora_finqa_68 loss: 1.9977036714553833
[2025-12-23 17:51:54,085] m-LoRA: Adapter lora_finqa_1 epoch: 1/1 iteration: 88/128 step: 45
[2025-12-23 17:51:54,142] m-LoRA: Adapter lora_finqa_16 loss: 7.906986138550565e-05
[2025-12-23 17:51:54,643] m-LoRA: Adapter lora_finqa_51 epoch: 1/1 iteration: 40/128 step: 21
[2025-12-23 17:51:54,700] m-LoRA: Adapter lora_finqa_45 loss: 1.5918352603912354
[2025-12-23 17:51:54,977] m-LoRA: Adapter lora_finqa_60 loss: 1.0120636224746704
[2025-12-23 17:51:54,980] m-LoRA: Adapter lora_finqa_66 epoch: 1/1 iteration: 16/128 step: 5
[2025-12-23 17:51:55,530] m-LoRA: Adapter lora_finqa_46 loss: 0.010283288545906544
[2025-12-23 17:51:55,534] m-LoRA: Adapter lora_finqa_42 epoch: 1/1 iteration: 56/128 step: 29
[2025-12-23 17:51:55,793] m-LoRA: Adapter lora_finqa_37 loss: 0.015587248839437962
[2025-12-23 17:51:55,796] m-LoRA: Adapter lora_finqa_7 epoch: 1/1 iteration: 88/128 step: 45
[2025-12-23 17:51:56,088] m-LoRA: Adapter lora_finqa_47 loss: 0.0005827833083458245
[2025-12-23 17:51:56,092] m-LoRA: Adapter lora_finqa_8 epoch: 1/1 iteration: 88/128 step: 45
[2025-12-23 17:51:56,760] m-LoRA: Adapter lora_finqa_61 loss: 0.2006741315126419
[2025-12-23 17:51:56,763] m-LoRA: Adapter lora_finqa_56 epoch: 1/1 iteration: 96/128 step: 13
[2025-12-23 17:51:57,679] m-LoRA: Adapter lora_finqa_23 loss: 8.090276242000982e-05
[2025-12-23 17:51:57,809] m-LoRA: Adapter lora_finqa_67 epoch: 1/1 iteration: 32/128 step: 5
[2025-12-23 17:51:58,384] m-LoRA: Adapter lora_finqa_48 loss: 0.009371701627969742
[2025-12-23 17:51:58,518] m-LoRA: Adapter lora_finqa_57 epoch: 1/1 iteration: 24/128 step: 13
[2025-12-23 17:51:59,220] m-LoRA: Adapter lora_finqa_25 loss: 0.00018633573199622333
[2025-12-23 17:51:59,223] m-LoRA: Adapter lora_finqa_58 epoch: 1/1 iteration: 96/128 step: 13
[2025-12-23 17:52:00,498] m-LoRA: Adapter lora_finqa_36 epoch: 1/1 iteration: 72/128 step: 37
[2025-12-23 17:52:00,555] m-LoRA: Adapter lora_finqa_62 loss: 2.393402099609375
[2025-12-23 17:52:01,739] m-LoRA: Adapter lora_finqa_63 loss: 0.19317276775836945
[2025-12-23 17:52:01,744] m-LoRA: Adapter lora_finqa_15 epoch: 1/1 iteration: 88/128 step: 45
[2025-12-23 17:52:03,935] m-LoRA: Adapter lora_finqa_69 loss: 1.987776517868042
[2025-12-23 17:52:04,319] m-LoRA: Adapter lora_finqa_68 epoch: 1/1 iteration: 64/128 step: 5
[2025-12-23 17:52:04,671] m-LoRA: Adapter lora_finqa_64 loss: 0.19786429405212402
[2025-12-23 17:52:04,676] m-LoRA: Adapter lora_finqa_16 epoch: 1/1 iteration: 88/128 step: 45
[2025-12-23 17:52:05,099] m-LoRA: Adapter lora_finqa_55 loss: 2.0683751106262207
[2025-12-23 17:52:05,102] m-LoRA: Adapter lora_finqa_45 epoch: 1/1 iteration: 112/128 step: 29
[2025-12-23 17:52:05,625] m-LoRA: Adapter lora_finqa_40 loss: 0.015784481540322304
[2025-12-23 17:52:05,628] m-LoRA: Adapter lora_finqa_60 epoch: 1/1 iteration: 24/128 step: 13
[2025-12-23 17:52:06,180] m-LoRA: Adapter lora_finqa_46 epoch: 1/1 iteration: 56/128 step: 29
[2025-12-23 17:52:06,213] m-LoRA: Adapter lora_finqa_65 loss: 0.18807701766490936
[2025-12-23 17:52:06,481] m-LoRA: Adapter lora_finqa_0 loss: 0.011176462285220623
[2025-12-23 17:52:06,484] m-LoRA: Adapter lora_finqa_37 epoch: 1/1 iteration: 72/128 step: 37
[2025-12-23 17:52:06,909] m-LoRA: Adapter lora_finqa_3 loss: 0.010818579234182835
[2025-12-23 17:52:06,913] m-LoRA: Adapter lora_finqa_47 epoch: 1/1 iteration: 56/128 step: 29
[2025-12-23 17:52:07,728] m-LoRA: Adapter lora_finqa_61 epoch: 1/1 iteration: 24/128 step: 13
[2025-12-23 17:52:07,785] m-LoRA: Adapter lora_finqa_41 loss: 0.03009435534477234
[2025-12-23 17:52:08,460] m-LoRA: Adapter lora_finqa_1 loss: 0.010891583748161793
[2025-12-23 17:52:08,464] m-LoRA: Adapter lora_finqa_23 epoch: 1/1 iteration: 88/128 step: 45
[2025-12-23 17:52:09,072] m-LoRA: Adapter lora_finqa_51 loss: 0.01729772984981537
[2025-12-23 17:52:09,076] m-LoRA: Adapter lora_finqa_48 epoch: 1/1 iteration: 56/128 step: 29
[2025-12-23 17:52:09,717] m-LoRA: Adapter lora_finqa_25 epoch: 1/1 iteration: 88/128 step: 45
[2025-12-23 17:52:09,778] m-LoRA: Adapter lora_finqa_66 loss: 1.1913411617279053
[2025-12-23 17:52:10,027] m-LoRA: Adapter lora_finqa_42 loss: 0.008206830359995365
[2025-12-23 17:52:10,030] m-LoRA: Adapter lora_finqa_62 epoch: 1/1 iteration: 48/128 step: 13
[2025-12-23 17:52:10,379] m-LoRA: Adapter lora_finqa_7 loss: 0.00017705801292322576
[2025-12-23 17:52:10,382] m-LoRA: Adapter lora_finqa_63 epoch: 1/1 iteration: 48/128 step: 13
[2025-12-23 17:52:10,670] m-LoRA: Adapter lora_finqa_8 loss: 0.000199592046556063
[2025-12-23 17:52:10,826] m-LoRA: Adapter lora_finqa_69 epoch: 1/1 iteration: 64/128 step: 5
[2025-12-23 17:52:11,945] m-LoRA: Adapter lora_finqa_64 epoch: 1/1 iteration: 48/128 step: 13
[2025-12-23 17:52:12,110] m-LoRA: Adapter lora_finqa_56 loss: 0.025699088349938393
[2025-12-23 17:52:13,240] m-LoRA: Adapter lora_finqa_55 epoch: 1/1 iteration: 40/128 step: 21
[2025-12-23 17:52:13,312] m-LoRA: Adapter lora_finqa_67 loss: 2.197542190551758
[2025-12-23 17:52:13,547] m-LoRA: Adapter lora_finqa_57 loss: 0.8282404541969299
[2025-12-23 17:52:13,550] m-LoRA: Adapter lora_finqa_40 epoch: 1/1 iteration: 72/128 step: 37
[2025-12-23 17:52:14,713] m-LoRA: Adapter lora_finqa_65 epoch: 1/1 iteration: 48/128 step: 13
[2025-12-23 17:52:14,834] m-LoRA: Adapter lora_finqa_58 loss: 0.027516132220625877
[2025-12-23 17:52:15,199] m-LoRA: Adapter lora_finqa_36 loss: 0.015213318169116974
[2025-12-23 17:52:15,202] m-LoRA: Adapter lora_finqa_0 epoch: 1/1 iteration: 90/128 step: 46
[2025-12-23 17:52:15,463] m-LoRA: Adapter lora_finqa_3 epoch: 1/1 iteration: 90/128 step: 46
[2025-12-23 17:52:15,494] m-LoRA: Adapter lora_finqa_15 loss: 7.61093178880401e-05
[2025-12-23 17:52:17,854] m-LoRA: Adapter lora_finqa_41 epoch: 1/1 iteration: 116/128 step: 30
[2025-12-23 17:52:18,198] m-LoRA: Adapter lora_finqa_68 loss: 1.7159804105758667
[2025-12-23 17:52:18,215] m-LoRA: Adapter lora_finqa_1 epoch: 1/1 iteration: 90/128 step: 46
[2025-12-23 17:52:18,272] m-LoRA: Adapter lora_finqa_16 loss: 7.87330573075451e-05
[2025-12-23 17:52:18,810] m-LoRA: Adapter lora_finqa_45 loss: 1.5294936895370483
[2025-12-23 17:52:18,815] m-LoRA: Adapter lora_finqa_51 epoch: 1/1 iteration: 42/128 step: 22
[2025-12-23 17:52:19,086] m-LoRA: Adapter lora_finqa_60 loss: 0.8357940912246704
[2025-12-23 17:52:19,089] m-LoRA: Adapter lora_finqa_66 epoch: 1/1 iteration: 20/128 step: 6
[2025-12-23 17:52:19,346] m-LoRA: Adapter lora_finqa_46 loss: 0.009243179112672806
[2025-12-23 17:52:19,463] m-LoRA: Adapter lora_finqa_42 epoch: 1/1 iteration: 58/128 step: 30
[2025-12-23 17:52:19,675] m-LoRA: Adapter lora_finqa_37 loss: 0.015142541378736496
[2025-12-23 17:52:19,678] m-LoRA: Adapter lora_finqa_7 epoch: 1/1 iteration: 90/128 step: 46
[2025-12-23 17:52:20,000] m-LoRA: Adapter lora_finqa_47 loss: 0.0005594163085334003
[2025-12-23 17:52:20,003] m-LoRA: Adapter lora_finqa_8 epoch: 1/1 iteration: 90/128 step: 46
[2025-12-23 17:52:20,249] m-LoRA: Adapter lora_finqa_61 loss: 0.13675656914710999
[2025-12-23 17:52:20,361] m-LoRA: Adapter lora_finqa_56 epoch: 1/1 iteration: 104/128 step: 14
[2025-12-23 17:52:20,609] m-LoRA: Adapter lora_finqa_23 loss: 7.609990279888734e-05
[2025-12-23 17:52:20,723] m-LoRA: Adapter lora_finqa_67 epoch: 1/1 iteration: 40/128 step: 6
[2025-12-23 17:52:21,468] m-LoRA: Adapter lora_finqa_48 loss: 0.008435102179646492
[2025-12-23 17:52:21,471] m-LoRA: Adapter lora_finqa_57 epoch: 1/1 iteration: 26/128 step: 14
[2025-12-23 17:52:21,803] m-LoRA: Adapter lora_finqa_25 loss: 0.00016192771727219224
[2025-12-23 17:52:21,901] m-LoRA: Adapter lora_finqa_58 epoch: 1/1 iteration: 104/128 step: 14
[2025-12-23 17:52:22,462] m-LoRA: Adapter lora_finqa_36 epoch: 1/1 iteration: 74/128 step: 38
[2025-12-23 17:52:22,520] m-LoRA: Adapter lora_finqa_62 loss: 2.3618903160095215
[2025-12-23 17:52:23,168] m-LoRA: Adapter lora_finqa_15 epoch: 1/1 iteration: 90/128 step: 46
[2025-12-23 17:52:23,225] m-LoRA: Adapter lora_finqa_63 loss: 0.12725794315338135
[2025-12-23 17:52:27,872] m-LoRA: Adapter lora_finqa_69 loss: 1.7033088207244873
[2025-12-23 17:52:28,253] m-LoRA: Adapter lora_finqa_68 epoch: 1/1 iteration: 80/128 step: 6
[2025-12-23 17:52:28,993] m-LoRA: Adapter lora_finqa_16 epoch: 1/1 iteration: 90/128 step: 46
[2025-12-23 17:52:29,059] m-LoRA: Adapter lora_finqa_64 loss: 0.1338537186384201
[2025-12-23 17:52:29,349] m-LoRA: Adapter lora_finqa_55 loss: 2.01809024810791
[2025-12-23 17:52:29,352] m-LoRA: Adapter lora_finqa_45 epoch: 1/1 iteration: 116/128 step: 30
[2025-12-23 17:52:29,665] m-LoRA: Adapter lora_finqa_40 loss: 0.015028647147119045
[2025-12-23 17:52:29,668] m-LoRA: Adapter lora_finqa_60 epoch: 1/1 iteration: 26/128 step: 14
[2025-12-23 17:52:30,764] m-LoRA: Adapter lora_finqa_46 epoch: 1/1 iteration: 58/128 step: 30
[2025-12-23 17:52:30,828] m-LoRA: Adapter lora_finqa_65 loss: 0.11892592906951904
[2025-12-23 17:52:31,109] m-LoRA: Adapter lora_finqa_0 loss: 0.010731427930295467
[2025-12-23 17:52:31,112] m-LoRA: Adapter lora_finqa_37 epoch: 1/1 iteration: 74/128 step: 38
[2025-12-23 17:52:31,359] m-LoRA: Adapter lora_finqa_3 loss: 0.010045545175671577
[2025-12-23 17:52:31,363] m-LoRA: Adapter lora_finqa_47 epoch: 1/1 iteration: 58/128 step: 30
[2025-12-23 17:52:32,747] m-LoRA: Adapter lora_finqa_61 epoch: 1/1 iteration: 26/128 step: 14
[2025-12-23 17:52:32,803] m-LoRA: Adapter lora_finqa_41 loss: 0.02725309506058693
[2025-12-23 17:52:33,150] m-LoRA: Adapter lora_finqa_23 epoch: 1/1 iteration: 90/128 step: 46
[2025-12-23 17:52:33,205] m-LoRA: Adapter lora_finqa_1 loss: 0.011218576692044735
[2025-12-23 17:52:33,518] m-LoRA: Adapter lora_finqa_48 epoch: 1/1 iteration: 58/128 step: 30
[2025-12-23 17:52:33,575] m-LoRA: Adapter lora_finqa_51 loss: 0.015072878450155258
[2025-12-23 17:52:34,863] m-LoRA: Adapter lora_finqa_25 epoch: 1/1 iteration: 90/128 step: 46
[2025-12-23 17:52:34,919] m-LoRA: Adapter lora_finqa_66 loss: 0.7729088664054871
[2025-12-23 17:52:35,351] m-LoRA: Adapter lora_finqa_42 loss: 0.00716232368722558
[2025-12-23 17:52:35,354] m-LoRA: Adapter lora_finqa_62 epoch: 1/1 iteration: 52/128 step: 14
[2025-12-23 17:52:35,653] m-LoRA: Adapter lora_finqa_7 loss: 0.0001565769052831456
[2025-12-23 17:52:35,656] m-LoRA: Adapter lora_finqa_63 epoch: 1/1 iteration: 52/128 step: 14
[2025-12-23 17:52:36,308] m-LoRA: Adapter lora_finqa_8 loss: 0.00018361677939537913
[2025-12-23 17:52:36,469] m-LoRA: Adapter lora_finqa_69 epoch: 1/1 iteration: 80/128 step: 6
[2025-12-23 17:52:38,828] m-LoRA: Adapter lora_finqa_64 epoch: 1/1 iteration: 52/128 step: 14
[2025-12-23 17:52:38,933] m-LoRA: Adapter lora_finqa_56 loss: 0.01943483203649521
[2025-12-23 17:52:39,956] m-LoRA: Adapter lora_finqa_55 epoch: 1/1 iteration: 42/128 step: 22
[2025-12-23 17:52:40,022] m-LoRA: Adapter lora_finqa_67 loss: 2.0499930381774902
[2025-12-23 17:52:40,633] m-LoRA: Adapter lora_finqa_40 epoch: 1/1 iteration: 74/128 step: 38
[2025-12-23 17:52:40,672] m-LoRA: Adapter lora_finqa_57 loss: 0.6615157723426819
[2025-12-23 17:52:41,761] m-LoRA: Adapter lora_finqa_65 epoch: 1/1 iteration: 52/128 step: 14
[2025-12-23 17:52:41,925] m-LoRA: Adapter lora_finqa_58 loss: 0.020546967163681984
[2025-12-23 17:52:42,442] m-LoRA: Adapter lora_finqa_0 epoch: 1/1 iteration: 92/128 step: 47
[2025-12-23 17:52:42,496] m-LoRA: Adapter lora_finqa_36 loss: 0.015660136938095093
[2025-12-23 17:52:42,990] m-LoRA: Adapter lora_finqa_15 loss: 7.339764852076769e-05
[2025-12-23 17:52:42,993] m-LoRA: Adapter lora_finqa_3 epoch: 1/1 iteration: 92/128 step: 47
[2025-12-23 17:52:45,225] m-LoRA: Adapter lora_finqa_41 epoch: 1/1 iteration: 120/128 step: 31
[2025-12-23 17:52:45,454] m-LoRA: Adapter lora_finqa_68 loss: 1.401369571685791
[2025-12-23 17:52:45,975] m-LoRA: Adapter lora_finqa_16 loss: 7.079145143507048e-05
[2025-12-23 17:52:45,978] m-LoRA: Adapter lora_finqa_1 epoch: 1/1 iteration: 92/128 step: 47
[2025-12-23 17:52:46,525] m-LoRA: Adapter lora_finqa_51 epoch: 1/1 iteration: 44/128 step: 23
[2025-12-23 17:52:46,579] m-LoRA: Adapter lora_finqa_45 loss: 1.4631205797195435
[2025-12-23 17:52:47,059] m-LoRA: Adapter lora_finqa_66 epoch: 1/1 iteration: 24/128 step: 7
[2025-12-23 17:52:47,141] m-LoRA: Adapter lora_finqa_60 loss: 0.6695252656936646
[2025-12-23 17:52:47,347] m-LoRA: Adapter lora_finqa_42 epoch: 1/1 iteration: 60/128 step: 31
[2025-12-23 17:52:47,383] m-LoRA: Adapter lora_finqa_46 loss: 0.008321167901158333
[2025-12-23 17:52:47,898] m-LoRA: Adapter lora_finqa_7 epoch: 1/1 iteration: 92/128 step: 47
[2025-12-23 17:52:47,950] m-LoRA: Adapter lora_finqa_37 loss: 0.014426209032535553
[2025-12-23 17:52:48,741] m-LoRA: Adapter lora_finqa_8 epoch: 1/1 iteration: 92/128 step: 47
[2025-12-23 17:52:48,797] m-LoRA: Adapter lora_finqa_47 loss: 0.00038463337114080787
[2025-12-23 17:52:49,210] m-LoRA: Adapter lora_finqa_61 loss: 0.07986366748809814
[2025-12-23 17:52:49,214] m-LoRA: Adapter lora_finqa_56 epoch: 1/1 iteration: 112/128 step: 15
[2025-12-23 17:52:49,802] m-LoRA: Adapter lora_finqa_23 loss: 7.2518851084169e-05
[2025-12-23 17:52:49,919] m-LoRA: Adapter lora_finqa_67 epoch: 1/1 iteration: 48/128 step: 7
[2025-12-23 17:52:50,194] m-LoRA: Adapter lora_finqa_48 loss: 0.0075582657009363174
[2025-12-23 17:52:50,197] m-LoRA: Adapter lora_finqa_57 epoch: 1/1 iteration: 28/128 step: 15
[2025-12-23 17:52:50,553] m-LoRA: Adapter lora_finqa_25 loss: 0.0002490890910848975
[2025-12-23 17:52:50,672] m-LoRA: Adapter lora_finqa_58 epoch: 1/1 iteration: 112/128 step: 15
[2025-12-23 17:52:51,408] m-LoRA: Adapter lora_finqa_62 loss: 2.3237757682800293
[2025-12-23 17:52:51,413] m-LoRA: Adapter lora_finqa_36 epoch: 1/1 iteration: 76/128 step: 39
[2025-12-23 17:52:51,986] m-LoRA: Adapter lora_finqa_63 loss: 0.07509426027536392
[2025-12-23 17:52:51,992] m-LoRA: Adapter lora_finqa_15 epoch: 1/1 iteration: 92/128 step: 47
[2025-12-23 17:52:54,331] m-LoRA: Adapter lora_finqa_69 loss: 1.391958236694336
[2025-12-23 17:52:54,718] m-LoRA: Adapter lora_finqa_68 epoch: 1/1 iteration: 96/128 step: 7
[2025-12-23 17:52:55,106] m-LoRA: Adapter lora_finqa_64 loss: 0.07810622453689575
[2025-12-23 17:52:55,111] m-LoRA: Adapter lora_finqa_16 epoch: 1/1 iteration: 92/128 step: 47
[2025-12-23 17:52:55,331] m-LoRA: Adapter lora_finqa_55 loss: 1.9678717851638794
[2025-12-23 17:52:55,335] m-LoRA: Adapter lora_finqa_45 epoch: 1/1 iteration: 120/128 step: 31
[2025-12-23 17:52:55,485] m-LoRA: Adapter lora_finqa_40 loss: 0.014366062358021736
[2025-12-23 17:52:55,489] m-LoRA: Adapter lora_finqa_60 epoch: 1/1 iteration: 28/128 step: 15
[2025-12-23 17:52:55,979] m-LoRA: Adapter lora_finqa_46 epoch: 1/1 iteration: 60/128 step: 31
[2025-12-23 17:52:56,034] m-LoRA: Adapter lora_finqa_65 loss: 0.0697915181517601
[2025-12-23 17:52:56,291] m-LoRA: Adapter lora_finqa_0 loss: 0.009848421439528465
[2025-12-23 17:52:56,294] m-LoRA: Adapter lora_finqa_37 epoch: 1/1 iteration: 76/128 step: 39
[2025-12-23 17:52:56,554] m-LoRA: Adapter lora_finqa_3 loss: 0.00961089227348566
[2025-12-23 17:52:56,558] m-LoRA: Adapter lora_finqa_47 epoch: 1/1 iteration: 60/128 step: 31
[2025-12-23 17:52:57,285] m-LoRA: Adapter lora_finqa_41 loss: 0.024697715416550636
[2025-12-23 17:52:57,290] m-LoRA: Adapter lora_finqa_61 epoch: 1/1 iteration: 28/128 step: 15
[2025-12-23 17:52:57,714] m-LoRA: Adapter lora_finqa_1 loss: 0.010079125873744488
[2025-12-23 17:52:57,717] m-LoRA: Adapter lora_finqa_23 epoch: 1/1 iteration: 92/128 step: 47
[2025-12-23 17:52:58,131] m-LoRA: Adapter lora_finqa_51 loss: 0.013846589252352715
[2025-12-23 17:52:58,135] m-LoRA: Adapter lora_finqa_48 epoch: 1/1 iteration: 60/128 step: 31
[2025-12-23 17:52:58,822] m-LoRA: Adapter lora_finqa_25 epoch: 1/1 iteration: 92/128 step: 47
[2025-12-23 17:52:58,880] m-LoRA: Adapter lora_finqa_66 loss: 0.5245078802108765
[2025-12-23 17:52:59,182] m-LoRA: Adapter lora_finqa_42 loss: 0.00713598495349288
[2025-12-23 17:52:59,185] m-LoRA: Adapter lora_finqa_62 epoch: 1/1 iteration: 56/128 step: 15
[2025-12-23 17:52:59,545] m-LoRA: Adapter lora_finqa_7 loss: 0.00013504135131370276
[2025-12-23 17:52:59,549] m-LoRA: Adapter lora_finqa_63 epoch: 1/1 iteration: 56/128 step: 15
[2025-12-23 17:52:59,873] m-LoRA: Adapter lora_finqa_8 loss: 0.00012214272283017635
[2025-12-23 17:53:00,029] m-LoRA: Adapter lora_finqa_69 epoch: 1/1 iteration: 96/128 step: 7
[2025-12-23 17:53:01,192] m-LoRA: Adapter lora_finqa_56 loss: 0.01587102934718132
[2025-12-23 17:53:01,227] m-LoRA: Adapter lora_finqa_64 epoch: 1/1 iteration: 56/128 step: 15
[2025-12-23 17:53:02,404] m-LoRA: Adapter lora_finqa_55 epoch: 1/1 iteration: 44/128 step: 23
[2025-12-23 17:53:02,517] m-LoRA: Adapter lora_finqa_67 loss: 1.896218180656433
[2025-12-23 17:53:02,756] m-LoRA: Adapter lora_finqa_57 loss: 0.5270063281059265
[2025-12-23 17:53:02,759] m-LoRA: Adapter lora_finqa_40 epoch: 1/1 iteration: 76/128 step: 39
[2025-12-23 17:53:03,842] m-LoRA: Adapter lora_finqa_65 epoch: 1/1 iteration: 56/128 step: 15
[2025-12-23 17:53:03,936] m-LoRA: Adapter lora_finqa_58 loss: 0.016336804255843163
[2025-12-23 17:53:04,209] m-LoRA: Adapter lora_finqa_36 loss: 0.014308793470263481
[2025-12-23 17:53:04,212] m-LoRA: Adapter lora_finqa_0 epoch: 1/1 iteration: 94/128 step: 48
[2025-12-23 17:53:04,570] m-LoRA: Adapter lora_finqa_15 loss: 6.966891669435427e-05
[2025-12-23 17:53:04,574] m-LoRA: Adapter lora_finqa_3 epoch: 1/1 iteration: 94/128 step: 48
[2025-12-23 17:53:06,988] m-LoRA: Adapter lora_finqa_41 epoch: 1/1 iteration: 124/128 step: 32
[2025-12-23 17:53:07,201] m-LoRA: Adapter lora_finqa_68 loss: 1.1254392862319946
[2025-12-23 17:53:07,709] m-LoRA: Adapter lora_finqa_16 loss: 6.834230589447543e-05
[2025-12-23 17:53:07,713] m-LoRA: Adapter lora_finqa_1 epoch: 1/1 iteration: 94/128 step: 48
[2025-12-23 17:53:08,169] m-LoRA: Adapter lora_finqa_51 epoch: 1/1 iteration: 46/128 step: 24
[2025-12-23 17:53:08,203] m-LoRA: Adapter lora_finqa_45 loss: 1.3901218175888062
[2025-12-23 17:53:08,444] m-LoRA: Adapter lora_finqa_60 loss: 0.5359005331993103
[2025-12-23 17:53:08,447] m-LoRA: Adapter lora_finqa_66 epoch: 1/1 iteration: 28/128 step: 8
[2025-12-23 17:53:08,706] m-LoRA: Adapter lora_finqa_46 loss: 0.009175384417176247
[2025-12-23 17:53:08,709] m-LoRA: Adapter lora_finqa_42 epoch: 1/1 iteration: 62/128 step: 32
[2025-12-23 17:53:08,996] m-LoRA: Adapter lora_finqa_37 loss: 0.014019623398780823
[2025-12-23 17:53:09,000] m-LoRA: Adapter lora_finqa_7 epoch: 1/1 iteration: 94/128 step: 48
[2025-12-23 17:53:09,295] m-LoRA: Adapter lora_finqa_47 loss: 0.0002522592549212277
[2025-12-23 17:53:09,298] m-LoRA: Adapter lora_finqa_8 epoch: 1/1 iteration: 94/128 step: 48
[2025-12-23 17:53:09,558] m-LoRA: Adapter lora_finqa_61 loss: 0.053051870316267014
[2025-12-23 17:53:09,692] m-LoRA: Adapter lora_finqa_56 epoch: 1/1 iteration: 120/128 step: 16
[2025-12-23 17:53:10,247] m-LoRA: Adapter lora_finqa_23 loss: 6.734234193572775e-05
[2025-12-23 17:53:10,347] m-LoRA: Adapter lora_finqa_67 epoch: 1/1 iteration: 56/128 step: 8
[2025-12-23 17:53:10,714] m-LoRA: Adapter lora_finqa_48 loss: 0.0067966110073029995
[2025-12-23 17:53:10,718] m-LoRA: Adapter lora_finqa_57 epoch: 1/1 iteration: 30/128 step: 16
[2025-12-23 17:53:11,085] m-LoRA: Adapter lora_finqa_25 loss: 0.00016905252414289862
[2025-12-23 17:53:11,213] m-LoRA: Adapter lora_finqa_58 epoch: 1/1 iteration: 120/128 step: 16
[2025-12-23 17:53:11,819] m-LoRA: Adapter lora_finqa_36 epoch: 1/1 iteration: 78/128 step: 40
[2025-12-23 17:53:11,876] m-LoRA: Adapter lora_finqa_62 loss: 2.2847580909729004
[2025-12-23 17:53:13,237] m-LoRA: Adapter lora_finqa_15 epoch: 1/1 iteration: 94/128 step: 48
[2025-12-23 17:53:13,293] m-LoRA: Adapter lora_finqa_63 loss: 0.04716752469539642
[2025-12-23 17:53:17,671] m-LoRA: Adapter lora_finqa_69 loss: 1.0886698961257935
[2025-12-23 17:53:18,054] m-LoRA: Adapter lora_finqa_68 epoch: 1/1 iteration: 112/128 step: 8
[2025-12-23 17:53:18,418] m-LoRA: Adapter lora_finqa_64 loss: 0.050896573811769485
[2025-12-23 17:53:18,423] m-LoRA: Adapter lora_finqa_16 epoch: 1/1 iteration: 94/128 step: 48
[2025-12-23 17:53:18,820] m-LoRA: Adapter lora_finqa_45 epoch: 1/1 iteration: 124/128 step: 32
[2025-12-23 17:53:18,893] m-LoRA: Adapter lora_finqa_55 loss: 1.9127851724624634
[2025-12-23 17:53:19,376] m-LoRA: Adapter lora_finqa_60 epoch: 1/1 iteration: 30/128 step: 16
[2025-12-23 17:53:19,429] m-LoRA: Adapter lora_finqa_40 loss: 0.014329451136291027
[2025-12-23 17:53:20,503] m-LoRA: Adapter lora_finqa_65 loss: 0.045491624623537064
[2025-12-23 17:53:20,509] m-LoRA: Adapter lora_finqa_46 epoch: 1/1 iteration: 62/128 step: 32
[2025-12-23 17:53:21,634] m-LoRA: Adapter lora_finqa_0 loss: 0.009733377024531364
[2025-12-23 17:53:21,637] m-LoRA: Adapter lora_finqa_37 epoch: 1/1 iteration: 78/128 step: 40
[2025-12-23 17:53:22,026] m-LoRA: Adapter lora_finqa_47 epoch: 1/1 iteration: 62/128 step: 32
[2025-12-23 17:53:22,089] m-LoRA: Adapter lora_finqa_3 loss: 0.009053402580320835
[2025-12-23 17:53:23,223] m-LoRA: Adapter lora_finqa_61 epoch: 1/1 iteration: 30/128 step: 16
[2025-12-23 17:53:23,280] m-LoRA: Adapter lora_finqa_41 loss: 0.02266683802008629
[2025-12-23 17:53:23,582] m-LoRA: Adapter lora_finqa_23 epoch: 1/1 iteration: 94/128 step: 48
[2025-12-23 17:53:23,635] m-LoRA: Adapter lora_finqa_1 loss: 0.008958566002547741
[2025-12-23 17:53:23,950] m-LoRA: Adapter lora_finqa_51 loss: 0.013760159723460674
[2025-12-23 17:53:23,953] m-LoRA: Adapter lora_finqa_48 epoch: 1/1 iteration: 62/128 step: 32
[2025-12-23 17:53:24,893] m-LoRA: Adapter lora_finqa_25 epoch: 1/1 iteration: 94/128 step: 48
[2025-12-23 17:53:24,950] m-LoRA: Adapter lora_finqa_66 loss: 0.3335127830505371
[2025-12-23 17:53:25,245] m-LoRA: Adapter lora_finqa_42 loss: 0.005986500531435013
[2025-12-23 17:53:25,248] m-LoRA: Adapter lora_finqa_62 epoch: 1/1 iteration: 60/128 step: 16
[2025-12-23 17:53:25,835] m-LoRA: Adapter lora_finqa_7 loss: 0.00012258310744073242
[2025-12-23 17:53:25,838] m-LoRA: Adapter lora_finqa_63 epoch: 1/1 iteration: 60/128 step: 16
[2025-12-23 17:53:26,539] m-LoRA: Adapter lora_finqa_8 loss: 0.00011002782412106171
[2025-12-23 17:53:26,695] m-LoRA: Adapter lora_finqa_69 epoch: 1/1 iteration: 112/128 step: 8
[2025-12-23 17:53:27,674] m-LoRA: Adapter lora_finqa_64 epoch: 1/1 iteration: 60/128 step: 16
[2025-12-23 17:53:27,776] m-LoRA: Adapter lora_finqa_56 loss: 0.013410655781626701
[2025-12-23 17:53:28,802] m-LoRA: Adapter lora_finqa_55 epoch: 1/1 iteration: 46/128 step: 24
[2025-12-23 17:53:28,902] m-LoRA: Adapter lora_finqa_67 loss: 1.731859564781189
[2025-12-23 17:53:29,530] m-LoRA: Adapter lora_finqa_40 epoch: 1/1 iteration: 78/128 step: 40
[2025-12-23 17:53:29,560] m-LoRA: Adapter lora_finqa_57 loss: 0.41703328490257263
[2025-12-23 17:53:30,638] m-LoRA: Adapter lora_finqa_65 epoch: 1/1 iteration: 60/128 step: 16
[2025-12-23 17:53:30,731] m-LoRA: Adapter lora_finqa_58 loss: 0.01386311650276184
[2025-12-23 17:53:31,357] m-LoRA: Adapter lora_finqa_36 loss: 0.013910524547100067
[2025-12-23 17:53:31,360] m-LoRA: Adapter lora_finqa_0 epoch: 1/1 iteration: 96/128 step: 49
[2025-12-23 17:53:31,879] m-LoRA: Adapter lora_finqa_15 loss: 6.587688403669745e-05
[2025-12-23 17:53:31,882] m-LoRA: Adapter lora_finqa_3 epoch: 1/1 iteration: 96/128 step: 49
[2025-12-23 17:53:34,007] m-LoRA: Finish and base model offload adapter - ['lora_finqa_41']
[2025-12-23 17:53:34,403] m-LoRA: Adapter lora_finqa_68 loss: 0.8242958188056946
[2025-12-23 17:53:34,419] m-LoRA: Task to running, need to load adapters: ['lora_finqa_70']
[2025-12-23 17:53:34,863] m-LoRA: Adapter lora_finqa_70 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:53:34,969] m-LoRA: Adapter lora_finqa_16 loss: 6.55156109132804e-05
[2025-12-23 17:53:34,972] m-LoRA: Adapter lora_finqa_1 epoch: 1/1 iteration: 96/128 step: 49
[2025-12-23 17:53:35,212] m-LoRA: Adapter lora_finqa_51 epoch: 1/1 iteration: 48/128 step: 25
[2025-12-23 17:53:35,269] m-LoRA: Adapter lora_finqa_45 loss: 1.3102805614471436
[2025-12-23 17:53:35,782] m-LoRA: Adapter lora_finqa_60 loss: 0.4231591820716858
[2025-12-23 17:53:35,785] m-LoRA: Adapter lora_finqa_66 epoch: 1/1 iteration: 32/128 step: 9
[2025-12-23 17:53:36,060] m-LoRA: Adapter lora_finqa_46 loss: 0.006664479151368141
[2025-12-23 17:53:36,063] m-LoRA: Adapter lora_finqa_42 epoch: 1/1 iteration: 64/128 step: 33
[2025-12-23 17:53:36,338] m-LoRA: Adapter lora_finqa_37 loss: 0.013658729381859303
[2025-12-23 17:53:36,341] m-LoRA: Adapter lora_finqa_7 epoch: 1/1 iteration: 96/128 step: 49
[2025-12-23 17:53:36,899] m-LoRA: Adapter lora_finqa_47 loss: 0.00021115636627655476
[2025-12-23 17:53:36,902] m-LoRA: Adapter lora_finqa_8 epoch: 1/1 iteration: 96/128 step: 49
[2025-12-23 17:53:37,327] m-LoRA: Adapter lora_finqa_61 loss: 0.03841960057616234
[2025-12-23 17:53:37,453] m-LoRA: Finish and base model offload adapter - ['lora_finqa_56']
[2025-12-23 17:53:38,215] m-LoRA: Adapter lora_finqa_23 loss: 6.425382161978632e-05
[2025-12-23 17:53:38,270] m-LoRA: Task to running, need to load adapters: ['lora_finqa_71']
[2025-12-23 17:53:38,412] m-LoRA: Adapter lora_finqa_71 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:53:38,712] m-LoRA: Adapter lora_finqa_48 loss: 0.0057076564989984035
[2025-12-23 17:53:38,716] m-LoRA: Adapter lora_finqa_67 epoch: 1/1 iteration: 64/128 step: 9
[2025-12-23 17:53:38,996] m-LoRA: Adapter lora_finqa_25 loss: 0.00011880081729032099
[2025-12-23 17:53:38,999] m-LoRA: Adapter lora_finqa_57 epoch: 1/1 iteration: 32/128 step: 17
[2025-12-23 17:53:39,215] m-LoRA: Finish and base model offload adapter - ['lora_finqa_58']
[2025-12-23 17:53:39,967] m-LoRA: Adapter lora_finqa_62 loss: 2.242727279663086
[2025-12-23 17:53:39,972] m-LoRA: Task to running, need to load adapters: ['lora_finqa_72']
[2025-12-23 17:53:40,165] m-LoRA: Adapter lora_finqa_72 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:53:40,257] m-LoRA: Adapter lora_finqa_36 epoch: 1/1 iteration: 80/128 step: 41
[2025-12-23 17:53:40,417] m-LoRA: Adapter lora_finqa_15 epoch: 1/1 iteration: 96/128 step: 49
[2025-12-23 17:53:40,473] m-LoRA: Adapter lora_finqa_63 loss: 0.03596468269824982
[2025-12-23 17:53:42,972] m-LoRA: Adapter lora_finqa_69 loss: 0.7996329665184021
[2025-12-23 17:53:43,355] m-LoRA: Finish and base model offload adapter - ['lora_finqa_68']
[2025-12-23 17:53:43,908] m-LoRA: Adapter lora_finqa_64 loss: 0.03794734552502632
[2025-12-23 17:53:43,914] m-LoRA: Task to running, need to load adapters: ['lora_finqa_73']
[2025-12-23 17:53:44,168] m-LoRA: Adapter lora_finqa_73 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:53:44,456] m-LoRA: Adapter lora_finqa_55 loss: 1.8575557470321655
[2025-12-23 17:53:44,460] m-LoRA: Adapter lora_finqa_16 epoch: 1/1 iteration: 96/128 step: 49
[2025-12-23 17:53:44,612] m-LoRA: Finish and base model offload adapter - ['lora_finqa_45']
[2025-12-23 17:53:44,987] m-LoRA: Adapter lora_finqa_40 loss: 0.013843324966728687
[2025-12-23 17:53:45,025] m-LoRA: Task to running, need to load adapters: ['lora_finqa_74']
[2025-12-23 17:53:45,215] m-LoRA: Adapter lora_finqa_74 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:53:45,371] m-LoRA: Adapter lora_finqa_65 loss: 0.03582322597503662
[2025-12-23 17:53:45,379] m-LoRA: Adapter lora_finqa_60 epoch: 1/1 iteration: 32/128 step: 17
[2025-12-23 17:53:45,554] m-LoRA: Adapter lora_finqa_0 loss: 0.009353822097182274
[2025-12-23 17:53:45,557] m-LoRA: Adapter lora_finqa_46 epoch: 1/1 iteration: 64/128 step: 33
[2025-12-23 17:53:45,688] m-LoRA: Adapter lora_finqa_3 loss: 0.008517010137438774
[2025-12-23 17:53:45,691] m-LoRA: Adapter lora_finqa_37 epoch: 1/1 iteration: 80/128 step: 41
[2025-12-23 17:53:46,064] m-LoRA: Adapter lora_finqa_70 loss: 2.5885283946990967
[2025-12-23 17:53:46,067] m-LoRA: Adapter lora_finqa_47 epoch: 1/1 iteration: 64/128 step: 33
[2025-12-23 17:53:46,207] m-LoRA: Adapter lora_finqa_61 epoch: 1/1 iteration: 32/128 step: 17
[2025-12-23 17:53:46,385] m-LoRA: Adapter lora_finqa_23 epoch: 1/1 iteration: 96/128 step: 49
[2025-12-23 17:53:46,443] m-LoRA: Adapter lora_finqa_1 loss: 0.008725030347704887
[2025-12-23 17:53:46,874] m-LoRA: Adapter lora_finqa_51 loss: 0.011790734715759754
[2025-12-23 17:53:46,878] m-LoRA: Adapter lora_finqa_48 epoch: 1/1 iteration: 64/128 step: 33
[2025-12-23 17:53:47,494] m-LoRA: Adapter lora_finqa_25 epoch: 1/1 iteration: 96/128 step: 49
[2025-12-23 17:53:47,548] m-LoRA: Adapter lora_finqa_66 loss: 0.21468906104564667
[2025-12-23 17:53:47,814] m-LoRA: Adapter lora_finqa_42 loss: 0.005412181839346886
[2025-12-23 17:53:47,817] m-LoRA: Adapter lora_finqa_62 epoch: 1/1 iteration: 64/128 step: 17
[2025-12-23 17:53:48,161] m-LoRA: Adapter lora_finqa_7 loss: 0.00011534228542586789
[2025-12-23 17:53:48,164] m-LoRA: Adapter lora_finqa_63 epoch: 1/1 iteration: 64/128 step: 17
[2025-12-23 17:53:48,457] m-LoRA: Adapter lora_finqa_8 loss: 0.00010111685696756467
[2025-12-23 17:53:48,612] m-LoRA: Finish and base model offload adapter - ['lora_finqa_69']
[2025-12-23 17:53:48,942] m-LoRA: Task to running, need to load adapters: ['lora_finqa_75']
[2025-12-23 17:53:49,009] m-LoRA: Adapter lora_finqa_75 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:53:49,704] m-LoRA: Adapter lora_finqa_64 epoch: 1/1 iteration: 64/128 step: 17
[2025-12-23 17:53:49,797] m-LoRA: Adapter lora_finqa_71 loss: 2.588528633117676
[2025-12-23 17:53:50,889] m-LoRA: Adapter lora_finqa_55 epoch: 1/1 iteration: 48/128 step: 25
[2025-12-23 17:53:50,950] m-LoRA: Adapter lora_finqa_67 loss: 1.5477148294448853
[2025-12-23 17:53:51,230] m-LoRA: Adapter lora_finqa_57 loss: 0.3276152014732361
[2025-12-23 17:53:51,233] m-LoRA: Adapter lora_finqa_40 epoch: 1/1 iteration: 80/128 step: 41
[2025-12-23 17:53:51,760] m-LoRA: Adapter lora_finqa_65 epoch: 1/1 iteration: 64/128 step: 17
[2025-12-23 17:53:51,818] m-LoRA: Adapter lora_finqa_72 loss: 2.5885279178619385
[2025-12-23 17:53:52,047] m-LoRA: Adapter lora_finqa_36 loss: 0.013773463666439056
[2025-12-23 17:53:52,051] m-LoRA: Adapter lora_finqa_0 epoch: 1/1 iteration: 98/128 step: 50
[2025-12-23 17:53:52,404] m-LoRA: Adapter lora_finqa_15 loss: 7.74633590481244e-05
[2025-12-23 17:53:52,407] m-LoRA: Adapter lora_finqa_3 epoch: 1/1 iteration: 98/128 step: 50
[2025-12-23 17:53:56,595] m-LoRA: Adapter lora_finqa_70 epoch: 1/1 iteration: 2/128 step: 2
[2025-12-23 17:53:56,812] m-LoRA: Adapter lora_finqa_73 loss: 2.5885279178619385
[2025-12-23 17:53:56,941] m-LoRA: Adapter lora_finqa_16 loss: 6.325290451059118e-05
[2025-12-23 17:53:56,944] m-LoRA: Adapter lora_finqa_1 epoch: 1/1 iteration: 98/128 step: 50
[2025-12-23 17:53:57,366] m-LoRA: Adapter lora_finqa_74 loss: 2.5885283946990967
[2025-12-23 17:53:57,369] m-LoRA: Adapter lora_finqa_51 epoch: 1/1 iteration: 50/128 step: 26
[2025-12-23 17:53:57,636] m-LoRA: Adapter lora_finqa_60 loss: 0.3379957675933838
[2025-12-23 17:53:57,640] m-LoRA: Adapter lora_finqa_66 epoch: 1/1 iteration: 36/128 step: 10
[2025-12-23 17:53:57,896] m-LoRA: Adapter lora_finqa_46 loss: 0.006163288839161396
[2025-12-23 17:53:57,899] m-LoRA: Adapter lora_finqa_42 epoch: 1/1 iteration: 66/128 step: 34
[2025-12-23 17:53:58,156] m-LoRA: Adapter lora_finqa_7 epoch: 1/1 iteration: 98/128 step: 50
[2025-12-23 17:53:58,193] m-LoRA: Adapter lora_finqa_37 loss: 0.014133498072624207
[2025-12-23 17:53:58,469] m-LoRA: Adapter lora_finqa_47 loss: 0.00020611703803297132
[2025-12-23 17:53:58,473] m-LoRA: Adapter lora_finqa_8 epoch: 1/1 iteration: 98/128 step: 50
[2025-12-23 17:53:58,739] m-LoRA: Adapter lora_finqa_61 loss: 0.031459204852581024
[2025-12-23 17:53:58,838] m-LoRA: Adapter lora_finqa_71 epoch: 1/1 iteration: 8/128 step: 2
[2025-12-23 17:53:59,086] m-LoRA: Adapter lora_finqa_23 loss: 6.103655323386192e-05
[2025-12-23 17:53:59,180] m-LoRA: Adapter lora_finqa_67 epoch: 1/1 iteration: 72/128 step: 10
[2025-12-23 17:53:59,469] m-LoRA: Adapter lora_finqa_48 loss: 0.004775157663971186
[2025-12-23 17:53:59,472] m-LoRA: Adapter lora_finqa_57 epoch: 1/1 iteration: 34/128 step: 18
[2025-12-23 17:54:00,228] m-LoRA: Adapter lora_finqa_25 loss: 0.00010653822391759604
[2025-12-23 17:54:00,232] m-LoRA: Adapter lora_finqa_72 epoch: 1/1 iteration: 4/128 step: 2
[2025-12-23 17:54:00,934] m-LoRA: Adapter lora_finqa_62 loss: 2.200223922729492
[2025-12-23 17:54:00,940] m-LoRA: Adapter lora_finqa_36 epoch: 1/1 iteration: 82/128 step: 42
[2025-12-23 17:54:01,575] m-LoRA: Adapter lora_finqa_63 loss: 0.029652254655957222
[2025-12-23 17:54:01,581] m-LoRA: Adapter lora_finqa_15 epoch: 1/1 iteration: 98/128 step: 50
[2025-12-23 17:54:04,045] m-LoRA: Adapter lora_finqa_75 loss: 2.588528633117676
[2025-12-23 17:54:04,329] m-LoRA: Adapter lora_finqa_73 epoch: 1/1 iteration: 16/128 step: 2
[2025-12-23 17:54:05,332] m-LoRA: Adapter lora_finqa_64 loss: 0.0306033156812191
[2025-12-23 17:54:05,338] m-LoRA: Adapter lora_finqa_16 epoch: 1/1 iteration: 98/128 step: 50
[2025-12-23 17:54:05,596] m-LoRA: Adapter lora_finqa_55 loss: 1.7971073389053345
[2025-12-23 17:54:05,599] m-LoRA: Adapter lora_finqa_74 epoch: 1/1 iteration: 2/128 step: 2
[2025-12-23 17:54:06,031] m-LoRA: Adapter lora_finqa_40 loss: 0.013661503791809082
[2025-12-23 17:54:06,034] m-LoRA: Adapter lora_finqa_60 epoch: 1/1 iteration: 34/128 step: 18
[2025-12-23 17:54:07,460] m-LoRA: Adapter lora_finqa_65 loss: 0.029201989993453026
[2025-12-23 17:54:07,465] m-LoRA: Adapter lora_finqa_46 epoch: 1/1 iteration: 66/128 step: 34
[2025-12-23 17:54:08,021] m-LoRA: Adapter lora_finqa_0 loss: 0.008316991850733757
[2025-12-23 17:54:08,024] m-LoRA: Adapter lora_finqa_37 epoch: 1/1 iteration: 82/128 step: 42
[2025-12-23 17:54:08,621] m-LoRA: Adapter lora_finqa_3 loss: 0.008441000245511532
[2025-12-23 17:54:08,624] m-LoRA: Adapter lora_finqa_47 epoch: 1/1 iteration: 66/128 step: 34
[2025-12-23 17:54:08,925] m-LoRA: Adapter lora_finqa_61 epoch: 1/1 iteration: 34/128 step: 18
[2025-12-23 17:54:08,976] m-LoRA: Adapter lora_finqa_70 loss: 2.471407413482666
[2025-12-23 17:54:09,660] m-LoRA: Adapter lora_finqa_1 loss: 0.007909558713436127
[2025-12-23 17:54:09,663] m-LoRA: Adapter lora_finqa_23 epoch: 1/1 iteration: 98/128 step: 50
[2025-12-23 17:54:10,030] m-LoRA: Adapter lora_finqa_51 loss: 0.011031607165932655
[2025-12-23 17:54:10,034] m-LoRA: Adapter lora_finqa_48 epoch: 1/1 iteration: 66/128 step: 34
[2025-12-23 17:54:11,174] m-LoRA: Adapter lora_finqa_66 loss: 0.11275387555360794
[2025-12-23 17:54:11,180] m-LoRA: Adapter lora_finqa_25 epoch: 1/1 iteration: 98/128 step: 50
[2025-12-23 17:54:11,915] m-LoRA: Adapter lora_finqa_42 loss: 0.004714134149253368
[2025-12-23 17:54:11,918] m-LoRA: Adapter lora_finqa_62 epoch: 1/1 iteration: 68/128 step: 18
[2025-12-23 17:54:12,199] m-LoRA: Adapter lora_finqa_7 loss: 0.00011095635272795334
[2025-12-23 17:54:12,202] m-LoRA: Adapter lora_finqa_63 epoch: 1/1 iteration: 68/128 step: 18
[2025-12-23 17:54:12,798] m-LoRA: Adapter lora_finqa_8 loss: 0.00010574552288744599
[2025-12-23 17:54:12,918] m-LoRA: Adapter lora_finqa_75 epoch: 1/1 iteration: 8/128 step: 2
[2025-12-23 17:54:13,935] m-LoRA: Adapter lora_finqa_64 epoch: 1/1 iteration: 68/128 step: 18
[2025-12-23 17:54:14,020] m-LoRA: Adapter lora_finqa_71 loss: 2.4749326705932617
[2025-12-23 17:54:14,985] m-LoRA: Adapter lora_finqa_55 epoch: 1/1 iteration: 50/128 step: 26
[2025-12-23 17:54:15,047] m-LoRA: Adapter lora_finqa_67 loss: 1.3882989883422852
[2025-12-23 17:54:15,654] m-LoRA: Adapter lora_finqa_40 epoch: 1/1 iteration: 82/128 step: 42
[2025-12-23 17:54:15,708] m-LoRA: Adapter lora_finqa_57 loss: 0.2613206207752228
[2025-12-23 17:54:16,235] m-LoRA: Adapter lora_finqa_72 loss: 2.58429217338562
[2025-12-23 17:54:16,241] m-LoRA: Adapter lora_finqa_65 epoch: 1/1 iteration: 68/128 step: 18
[2025-12-23 17:54:16,881] m-LoRA: Adapter lora_finqa_36 loss: 0.013689789921045303
[2025-12-23 17:54:16,884] m-LoRA: Adapter lora_finqa_0 epoch: 1/1 iteration: 100/128 step: 51
[2025-12-23 17:54:17,538] m-LoRA: Adapter lora_finqa_15 loss: 6.534144631586969e-05
[2025-12-23 17:54:17,542] m-LoRA: Adapter lora_finqa_3 epoch: 1/1 iteration: 100/128 step: 51
[2025-12-23 17:54:19,639] m-LoRA: Adapter lora_finqa_70 epoch: 1/1 iteration: 4/128 step: 3
[2025-12-23 17:54:19,842] m-LoRA: Adapter lora_finqa_73 loss: 2.4771158695220947
[2025-12-23 17:54:20,371] m-LoRA: Adapter lora_finqa_16 loss: 6.026566188666038e-05
[2025-12-23 17:54:20,374] m-LoRA: Adapter lora_finqa_1 epoch: 1/1 iteration: 100/128 step: 51
[2025-12-23 17:54:20,951] m-LoRA: Adapter lora_finqa_74 loss: 2.3148791790008545
[2025-12-23 17:54:20,955] m-LoRA: Adapter lora_finqa_51 epoch: 1/1 iteration: 52/128 step: 27
[2025-12-23 17:54:21,254] m-LoRA: Adapter lora_finqa_60 loss: 0.26242926716804504
[2025-12-23 17:54:21,258] m-LoRA: Adapter lora_finqa_66 epoch: 1/1 iteration: 40/128 step: 11
[2025-12-23 17:54:21,551] m-LoRA: Adapter lora_finqa_46 loss: 0.004810489248484373
[2025-12-23 17:54:21,554] m-LoRA: Adapter lora_finqa_42 epoch: 1/1 iteration: 68/128 step: 35
[2025-12-23 17:54:21,850] m-LoRA: Adapter lora_finqa_37 loss: 0.012885472737252712
[2025-12-23 17:54:21,853] m-LoRA: Adapter lora_finqa_7 epoch: 1/1 iteration: 100/128 step: 51
[2025-12-23 17:54:22,130] m-LoRA: Adapter lora_finqa_47 loss: 0.0001809229579521343
[2025-12-23 17:54:22,134] m-LoRA: Adapter lora_finqa_8 epoch: 1/1 iteration: 100/128 step: 51
[2025-12-23 17:54:22,380] m-LoRA: Adapter lora_finqa_61 loss: 0.025867946445941925
[2025-12-23 17:54:22,476] m-LoRA: Adapter lora_finqa_71 epoch: 1/1 iteration: 16/128 step: 3
[2025-12-23 17:54:23,422] m-LoRA: Adapter lora_finqa_23 loss: 6.202808435773477e-05
[2025-12-23 17:54:23,515] m-LoRA: Adapter lora_finqa_67 epoch: 1/1 iteration: 80/128 step: 11
[2025-12-23 17:54:24,236] m-LoRA: Adapter lora_finqa_57 epoch: 1/1 iteration: 36/128 step: 19
[2025-12-23 17:54:24,291] m-LoRA: Adapter lora_finqa_48 loss: 0.0038058932404965162
[2025-12-23 17:54:24,649] m-LoRA: Adapter lora_finqa_25 loss: 0.00011232686665607616
[2025-12-23 17:54:24,652] m-LoRA: Adapter lora_finqa_72 epoch: 1/1 iteration: 8/128 step: 3
[2025-12-23 17:54:25,404] m-LoRA: Adapter lora_finqa_62 loss: 2.158740282058716
[2025-12-23 17:54:25,410] m-LoRA: Adapter lora_finqa_36 epoch: 1/1 iteration: 84/128 step: 43
[2025-12-23 17:54:26,016] m-LoRA: Adapter lora_finqa_15 epoch: 1/1 iteration: 100/128 step: 51
[2025-12-23 17:54:26,076] m-LoRA: Adapter lora_finqa_63 loss: 0.023892711848020554
[2025-12-23 17:54:27,285] m-LoRA: Adapter lora_finqa_75 loss: 2.5850300788879395
[2025-12-23 17:54:27,497] m-LoRA: Adapter lora_finqa_73 epoch: 1/1 iteration: 32/128 step: 3
[2025-12-23 17:54:27,907] m-LoRA: Adapter lora_finqa_64 loss: 0.025942355394363403
[2025-12-23 17:54:27,912] m-LoRA: Adapter lora_finqa_16 epoch: 1/1 iteration: 100/128 step: 51
[2025-12-23 17:54:28,148] m-LoRA: Adapter lora_finqa_55 loss: 1.735959529876709
[2025-12-23 17:54:28,152] m-LoRA: Adapter lora_finqa_74 epoch: 1/1 iteration: 4/128 step: 3
[2025-12-23 17:54:28,422] m-LoRA: Adapter lora_finqa_40 loss: 0.012644544243812561
[2025-12-23 17:54:28,426] m-LoRA: Adapter lora_finqa_60 epoch: 1/1 iteration: 36/128 step: 19
[2025-12-23 17:54:29,114] m-LoRA: Adapter lora_finqa_46 epoch: 1/1 iteration: 68/128 step: 35
[2025-12-23 17:54:29,159] m-LoRA: Adapter lora_finqa_65 loss: 0.02424667775630951
[2025-12-23 17:54:29,516] m-LoRA: Adapter lora_finqa_0 loss: 0.007861659862101078
[2025-12-23 17:54:29,520] m-LoRA: Adapter lora_finqa_37 epoch: 1/1 iteration: 84/128 step: 43
[2025-12-23 17:54:29,827] m-LoRA: Adapter lora_finqa_3 loss: 0.007575185503810644
[2025-12-23 17:54:29,830] m-LoRA: Adapter lora_finqa_47 epoch: 1/1 iteration: 68/128 step: 35
[2025-12-23 17:54:30,189] m-LoRA: Adapter lora_finqa_70 loss: 2.2523279190063477
[2025-12-23 17:54:30,192] m-LoRA: Adapter lora_finqa_61 epoch: 1/1 iteration: 36/128 step: 19
[2025-12-23 17:54:30,533] m-LoRA: Adapter lora_finqa_1 loss: 0.008630653843283653
[2025-12-23 17:54:30,536] m-LoRA: Adapter lora_finqa_23 epoch: 1/1 iteration: 100/128 step: 51
[2025-12-23 17:54:30,881] m-LoRA: Adapter lora_finqa_51 loss: 0.010773450136184692
[2025-12-23 17:54:30,884] m-LoRA: Adapter lora_finqa_48 epoch: 1/1 iteration: 68/128 step: 35
[2025-12-23 17:54:31,540] m-LoRA: Adapter lora_finqa_25 epoch: 1/1 iteration: 100/128 step: 51
[2025-12-23 17:54:31,596] m-LoRA: Adapter lora_finqa_66 loss: 0.054602641612291336
[2025-12-23 17:54:31,900] m-LoRA: Adapter lora_finqa_42 loss: 0.002650817856192589
[2025-12-23 17:54:31,904] m-LoRA: Adapter lora_finqa_62 epoch: 1/1 iteration: 72/128 step: 19
[2025-12-23 17:54:32,239] m-LoRA: Adapter lora_finqa_7 loss: 0.00011957378592342138
[2025-12-23 17:54:32,243] m-LoRA: Adapter lora_finqa_63 epoch: 1/1 iteration: 72/128 step: 19
[2025-12-23 17:54:32,562] m-LoRA: Adapter lora_finqa_8 loss: 8.731892012292519e-05
[2025-12-23 17:54:32,678] m-LoRA: Adapter lora_finqa_75 epoch: 1/1 iteration: 16/128 step: 3
[2025-12-23 17:54:33,819] m-LoRA: Adapter lora_finqa_64 epoch: 1/1 iteration: 72/128 step: 19
[2025-12-23 17:54:33,903] m-LoRA: Adapter lora_finqa_71 loss: 2.2498714923858643
[2025-12-23 17:54:35,064] m-LoRA: Adapter lora_finqa_55 epoch: 1/1 iteration: 52/128 step: 27
[2025-12-23 17:54:35,124] m-LoRA: Adapter lora_finqa_67 loss: 1.197263479232788
[2025-12-23 17:54:35,391] m-LoRA: Adapter lora_finqa_57 loss: 0.2044508457183838
[2025-12-23 17:54:35,394] m-LoRA: Adapter lora_finqa_40 epoch: 1/1 iteration: 84/128 step: 43
[2025-12-23 17:54:36,002] m-LoRA: Adapter lora_finqa_65 epoch: 1/1 iteration: 72/128 step: 19
[2025-12-23 17:54:36,079] m-LoRA: Adapter lora_finqa_72 loss: 2.5783612728118896
[2025-12-23 17:54:36,305] m-LoRA: Adapter lora_finqa_36 loss: 0.012912251986563206
[2025-12-23 17:54:36,308] m-LoRA: Adapter lora_finqa_0 epoch: 1/1 iteration: 102/128 step: 52
[2025-12-23 17:54:36,586] m-LoRA: Adapter lora_finqa_15 loss: 6.280390516621992e-05
[2025-12-23 17:54:36,590] m-LoRA: Adapter lora_finqa_3 epoch: 1/1 iteration: 102/128 step: 52
[2025-12-23 17:54:38,885] m-LoRA: Adapter lora_finqa_70 epoch: 1/1 iteration: 6/128 step: 4
[2025-12-23 17:54:39,192] m-LoRA: Adapter lora_finqa_73 loss: 2.2595014572143555
[2025-12-23 17:54:39,210] m-LoRA: Adapter lora_finqa_1 epoch: 1/1 iteration: 102/128 step: 52
[2025-12-23 17:54:39,269] m-LoRA: Adapter lora_finqa_16 loss: 5.7815679610939696e-05
[2025-12-23 17:54:39,696] m-LoRA: Adapter lora_finqa_74 loss: 1.9199540615081787
[2025-12-23 17:54:39,699] m-LoRA: Adapter lora_finqa_51 epoch: 1/1 iteration: 54/128 step: 28
[2025-12-23 17:54:39,910] m-LoRA: Adapter lora_finqa_60 loss: 0.20720140635967255
[2025-12-23 17:54:39,913] m-LoRA: Adapter lora_finqa_66 epoch: 1/1 iteration: 44/128 step: 12
[2025-12-23 17:54:40,189] m-LoRA: Adapter lora_finqa_46 loss: 0.004064975306391716
[2025-12-23 17:54:40,192] m-LoRA: Adapter lora_finqa_42 epoch: 1/1 iteration: 70/128 step: 36
[2025-12-23 17:54:40,488] m-LoRA: Adapter lora_finqa_37 loss: 0.012733612209558487
[2025-12-23 17:54:40,491] m-LoRA: Adapter lora_finqa_7 epoch: 1/1 iteration: 102/128 step: 52
[2025-12-23 17:54:40,784] m-LoRA: Adapter lora_finqa_47 loss: 0.00014321993512567133
[2025-12-23 17:54:40,787] m-LoRA: Adapter lora_finqa_8 epoch: 1/1 iteration: 102/128 step: 52
[2025-12-23 17:54:41,056] m-LoRA: Adapter lora_finqa_61 loss: 0.021455315873026848
[2025-12-23 17:54:41,185] m-LoRA: Adapter lora_finqa_71 epoch: 1/1 iteration: 24/128 step: 4
[2025-12-23 17:54:41,381] m-LoRA: Adapter lora_finqa_23 loss: 5.9837901062564924e-05
[2025-12-23 17:54:41,509] m-LoRA: Adapter lora_finqa_67 epoch: 1/1 iteration: 88/128 step: 12
[2025-12-23 17:54:41,757] m-LoRA: Adapter lora_finqa_48 loss: 0.00309919286519289
[2025-12-23 17:54:41,760] m-LoRA: Adapter lora_finqa_57 epoch: 1/1 iteration: 38/128 step: 20
[2025-12-23 17:54:42,319] m-LoRA: Adapter lora_finqa_25 loss: 0.0001057526606018655
[2025-12-23 17:54:42,322] m-LoRA: Adapter lora_finqa_72 epoch: 1/1 iteration: 12/128 step: 4
[2025-12-23 17:54:43,188] m-LoRA: Adapter lora_finqa_36 epoch: 1/1 iteration: 86/128 step: 44
[2025-12-23 17:54:43,241] m-LoRA: Adapter lora_finqa_62 loss: 2.1123359203338623
[2025-12-23 17:54:43,963] m-LoRA: Adapter lora_finqa_63 loss: 0.01974308490753174
[2025-12-23 17:54:43,969] m-LoRA: Adapter lora_finqa_15 epoch: 1/1 iteration: 102/128 step: 52
[2025-12-23 17:54:46,563] m-LoRA: Adapter lora_finqa_75 loss: 2.577705144882202
[2025-12-23 17:54:46,785] m-LoRA: Adapter lora_finqa_73 epoch: 1/1 iteration: 48/128 step: 4
[2025-12-23 17:54:47,805] m-LoRA: Adapter lora_finqa_16 epoch: 1/1 iteration: 102/128 step: 52
[2025-12-23 17:54:47,860] m-LoRA: Adapter lora_finqa_64 loss: 0.02124367654323578
[2025-12-23 17:54:48,091] m-LoRA: Adapter lora_finqa_55 loss: 1.6694564819335938
[2025-12-23 17:54:48,094] m-LoRA: Adapter lora_finqa_74 epoch: 1/1 iteration: 6/128 step: 4
[2025-12-23 17:54:48,356] m-LoRA: Adapter lora_finqa_40 loss: 0.012807976454496384
[2025-12-23 17:54:48,359] m-LoRA: Adapter lora_finqa_60 epoch: 1/1 iteration: 38/128 step: 20
[2025-12-23 17:54:49,051] m-LoRA: Adapter lora_finqa_46 epoch: 1/1 iteration: 70/128 step: 36
[2025-12-23 17:54:49,105] m-LoRA: Adapter lora_finqa_65 loss: 0.019741293042898178
[2025-12-23 17:54:49,439] m-LoRA: Adapter lora_finqa_0 loss: 0.008762476965785027
[2025-12-23 17:54:49,442] m-LoRA: Adapter lora_finqa_37 epoch: 1/1 iteration: 86/128 step: 44
[2025-12-23 17:54:49,733] m-LoRA: Adapter lora_finqa_3 loss: 0.007448648102581501
[2025-12-23 17:54:49,736] m-LoRA: Adapter lora_finqa_47 epoch: 1/1 iteration: 70/128 step: 36
[2025-12-23 17:54:49,999] m-LoRA: Adapter lora_finqa_61 epoch: 1/1 iteration: 38/128 step: 20
[2025-12-23 17:54:50,053] m-LoRA: Adapter lora_finqa_70 loss: 1.9895410537719727
[2025-12-23 17:54:50,325] m-LoRA: Adapter lora_finqa_1 loss: 0.007217870093882084
[2025-12-23 17:54:50,328] m-LoRA: Adapter lora_finqa_23 epoch: 1/1 iteration: 102/128 step: 52
[2025-12-23 17:54:50,661] m-LoRA: Adapter lora_finqa_51 loss: 0.009439029730856419
[2025-12-23 17:54:50,664] m-LoRA: Adapter lora_finqa_48 epoch: 1/1 iteration: 70/128 step: 36
[2025-12-23 17:54:51,275] m-LoRA: Adapter lora_finqa_25 epoch: 1/1 iteration: 102/128 step: 52
[2025-12-23 17:54:51,317] m-LoRA: Adapter lora_finqa_66 loss: 0.03546067327260971
[2025-12-23 17:54:51,635] m-LoRA: Adapter lora_finqa_42 loss: 0.0024597698356956244
[2025-12-23 17:54:51,639] m-LoRA: Adapter lora_finqa_62 epoch: 1/1 iteration: 76/128 step: 20
[2025-12-23 17:54:51,977] m-LoRA: Adapter lora_finqa_7 loss: 8.769134728936478e-05
[2025-12-23 17:54:51,980] m-LoRA: Adapter lora_finqa_63 epoch: 1/1 iteration: 76/128 step: 20
[2025-12-23 17:54:52,284] m-LoRA: Adapter lora_finqa_8 loss: 8.267756493296474e-05
[2025-12-23 17:54:52,483] m-LoRA: Adapter lora_finqa_75 epoch: 1/1 iteration: 24/128 step: 4
[2025-12-23 17:54:54,944] m-LoRA: Adapter lora_finqa_64 epoch: 1/1 iteration: 76/128 step: 20
[2025-12-23 17:54:55,039] m-LoRA: Adapter lora_finqa_71 loss: 1.984527349472046
[2025-12-23 17:54:56,094] m-LoRA: Adapter lora_finqa_55 epoch: 1/1 iteration: 54/128 step: 28
[2025-12-23 17:54:56,139] m-LoRA: Adapter lora_finqa_67 loss: 1.0026564598083496
[2025-12-23 17:54:56,800] m-LoRA: Adapter lora_finqa_57 loss: 0.15686577558517456
[2025-12-23 17:54:56,803] m-LoRA: Adapter lora_finqa_40 epoch: 1/1 iteration: 86/128 step: 44
[2025-12-23 17:54:58,086] m-LoRA: Adapter lora_finqa_72 loss: 2.5677998065948486
[2025-12-23 17:54:58,091] m-LoRA: Adapter lora_finqa_65 epoch: 1/1 iteration: 76/128 step: 20
[2025-12-23 17:54:58,706] m-LoRA: Adapter lora_finqa_36 loss: 0.01239796169102192
[2025-12-23 17:54:58,709] m-LoRA: Adapter lora_finqa_0 epoch: 1/1 iteration: 104/128 step: 53
[2025-12-23 17:54:59,419] m-LoRA: Adapter lora_finqa_15 loss: 5.667156437993981e-05
[2025-12-23 17:54:59,423] m-LoRA: Adapter lora_finqa_3 epoch: 1/1 iteration: 104/128 step: 53
[2025-12-23 17:55:01,433] m-LoRA: Adapter lora_finqa_70 epoch: 1/1 iteration: 8/128 step: 5
[2025-12-23 17:55:01,646] m-LoRA: Adapter lora_finqa_73 loss: 1.9946935176849365
[2025-12-23 17:55:02,141] m-LoRA: Adapter lora_finqa_1 epoch: 1/1 iteration: 104/128 step: 53
[2025-12-23 17:55:02,194] m-LoRA: Adapter lora_finqa_16 loss: 5.678738671122119e-05
[2025-12-23 17:55:02,660] m-LoRA: Adapter lora_finqa_51 epoch: 1/1 iteration: 56/128 step: 29
[2025-12-23 17:55:02,714] m-LoRA: Adapter lora_finqa_74 loss: 1.4905197620391846
[2025-12-23 17:55:03,056] m-LoRA: Adapter lora_finqa_60 loss: 0.15952888131141663
[2025-12-23 17:55:03,060] m-LoRA: Adapter lora_finqa_66 epoch: 1/1 iteration: 48/128 step: 13
[2025-12-23 17:55:03,612] m-LoRA: Adapter lora_finqa_46 loss: 0.0030004549771547318
[2025-12-23 17:55:03,615] m-LoRA: Adapter lora_finqa_42 epoch: 1/1 iteration: 72/128 step: 37
[2025-12-23 17:55:04,180] m-LoRA: Adapter lora_finqa_37 loss: 0.012092648074030876
[2025-12-23 17:55:04,183] m-LoRA: Adapter lora_finqa_7 epoch: 1/1 iteration: 104/128 step: 53
[2025-12-23 17:55:05,052] m-LoRA: Adapter lora_finqa_47 loss: 0.00013462667993735522
[2025-12-23 17:55:05,056] m-LoRA: Adapter lora_finqa_8 epoch: 1/1 iteration: 104/128 step: 53
[2025-12-23 17:55:05,468] m-LoRA: Adapter lora_finqa_61 loss: 0.017909690737724304
[2025-12-23 17:55:05,606] m-LoRA: Adapter lora_finqa_71 epoch: 1/1 iteration: 32/128 step: 5
[2025-12-23 17:55:06,214] m-LoRA: Adapter lora_finqa_23 loss: 5.4959560657152906e-05
[2025-12-23 17:55:06,345] m-LoRA: Adapter lora_finqa_67 epoch: 1/1 iteration: 96/128 step: 13
[2025-12-23 17:55:06,993] m-LoRA: Adapter lora_finqa_57 epoch: 1/1 iteration: 40/128 step: 21
[2025-12-23 17:55:07,047] m-LoRA: Adapter lora_finqa_48 loss: 0.002281020861119032
[2025-12-23 17:55:07,802] m-LoRA: Adapter lora_finqa_25 loss: 0.00012873332889284939
[2025-12-23 17:55:07,805] m-LoRA: Adapter lora_finqa_72 epoch: 1/1 iteration: 16/128 step: 5
[2025-12-23 17:55:08,363] m-LoRA: Adapter lora_finqa_36 epoch: 1/1 iteration: 88/128 step: 45
[2025-12-23 17:55:08,422] m-LoRA: Adapter lora_finqa_62 loss: 2.0667788982391357
[2025-12-23 17:55:09,034] m-LoRA: Adapter lora_finqa_63 loss: 0.0167095810174942
[2025-12-23 17:55:09,039] m-LoRA: Adapter lora_finqa_15 epoch: 1/1 iteration: 104/128 step: 53
[2025-12-23 17:55:10,221] m-LoRA: Adapter lora_finqa_75 loss: 2.5677363872528076
[2025-12-23 17:55:10,431] m-LoRA: Adapter lora_finqa_73 epoch: 1/1 iteration: 64/128 step: 5
[2025-12-23 17:55:10,898] m-LoRA: Adapter lora_finqa_64 loss: 0.017814068123698235
[2025-12-23 17:55:10,903] m-LoRA: Adapter lora_finqa_16 epoch: 1/1 iteration: 104/128 step: 53
[2025-12-23 17:55:11,437] m-LoRA: Adapter lora_finqa_55 loss: 1.6048264503479004
[2025-12-23 17:55:11,440] m-LoRA: Adapter lora_finqa_74 epoch: 1/1 iteration: 8/128 step: 5
[2025-12-23 17:55:11,726] m-LoRA: Adapter lora_finqa_40 loss: 0.013239224441349506
[2025-12-23 17:55:11,730] m-LoRA: Adapter lora_finqa_60 epoch: 1/1 iteration: 40/128 step: 21
[2025-12-23 17:55:12,547] m-LoRA: Adapter lora_finqa_65 loss: 0.01630467176437378
[2025-12-23 17:55:12,553] m-LoRA: Adapter lora_finqa_46 epoch: 1/1 iteration: 72/128 step: 37
[2025-12-23 17:55:13,297] m-LoRA: Adapter lora_finqa_0 loss: 0.006962033454328775
[2025-12-23 17:55:13,300] m-LoRA: Adapter lora_finqa_37 epoch: 1/1 iteration: 88/128 step: 45
[2025-12-23 17:55:13,767] m-LoRA: Adapter lora_finqa_3 loss: 0.006859109736979008
[2025-12-23 17:55:13,771] m-LoRA: Adapter lora_finqa_47 epoch: 1/1 iteration: 72/128 step: 37
[2025-12-23 17:55:14,122] m-LoRA: Adapter lora_finqa_70 loss: 1.7062369585037231
[2025-12-23 17:55:14,125] m-LoRA: Adapter lora_finqa_61 epoch: 1/1 iteration: 40/128 step: 21
[2025-12-23 17:55:14,477] m-LoRA: Adapter lora_finqa_1 loss: 0.0076196989975869656
[2025-12-23 17:55:14,480] m-LoRA: Adapter lora_finqa_23 epoch: 1/1 iteration: 104/128 step: 53
[2025-12-23 17:55:14,810] m-LoRA: Adapter lora_finqa_51 loss: 0.008923091925680637
[2025-12-23 17:55:14,814] m-LoRA: Adapter lora_finqa_48 epoch: 1/1 iteration: 72/128 step: 37
[2025-12-23 17:55:15,504] m-LoRA: Adapter lora_finqa_25 epoch: 1/1 iteration: 104/128 step: 53
[2025-12-23 17:55:15,564] m-LoRA: Adapter lora_finqa_66 loss: 0.025405708700418472
[2025-12-23 17:55:15,836] m-LoRA: Adapter lora_finqa_42 loss: 0.001304021803662181
[2025-12-23 17:55:15,839] m-LoRA: Adapter lora_finqa_62 epoch: 1/1 iteration: 80/128 step: 21
[2025-12-23 17:55:16,127] m-LoRA: Adapter lora_finqa_7 loss: 9.066965867532417e-05
[2025-12-23 17:55:16,131] m-LoRA: Adapter lora_finqa_63 epoch: 1/1 iteration: 80/128 step: 21
[2025-12-23 17:55:16,468] m-LoRA: Adapter lora_finqa_8 loss: 7.803714834153652e-05
[2025-12-23 17:55:16,550] m-LoRA: Adapter lora_finqa_75 epoch: 1/1 iteration: 32/128 step: 5
[2025-12-23 17:55:17,783] m-LoRA: Adapter lora_finqa_64 epoch: 1/1 iteration: 80/128 step: 21
[2025-12-23 17:55:17,872] m-LoRA: Adapter lora_finqa_71 loss: 1.7017080783843994
[2025-12-23 17:55:18,857] m-LoRA: Adapter lora_finqa_55 epoch: 1/1 iteration: 56/128 step: 29
[2025-12-23 17:55:18,923] m-LoRA: Adapter lora_finqa_67 loss: 0.8282803893089294
[2025-12-23 17:55:19,177] m-LoRA: Adapter lora_finqa_57 loss: 0.11065808683633804
[2025-12-23 17:55:19,180] m-LoRA: Adapter lora_finqa_40 epoch: 1/1 iteration: 88/128 step: 45
[2025-12-23 17:55:19,827] m-LoRA: Adapter lora_finqa_65 epoch: 1/1 iteration: 80/128 step: 21
[2025-12-23 17:55:19,905] m-LoRA: Adapter lora_finqa_72 loss: 2.555130958557129
[2025-12-23 17:55:20,086] m-LoRA: Adapter lora_finqa_36 loss: 0.0120916236191988
[2025-12-23 17:55:20,089] m-LoRA: Adapter lora_finqa_0 epoch: 1/1 iteration: 106/128 step: 54
[2025-12-23 17:55:20,355] m-LoRA: Adapter lora_finqa_3 epoch: 1/1 iteration: 106/128 step: 54
[2025-12-23 17:55:20,408] m-LoRA: Adapter lora_finqa_15 loss: 5.612867607851513e-05
[2025-12-23 17:55:22,912] m-LoRA: Adapter lora_finqa_73 loss: 1.7116475105285645
[2025-12-23 17:55:22,930] m-LoRA: Adapter lora_finqa_70 epoch: 1/1 iteration: 10/128 step: 6
[2025-12-23 17:55:23,064] m-LoRA: Adapter lora_finqa_16 loss: 5.387133569456637e-05
[2025-12-23 17:55:23,068] m-LoRA: Adapter lora_finqa_1 epoch: 1/1 iteration: 106/128 step: 54
[2025-12-23 17:55:23,412] m-LoRA: Adapter lora_finqa_74 loss: 1.1939772367477417
[2025-12-23 17:55:23,560] m-LoRA: Adapter lora_finqa_51 epoch: 1/1 iteration: 58/128 step: 30
[2025-12-23 17:55:23,801] m-LoRA: Adapter lora_finqa_60 loss: 0.11212587356567383
[2025-12-23 17:55:23,805] m-LoRA: Adapter lora_finqa_66 epoch: 1/1 iteration: 52/128 step: 14
[2025-12-23 17:55:24,057] m-LoRA: Adapter lora_finqa_46 loss: 0.003769036615267396
[2025-12-23 17:55:24,061] m-LoRA: Adapter lora_finqa_42 epoch: 1/1 iteration: 74/128 step: 38
[2025-12-23 17:55:24,357] m-LoRA: Adapter lora_finqa_37 loss: 0.011835935525596142
[2025-12-23 17:55:24,360] m-LoRA: Adapter lora_finqa_7 epoch: 1/1 iteration: 106/128 step: 54
[2025-12-23 17:55:24,615] m-LoRA: Adapter lora_finqa_8 epoch: 1/1 iteration: 106/128 step: 54
[2025-12-23 17:55:24,666] m-LoRA: Adapter lora_finqa_47 loss: 0.00012065158080076799
[2025-12-23 17:55:25,009] m-LoRA: Adapter lora_finqa_61 loss: 0.01612757332623005
[2025-12-23 17:55:25,012] m-LoRA: Adapter lora_finqa_71 epoch: 1/1 iteration: 40/128 step: 6
[2025-12-23 17:55:25,209] m-LoRA: Adapter lora_finqa_23 loss: 5.3488816774915904e-05
[2025-12-23 17:55:25,295] m-LoRA: Adapter lora_finqa_67 epoch: 1/1 iteration: 104/128 step: 14
[2025-12-23 17:55:25,569] m-LoRA: Adapter lora_finqa_48 loss: 0.001941183116286993
[2025-12-23 17:55:25,573] m-LoRA: Adapter lora_finqa_57 epoch: 1/1 iteration: 42/128 step: 22
[2025-12-23 17:55:26,335] m-LoRA: Adapter lora_finqa_25 loss: 9.172685531666502e-05
[2025-12-23 17:55:26,338] m-LoRA: Adapter lora_finqa_72 epoch: 1/1 iteration: 20/128 step: 6
[2025-12-23 17:55:27,003] m-LoRA: Adapter lora_finqa_36 epoch: 1/1 iteration: 90/128 step: 46
[2025-12-23 17:55:27,058] m-LoRA: Adapter lora_finqa_62 loss: 2.0152699947357178
[2025-12-23 17:55:27,711] m-LoRA: Adapter lora_finqa_63 loss: 0.014987032860517502
[2025-12-23 17:55:27,716] m-LoRA: Adapter lora_finqa_15 epoch: 1/1 iteration: 106/128 step: 54
[2025-12-23 17:55:29,032] m-LoRA: Adapter lora_finqa_75 loss: 2.555816411972046
[2025-12-23 17:55:29,266] m-LoRA: Adapter lora_finqa_73 epoch: 1/1 iteration: 80/128 step: 6
[2025-12-23 17:55:29,719] m-LoRA: Adapter lora_finqa_64 loss: 0.015324924141168594
[2025-12-23 17:55:29,725] m-LoRA: Adapter lora_finqa_16 epoch: 1/1 iteration: 106/128 step: 54
[2025-12-23 17:55:30,009] m-LoRA: Adapter lora_finqa_55 loss: 1.539423942565918
[2025-12-23 17:55:30,012] m-LoRA: Adapter lora_finqa_74 epoch: 1/1 iteration: 10/128 step: 6
[2025-12-23 17:55:30,309] m-LoRA: Adapter lora_finqa_40 loss: 0.013030145317316055
[2025-12-23 17:55:30,313] m-LoRA: Adapter lora_finqa_60 epoch: 1/1 iteration: 42/128 step: 22
[2025-12-23 17:55:31,021] m-LoRA: Adapter lora_finqa_46 epoch: 1/1 iteration: 74/128 step: 38
[2025-12-23 17:55:31,095] m-LoRA: Adapter lora_finqa_65 loss: 0.014181268401443958
[2025-12-23 17:55:31,445] m-LoRA: Adapter lora_finqa_0 loss: 0.006285106763243675
[2025-12-23 17:55:31,448] m-LoRA: Adapter lora_finqa_37 epoch: 1/1 iteration: 90/128 step: 46
[2025-12-23 17:55:31,716] m-LoRA: Adapter lora_finqa_3 loss: 0.006038646213710308
[2025-12-23 17:55:31,720] m-LoRA: Adapter lora_finqa_47 epoch: 1/1 iteration: 74/128 step: 38
[2025-12-23 17:55:31,958] m-LoRA: Adapter lora_finqa_61 epoch: 1/1 iteration: 42/128 step: 22
[2025-12-23 17:55:32,014] m-LoRA: Adapter lora_finqa_70 loss: 1.3968470096588135
[2025-12-23 17:55:32,321] m-LoRA: Adapter lora_finqa_1 loss: 0.005814261268824339
[2025-12-23 17:55:32,324] m-LoRA: Adapter lora_finqa_23 epoch: 1/1 iteration: 106/128 step: 54
[2025-12-23 17:55:32,767] m-LoRA: Adapter lora_finqa_51 loss: 0.00826272927224636
[2025-12-23 17:55:32,770] m-LoRA: Adapter lora_finqa_48 epoch: 1/1 iteration: 74/128 step: 38
[2025-12-23 17:55:33,410] m-LoRA: Adapter lora_finqa_25 epoch: 1/1 iteration: 106/128 step: 54
[2025-12-23 17:55:33,485] m-LoRA: Adapter lora_finqa_66 loss: 0.01912888139486313
[2025-12-23 17:55:33,854] m-LoRA: Adapter lora_finqa_42 loss: 0.000923413666896522
[2025-12-23 17:55:33,858] m-LoRA: Adapter lora_finqa_62 epoch: 1/1 iteration: 84/128 step: 22
[2025-12-23 17:55:34,219] m-LoRA: Adapter lora_finqa_7 loss: 7.944377284729853e-05
[2025-12-23 17:55:34,223] m-LoRA: Adapter lora_finqa_63 epoch: 1/1 iteration: 84/128 step: 22
[2025-12-23 17:55:34,526] m-LoRA: Adapter lora_finqa_8 loss: 8.626659837318584e-05
[2025-12-23 17:55:34,657] m-LoRA: Adapter lora_finqa_75 epoch: 1/1 iteration: 40/128 step: 6
[2025-12-23 17:55:35,863] m-LoRA: Adapter lora_finqa_64 epoch: 1/1 iteration: 84/128 step: 22
[2025-12-23 17:55:35,951] m-LoRA: Adapter lora_finqa_71 loss: 1.3911309242248535
[2025-12-23 17:55:37,303] m-LoRA: Adapter lora_finqa_67 loss: 0.6614401936531067
[2025-12-23 17:55:37,313] m-LoRA: Adapter lora_finqa_55 epoch: 1/1 iteration: 58/128 step: 30
[2025-12-23 17:55:37,557] m-LoRA: Adapter lora_finqa_57 loss: 0.08118288218975067
[2025-12-23 17:55:37,560] m-LoRA: Adapter lora_finqa_40 epoch: 1/1 iteration: 90/128 step: 46
[2025-12-23 17:55:38,156] m-LoRA: Adapter lora_finqa_65 epoch: 1/1 iteration: 84/128 step: 22
[2025-12-23 17:55:38,231] m-LoRA: Adapter lora_finqa_72 loss: 2.540628671646118
[2025-12-23 17:55:38,450] m-LoRA: Adapter lora_finqa_36 loss: 0.01211169920861721
[2025-12-23 17:55:38,453] m-LoRA: Adapter lora_finqa_0 epoch: 1/1 iteration: 108/128 step: 55
[2025-12-23 17:55:38,712] m-LoRA: Adapter lora_finqa_15 loss: 5.2838135161437094e-05
[2025-12-23 17:55:38,715] m-LoRA: Adapter lora_finqa_3 epoch: 1/1 iteration: 108/128 step: 55
[2025-12-23 17:55:43,125] m-LoRA: Adapter lora_finqa_70 epoch: 1/1 iteration: 12/128 step: 7
[2025-12-23 17:55:43,444] m-LoRA: Adapter lora_finqa_73 loss: 1.398249864578247
[2025-12-23 17:55:43,462] m-LoRA: Adapter lora_finqa_1 epoch: 1/1 iteration: 108/128 step: 55
[2025-12-23 17:55:43,518] m-LoRA: Adapter lora_finqa_16 loss: 5.223727930570021e-05
[2025-12-23 17:55:43,889] m-LoRA: Adapter lora_finqa_74 loss: 0.7850873470306396
[2025-12-23 17:55:43,891] m-LoRA: Adapter lora_finqa_51 epoch: 1/1 iteration: 60/128 step: 31
[2025-12-23 17:55:44,054] m-LoRA: Adapter lora_finqa_60 loss: 0.08414426445960999
[2025-12-23 17:55:44,057] m-LoRA: Adapter lora_finqa_66 epoch: 1/1 iteration: 56/128 step: 15
[2025-12-23 17:55:44,295] m-LoRA: Adapter lora_finqa_42 epoch: 1/1 iteration: 76/128 step: 39
[2025-12-23 17:55:44,349] m-LoRA: Adapter lora_finqa_46 loss: 0.0018411120399832726
[2025-12-23 17:55:44,652] m-LoRA: Adapter lora_finqa_37 loss: 0.01132462453097105
[2025-12-23 17:55:44,656] m-LoRA: Adapter lora_finqa_7 epoch: 1/1 iteration: 108/128 step: 55
[2025-12-23 17:55:44,935] m-LoRA: Adapter lora_finqa_47 loss: 0.00011257311416557059
[2025-12-23 17:55:44,938] m-LoRA: Adapter lora_finqa_8 epoch: 1/1 iteration: 108/128 step: 55
[2025-12-23 17:55:45,304] m-LoRA: Adapter lora_finqa_61 loss: 0.014405323192477226
[2025-12-23 17:55:45,307] m-LoRA: Adapter lora_finqa_71 epoch: 1/1 iteration: 48/128 step: 7
[2025-12-23 17:55:45,485] m-LoRA: Adapter lora_finqa_23 loss: 5.502838394022547e-05
[2025-12-23 17:55:45,614] m-LoRA: Adapter lora_finqa_67 epoch: 1/1 iteration: 112/128 step: 15
[2025-12-23 17:55:45,867] m-LoRA: Adapter lora_finqa_48 loss: 0.0016281765419989824
[2025-12-23 17:55:45,870] m-LoRA: Adapter lora_finqa_57 epoch: 1/1 iteration: 44/128 step: 23
[2025-12-23 17:55:46,484] m-LoRA: Adapter lora_finqa_25 loss: 8.03910952527076e-05
[2025-12-23 17:55:46,487] m-LoRA: Adapter lora_finqa_72 epoch: 1/1 iteration: 24/128 step: 7
[2025-12-23 17:55:47,344] m-LoRA: Adapter lora_finqa_62 loss: 1.9653717279434204
[2025-12-23 17:55:47,350] m-LoRA: Adapter lora_finqa_36 epoch: 1/1 iteration: 92/128 step: 47
[2025-12-23 17:55:48,085] m-LoRA: Adapter lora_finqa_63 loss: 0.014060916379094124
[2025-12-23 17:55:48,090] m-LoRA: Adapter lora_finqa_15 epoch: 1/1 iteration: 108/128 step: 55
[2025-12-23 17:55:50,556] m-LoRA: Adapter lora_finqa_75 loss: 2.5397188663482666
[2025-12-23 17:55:50,762] m-LoRA: Adapter lora_finqa_73 epoch: 1/1 iteration: 96/128 step: 7
[2025-12-23 17:55:51,823] m-LoRA: Adapter lora_finqa_64 loss: 0.014390144497156143
[2025-12-23 17:55:51,828] m-LoRA: Adapter lora_finqa_16 epoch: 1/1 iteration: 108/128 step: 55
[2025-12-23 17:55:52,136] m-LoRA: Adapter lora_finqa_55 loss: 1.4781389236450195
[2025-12-23 17:55:52,139] m-LoRA: Adapter lora_finqa_74 epoch: 1/1 iteration: 12/128 step: 7
[2025-12-23 17:55:52,761] m-LoRA: Adapter lora_finqa_40 loss: 0.011612500995397568
[2025-12-23 17:55:52,764] m-LoRA: Adapter lora_finqa_60 epoch: 1/1 iteration: 44/128 step: 23
[2025-12-23 17:55:53,934] m-LoRA: Adapter lora_finqa_46 epoch: 1/1 iteration: 76/128 step: 39
[2025-12-23 17:55:53,989] m-LoRA: Adapter lora_finqa_65 loss: 0.013390258885920048
[2025-12-23 17:55:54,712] m-LoRA: Adapter lora_finqa_0 loss: 0.0067371707409620285
[2025-12-23 17:55:54,715] m-LoRA: Adapter lora_finqa_37 epoch: 1/1 iteration: 92/128 step: 47
[2025-12-23 17:55:55,314] m-LoRA: Adapter lora_finqa_3 loss: 0.005896394606679678
[2025-12-23 17:55:55,317] m-LoRA: Adapter lora_finqa_47 epoch: 1/1 iteration: 76/128 step: 39
[2025-12-23 17:55:55,728] m-LoRA: Adapter lora_finqa_70 loss: 1.10330069065094
[2025-12-23 17:55:55,732] m-LoRA: Adapter lora_finqa_61 epoch: 1/1 iteration: 44/128 step: 23
[2025-12-23 17:55:56,084] m-LoRA: Adapter lora_finqa_1 loss: 0.005456910468637943
[2025-12-23 17:55:56,087] m-LoRA: Adapter lora_finqa_23 epoch: 1/1 iteration: 108/128 step: 55
[2025-12-23 17:55:56,455] m-LoRA: Adapter lora_finqa_51 loss: 0.006825380027294159
[2025-12-23 17:55:56,458] m-LoRA: Adapter lora_finqa_48 epoch: 1/1 iteration: 76/128 step: 39
[2025-12-23 17:55:57,135] m-LoRA: Adapter lora_finqa_66 loss: 0.015494673512876034
[2025-12-23 17:55:57,140] m-LoRA: Adapter lora_finqa_25 epoch: 1/1 iteration: 108/128 step: 55
[2025-12-23 17:55:57,450] m-LoRA: Adapter lora_finqa_42 loss: 0.0011084728175774217
[2025-12-23 17:55:57,453] m-LoRA: Adapter lora_finqa_62 epoch: 1/1 iteration: 88/128 step: 23
[2025-12-23 17:55:57,726] m-LoRA: Adapter lora_finqa_7 loss: 7.340096635743976e-05
[2025-12-23 17:55:57,729] m-LoRA: Adapter lora_finqa_63 epoch: 1/1 iteration: 88/128 step: 23
[2025-12-23 17:55:58,031] m-LoRA: Adapter lora_finqa_8 loss: 7.857890159357339e-05
[2025-12-23 17:55:58,114] m-LoRA: Adapter lora_finqa_75 epoch: 1/1 iteration: 48/128 step: 7
[2025-12-23 17:55:59,322] m-LoRA: Adapter lora_finqa_64 epoch: 1/1 iteration: 88/128 step: 23
[2025-12-23 17:55:59,421] m-LoRA: Adapter lora_finqa_71 loss: 1.0877104997634888
[2025-12-23 17:56:00,374] m-LoRA: Adapter lora_finqa_55 epoch: 1/1 iteration: 60/128 step: 31
[2025-12-23 17:56:00,477] m-LoRA: Adapter lora_finqa_67 loss: 0.5296962857246399
[2025-12-23 17:56:01,109] m-LoRA: Adapter lora_finqa_40 epoch: 1/1 iteration: 92/128 step: 47
[2025-12-23 17:56:01,158] m-LoRA: Adapter lora_finqa_57 loss: 0.06323830038309097
[2025-12-23 17:56:02,270] m-LoRA: Adapter lora_finqa_72 loss: 2.5213541984558105
[2025-12-23 17:56:02,320] m-LoRA: Adapter lora_finqa_65 epoch: 1/1 iteration: 88/128 step: 23
[2025-12-23 17:56:02,918] m-LoRA: Adapter lora_finqa_0 epoch: 1/1 iteration: 110/128 step: 56
[2025-12-23 17:56:02,972] m-LoRA: Adapter lora_finqa_36 loss: 0.01126619428396225
[2025-12-23 17:56:03,660] m-LoRA: Adapter lora_finqa_15 loss: 5.249048990663141e-05
[2025-12-23 17:56:03,664] m-LoRA: Adapter lora_finqa_3 epoch: 1/1 iteration: 110/128 step: 56
[2025-12-23 17:56:05,626] m-LoRA: Adapter lora_finqa_70 epoch: 1/1 iteration: 14/128 step: 8
[2025-12-23 17:56:05,962] m-LoRA: Adapter lora_finqa_73 loss: 1.1034789085388184
[2025-12-23 17:56:05,979] m-LoRA: Adapter lora_finqa_1 epoch: 1/1 iteration: 110/128 step: 56
[2025-12-23 17:56:06,074] m-LoRA: Adapter lora_finqa_16 loss: 5.027290171710774e-05
[2025-12-23 17:56:06,531] m-LoRA: Adapter lora_finqa_51 epoch: 1/1 iteration: 62/128 step: 32
[2025-12-23 17:56:06,566] m-LoRA: Adapter lora_finqa_74 loss: 0.5357523560523987
[2025-12-23 17:56:06,884] m-LoRA: Adapter lora_finqa_60 loss: 0.06526803970336914
[2025-12-23 17:56:06,888] m-LoRA: Adapter lora_finqa_66 epoch: 1/1 iteration: 60/128 step: 16
[2025-12-23 17:56:07,156] m-LoRA: Adapter lora_finqa_46 loss: 0.0013775426195934415
[2025-12-23 17:56:07,159] m-LoRA: Adapter lora_finqa_42 epoch: 1/1 iteration: 78/128 step: 40
[2025-12-23 17:56:07,433] m-LoRA: Adapter lora_finqa_37 loss: 0.011033342219889164
[2025-12-23 17:56:07,437] m-LoRA: Adapter lora_finqa_7 epoch: 1/1 iteration: 110/128 step: 56
[2025-12-23 17:56:07,716] m-LoRA: Adapter lora_finqa_47 loss: 0.00010178917727898806
[2025-12-23 17:56:07,720] m-LoRA: Adapter lora_finqa_8 epoch: 1/1 iteration: 110/128 step: 56
[2025-12-23 17:56:08,244] m-LoRA: Adapter lora_finqa_61 loss: 0.01402677409350872
[2025-12-23 17:56:08,385] m-LoRA: Adapter lora_finqa_71 epoch: 1/1 iteration: 56/128 step: 8
[2025-12-23 17:56:09,153] m-LoRA: Adapter lora_finqa_23 loss: 5.184023757465184e-05
[2025-12-23 17:56:09,281] m-LoRA: Adapter lora_finqa_67 epoch: 1/1 iteration: 120/128 step: 16
[2025-12-23 17:56:09,975] m-LoRA: Adapter lora_finqa_48 loss: 0.0015800307737663388
[2025-12-23 17:56:09,979] m-LoRA: Adapter lora_finqa_57 epoch: 1/1 iteration: 46/128 step: 24
[2025-12-23 17:56:10,598] m-LoRA: Adapter lora_finqa_25 loss: 9.343445708509535e-05
[2025-12-23 17:56:10,602] m-LoRA: Adapter lora_finqa_72 epoch: 1/1 iteration: 28/128 step: 8
[2025-12-23 17:56:11,299] m-LoRA: Adapter lora_finqa_36 epoch: 1/1 iteration: 94/128 step: 48
[2025-12-23 17:56:11,361] m-LoRA: Adapter lora_finqa_62 loss: 1.9108390808105469
[2025-12-23 17:56:12,119] m-LoRA: Adapter lora_finqa_63 loss: 0.012767364270985126
[2025-12-23 17:56:12,124] m-LoRA: Adapter lora_finqa_15 epoch: 1/1 iteration: 110/128 step: 56
[2025-12-23 17:56:13,282] m-LoRA: Adapter lora_finqa_75 loss: 2.521091938018799
[2025-12-23 17:56:13,502] m-LoRA: Adapter lora_finqa_73 epoch: 1/1 iteration: 112/128 step: 8
[2025-12-23 17:56:13,944] m-LoRA: Adapter lora_finqa_64 loss: 0.013040085323154926
[2025-12-23 17:56:13,951] m-LoRA: Adapter lora_finqa_16 epoch: 1/1 iteration: 110/128 step: 56
[2025-12-23 17:56:14,504] m-LoRA: Adapter lora_finqa_55 loss: 1.4090595245361328
[2025-12-23 17:56:14,508] m-LoRA: Adapter lora_finqa_74 epoch: 1/1 iteration: 14/128 step: 8
[2025-12-23 17:56:14,782] m-LoRA: Adapter lora_finqa_40 loss: 0.010761952959001064
[2025-12-23 17:56:14,785] m-LoRA: Adapter lora_finqa_60 epoch: 1/1 iteration: 46/128 step: 24
[2025-12-23 17:56:15,619] m-LoRA: Adapter lora_finqa_46 epoch: 1/1 iteration: 78/128 step: 40
[2025-12-23 17:56:15,675] m-LoRA: Adapter lora_finqa_65 loss: 0.012147440575063229
[2025-12-23 17:56:16,018] m-LoRA: Adapter lora_finqa_37 epoch: 1/1 iteration: 94/128 step: 48
[2025-12-23 17:56:16,075] m-LoRA: Adapter lora_finqa_0 loss: 0.005168105475604534
[2025-12-23 17:56:16,391] m-LoRA: Adapter lora_finqa_3 loss: 0.0047784484922885895
[2025-12-23 17:56:16,394] m-LoRA: Adapter lora_finqa_47 epoch: 1/1 iteration: 78/128 step: 40
[2025-12-23 17:56:16,657] m-LoRA: Adapter lora_finqa_61 epoch: 1/1 iteration: 46/128 step: 24
[2025-12-23 17:56:16,714] m-LoRA: Adapter lora_finqa_70 loss: 0.8137655854225159
[2025-12-23 17:56:16,983] m-LoRA: Adapter lora_finqa_1 loss: 0.006174012087285519
[2025-12-23 17:56:16,986] m-LoRA: Adapter lora_finqa_23 epoch: 1/1 iteration: 110/128 step: 56
[2025-12-23 17:56:17,336] m-LoRA: Adapter lora_finqa_51 loss: 0.006026280578225851
[2025-12-23 17:56:17,340] m-LoRA: Adapter lora_finqa_48 epoch: 1/1 iteration: 78/128 step: 40
[2025-12-23 17:56:17,918] m-LoRA: Adapter lora_finqa_25 epoch: 1/1 iteration: 110/128 step: 56
[2025-12-23 17:56:17,976] m-LoRA: Adapter lora_finqa_66 loss: 0.013204122893512249
[2025-12-23 17:56:18,317] m-LoRA: Adapter lora_finqa_42 loss: 0.0006675526383332908
[2025-12-23 17:56:18,320] m-LoRA: Adapter lora_finqa_62 epoch: 1/1 iteration: 92/128 step: 24
[2025-12-23 17:56:18,641] m-LoRA: Adapter lora_finqa_7 loss: 7.917131733847782e-05
[2025-12-23 17:56:18,645] m-LoRA: Adapter lora_finqa_63 epoch: 1/1 iteration: 92/128 step: 24
[2025-12-23 17:56:18,945] m-LoRA: Adapter lora_finqa_8 loss: 7.878952601458877e-05
[2025-12-23 17:56:19,039] m-LoRA: Adapter lora_finqa_75 epoch: 1/1 iteration: 56/128 step: 8
[2025-12-23 17:56:20,163] m-LoRA: Adapter lora_finqa_64 epoch: 1/1 iteration: 92/128 step: 24
[2025-12-23 17:56:20,264] m-LoRA: Adapter lora_finqa_71 loss: 0.7959313988685608
[2025-12-23 17:56:21,358] m-LoRA: Adapter lora_finqa_55 epoch: 1/1 iteration: 62/128 step: 32
[2025-12-23 17:56:21,459] m-LoRA: Adapter lora_finqa_67 loss: 0.4197722375392914
[2025-12-23 17:56:21,716] m-LoRA: Adapter lora_finqa_57 loss: 0.05283457040786743
[2025-12-23 17:56:21,719] m-LoRA: Adapter lora_finqa_40 epoch: 1/1 iteration: 94/128 step: 48
[2025-12-23 17:56:22,352] m-LoRA: Adapter lora_finqa_65 epoch: 1/1 iteration: 92/128 step: 24
[2025-12-23 17:56:22,426] m-LoRA: Adapter lora_finqa_72 loss: 2.500200033187866
[2025-12-23 17:56:22,642] m-LoRA: Adapter lora_finqa_0 epoch: 1/1 iteration: 112/128 step: 57
[2025-12-23 17:56:22,696] m-LoRA: Adapter lora_finqa_36 loss: 0.010727178305387497
[2025-12-23 17:56:23,091] m-LoRA: Adapter lora_finqa_15 loss: 4.924997119815089e-05
[2025-12-23 17:56:23,094] m-LoRA: Adapter lora_finqa_3 epoch: 1/1 iteration: 112/128 step: 57
[2025-12-23 17:56:25,318] m-LoRA: Adapter lora_finqa_70 epoch: 1/1 iteration: 16/128 step: 9
[2025-12-23 17:56:25,653] m-LoRA: Adapter lora_finqa_73 loss: 0.8101027011871338
[2025-12-23 17:56:25,670] m-LoRA: Adapter lora_finqa_1 epoch: 1/1 iteration: 112/128 step: 57
[2025-12-23 17:56:25,734] m-LoRA: Adapter lora_finqa_16 loss: 4.8653295380063355e-05
[2025-12-23 17:56:26,118] m-LoRA: Adapter lora_finqa_74 loss: 0.3390110731124878
[2025-12-23 17:56:26,121] m-LoRA: Adapter lora_finqa_51 epoch: 1/1 iteration: 64/128 step: 33
[2025-12-23 17:56:26,312] m-LoRA: Adapter lora_finqa_60 loss: 0.052858106791973114
[2025-12-23 17:56:26,315] m-LoRA: Adapter lora_finqa_66 epoch: 1/1 iteration: 64/128 step: 17
[2025-12-23 17:56:26,568] m-LoRA: Adapter lora_finqa_46 loss: 0.0007159900851547718
[2025-12-23 17:56:26,572] m-LoRA: Adapter lora_finqa_42 epoch: 1/1 iteration: 80/128 step: 41
[2025-12-23 17:56:26,870] m-LoRA: Adapter lora_finqa_37 loss: 0.010593168437480927
[2025-12-23 17:56:26,873] m-LoRA: Adapter lora_finqa_7 epoch: 1/1 iteration: 112/128 step: 57
[2025-12-23 17:56:27,134] m-LoRA: Adapter lora_finqa_8 epoch: 1/1 iteration: 112/128 step: 57
[2025-12-23 17:56:27,191] m-LoRA: Adapter lora_finqa_47 loss: 9.557329030940309e-05
[2025-12-23 17:56:27,431] m-LoRA: Adapter lora_finqa_61 loss: 0.01219112891703844
[2025-12-23 17:56:27,544] m-LoRA: Adapter lora_finqa_71 epoch: 1/1 iteration: 64/128 step: 9
[2025-12-23 17:56:27,765] m-LoRA: Adapter lora_finqa_23 loss: 4.987262582289986e-05
[2025-12-23 17:56:27,879] m-LoRA: Finish and base model offload adapter - ['lora_finqa_67']
[2025-12-23 17:56:28,096] m-LoRA: Task to running, need to load adapters: ['lora_finqa_76']
[2025-12-23 17:56:28,210] m-LoRA: Adapter lora_finqa_76 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:56:28,634] m-LoRA: Adapter lora_finqa_48 loss: 0.0009374925284646451
[2025-12-23 17:56:28,637] m-LoRA: Adapter lora_finqa_57 epoch: 1/1 iteration: 48/128 step: 25
[2025-12-23 17:56:28,906] m-LoRA: Adapter lora_finqa_25 loss: 8.145610627252609e-05
[2025-12-23 17:56:28,909] m-LoRA: Adapter lora_finqa_72 epoch: 1/1 iteration: 32/128 step: 9
[2025-12-23 17:56:29,540] m-LoRA: Adapter lora_finqa_36 epoch: 1/1 iteration: 96/128 step: 49
[2025-12-23 17:56:29,600] m-LoRA: Adapter lora_finqa_62 loss: 1.8536876440048218
[2025-12-23 17:56:30,221] m-LoRA: Adapter lora_finqa_15 epoch: 1/1 iteration: 112/128 step: 57
[2025-12-23 17:56:30,283] m-LoRA: Adapter lora_finqa_63 loss: 0.012040258385241032
[2025-12-23 17:56:31,578] m-LoRA: Adapter lora_finqa_75 loss: 2.50026535987854
[2025-12-23 17:56:31,789] m-LoRA: Finish and base model offload adapter - ['lora_finqa_73']
[2025-12-23 17:56:32,762] m-LoRA: Adapter lora_finqa_64 loss: 0.012144752778112888
[2025-12-23 17:56:32,767] m-LoRA: Task to running, need to load adapters: ['lora_finqa_77']
[2025-12-23 17:56:32,924] m-LoRA: Adapter lora_finqa_77 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:56:33,035] m-LoRA: Adapter lora_finqa_55 loss: 1.3288058042526245
[2025-12-23 17:56:33,038] m-LoRA: Adapter lora_finqa_16 epoch: 1/1 iteration: 112/128 step: 57
[2025-12-23 17:56:33,149] m-LoRA: Adapter lora_finqa_40 loss: 0.010519140399992466
[2025-12-23 17:56:33,152] m-LoRA: Adapter lora_finqa_74 epoch: 1/1 iteration: 16/128 step: 9
[2025-12-23 17:56:33,249] m-LoRA: Adapter lora_finqa_60 epoch: 1/1 iteration: 48/128 step: 25
[2025-12-23 17:56:33,599] m-LoRA: Adapter lora_finqa_46 epoch: 1/1 iteration: 80/128 step: 41
[2025-12-23 17:56:33,663] m-LoRA: Adapter lora_finqa_65 loss: 0.011418684385716915
[2025-12-23 17:56:33,983] m-LoRA: Adapter lora_finqa_0 loss: 0.005911162588745356
[2025-12-23 17:56:33,986] m-LoRA: Adapter lora_finqa_37 epoch: 1/1 iteration: 96/128 step: 49
[2025-12-23 17:56:34,267] m-LoRA: Adapter lora_finqa_47 epoch: 1/1 iteration: 80/128 step: 41
[2025-12-23 17:56:34,323] m-LoRA: Adapter lora_finqa_3 loss: 0.004242049530148506
[2025-12-23 17:56:34,596] m-LoRA: Adapter lora_finqa_61 epoch: 1/1 iteration: 48/128 step: 25
[2025-12-23 17:56:34,650] m-LoRA: Adapter lora_finqa_70 loss: 0.5605710744857788
[2025-12-23 17:56:35,029] m-LoRA: Adapter lora_finqa_1 loss: 0.005161783657968044
[2025-12-23 17:56:35,032] m-LoRA: Adapter lora_finqa_23 epoch: 1/1 iteration: 112/128 step: 57
[2025-12-23 17:56:35,332] m-LoRA: Adapter lora_finqa_51 loss: 0.004945515654981136
[2025-12-23 17:56:35,336] m-LoRA: Adapter lora_finqa_48 epoch: 1/1 iteration: 80/128 step: 41
[2025-12-23 17:56:35,947] m-LoRA: Adapter lora_finqa_66 loss: 0.011358504183590412
[2025-12-23 17:56:35,953] m-LoRA: Adapter lora_finqa_25 epoch: 1/1 iteration: 112/128 step: 57
[2025-12-23 17:56:36,336] m-LoRA: Adapter lora_finqa_42 loss: 0.0004473342269193381
[2025-12-23 17:56:36,340] m-LoRA: Adapter lora_finqa_62 epoch: 1/1 iteration: 96/128 step: 25
[2025-12-23 17:56:36,703] m-LoRA: Adapter lora_finqa_7 loss: 7.080799696268514e-05
[2025-12-23 17:56:36,707] m-LoRA: Adapter lora_finqa_63 epoch: 1/1 iteration: 96/128 step: 25
[2025-12-23 17:56:37,026] m-LoRA: Adapter lora_finqa_8 loss: 6.66585037834011e-05
[2025-12-23 17:56:37,161] m-LoRA: Adapter lora_finqa_75 epoch: 1/1 iteration: 64/128 step: 9
[2025-12-23 17:56:39,865] m-LoRA: Adapter lora_finqa_71 loss: 0.5485754013061523
[2025-12-23 17:56:39,875] m-LoRA: Adapter lora_finqa_64 epoch: 1/1 iteration: 96/128 step: 25
[2025-12-23 17:56:42,289] m-LoRA: Adapter lora_finqa_55 epoch: 1/1 iteration: 64/128 step: 33
[2025-12-23 17:56:42,368] m-LoRA: Adapter lora_finqa_76 loss: 2.588528633117676
[2025-12-23 17:56:42,631] m-LoRA: Adapter lora_finqa_57 loss: 0.043781351298093796
[2025-12-23 17:56:42,634] m-LoRA: Adapter lora_finqa_40 epoch: 1/1 iteration: 96/128 step: 49
[2025-12-23 17:56:43,868] m-LoRA: Adapter lora_finqa_65 epoch: 1/1 iteration: 96/128 step: 25
[2025-12-23 17:56:43,941] m-LoRA: Adapter lora_finqa_72 loss: 2.479680061340332
[2025-12-23 17:56:44,347] m-LoRA: Adapter lora_finqa_36 loss: 0.010234862565994263
[2025-12-23 17:56:44,350] m-LoRA: Adapter lora_finqa_0 epoch: 1/1 iteration: 114/128 step: 58
[2025-12-23 17:56:45,135] m-LoRA: Adapter lora_finqa_3 epoch: 1/1 iteration: 114/128 step: 58
[2025-12-23 17:56:45,189] m-LoRA: Adapter lora_finqa_15 loss: 4.766254642163403e-05
[2025-12-23 17:56:46,445] m-LoRA: Adapter lora_finqa_77 loss: 2.5885279178619385
[2025-12-23 17:56:46,451] m-LoRA: Adapter lora_finqa_70 epoch: 1/1 iteration: 18/128 step: 10
[2025-12-23 17:56:46,699] m-LoRA: Adapter lora_finqa_16 loss: 4.8912173951976e-05
[2025-12-23 17:56:46,702] m-LoRA: Adapter lora_finqa_1 epoch: 1/1 iteration: 114/128 step: 58
[2025-12-23 17:56:46,999] m-LoRA: Adapter lora_finqa_74 loss: 0.21201562881469727
[2025-12-23 17:56:47,003] m-LoRA: Adapter lora_finqa_51 epoch: 1/1 iteration: 66/128 step: 34
[2025-12-23 17:56:47,393] m-LoRA: Adapter lora_finqa_60 loss: 0.04427921026945114
[2025-12-23 17:56:47,396] m-LoRA: Adapter lora_finqa_66 epoch: 1/1 iteration: 68/128 step: 18
[2025-12-23 17:56:47,785] m-LoRA: Adapter lora_finqa_46 loss: 0.0005095309461466968
[2025-12-23 17:56:47,789] m-LoRA: Adapter lora_finqa_42 epoch: 1/1 iteration: 82/128 step: 42
[2025-12-23 17:56:48,080] m-LoRA: Adapter lora_finqa_37 loss: 0.01006252970546484
[2025-12-23 17:56:48,083] m-LoRA: Adapter lora_finqa_7 epoch: 1/1 iteration: 114/128 step: 58
[2025-12-23 17:56:48,433] m-LoRA: Adapter lora_finqa_8 epoch: 1/1 iteration: 114/128 step: 58
[2025-12-23 17:56:48,497] m-LoRA: Adapter lora_finqa_47 loss: 8.777038601692766e-05
[2025-12-23 17:56:48,814] m-LoRA: Adapter lora_finqa_61 loss: 0.01141700055450201
[2025-12-23 17:56:48,934] m-LoRA: Adapter lora_finqa_71 epoch: 1/1 iteration: 72/128 step: 10
[2025-12-23 17:56:49,519] m-LoRA: Adapter lora_finqa_23 loss: 5.075581793789752e-05
[2025-12-23 17:56:49,652] m-LoRA: Adapter lora_finqa_76 epoch: 1/1 iteration: 8/128 step: 2
[2025-12-23 17:56:50,261] m-LoRA: Adapter lora_finqa_48 loss: 0.0005338406190276146
[2025-12-23 17:56:50,264] m-LoRA: Adapter lora_finqa_57 epoch: 1/1 iteration: 50/128 step: 26
[2025-12-23 17:56:50,972] m-LoRA: Adapter lora_finqa_25 loss: 7.990394806256518e-05
[2025-12-23 17:56:50,975] m-LoRA: Adapter lora_finqa_72 epoch: 1/1 iteration: 36/128 step: 10
[2025-12-23 17:56:51,539] m-LoRA: Adapter lora_finqa_36 epoch: 1/1 iteration: 98/128 step: 50
[2025-12-23 17:56:51,572] m-LoRA: Adapter lora_finqa_62 loss: 1.7972533702850342
[2025-12-23 17:56:52,120] m-LoRA: Adapter lora_finqa_63 loss: 0.01096043735742569
[2025-12-23 17:56:52,125] m-LoRA: Adapter lora_finqa_15 epoch: 1/1 iteration: 114/128 step: 58
[2025-12-23 17:56:53,184] m-LoRA: Adapter lora_finqa_77 epoch: 1/1 iteration: 4/128 step: 2
[2025-12-23 17:56:53,259] m-LoRA: Adapter lora_finqa_75 loss: 2.4770684242248535
[2025-12-23 17:56:53,733] m-LoRA: Adapter lora_finqa_64 loss: 0.011858155019581318
[2025-12-23 17:56:53,738] m-LoRA: Adapter lora_finqa_16 epoch: 1/1 iteration: 114/128 step: 58
[2025-12-23 17:56:54,280] m-LoRA: Adapter lora_finqa_55 loss: 1.248375415802002
[2025-12-23 17:56:54,284] m-LoRA: Adapter lora_finqa_74 epoch: 1/1 iteration: 18/128 step: 10
[2025-12-23 17:56:54,713] m-LoRA: Adapter lora_finqa_40 loss: 0.010749999433755875
[2025-12-23 17:56:54,717] m-LoRA: Adapter lora_finqa_60 epoch: 1/1 iteration: 50/128 step: 26
[2025-12-23 17:56:55,448] m-LoRA: Adapter lora_finqa_65 loss: 0.011019234545528889
[2025-12-23 17:56:55,453] m-LoRA: Adapter lora_finqa_46 epoch: 1/1 iteration: 82/128 step: 42
[2025-12-23 17:56:55,817] m-LoRA: Adapter lora_finqa_0 loss: 0.004037091042846441
[2025-12-23 17:56:55,821] m-LoRA: Adapter lora_finqa_37 epoch: 1/1 iteration: 98/128 step: 50
[2025-12-23 17:56:56,121] m-LoRA: Adapter lora_finqa_3 loss: 0.003643528325483203
[2025-12-23 17:56:56,124] m-LoRA: Adapter lora_finqa_47 epoch: 1/1 iteration: 82/128 step: 42
[2025-12-23 17:56:56,759] m-LoRA: Adapter lora_finqa_70 loss: 0.4174267053604126
[2025-12-23 17:56:56,762] m-LoRA: Adapter lora_finqa_61 epoch: 1/1 iteration: 50/128 step: 26
[2025-12-23 17:56:57,484] m-LoRA: Adapter lora_finqa_1 loss: 0.0034598917700350285
[2025-12-23 17:56:57,487] m-LoRA: Adapter lora_finqa_23 epoch: 1/1 iteration: 114/128 step: 58
[2025-12-23 17:56:58,210] m-LoRA: Adapter lora_finqa_51 loss: 0.004254765808582306
[2025-12-23 17:56:58,213] m-LoRA: Adapter lora_finqa_48 epoch: 1/1 iteration: 82/128 step: 42
[2025-12-23 17:56:58,828] m-LoRA: Adapter lora_finqa_25 epoch: 1/1 iteration: 114/128 step: 58
[2025-12-23 17:56:58,888] m-LoRA: Adapter lora_finqa_66 loss: 0.010410686954855919
[2025-12-23 17:56:59,509] m-LoRA: Adapter lora_finqa_42 loss: 0.000255833932897076
[2025-12-23 17:56:59,512] m-LoRA: Adapter lora_finqa_62 epoch: 1/1 iteration: 100/128 step: 26
[2025-12-23 17:57:00,144] m-LoRA: Adapter lora_finqa_7 loss: 7.216590165626258e-05
[2025-12-23 17:57:00,148] m-LoRA: Adapter lora_finqa_63 epoch: 1/1 iteration: 100/128 step: 26
[2025-12-23 17:57:00,848] m-LoRA: Adapter lora_finqa_8 loss: 6.965717329876497e-05
[2025-12-23 17:57:00,978] m-LoRA: Adapter lora_finqa_75 epoch: 1/1 iteration: 72/128 step: 10
[2025-12-23 17:57:01,989] m-LoRA: Adapter lora_finqa_64 epoch: 1/1 iteration: 100/128 step: 26
[2025-12-23 17:57:02,070] m-LoRA: Adapter lora_finqa_71 loss: 0.3889486491680145
[2025-12-23 17:57:03,033] m-LoRA: Adapter lora_finqa_55 epoch: 1/1 iteration: 66/128 step: 34
[2025-12-23 17:57:03,103] m-LoRA: Adapter lora_finqa_76 loss: 2.474412441253662
[2025-12-23 17:57:03,365] m-LoRA: Adapter lora_finqa_57 loss: 0.03863268718123436
[2025-12-23 17:57:03,450] m-LoRA: Adapter lora_finqa_40 epoch: 1/1 iteration: 98/128 step: 50
[2025-12-23 17:57:03,953] m-LoRA: Adapter lora_finqa_65 epoch: 1/1 iteration: 100/128 step: 26
[2025-12-23 17:57:04,029] m-LoRA: Adapter lora_finqa_72 loss: 2.4526243209838867
[2025-12-23 17:57:04,215] m-LoRA: Adapter lora_finqa_0 epoch: 1/1 iteration: 116/128 step: 59
[2025-12-23 17:57:04,270] m-LoRA: Adapter lora_finqa_36 loss: 0.010325426235795021
[2025-12-23 17:57:04,569] m-LoRA: Adapter lora_finqa_15 loss: 4.741039811051451e-05
[2025-12-23 17:57:04,638] m-LoRA: Adapter lora_finqa_3 epoch: 1/1 iteration: 116/128 step: 59
[2025-12-23 17:57:05,244] m-LoRA: Adapter lora_finqa_70 epoch: 1/1 iteration: 20/128 step: 11
[2025-12-23 17:57:05,303] m-LoRA: Adapter lora_finqa_77 loss: 2.5429320335388184
[2025-12-23 17:57:05,606] m-LoRA: Adapter lora_finqa_16 loss: 4.7477071348112077e-05
[2025-12-23 17:57:05,610] m-LoRA: Adapter lora_finqa_1 epoch: 1/1 iteration: 116/128 step: 59
[2025-12-23 17:57:05,959] m-LoRA: Adapter lora_finqa_74 loss: 0.11536859720945358
[2025-12-23 17:57:05,962] m-LoRA: Adapter lora_finqa_51 epoch: 1/1 iteration: 68/128 step: 35
[2025-12-23 17:57:06,293] m-LoRA: Adapter lora_finqa_60 loss: 0.03952014446258545
[2025-12-23 17:57:06,296] m-LoRA: Adapter lora_finqa_66 epoch: 1/1 iteration: 72/128 step: 19
[2025-12-23 17:57:06,603] m-LoRA: Adapter lora_finqa_46 loss: 0.0006915307603776455
[2025-12-23 17:57:06,606] m-LoRA: Adapter lora_finqa_42 epoch: 1/1 iteration: 84/128 step: 43
[2025-12-23 17:57:06,961] m-LoRA: Adapter lora_finqa_37 loss: 0.009616115130484104
[2025-12-23 17:57:06,964] m-LoRA: Adapter lora_finqa_7 epoch: 1/1 iteration: 116/128 step: 59
[2025-12-23 17:57:07,343] m-LoRA: Adapter lora_finqa_47 loss: 8.180712757166475e-05
[2025-12-23 17:57:07,347] m-LoRA: Adapter lora_finqa_8 epoch: 1/1 iteration: 116/128 step: 59
[2025-12-23 17:57:07,772] m-LoRA: Adapter lora_finqa_61 loss: 0.011259077116847038
[2025-12-23 17:57:07,775] m-LoRA: Adapter lora_finqa_71 epoch: 1/1 iteration: 80/128 step: 11
[2025-12-23 17:57:08,094] m-LoRA: Adapter lora_finqa_23 loss: 4.569792145048268e-05
[2025-12-23 17:57:08,235] m-LoRA: Adapter lora_finqa_76 epoch: 1/1 iteration: 16/128 step: 3
[2025-12-23 17:57:08,509] m-LoRA: Adapter lora_finqa_48 loss: 0.00029323031776584685
[2025-12-23 17:57:08,512] m-LoRA: Adapter lora_finqa_57 epoch: 1/1 iteration: 52/128 step: 27
[2025-12-23 17:57:08,892] m-LoRA: Adapter lora_finqa_25 loss: 6.705630221404135e-05
[2025-12-23 17:57:08,895] m-LoRA: Adapter lora_finqa_72 epoch: 1/1 iteration: 40/128 step: 11
[2025-12-23 17:57:09,572] m-LoRA: Adapter lora_finqa_36 epoch: 1/1 iteration: 100/128 step: 51
[2025-12-23 17:57:09,630] m-LoRA: Adapter lora_finqa_62 loss: 1.7335094213485718
[2025-12-23 17:57:10,185] m-LoRA: Adapter lora_finqa_15 epoch: 1/1 iteration: 116/128 step: 59
[2025-12-23 17:57:10,239] m-LoRA: Adapter lora_finqa_63 loss: 0.010134135372936726
[2025-12-23 17:57:11,361] m-LoRA: Adapter lora_finqa_77 epoch: 1/1 iteration: 8/128 step: 3
[2025-12-23 17:57:11,439] m-LoRA: Adapter lora_finqa_75 loss: 2.450756788253784
[2025-12-23 17:57:11,884] m-LoRA: Adapter lora_finqa_16 epoch: 1/1 iteration: 116/128 step: 59
[2025-12-23 17:57:11,939] m-LoRA: Adapter lora_finqa_64 loss: 0.010401509702205658
[2025-12-23 17:57:12,149] m-LoRA: Adapter lora_finqa_74 epoch: 1/1 iteration: 20/128 step: 11
[2025-12-23 17:57:12,206] m-LoRA: Adapter lora_finqa_55 loss: 1.1704065799713135
[2025-12-23 17:57:12,417] m-LoRA: Adapter lora_finqa_40 loss: 0.010446158237755299
[2025-12-23 17:57:12,420] m-LoRA: Adapter lora_finqa_60 epoch: 1/1 iteration: 52/128 step: 27
[2025-12-23 17:57:13,004] m-LoRA: Adapter lora_finqa_46 epoch: 1/1 iteration: 84/128 step: 43
[2025-12-23 17:57:13,057] m-LoRA: Adapter lora_finqa_65 loss: 0.009140638634562492
[2025-12-23 17:57:13,390] m-LoRA: Adapter lora_finqa_0 loss: 0.003910488449037075
[2025-12-23 17:57:13,394] m-LoRA: Adapter lora_finqa_37 epoch: 1/1 iteration: 100/128 step: 51
[2025-12-23 17:57:13,782] m-LoRA: Adapter lora_finqa_3 loss: 0.0036027287133038044
[2025-12-23 17:57:13,785] m-LoRA: Adapter lora_finqa_47 epoch: 1/1 iteration: 84/128 step: 43
[2025-12-23 17:57:14,144] m-LoRA: Adapter lora_finqa_70 loss: 0.270029753446579
[2025-12-23 17:57:14,147] m-LoRA: Adapter lora_finqa_61 epoch: 1/1 iteration: 52/128 step: 27
[2025-12-23 17:57:14,463] m-LoRA: Adapter lora_finqa_1 loss: 0.0029642265290021896
[2025-12-23 17:57:14,466] m-LoRA: Adapter lora_finqa_23 epoch: 1/1 iteration: 116/128 step: 59
[2025-12-23 17:57:14,806] m-LoRA: Adapter lora_finqa_51 loss: 0.0030965027399361134
[2025-12-23 17:57:14,809] m-LoRA: Adapter lora_finqa_48 epoch: 1/1 iteration: 84/128 step: 43
[2025-12-23 17:57:15,486] m-LoRA: Adapter lora_finqa_66 loss: 0.009332442656159401
[2025-12-23 17:57:15,492] m-LoRA: Adapter lora_finqa_25 epoch: 1/1 iteration: 116/128 step: 59
[2025-12-23 17:57:15,803] m-LoRA: Adapter lora_finqa_42 loss: 0.00034051129478029907
[2025-12-23 17:57:15,806] m-LoRA: Adapter lora_finqa_62 epoch: 1/1 iteration: 104/128 step: 27
[2025-12-23 17:57:16,097] m-LoRA: Adapter lora_finqa_7 loss: 6.837960245320573e-05
[2025-12-23 17:57:16,101] m-LoRA: Adapter lora_finqa_63 epoch: 1/1 iteration: 104/128 step: 27
[2025-12-23 17:57:16,486] m-LoRA: Adapter lora_finqa_8 loss: 6.0657526773866266e-05
[2025-12-23 17:57:16,490] m-LoRA: Adapter lora_finqa_75 epoch: 1/1 iteration: 80/128 step: 11
[2025-12-23 17:57:17,592] m-LoRA: Adapter lora_finqa_64 epoch: 1/1 iteration: 104/128 step: 27
[2025-12-23 17:57:17,674] m-LoRA: Adapter lora_finqa_71 loss: 0.2616681456565857
[2025-12-23 17:57:18,800] m-LoRA: Adapter lora_finqa_55 epoch: 1/1 iteration: 68/128 step: 35
[2025-12-23 17:57:18,865] m-LoRA: Adapter lora_finqa_76 loss: 2.2499871253967285
[2025-12-23 17:57:19,160] m-LoRA: Adapter lora_finqa_57 loss: 0.03499215841293335
[2025-12-23 17:57:19,164] m-LoRA: Adapter lora_finqa_40 epoch: 1/1 iteration: 100/128 step: 51
[2025-12-23 17:57:19,819] m-LoRA: Adapter lora_finqa_65 epoch: 1/1 iteration: 104/128 step: 27
[2025-12-23 17:57:19,897] m-LoRA: Adapter lora_finqa_72 loss: 2.422632932662964
[2025-12-23 17:57:20,129] m-LoRA: Adapter lora_finqa_36 loss: 0.009762330912053585
[2025-12-23 17:57:20,132] m-LoRA: Adapter lora_finqa_0 epoch: 1/1 iteration: 118/128 step: 60
[2025-12-23 17:57:20,448] m-LoRA: Adapter lora_finqa_15 loss: 4.502817682805471e-05
[2025-12-23 17:57:20,451] m-LoRA: Adapter lora_finqa_3 epoch: 1/1 iteration: 118/128 step: 60
[2025-12-23 17:57:21,115] m-LoRA: Adapter lora_finqa_70 epoch: 1/1 iteration: 22/128 step: 12
[2025-12-23 17:57:21,147] m-LoRA: Adapter lora_finqa_77 loss: 2.4553422927856445
[2025-12-23 17:57:21,387] m-LoRA: Adapter lora_finqa_1 epoch: 1/1 iteration: 118/128 step: 60
[2025-12-23 17:57:21,446] m-LoRA: Adapter lora_finqa_16 loss: 4.644261207431555e-05
[2025-12-23 17:57:21,781] m-LoRA: Adapter lora_finqa_74 loss: 0.06680138409137726
[2025-12-23 17:57:21,784] m-LoRA: Adapter lora_finqa_51 epoch: 1/1 iteration: 70/128 step: 36
[2025-12-23 17:57:22,173] m-LoRA: Adapter lora_finqa_60 loss: 0.03504663705825806
[2025-12-23 17:57:22,177] m-LoRA: Adapter lora_finqa_66 epoch: 1/1 iteration: 76/128 step: 20
[2025-12-23 17:57:22,444] m-LoRA: Adapter lora_finqa_42 epoch: 1/1 iteration: 86/128 step: 44
[2025-12-23 17:57:22,499] m-LoRA: Adapter lora_finqa_46 loss: 0.0003131166158709675
[2025-12-23 17:57:22,773] m-LoRA: Adapter lora_finqa_37 loss: 0.010349825955927372
[2025-12-23 17:57:22,776] m-LoRA: Adapter lora_finqa_7 epoch: 1/1 iteration: 118/128 step: 60
[2025-12-23 17:57:23,171] m-LoRA: Adapter lora_finqa_47 loss: 7.735884719295427e-05
[2025-12-23 17:57:23,174] m-LoRA: Adapter lora_finqa_8 epoch: 1/1 iteration: 118/128 step: 60
[2025-12-23 17:57:23,482] m-LoRA: Adapter lora_finqa_61 loss: 0.009724732488393784
[2025-12-23 17:57:23,579] m-LoRA: Adapter lora_finqa_71 epoch: 1/1 iteration: 88/128 step: 12
[2025-12-23 17:57:23,872] m-LoRA: Adapter lora_finqa_23 loss: 4.3840991565957665e-05
[2025-12-23 17:57:23,970] m-LoRA: Adapter lora_finqa_76 epoch: 1/1 iteration: 24/128 step: 4
[2025-12-23 17:57:24,279] m-LoRA: Adapter lora_finqa_48 loss: 0.00032152258791029453
[2025-12-23 17:57:24,282] m-LoRA: Adapter lora_finqa_57 epoch: 1/1 iteration: 54/128 step: 28
[2025-12-23 17:57:24,654] m-LoRA: Adapter lora_finqa_25 loss: 6.342028063954785e-05
[2025-12-23 17:57:24,657] m-LoRA: Adapter lora_finqa_72 epoch: 1/1 iteration: 44/128 step: 12
[2025-12-23 17:57:25,268] m-LoRA: Adapter lora_finqa_36 epoch: 1/1 iteration: 102/128 step: 52
[2025-12-23 17:57:25,344] m-LoRA: Adapter lora_finqa_62 loss: 1.667279601097107
[2025-12-23 17:57:25,962] m-LoRA: Adapter lora_finqa_15 epoch: 1/1 iteration: 118/128 step: 60
[2025-12-23 17:57:26,000] m-LoRA: Adapter lora_finqa_63 loss: 0.009498516097664833
[2025-12-23 17:57:27,120] m-LoRA: Adapter lora_finqa_77 epoch: 1/1 iteration: 12/128 step: 4
[2025-12-23 17:57:27,223] m-LoRA: Adapter lora_finqa_75 loss: 2.42254900932312
[2025-12-23 17:57:27,791] m-LoRA: Adapter lora_finqa_16 epoch: 1/1 iteration: 118/128 step: 60
[2025-12-23 17:57:27,846] m-LoRA: Adapter lora_finqa_64 loss: 0.00987864937633276
[2025-12-23 17:57:28,100] m-LoRA: Adapter lora_finqa_74 epoch: 1/1 iteration: 22/128 step: 12
[2025-12-23 17:57:28,154] m-LoRA: Adapter lora_finqa_55 loss: 1.0927212238311768
[2025-12-23 17:57:28,478] m-LoRA: Adapter lora_finqa_40 loss: 0.009022092446684837
[2025-12-23 17:57:28,481] m-LoRA: Adapter lora_finqa_60 epoch: 1/1 iteration: 54/128 step: 28
[2025-12-23 17:57:29,004] m-LoRA: Adapter lora_finqa_46 epoch: 1/1 iteration: 86/128 step: 44
[2025-12-23 17:57:29,062] m-LoRA: Adapter lora_finqa_65 loss: 0.008478140458464622
[2025-12-23 17:57:29,319] m-LoRA: Adapter lora_finqa_37 epoch: 1/1 iteration: 102/128 step: 52
[2025-12-23 17:57:29,357] m-LoRA: Adapter lora_finqa_0 loss: 0.0033123944886028767
[2025-12-23 17:57:29,862] m-LoRA: Adapter lora_finqa_3 loss: 0.003272534115239978
[2025-12-23 17:57:29,865] m-LoRA: Adapter lora_finqa_47 epoch: 1/1 iteration: 86/128 step: 44
[2025-12-23 17:57:30,169] m-LoRA: Adapter lora_finqa_70 loss: 0.1934022456407547
[2025-12-23 17:57:30,173] m-LoRA: Adapter lora_finqa_61 epoch: 1/1 iteration: 54/128 step: 28
[2025-12-23 17:57:30,564] m-LoRA: Adapter lora_finqa_1 loss: 0.0025439311284571886
[2025-12-23 17:57:30,568] m-LoRA: Adapter lora_finqa_23 epoch: 1/1 iteration: 118/128 step: 60
[2025-12-23 17:57:30,902] m-LoRA: Adapter lora_finqa_48 epoch: 1/1 iteration: 86/128 step: 44
[2025-12-23 17:57:30,941] m-LoRA: Adapter lora_finqa_51 loss: 0.002266802592203021
[2025-12-23 17:57:31,623] m-LoRA: Adapter lora_finqa_66 loss: 0.007927902974188328
[2025-12-23 17:57:31,628] m-LoRA: Adapter lora_finqa_25 epoch: 1/1 iteration: 118/128 step: 60
[2025-12-23 17:57:31,939] m-LoRA: Adapter lora_finqa_42 loss: 0.0001868381950771436
[2025-12-23 17:57:31,942] m-LoRA: Adapter lora_finqa_62 epoch: 1/1 iteration: 108/128 step: 28
[2025-12-23 17:57:32,255] m-LoRA: Adapter lora_finqa_7 loss: 7.194303907454014e-05
[2025-12-23 17:57:32,259] m-LoRA: Adapter lora_finqa_63 epoch: 1/1 iteration: 108/128 step: 28
[2025-12-23 17:57:32,564] m-LoRA: Adapter lora_finqa_8 loss: 5.869993765372783e-05
[2025-12-23 17:57:32,754] m-LoRA: Adapter lora_finqa_75 epoch: 1/1 iteration: 88/128 step: 12
[2025-12-23 17:57:35,179] m-LoRA: Adapter lora_finqa_64 epoch: 1/1 iteration: 108/128 step: 28
[2025-12-23 17:57:35,254] m-LoRA: Adapter lora_finqa_71 loss: 0.18592770397663116
[2025-12-23 17:57:37,504] m-LoRA: Adapter lora_finqa_55 epoch: 1/1 iteration: 70/128 step: 36
[2025-12-23 17:57:37,570] m-LoRA: Adapter lora_finqa_76 loss: 1.9891754388809204
[2025-12-23 17:57:37,830] m-LoRA: Adapter lora_finqa_57 loss: 0.03179389238357544
[2025-12-23 17:57:37,833] m-LoRA: Adapter lora_finqa_40 epoch: 1/1 iteration: 102/128 step: 52
[2025-12-23 17:57:38,951] m-LoRA: Adapter lora_finqa_65 epoch: 1/1 iteration: 108/128 step: 28
[2025-12-23 17:57:39,009] m-LoRA: Adapter lora_finqa_72 loss: 2.39388370513916
[2025-12-23 17:57:39,431] m-LoRA: Adapter lora_finqa_36 loss: 0.009463564492762089
[2025-12-23 17:57:39,434] m-LoRA: Adapter lora_finqa_0 epoch: 1/1 iteration: 120/128 step: 61
[2025-12-23 17:57:40,095] m-LoRA: Adapter lora_finqa_15 loss: 4.851008634432219e-05
[2025-12-23 17:57:40,098] m-LoRA: Adapter lora_finqa_3 epoch: 1/1 iteration: 120/128 step: 61
[2025-12-23 17:57:41,386] m-LoRA: Adapter lora_finqa_70 epoch: 1/1 iteration: 24/128 step: 13
[2025-12-23 17:57:41,418] m-LoRA: Adapter lora_finqa_77 loss: 2.3372609615325928
[2025-12-23 17:57:41,678] m-LoRA: Adapter lora_finqa_1 epoch: 1/1 iteration: 120/128 step: 61
[2025-12-23 17:57:41,733] m-LoRA: Adapter lora_finqa_16 loss: 4.325925692683086e-05
[2025-12-23 17:57:42,274] m-LoRA: Adapter lora_finqa_74 loss: 0.04574548825621605
[2025-12-23 17:57:42,277] m-LoRA: Adapter lora_finqa_51 epoch: 1/1 iteration: 72/128 step: 37
[2025-12-23 17:57:42,679] m-LoRA: Adapter lora_finqa_60 loss: 0.03253021463751793
[2025-12-23 17:57:42,683] m-LoRA: Adapter lora_finqa_66 epoch: 1/1 iteration: 80/128 step: 21
[2025-12-23 17:57:43,372] m-LoRA: Adapter lora_finqa_46 loss: 0.0002326488756807521
[2025-12-23 17:57:43,376] m-LoRA: Adapter lora_finqa_42 epoch: 1/1 iteration: 88/128 step: 45
[2025-12-23 17:57:44,046] m-LoRA: Adapter lora_finqa_37 loss: 0.008772349916398525
[2025-12-23 17:57:44,050] m-LoRA: Adapter lora_finqa_7 epoch: 1/1 iteration: 120/128 step: 61
[2025-12-23 17:57:44,702] m-LoRA: Adapter lora_finqa_47 loss: 7.56877416279167e-05
[2025-12-23 17:57:44,705] m-LoRA: Adapter lora_finqa_8 epoch: 1/1 iteration: 120/128 step: 61
[2025-12-23 17:57:45,467] m-LoRA: Adapter lora_finqa_61 loss: 0.008908857591450214
[2025-12-23 17:57:45,471] m-LoRA: Adapter lora_finqa_71 epoch: 1/1 iteration: 96/128 step: 13
[2025-12-23 17:57:45,981] m-LoRA: Adapter lora_finqa_23 loss: 4.242319846525788e-05
[2025-12-23 17:57:46,077] m-LoRA: Adapter lora_finqa_76 epoch: 1/1 iteration: 32/128 step: 5
[2025-12-23 17:57:46,724] m-LoRA: Adapter lora_finqa_48 loss: 0.00019504853116814047
[2025-12-23 17:57:46,728] m-LoRA: Adapter lora_finqa_57 epoch: 1/1 iteration: 56/128 step: 29
[2025-12-23 17:57:47,418] m-LoRA: Adapter lora_finqa_25 loss: 9.297353244619444e-05
[2025-12-23 17:57:47,422] m-LoRA: Adapter lora_finqa_72 epoch: 1/1 iteration: 48/128 step: 13
[2025-12-23 17:57:47,946] m-LoRA: Adapter lora_finqa_36 epoch: 1/1 iteration: 104/128 step: 53
[2025-12-23 17:57:47,977] m-LoRA: Adapter lora_finqa_62 loss: 1.603175163269043
[2025-12-23 17:57:48,626] m-LoRA: Adapter lora_finqa_63 loss: 0.008347264491021633
[2025-12-23 17:57:48,631] m-LoRA: Adapter lora_finqa_15 epoch: 1/1 iteration: 120/128 step: 61
[2025-12-23 17:57:49,619] m-LoRA: Adapter lora_finqa_77 epoch: 1/1 iteration: 16/128 step: 5
[2025-12-23 17:57:49,699] m-LoRA: Adapter lora_finqa_75 loss: 2.3920176029205322
[2025-12-23 17:57:50,164] m-LoRA: Adapter lora_finqa_64 loss: 0.009829320944845676
[2025-12-23 17:57:50,169] m-LoRA: Adapter lora_finqa_16 epoch: 1/1 iteration: 120/128 step: 61
[2025-12-23 17:57:50,706] m-LoRA: Adapter lora_finqa_74 epoch: 1/1 iteration: 24/128 step: 13
[2025-12-23 17:57:50,743] m-LoRA: Adapter lora_finqa_55 loss: 1.0168752670288086
[2025-12-23 17:57:51,017] m-LoRA: Adapter lora_finqa_40 loss: 0.009405682794749737
[2025-12-23 17:57:51,020] m-LoRA: Adapter lora_finqa_60 epoch: 1/1 iteration: 56/128 step: 29
[2025-12-23 17:57:51,816] m-LoRA: Adapter lora_finqa_65 loss: 0.007882971316576004
[2025-12-23 17:57:51,821] m-LoRA: Adapter lora_finqa_46 epoch: 1/1 iteration: 88/128 step: 45
[2025-12-23 17:57:52,216] m-LoRA: Adapter lora_finqa_0 loss: 0.0025760082062333822
[2025-12-23 17:57:52,220] m-LoRA: Adapter lora_finqa_37 epoch: 1/1 iteration: 104/128 step: 53
[2025-12-23 17:57:52,554] m-LoRA: Adapter lora_finqa_3 loss: 0.002763981930911541
[2025-12-23 17:57:52,558] m-LoRA: Adapter lora_finqa_47 epoch: 1/1 iteration: 88/128 step: 45
[2025-12-23 17:57:52,843] m-LoRA: Adapter lora_finqa_70 loss: 0.1265900582075119
[2025-12-23 17:57:52,846] m-LoRA: Adapter lora_finqa_61 epoch: 1/1 iteration: 56/128 step: 29
[2025-12-23 17:57:53,183] m-LoRA: Adapter lora_finqa_1 loss: 0.002057935344055295
[2025-12-23 17:57:53,186] m-LoRA: Adapter lora_finqa_23 epoch: 1/1 iteration: 120/128 step: 61
[2025-12-23 17:57:53,880] m-LoRA: Adapter lora_finqa_51 loss: 0.0015641824575141072
[2025-12-23 17:57:53,883] m-LoRA: Adapter lora_finqa_48 epoch: 1/1 iteration: 88/128 step: 45
[2025-12-23 17:57:54,500] m-LoRA: Adapter lora_finqa_66 loss: 0.006818360183387995
[2025-12-23 17:57:54,505] m-LoRA: Adapter lora_finqa_25 epoch: 1/1 iteration: 120/128 step: 61
[2025-12-23 17:57:55,201] m-LoRA: Adapter lora_finqa_42 loss: 0.00015822540444787592
[2025-12-23 17:57:55,204] m-LoRA: Adapter lora_finqa_62 epoch: 1/1 iteration: 112/128 step: 29
[2025-12-23 17:57:55,457] m-LoRA: Adapter lora_finqa_7 loss: 6.24988169874996e-05
[2025-12-23 17:57:55,578] m-LoRA: Adapter lora_finqa_63 epoch: 1/1 iteration: 112/128 step: 29
[2025-12-23 17:57:55,871] m-LoRA: Adapter lora_finqa_8 loss: 5.749682895839214e-05
[2025-12-23 17:57:55,989] m-LoRA: Adapter lora_finqa_75 epoch: 1/1 iteration: 96/128 step: 13
[2025-12-23 17:57:57,138] m-LoRA: Adapter lora_finqa_64 epoch: 1/1 iteration: 112/128 step: 29
[2025-12-23 17:57:57,219] m-LoRA: Adapter lora_finqa_71 loss: 0.11897094547748566
[2025-12-23 17:57:58,186] m-LoRA: Adapter lora_finqa_55 epoch: 1/1 iteration: 72/128 step: 37
[2025-12-23 17:57:58,288] m-LoRA: Adapter lora_finqa_76 loss: 1.7026770114898682
[2025-12-23 17:57:58,533] m-LoRA: Adapter lora_finqa_57 loss: 0.02883736416697502
[2025-12-23 17:57:58,536] m-LoRA: Adapter lora_finqa_40 epoch: 1/1 iteration: 104/128 step: 53
[2025-12-23 17:57:59,306] m-LoRA: Adapter lora_finqa_72 loss: 2.3607044219970703
[2025-12-23 17:57:59,312] m-LoRA: Adapter lora_finqa_65 epoch: 1/1 iteration: 112/128 step: 29
[2025-12-23 17:57:59,586] m-LoRA: Adapter lora_finqa_36 loss: 0.008611137047410011
[2025-12-23 17:57:59,590] m-LoRA: Adapter lora_finqa_0 epoch: 1/1 iteration: 122/128 step: 62
[2025-12-23 17:57:59,874] m-LoRA: Adapter lora_finqa_15 loss: 4.232844366924837e-05
[2025-12-23 17:57:59,877] m-LoRA: Adapter lora_finqa_3 epoch: 1/1 iteration: 122/128 step: 62
[2025-12-23 17:58:00,609] m-LoRA: Adapter lora_finqa_70 epoch: 1/1 iteration: 26/128 step: 14
[2025-12-23 17:58:00,669] m-LoRA: Adapter lora_finqa_77 loss: 2.195693254470825
[2025-12-23 17:58:00,952] m-LoRA: Adapter lora_finqa_16 loss: 4.238777546561323e-05
[2025-12-23 17:58:01,010] m-LoRA: Adapter lora_finqa_1 epoch: 1/1 iteration: 122/128 step: 62
[2025-12-23 17:58:01,349] m-LoRA: Adapter lora_finqa_74 loss: 0.035080164670944214
[2025-12-23 17:58:01,353] m-LoRA: Adapter lora_finqa_51 epoch: 1/1 iteration: 74/128 step: 38
[2025-12-23 17:58:01,680] m-LoRA: Adapter lora_finqa_60 loss: 0.029091447591781616
[2025-12-23 17:58:01,683] m-LoRA: Adapter lora_finqa_66 epoch: 1/1 iteration: 84/128 step: 22
[2025-12-23 17:58:01,980] m-LoRA: Adapter lora_finqa_46 loss: 0.00018985418137162924
[2025-12-23 17:58:01,983] m-LoRA: Adapter lora_finqa_42 epoch: 1/1 iteration: 90/128 step: 46
[2025-12-23 17:58:02,324] m-LoRA: Adapter lora_finqa_37 loss: 0.008340372703969479
[2025-12-23 17:58:02,328] m-LoRA: Adapter lora_finqa_7 epoch: 1/1 iteration: 122/128 step: 62
[2025-12-23 17:58:02,634] m-LoRA: Adapter lora_finqa_47 loss: 6.975371070438996e-05
[2025-12-23 17:58:02,637] m-LoRA: Adapter lora_finqa_8 epoch: 1/1 iteration: 122/128 step: 62
[2025-12-23 17:58:03,055] m-LoRA: Adapter lora_finqa_61 loss: 0.007999776862561703
[2025-12-23 17:58:03,058] m-LoRA: Adapter lora_finqa_71 epoch: 1/1 iteration: 104/128 step: 14
[2025-12-23 17:58:03,310] m-LoRA: Adapter lora_finqa_23 loss: 4.217103196424432e-05
[2025-12-23 17:58:03,438] m-LoRA: Adapter lora_finqa_76 epoch: 1/1 iteration: 40/128 step: 6
[2025-12-23 17:58:03,717] m-LoRA: Adapter lora_finqa_48 loss: 0.00022437507868744433
[2025-12-23 17:58:03,720] m-LoRA: Adapter lora_finqa_57 epoch: 1/1 iteration: 58/128 step: 30
[2025-12-23 17:58:04,083] m-LoRA: Adapter lora_finqa_25 loss: 6.490135274361819e-05
[2025-12-23 17:58:04,087] m-LoRA: Adapter lora_finqa_72 epoch: 1/1 iteration: 52/128 step: 14
[2025-12-23 17:58:04,793] m-LoRA: Adapter lora_finqa_62 loss: 1.541624903678894
[2025-12-23 17:58:04,798] m-LoRA: Adapter lora_finqa_36 epoch: 1/1 iteration: 106/128 step: 54
[2025-12-23 17:58:05,495] m-LoRA: Adapter lora_finqa_63 loss: 0.008112446404993534
[2025-12-23 17:58:05,501] m-LoRA: Adapter lora_finqa_15 epoch: 1/1 iteration: 122/128 step: 62
[2025-12-23 17:58:06,564] m-LoRA: Adapter lora_finqa_77 epoch: 1/1 iteration: 20/128 step: 6
[2025-12-23 17:58:06,631] m-LoRA: Adapter lora_finqa_75 loss: 2.356844425201416
[2025-12-23 17:58:07,244] m-LoRA: Adapter lora_finqa_64 loss: 0.008237659931182861
[2025-12-23 17:58:07,249] m-LoRA: Adapter lora_finqa_16 epoch: 1/1 iteration: 122/128 step: 62
[2025-12-23 17:58:07,609] m-LoRA: Adapter lora_finqa_55 loss: 0.9387373924255371
[2025-12-23 17:58:07,612] m-LoRA: Adapter lora_finqa_74 epoch: 1/1 iteration: 26/128 step: 14
[2025-12-23 17:58:07,893] m-LoRA: Adapter lora_finqa_40 loss: 0.00862434133887291
[2025-12-23 17:58:07,897] m-LoRA: Adapter lora_finqa_60 epoch: 1/1 iteration: 58/128 step: 30
[2025-12-23 17:58:08,457] m-LoRA: Adapter lora_finqa_46 epoch: 1/1 iteration: 90/128 step: 46
[2025-12-23 17:58:08,514] m-LoRA: Adapter lora_finqa_65 loss: 0.0066166468895971775
[2025-12-23 17:58:08,809] m-LoRA: Adapter lora_finqa_37 epoch: 1/1 iteration: 106/128 step: 54
[2025-12-23 17:58:08,864] m-LoRA: Adapter lora_finqa_0 loss: 0.0020156470127403736
[2025-12-23 17:58:09,261] m-LoRA: Adapter lora_finqa_3 loss: 0.002772901440039277
[2025-12-23 17:58:09,264] m-LoRA: Adapter lora_finqa_47 epoch: 1/1 iteration: 90/128 step: 46
[2025-12-23 17:58:09,579] m-LoRA: Adapter lora_finqa_70 loss: 0.077018141746521
[2025-12-23 17:58:09,582] m-LoRA: Adapter lora_finqa_61 epoch: 1/1 iteration: 58/128 step: 30
[2025-12-23 17:58:09,939] m-LoRA: Adapter lora_finqa_1 loss: 0.0024971524253487587
[2025-12-23 17:58:09,943] m-LoRA: Adapter lora_finqa_23 epoch: 1/1 iteration: 122/128 step: 62
[2025-12-23 17:58:10,270] m-LoRA: Adapter lora_finqa_51 loss: 0.0010604211129248142
[2025-12-23 17:58:10,273] m-LoRA: Adapter lora_finqa_48 epoch: 1/1 iteration: 90/128 step: 46
[2025-12-23 17:58:10,930] m-LoRA: Adapter lora_finqa_66 loss: 0.006520545110106468
[2025-12-23 17:58:10,936] m-LoRA: Adapter lora_finqa_25 epoch: 1/1 iteration: 122/128 step: 62
[2025-12-23 17:58:11,248] m-LoRA: Adapter lora_finqa_42 loss: 0.00013687091995961964
[2025-12-23 17:58:11,252] m-LoRA: Adapter lora_finqa_62 epoch: 1/1 iteration: 116/128 step: 30
[2025-12-23 17:58:11,565] m-LoRA: Adapter lora_finqa_7 loss: 6.624115485465154e-05
[2025-12-23 17:58:11,569] m-LoRA: Adapter lora_finqa_63 epoch: 1/1 iteration: 116/128 step: 30
[2025-12-23 17:58:11,878] m-LoRA: Adapter lora_finqa_8 loss: 5.743575457017869e-05
[2025-12-23 17:58:12,012] m-LoRA: Adapter lora_finqa_75 epoch: 1/1 iteration: 104/128 step: 14
[2025-12-23 17:58:13,145] m-LoRA: Adapter lora_finqa_64 epoch: 1/1 iteration: 116/128 step: 30
[2025-12-23 17:58:13,293] m-LoRA: Adapter lora_finqa_71 loss: 0.0682273581624031
[2025-12-23 17:58:15,057] m-LoRA: Adapter lora_finqa_55 epoch: 1/1 iteration: 74/128 step: 38
[2025-12-23 17:58:15,121] m-LoRA: Adapter lora_finqa_76 loss: 1.393775224685669
[2025-12-23 17:58:15,402] m-LoRA: Adapter lora_finqa_57 loss: 0.02630041353404522
[2025-12-23 17:58:15,405] m-LoRA: Adapter lora_finqa_40 epoch: 1/1 iteration: 106/128 step: 54
[2025-12-23 17:58:15,983] m-LoRA: Adapter lora_finqa_65 epoch: 1/1 iteration: 116/128 step: 30
[2025-12-23 17:58:16,064] m-LoRA: Adapter lora_finqa_72 loss: 2.3221662044525146
[2025-12-23 17:58:16,234] m-LoRA: Adapter lora_finqa_36 loss: 0.008068537339568138
[2025-12-23 17:58:16,238] m-LoRA: Adapter lora_finqa_0 epoch: 1/1 iteration: 124/128 step: 63
[2025-12-23 17:58:16,530] m-LoRA: Adapter lora_finqa_15 loss: 4.195000292384066e-05
[2025-12-23 17:58:16,534] m-LoRA: Adapter lora_finqa_3 epoch: 1/1 iteration: 124/128 step: 63
[2025-12-23 17:58:17,772] m-LoRA: Adapter lora_finqa_77 loss: 2.0463316440582275
[2025-12-23 17:58:17,778] m-LoRA: Adapter lora_finqa_70 epoch: 1/1 iteration: 28/128 step: 15
[2025-12-23 17:58:17,982] m-LoRA: Adapter lora_finqa_16 loss: 4.155036367592402e-05
[2025-12-23 17:58:17,986] m-LoRA: Adapter lora_finqa_1 epoch: 1/1 iteration: 124/128 step: 63
[2025-12-23 17:58:18,179] m-LoRA: Adapter lora_finqa_74 loss: 0.02517702244222164
[2025-12-23 17:58:18,182] m-LoRA: Adapter lora_finqa_51 epoch: 1/1 iteration: 76/128 step: 39
[2025-12-23 17:58:18,496] m-LoRA: Adapter lora_finqa_66 epoch: 1/1 iteration: 88/128 step: 23
[2025-12-23 17:58:18,575] m-LoRA: Adapter lora_finqa_60 loss: 0.02642596885561943
[2025-12-23 17:58:18,853] m-LoRA: Adapter lora_finqa_46 loss: 0.00019061686180066317
[2025-12-23 17:58:18,856] m-LoRA: Adapter lora_finqa_42 epoch: 1/1 iteration: 92/128 step: 47
[2025-12-23 17:58:19,212] m-LoRA: Adapter lora_finqa_37 loss: 0.008341030217707157
[2025-12-23 17:58:19,215] m-LoRA: Adapter lora_finqa_7 epoch: 1/1 iteration: 124/128 step: 63
[2025-12-23 17:58:19,665] m-LoRA: Adapter lora_finqa_47 loss: 6.935901910765097e-05
[2025-12-23 17:58:19,668] m-LoRA: Adapter lora_finqa_8 epoch: 1/1 iteration: 124/128 step: 63
[2025-12-23 17:58:19,989] m-LoRA: Adapter lora_finqa_61 loss: 0.0071430327370762825
[2025-12-23 17:58:20,121] m-LoRA: Adapter lora_finqa_71 epoch: 1/1 iteration: 112/128 step: 15
[2025-12-23 17:58:20,424] m-LoRA: Adapter lora_finqa_23 loss: 4.059427374158986e-05
[2025-12-23 17:58:20,552] m-LoRA: Adapter lora_finqa_76 epoch: 1/1 iteration: 48/128 step: 7
[2025-12-23 17:58:20,839] m-LoRA: Adapter lora_finqa_48 loss: 0.00015318630903493613
[2025-12-23 17:58:20,843] m-LoRA: Adapter lora_finqa_57 epoch: 1/1 iteration: 60/128 step: 31
[2025-12-23 17:58:21,149] m-LoRA: Adapter lora_finqa_72 epoch: 1/1 iteration: 56/128 step: 15
[2025-12-23 17:58:21,224] m-LoRA: Adapter lora_finqa_25 loss: 6.456392293330282e-05
[2025-12-23 17:58:21,819] m-LoRA: Adapter lora_finqa_36 epoch: 1/1 iteration: 108/128 step: 55
[2025-12-23 17:58:21,884] m-LoRA: Adapter lora_finqa_62 loss: 1.4769552946090698
[2025-12-23 17:58:23,286] m-LoRA: Adapter lora_finqa_15 epoch: 1/1 iteration: 124/128 step: 63
[2025-12-23 17:58:23,321] m-LoRA: Adapter lora_finqa_63 loss: 0.006446159444749355
[2025-12-23 17:58:25,173] m-LoRA: Adapter lora_finqa_77 epoch: 1/1 iteration: 24/128 step: 7
[2025-12-23 17:58:25,251] m-LoRA: Adapter lora_finqa_75 loss: 2.321152687072754
[2025-12-23 17:58:26,385] m-LoRA: Adapter lora_finqa_16 epoch: 1/1 iteration: 124/128 step: 63
[2025-12-23 17:58:26,444] m-LoRA: Adapter lora_finqa_64 loss: 0.007842088118195534
[2025-12-23 17:58:26,663] m-LoRA: Adapter lora_finqa_55 loss: 0.8603343367576599
[2025-12-23 17:58:26,666] m-LoRA: Adapter lora_finqa_74 epoch: 1/1 iteration: 28/128 step: 15
[2025-12-23 17:58:27,503] m-LoRA: Adapter lora_finqa_40 loss: 0.007539954502135515
[2025-12-23 17:58:27,507] m-LoRA: Adapter lora_finqa_60 epoch: 1/1 iteration: 60/128 step: 31
[2025-12-23 17:58:28,307] m-LoRA: Adapter lora_finqa_65 loss: 0.00611847871914506
[2025-12-23 17:58:28,312] m-LoRA: Adapter lora_finqa_46 epoch: 1/1 iteration: 92/128 step: 47
[2025-12-23 17:58:28,966] m-LoRA: Adapter lora_finqa_0 loss: 0.002025052672252059
[2025-12-23 17:58:28,969] m-LoRA: Adapter lora_finqa_37 epoch: 1/1 iteration: 108/128 step: 55
[2025-12-23 17:58:29,656] m-LoRA: Adapter lora_finqa_3 loss: 0.0020438816864043474
[2025-12-23 17:58:29,660] m-LoRA: Adapter lora_finqa_47 epoch: 1/1 iteration: 92/128 step: 47
[2025-12-23 17:58:29,980] m-LoRA: Adapter lora_finqa_70 loss: 0.05161790922284126
[2025-12-23 17:58:29,983] m-LoRA: Adapter lora_finqa_61 epoch: 1/1 iteration: 60/128 step: 31
[2025-12-23 17:58:30,340] m-LoRA: Adapter lora_finqa_1 loss: 0.0013466384261846542
[2025-12-23 17:58:30,343] m-LoRA: Adapter lora_finqa_23 epoch: 1/1 iteration: 124/128 step: 63
[2025-12-23 17:58:30,651] m-LoRA: Adapter lora_finqa_48 epoch: 1/1 iteration: 92/128 step: 47
[2025-12-23 17:58:30,703] m-LoRA: Adapter lora_finqa_51 loss: 0.0011126509634777904
[2025-12-23 17:58:31,723] m-LoRA: Adapter lora_finqa_25 epoch: 1/1 iteration: 124/128 step: 63
[2025-12-23 17:58:31,778] m-LoRA: Adapter lora_finqa_66 loss: 0.005158022977411747
[2025-12-23 17:58:32,330] m-LoRA: Adapter lora_finqa_42 loss: 0.00015026560868136585
[2025-12-23 17:58:32,333] m-LoRA: Adapter lora_finqa_62 epoch: 1/1 iteration: 120/128 step: 31
[2025-12-23 17:58:32,965] m-LoRA: Adapter lora_finqa_7 loss: 5.555384632316418e-05
[2025-12-23 17:58:32,968] m-LoRA: Adapter lora_finqa_63 epoch: 1/1 iteration: 120/128 step: 31
[2025-12-23 17:58:33,645] m-LoRA: Adapter lora_finqa_8 loss: 5.862520629307255e-05
[2025-12-23 17:58:33,756] m-LoRA: Adapter lora_finqa_75 epoch: 1/1 iteration: 112/128 step: 15
[2025-12-23 17:58:34,830] m-LoRA: Adapter lora_finqa_64 epoch: 1/1 iteration: 120/128 step: 31
[2025-12-23 17:58:34,926] m-LoRA: Adapter lora_finqa_71 loss: 0.04455552250146866
[2025-12-23 17:58:35,917] m-LoRA: Adapter lora_finqa_55 epoch: 1/1 iteration: 76/128 step: 39
[2025-12-23 17:58:36,007] m-LoRA: Adapter lora_finqa_76 loss: 1.0905580520629883
[2025-12-23 17:58:36,612] m-LoRA: Adapter lora_finqa_40 epoch: 1/1 iteration: 108/128 step: 55
[2025-12-23 17:58:36,642] m-LoRA: Adapter lora_finqa_57 loss: 0.02371453121304512
[2025-12-23 17:58:37,968] m-LoRA: Adapter lora_finqa_72 loss: 2.285123109817505
[2025-12-23 17:58:37,974] m-LoRA: Adapter lora_finqa_65 epoch: 1/1 iteration: 120/128 step: 31
[2025-12-23 17:58:38,597] m-LoRA: Adapter lora_finqa_36 loss: 0.007568054366856813
[2025-12-23 17:58:38,600] m-LoRA: Adapter lora_finqa_0 epoch: 1/1 iteration: 126/128 step: 64
[2025-12-23 17:58:39,253] m-LoRA: Adapter lora_finqa_15 loss: 4.066962355864234e-05
[2025-12-23 17:58:39,256] m-LoRA: Adapter lora_finqa_3 epoch: 1/1 iteration: 126/128 step: 64
[2025-12-23 17:58:39,915] m-LoRA: Adapter lora_finqa_70 epoch: 1/1 iteration: 30/128 step: 16
[2025-12-23 17:58:39,948] m-LoRA: Adapter lora_finqa_77 loss: 1.8934060335159302
[2025-12-23 17:58:40,526] m-LoRA: Adapter lora_finqa_16 loss: 4.083482417627238e-05
[2025-12-23 17:58:40,529] m-LoRA: Adapter lora_finqa_1 epoch: 1/1 iteration: 126/128 step: 64
[2025-12-23 17:58:40,854] m-LoRA: Adapter lora_finqa_74 loss: 0.01842975802719593
[2025-12-23 17:58:40,857] m-LoRA: Adapter lora_finqa_51 epoch: 1/1 iteration: 78/128 step: 40
[2025-12-23 17:58:41,239] m-LoRA: Adapter lora_finqa_60 loss: 0.023772476240992546
[2025-12-23 17:58:41,242] m-LoRA: Adapter lora_finqa_66 epoch: 1/1 iteration: 92/128 step: 24
[2025-12-23 17:58:41,611] m-LoRA: Adapter lora_finqa_46 loss: 0.00015395261289086193
[2025-12-23 17:58:41,614] m-LoRA: Adapter lora_finqa_42 epoch: 1/1 iteration: 94/128 step: 48
[2025-12-23 17:58:41,989] m-LoRA: Adapter lora_finqa_7 epoch: 1/1 iteration: 126/128 step: 64
[2025-12-23 17:58:42,041] m-LoRA: Adapter lora_finqa_37 loss: 0.007311259862035513
[2025-12-23 17:58:42,668] m-LoRA: Adapter lora_finqa_47 loss: 6.733173358952627e-05
[2025-12-23 17:58:42,671] m-LoRA: Adapter lora_finqa_8 epoch: 1/1 iteration: 126/128 step: 64
[2025-12-23 17:58:42,982] m-LoRA: Adapter lora_finqa_61 loss: 0.006491066887974739
[2025-12-23 17:58:43,112] m-LoRA: Adapter lora_finqa_71 epoch: 1/1 iteration: 120/128 step: 16
[2025-12-23 17:58:43,703] m-LoRA: Adapter lora_finqa_23 loss: 3.963436029152945e-05
[2025-12-23 17:58:43,832] m-LoRA: Adapter lora_finqa_76 epoch: 1/1 iteration: 56/128 step: 8
[2025-12-23 17:58:44,430] m-LoRA: Adapter lora_finqa_48 loss: 0.00014594040112569928
[2025-12-23 17:58:44,433] m-LoRA: Adapter lora_finqa_57 epoch: 1/1 iteration: 62/128 step: 32
[2025-12-23 17:58:44,821] m-LoRA: Adapter lora_finqa_25 loss: 5.80404739594087e-05
[2025-12-23 17:58:44,825] m-LoRA: Adapter lora_finqa_72 epoch: 1/1 iteration: 60/128 step: 16
[2025-12-23 17:58:45,367] m-LoRA: Adapter lora_finqa_36 epoch: 1/1 iteration: 110/128 step: 56
[2025-12-23 17:58:45,402] m-LoRA: Adapter lora_finqa_62 loss: 1.405339002609253
[2025-12-23 17:58:46,029] m-LoRA: Adapter lora_finqa_63 loss: 0.006113413255661726
[2025-12-23 17:58:46,035] m-LoRA: Adapter lora_finqa_15 epoch: 1/1 iteration: 126/128 step: 64
[2025-12-23 17:58:47,130] m-LoRA: Adapter lora_finqa_77 epoch: 1/1 iteration: 28/128 step: 8
[2025-12-23 17:58:47,212] m-LoRA: Adapter lora_finqa_75 loss: 2.2811005115509033
[2025-12-23 17:58:47,685] m-LoRA: Adapter lora_finqa_16 epoch: 1/1 iteration: 126/128 step: 64
[2025-12-23 17:58:47,719] m-LoRA: Adapter lora_finqa_64 loss: 0.006627557333558798
[2025-12-23 17:58:47,951] m-LoRA: Adapter lora_finqa_55 loss: 0.7868988513946533
[2025-12-23 17:58:47,955] m-LoRA: Adapter lora_finqa_74 epoch: 1/1 iteration: 30/128 step: 16
[2025-12-23 17:58:48,232] m-LoRA: Adapter lora_finqa_40 loss: 0.007030704990029335
[2025-12-23 17:58:48,235] m-LoRA: Adapter lora_finqa_60 epoch: 1/1 iteration: 62/128 step: 32
[2025-12-23 17:58:48,879] m-LoRA: Adapter lora_finqa_46 epoch: 1/1 iteration: 94/128 step: 48
[2025-12-23 17:58:48,932] m-LoRA: Adapter lora_finqa_65 loss: 0.004912588279694319
[2025-12-23 17:58:49,243] m-LoRA: Adapter lora_finqa_0 loss: 0.0013706522295251489
[2025-12-23 17:58:49,246] m-LoRA: Adapter lora_finqa_37 epoch: 1/1 iteration: 110/128 step: 56
[2025-12-23 17:58:49,624] m-LoRA: Adapter lora_finqa_3 loss: 0.0014270632527768612
[2025-12-23 17:58:49,627] m-LoRA: Adapter lora_finqa_47 epoch: 1/1 iteration: 94/128 step: 48
[2025-12-23 17:58:49,964] m-LoRA: Adapter lora_finqa_70 loss: 0.03746224194765091
[2025-12-23 17:58:49,967] m-LoRA: Adapter lora_finqa_61 epoch: 1/1 iteration: 62/128 step: 32
[2025-12-23 17:58:50,251] m-LoRA: Adapter lora_finqa_1 loss: 0.0011838818900287151
[2025-12-23 17:58:50,254] m-LoRA: Adapter lora_finqa_23 epoch: 1/1 iteration: 126/128 step: 64
[2025-12-23 17:58:50,607] m-LoRA: Adapter lora_finqa_51 loss: 0.0006874256650917232
[2025-12-23 17:58:50,610] m-LoRA: Adapter lora_finqa_48 epoch: 1/1 iteration: 94/128 step: 48
[2025-12-23 17:58:51,265] m-LoRA: Adapter lora_finqa_66 loss: 0.0033179933670908213
[2025-12-23 17:58:51,271] m-LoRA: Adapter lora_finqa_25 epoch: 1/1 iteration: 126/128 step: 64
[2025-12-23 17:58:51,644] m-LoRA: Adapter lora_finqa_42 loss: 0.00011425556294852868
[2025-12-23 17:58:51,647] m-LoRA: Adapter lora_finqa_62 epoch: 1/1 iteration: 124/128 step: 32
[2025-12-23 17:58:51,915] m-LoRA: Adapter lora_finqa_7 loss: 6.960439350223169e-05
[2025-12-23 17:58:52,046] m-LoRA: Adapter lora_finqa_63 epoch: 1/1 iteration: 124/128 step: 32
[2025-12-23 17:58:52,288] m-LoRA: Adapter lora_finqa_8 loss: 5.55967417312786e-05
[2025-12-23 17:58:52,461] m-LoRA: Adapter lora_finqa_75 epoch: 1/1 iteration: 120/128 step: 16
[2025-12-23 17:58:53,715] m-LoRA: Adapter lora_finqa_71 loss: 0.035649623721838
[2025-12-23 17:58:53,725] m-LoRA: Adapter lora_finqa_64 epoch: 1/1 iteration: 124/128 step: 32
[2025-12-23 17:58:54,870] m-LoRA: Adapter lora_finqa_55 epoch: 1/1 iteration: 78/128 step: 40
[2025-12-23 17:58:54,953] m-LoRA: Adapter lora_finqa_76 loss: 0.7975608110427856
[2025-12-23 17:58:55,230] m-LoRA: Adapter lora_finqa_57 loss: 0.021014966070652008
[2025-12-23 17:58:55,233] m-LoRA: Adapter lora_finqa_40 epoch: 1/1 iteration: 110/128 step: 56
[2025-12-23 17:58:55,865] m-LoRA: Adapter lora_finqa_65 epoch: 1/1 iteration: 124/128 step: 32
[2025-12-23 17:58:55,942] m-LoRA: Adapter lora_finqa_72 loss: 2.2416136264801025
[2025-12-23 17:58:56,154] m-LoRA: Finish and base model offload adapter - ['lora_finqa_0']
[2025-12-23 17:58:56,323] m-LoRA: Adapter lora_finqa_36 loss: 0.007094290107488632
[2025-12-23 17:58:56,327] m-LoRA: Task to running, need to load adapters: ['lora_finqa_78']
[2025-12-23 17:58:56,514] m-LoRA: Adapter lora_finqa_78 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:58:56,750] m-LoRA: Finish and base model offload adapter - ['lora_finqa_3']
[2025-12-23 17:58:56,883] m-LoRA: Adapter lora_finqa_15 loss: 4.045090827275999e-05
[2025-12-23 17:58:56,886] m-LoRA: Task to running, need to load adapters: ['lora_finqa_79']
[2025-12-23 17:58:57,222] m-LoRA: Adapter lora_finqa_79 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:58:57,337] m-LoRA: Adapter lora_finqa_77 loss: 1.7306609153747559
[2025-12-23 17:58:57,343] m-LoRA: Adapter lora_finqa_70 epoch: 1/1 iteration: 32/128 step: 17
[2025-12-23 17:58:57,589] m-LoRA: Finish and base model offload adapter - ['lora_finqa_1']
[2025-12-23 17:58:57,728] m-LoRA: Adapter lora_finqa_16 loss: 3.97078474634327e-05
[2025-12-23 17:58:57,731] m-LoRA: Task to running, need to load adapters: ['lora_finqa_80']
[2025-12-23 17:58:57,921] m-LoRA: Adapter lora_finqa_80 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:58:58,053] m-LoRA: Adapter lora_finqa_74 loss: 0.013704915530979633
[2025-12-23 17:58:58,056] m-LoRA: Adapter lora_finqa_51 epoch: 1/1 iteration: 80/128 step: 41
[2025-12-23 17:58:58,291] m-LoRA: Adapter lora_finqa_60 loss: 0.02124851755797863
[2025-12-23 17:58:58,294] m-LoRA: Adapter lora_finqa_66 epoch: 1/1 iteration: 96/128 step: 25
[2025-12-23 17:58:58,688] m-LoRA: Adapter lora_finqa_46 loss: 0.00013949160347692668
[2025-12-23 17:58:58,692] m-LoRA: Adapter lora_finqa_42 epoch: 1/1 iteration: 96/128 step: 49
[2025-12-23 17:58:59,027] m-LoRA: Finish and base model offload adapter - ['lora_finqa_7']
[2025-12-23 17:58:59,752] m-LoRA: Adapter lora_finqa_37 loss: 0.006987889762967825
[2025-12-23 17:58:59,756] m-LoRA: Task to running, need to load adapters: ['lora_finqa_81']
[2025-12-23 17:58:59,985] m-LoRA: Adapter lora_finqa_81 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:59:00,199] m-LoRA: Finish and base model offload adapter - ['lora_finqa_8']
[2025-12-23 17:59:00,662] m-LoRA: Adapter lora_finqa_47 loss: 6.041003507561982e-05
[2025-12-23 17:59:00,666] m-LoRA: Task to running, need to load adapters: ['lora_finqa_82']
[2025-12-23 17:59:00,887] m-LoRA: Adapter lora_finqa_82 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:59:01,159] m-LoRA: Finish and base model offload adapter - ['lora_finqa_71']
[2025-12-23 17:59:01,474] m-LoRA: Adapter lora_finqa_61 loss: 0.005333012901246548
[2025-12-23 17:59:01,551] m-LoRA: Task to running, need to load adapters: ['lora_finqa_83']
[2025-12-23 17:59:01,788] m-LoRA: Adapter lora_finqa_83 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:59:02,182] m-LoRA: Adapter lora_finqa_23 loss: 3.899498551618308e-05
[2025-12-23 17:59:02,186] m-LoRA: Adapter lora_finqa_76 epoch: 1/1 iteration: 64/128 step: 9
[2025-12-23 17:59:02,400] m-LoRA: Adapter lora_finqa_48 loss: 0.00012762997357640415
[2025-12-23 17:59:02,404] m-LoRA: Adapter lora_finqa_57 epoch: 1/1 iteration: 64/128 step: 33
[2025-12-23 17:59:02,566] m-LoRA: Adapter lora_finqa_25 loss: 5.6369452067883685e-05
[2025-12-23 17:59:02,570] m-LoRA: Adapter lora_finqa_72 epoch: 1/1 iteration: 64/128 step: 17
[2025-12-23 17:59:02,701] m-LoRA: Adapter lora_finqa_62 loss: 1.3243416547775269
[2025-12-23 17:59:02,707] m-LoRA: Adapter lora_finqa_36 epoch: 1/1 iteration: 112/128 step: 57
[2025-12-23 17:59:02,854] m-LoRA: Finish and base model offload adapter - ['lora_finqa_15']
[2025-12-23 17:59:03,307] m-LoRA: Adapter lora_finqa_63 loss: 0.0052014864049851894
[2025-12-23 17:59:03,313] m-LoRA: Task to running, need to load adapters: ['lora_finqa_84']
[2025-12-23 17:59:03,656] m-LoRA: Adapter lora_finqa_84 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:59:03,767] m-LoRA: Adapter lora_finqa_75 loss: 2.241584300994873
[2025-12-23 17:59:03,777] m-LoRA: Adapter lora_finqa_77 epoch: 1/1 iteration: 32/128 step: 9
[2025-12-23 17:59:04,356] m-LoRA: Finish and base model offload adapter - ['lora_finqa_16']
[2025-12-23 17:59:04,777] m-LoRA: Adapter lora_finqa_64 loss: 0.007018424104899168
[2025-12-23 17:59:04,783] m-LoRA: Task to running, need to load adapters: ['lora_finqa_85']
[2025-12-23 17:59:05,111] m-LoRA: Adapter lora_finqa_85 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:59:05,222] m-LoRA: Adapter lora_finqa_55 loss: 0.7073231935501099
[2025-12-23 17:59:05,225] m-LoRA: Adapter lora_finqa_74 epoch: 1/1 iteration: 32/128 step: 17
[2025-12-23 17:59:05,339] m-LoRA: Adapter lora_finqa_40 loss: 0.007195897400379181
[2025-12-23 17:59:05,342] m-LoRA: Adapter lora_finqa_60 epoch: 1/1 iteration: 64/128 step: 33
[2025-12-23 17:59:05,677] m-LoRA: Adapter lora_finqa_65 loss: 0.0037904533091932535
[2025-12-23 17:59:05,683] m-LoRA: Adapter lora_finqa_46 epoch: 1/1 iteration: 96/128 step: 49
[2025-12-23 17:59:07,910] m-LoRA: Adapter lora_finqa_37 epoch: 1/1 iteration: 112/128 step: 57
[2025-12-23 17:59:08,152] m-LoRA: Adapter lora_finqa_78 loss: 2.5885279178619385
[2025-12-23 17:59:08,588] m-LoRA: Adapter lora_finqa_79 loss: 2.5885283946990967
[2025-12-23 17:59:08,591] m-LoRA: Adapter lora_finqa_47 epoch: 1/1 iteration: 96/128 step: 49
[2025-12-23 17:59:08,833] m-LoRA: Adapter lora_finqa_61 epoch: 1/1 iteration: 64/128 step: 33
[2025-12-23 17:59:08,888] m-LoRA: Adapter lora_finqa_70 loss: 0.03037206083536148
[2025-12-23 17:59:09,418] m-LoRA: Finish and base model offload adapter - ['lora_finqa_23']
[2025-12-23 17:59:09,857] m-LoRA: Adapter lora_finqa_80 loss: 2.5885279178619385
[2025-12-23 17:59:09,863] m-LoRA: Task to running, need to load adapters: ['lora_finqa_86']
[2025-12-23 17:59:10,037] m-LoRA: Adapter lora_finqa_86 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:59:10,239] m-LoRA: Adapter lora_finqa_51 loss: 0.00047554963384754956
[2025-12-23 17:59:10,242] m-LoRA: Adapter lora_finqa_48 epoch: 1/1 iteration: 96/128 step: 49
[2025-12-23 17:59:10,390] m-LoRA: Finish and base model offload adapter - ['lora_finqa_25']
[2025-12-23 17:59:10,669] m-LoRA: Adapter lora_finqa_66 loss: 0.0028848322108387947
[2025-12-23 17:59:10,675] m-LoRA: Task to running, need to load adapters: ['lora_finqa_87']
[2025-12-23 17:59:11,095] m-LoRA: Adapter lora_finqa_87 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:59:11,279] m-LoRA: Finish and base model offload adapter - ['lora_finqa_62']
[2025-12-23 17:59:11,522] m-LoRA: Adapter lora_finqa_42 loss: 0.00010313824168406427
[2025-12-23 17:59:11,548] m-LoRA: Task to running, need to load adapters: ['lora_finqa_88']
[2025-12-23 17:59:11,739] m-LoRA: Adapter lora_finqa_88 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:59:11,874] m-LoRA: Finish and base model offload adapter - ['lora_finqa_63']
[2025-12-23 17:59:12,101] m-LoRA: Adapter lora_finqa_81 loss: 2.5885283946990967
[2025-12-23 17:59:12,142] m-LoRA: Task to running, need to load adapters: ['lora_finqa_89']
[2025-12-23 17:59:12,247] m-LoRA: Adapter lora_finqa_89 epoch: 1/1 iteration: 0/128 step: 1
[2025-12-23 17:59:15,721] m-LoRA: Adapter lora_finqa_82 loss: 2.5885279178619385
[2025-12-23 17:59:15,817] m-LoRA: Finish and base model offload adapter - ['lora_finqa_75']
[2025-12-23 17:59:19,665] m-LoRA: Finish and base model offload adapter - ['lora_finqa_64']
[2025-12-23 17:59:20,428] m-LoRA: Adapter lora_finqa_83 loss: 2.5885279178619385
[2025-12-23 17:59:20,982] m-LoRA: Adapter lora_finqa_76 loss: 0.5494461059570312
[2025-12-23 17:59:21,174] m-LoRA: Adapter lora_finqa_55 epoch: 1/1 iteration: 80/128 step: 41
[2025-12-23 17:59:21,456] m-LoRA: Adapter lora_finqa_57 loss: 0.018722357228398323
[2025-12-23 17:59:21,459] m-LoRA: Adapter lora_finqa_40 epoch: 1/1 iteration: 112/128 step: 57
[2025-12-23 17:59:21,896] m-LoRA: Finish and base model offload adapter - ['lora_finqa_65']
[2025-12-23 17:59:22,238] m-LoRA: Adapter lora_finqa_72 loss: 2.200242519378662
[2025-12-23 17:59:22,516] m-LoRA: Adapter lora_finqa_36 loss: 0.006574613973498344
[2025-12-23 17:59:22,520] m-LoRA: Adapter lora_finqa_78 epoch: 1/1 iteration: 16/128 step: 2
[2025-12-23 17:59:22,810] m-LoRA: Adapter lora_finqa_84 loss: 2.5885283946990967
[2025-12-23 17:59:22,813] m-LoRA: Adapter lora_finqa_79 epoch: 1/1 iteration: 2/128 step: 2
[2025-12-23 17:59:23,039] m-LoRA: Adapter lora_finqa_70 epoch: 1/1 iteration: 34/128 step: 18
[2025-12-23 17:59:23,071] m-LoRA: Adapter lora_finqa_77 loss: 1.5471434593200684
[2025-12-23 17:59:23,552] m-LoRA: Adapter lora_finqa_85 loss: 2.5885283946990967
[2025-12-23 17:59:23,556] m-LoRA: Adapter lora_finqa_80 epoch: 1/1 iteration: 4/128 step: 2
[2025-12-23 17:59:23,995] m-LoRA: Adapter lora_finqa_74 loss: 0.011844288557767868
[2025-12-23 17:59:23,998] m-LoRA: Adapter lora_finqa_51 epoch: 1/1 iteration: 82/128 step: 42
[2025-12-23 17:59:24,290] m-LoRA: Adapter lora_finqa_60 loss: 0.018848588690161705
[2025-12-23 17:59:24,294] m-LoRA: Adapter lora_finqa_66 epoch: 1/1 iteration: 100/128 step: 26
[2025-12-23 17:59:24,612] m-LoRA: Adapter lora_finqa_46 loss: 0.00012744925334118307
[2025-12-23 17:59:24,615] m-LoRA: Adapter lora_finqa_42 epoch: 1/1 iteration: 98/128 step: 50
[2025-12-23 17:59:25,329] m-LoRA: Adapter lora_finqa_81 epoch: 1/1 iteration: 2/128 step: 2
[2025-12-23 17:59:25,363] m-LoRA: Adapter lora_finqa_37 loss: 0.006456729024648666
[2025-12-23 17:59:25,778] m-LoRA: Adapter lora_finqa_47 loss: 5.796982441097498e-05
[2025-12-23 17:59:25,947] m-LoRA: Adapter lora_finqa_82 epoch: 1/1 iteration: 16/128 step: 2
[2025-12-23 17:59:26,201] m-LoRA: Adapter lora_finqa_61 loss: 0.005137655884027481
[2025-12-23 17:59:26,392] m-LoRA: Adapter lora_finqa_83 epoch: 1/1 iteration: 16/128 step: 2
[2025-12-23 17:59:26,861] m-LoRA: Adapter lora_finqa_86 loss: 2.5885279178619385
[2025-12-23 17:59:26,993] m-LoRA: Adapter lora_finqa_76 epoch: 1/1 iteration: 72/128 step: 10
[2025-12-23 17:59:27,267] m-LoRA: Adapter lora_finqa_48 loss: 0.00011483026173664257
[2025-12-23 17:59:27,270] m-LoRA: Adapter lora_finqa_57 epoch: 1/1 iteration: 66/128 step: 34
[2025-12-23 17:59:29,967] m-LoRA: Adapter lora_finqa_72 epoch: 1/1 iteration: 68/128 step: 18
[2025-12-23 17:59:30,094] m-LoRA: Adapter lora_finqa_87 loss: 2.588528633117676
[2025-12-23 17:59:31,322] m-LoRA: Adapter lora_finqa_88 loss: 2.5885279178619385
[2025-12-23 17:59:31,327] m-LoRA: Adapter lora_finqa_36 epoch: 1/1 iteration: 114/128 step: 58
[2025-12-23 17:59:33,379] m-LoRA: Adapter lora_finqa_84 epoch: 1/1 iteration: 2/128 step: 2
[2025-12-23 17:59:33,446] m-LoRA: Adapter lora_finqa_89 loss: 2.588528633117676
[2025-12-23 17:59:33,968] m-LoRA: Adapter lora_finqa_55 loss: 0.6371814608573914
[2025-12-23 17:59:33,971] m-LoRA: Adapter lora_finqa_77 epoch: 1/1 iteration: 36/128 step: 10
[2025-12-23 17:59:34,537] m-LoRA: Adapter lora_finqa_40 loss: 0.006178972311317921
[2025-12-23 17:59:34,541] m-LoRA: Adapter lora_finqa_85 epoch: 1/1 iteration: 2/128 step: 2
[2025-12-23 17:59:36,603] m-LoRA: Adapter lora_finqa_74 epoch: 1/1 iteration: 34/128 step: 18
[2025-12-23 17:59:36,803] m-LoRA: Adapter lora_finqa_78 loss: 2.473517417907715
[2025-12-23 17:59:37,225] m-LoRA: Adapter lora_finqa_79 loss: 2.3183159828186035
[2025-12-23 17:59:37,228] m-LoRA: Adapter lora_finqa_60 epoch: 1/1 iteration: 66/128 step: 34
[2025-12-23 17:59:37,707] m-LoRA: Adapter lora_finqa_46 epoch: 1/1 iteration: 98/128 step: 50
[2025-12-23 17:59:37,738] m-LoRA: Adapter lora_finqa_70 loss: 0.025981463491916656
[2025-12-23 17:59:38,258] m-LoRA: Adapter lora_finqa_80 loss: 2.4707906246185303
[2025-12-23 17:59:38,263] m-LoRA: Adapter lora_finqa_37 epoch: 1/1 iteration: 114/128 step: 58
[2025-12-23 17:59:38,757] m-LoRA: Adapter lora_finqa_51 loss: 0.0008136033429764211
[2025-12-23 17:59:38,761] m-LoRA: Adapter lora_finqa_47 epoch: 1/1 iteration: 98/128 step: 50
[2025-12-23 17:59:39,296] m-LoRA: Adapter lora_finqa_66 loss: 0.0015878616832196712
[2025-12-23 17:59:39,301] m-LoRA: Adapter lora_finqa_61 epoch: 1/1 iteration: 66/128 step: 34
[2025-12-23 17:59:40,319] m-LoRA: Adapter lora_finqa_42 loss: 0.00013672022032551467
[2025-12-23 17:59:40,322] m-LoRA: Adapter lora_finqa_86 epoch: 1/1 iteration: 4/128 step: 2
[2025-12-23 17:59:40,926] m-LoRA: Adapter lora_finqa_81 loss: 2.4793753623962402
[2025-12-23 17:59:40,929] m-LoRA: Adapter lora_finqa_48 epoch: 1/1 iteration: 98/128 step: 50
[2025-12-23 17:59:43,173] m-LoRA: Adapter lora_finqa_87 epoch: 1/1 iteration: 8/128 step: 2
[2025-12-23 17:59:43,364] m-LoRA: Adapter lora_finqa_82 loss: 2.4704082012176514
[2025-12-23 17:59:45,424] m-LoRA: Adapter lora_finqa_83 loss: 2.3152976036071777
[2025-12-23 17:59:45,503] m-LoRA: Adapter lora_finqa_88 epoch: 1/1 iteration: 4/128 step: 2
[2025-12-23 17:59:46,666] m-LoRA: Adapter lora_finqa_89 epoch: 1/1 iteration: 8/128 step: 2
[2025-12-23 17:59:46,795] m-LoRA: Adapter lora_finqa_76 loss: 0.39504775404930115
[2025-12-23 17:59:46,897] m-LoRA: Adapter lora_finqa_57 loss: 0.017478857189416885
[2025-12-23 17:59:46,900] m-LoRA: Adapter lora_finqa_55 epoch: 1/1 iteration: 82/128 step: 42
[2025-12-23 17:59:47,453] m-LoRA: Adapter lora_finqa_40 epoch: 1/1 iteration: 114/128 step: 58
[2025-12-23 17:59:47,508] m-LoRA: Adapter lora_finqa_72 loss: 2.15282940864563
[2025-12-23 17:59:47,702] m-LoRA: Adapter lora_finqa_36 loss: 0.006546057760715485
[2025-12-23 17:59:47,858] m-LoRA: Adapter lora_finqa_78 epoch: 1/1 iteration: 32/128 step: 3
[2025-12-23 17:59:48,187] m-LoRA: Adapter lora_finqa_84 loss: 2.5435750484466553
[2025-12-23 17:59:48,190] m-LoRA: Adapter lora_finqa_79 epoch: 1/1 iteration: 4/128 step: 3
[2025-12-23 17:59:48,783] m-LoRA: Adapter lora_finqa_77 loss: 1.3843799829483032
[2025-12-23 17:59:48,789] m-LoRA: Adapter lora_finqa_70 epoch: 1/1 iteration: 36/128 step: 19
[2025-12-23 17:59:49,196] m-LoRA: Adapter lora_finqa_85 loss: 2.3176803588867188
[2025-12-23 17:59:49,199] m-LoRA: Adapter lora_finqa_80 epoch: 1/1 iteration: 8/128 step: 3
[2025-12-23 17:59:49,485] m-LoRA: Adapter lora_finqa_74 loss: 0.011037986725568771
[2025-12-23 17:59:49,489] m-LoRA: Adapter lora_finqa_51 epoch: 1/1 iteration: 84/128 step: 43
[2025-12-23 17:59:49,925] m-LoRA: Adapter lora_finqa_60 loss: 0.01707613840699196
[2025-12-23 17:59:49,929] m-LoRA: Adapter lora_finqa_66 epoch: 1/1 iteration: 104/128 step: 27
[2025-12-23 17:59:50,414] m-LoRA: Adapter lora_finqa_46 loss: 0.00010243891301797703
[2025-12-23 17:59:50,418] m-LoRA: Adapter lora_finqa_42 epoch: 1/1 iteration: 100/128 step: 51
[2025-12-23 17:59:50,693] m-LoRA: Adapter lora_finqa_37 loss: 0.0058299945667386055
[2025-12-23 17:59:50,696] m-LoRA: Adapter lora_finqa_81 epoch: 1/1 iteration: 4/128 step: 3
[2025-12-23 17:59:51,079] m-LoRA: Adapter lora_finqa_47 loss: 5.6085573305608705e-05
[2025-12-23 17:59:51,235] m-LoRA: Adapter lora_finqa_82 epoch: 1/1 iteration: 32/128 step: 3
[2025-12-23 17:59:51,533] m-LoRA: Adapter lora_finqa_61 loss: 0.004696259740740061
[2025-12-23 17:59:51,704] m-LoRA: Adapter lora_finqa_83 epoch: 1/1 iteration: 32/128 step: 3
[2025-12-23 17:59:52,176] m-LoRA: Adapter lora_finqa_86 loss: 2.4726450443267822
[2025-12-23 17:59:52,326] m-LoRA: Adapter lora_finqa_76 epoch: 1/1 iteration: 80/128 step: 11
[2025-12-23 17:59:52,601] m-LoRA: Adapter lora_finqa_48 loss: 0.0001094474719138816
[2025-12-23 17:59:52,604] m-LoRA: Adapter lora_finqa_57 epoch: 1/1 iteration: 68/128 step: 35
[2025-12-23 17:59:53,837] m-LoRA: Adapter lora_finqa_72 epoch: 1/1 iteration: 72/128 step: 19
[2025-12-23 17:59:53,930] m-LoRA: Adapter lora_finqa_87 loss: 2.476726770401001
[2025-12-23 17:59:54,531] m-LoRA: Adapter lora_finqa_88 loss: 2.3165388107299805
[2025-12-23 17:59:54,537] m-LoRA: Adapter lora_finqa_36 epoch: 1/1 iteration: 116/128 step: 59
[2025-12-23 17:59:55,961] m-LoRA: Adapter lora_finqa_84 epoch: 1/1 iteration: 4/128 step: 3
[2025-12-23 17:59:56,052] m-LoRA: Adapter lora_finqa_89 loss: 2.5425760746002197
[2025-12-23 17:59:56,486] m-LoRA: Adapter lora_finqa_55 loss: 0.5740622878074646
[2025-12-23 17:59:56,489] m-LoRA: Adapter lora_finqa_77 epoch: 1/1 iteration: 40/128 step: 11
[2025-12-23 17:59:56,744] m-LoRA: Adapter lora_finqa_40 loss: 0.006236454471945763
[2025-12-23 17:59:56,747] m-LoRA: Adapter lora_finqa_85 epoch: 1/1 iteration: 4/128 step: 3
[2025-12-23 17:59:58,980] m-LoRA: Adapter lora_finqa_74 epoch: 1/1 iteration: 36/128 step: 19
[2025-12-23 17:59:59,180] m-LoRA: Adapter lora_finqa_78 loss: 2.2513346672058105
[2025-12-23 17:59:59,610] m-LoRA: Adapter lora_finqa_79 loss: 1.9233627319335938
[2025-12-23 17:59:59,613] m-LoRA: Adapter lora_finqa_60 epoch: 1/1 iteration: 68/128 step: 35
[2025-12-23 17:59:59,935] m-LoRA: Adapter lora_finqa_46 epoch: 1/1 iteration: 100/128 step: 51
[2025-12-23 17:59:59,967] m-LoRA: Adapter lora_finqa_70 loss: 0.021028418093919754
[2025-12-23 18:00:00,506] m-LoRA: Adapter lora_finqa_37 epoch: 1/1 iteration: 116/128 step: 59
[2025-12-23 18:00:00,564] m-LoRA: Adapter lora_finqa_80 loss: 2.250563383102417
[2025-12-23 18:00:00,854] m-LoRA: Adapter lora_finqa_47 epoch: 1/1 iteration: 100/128 step: 51
[2025-12-23 18:00:00,911] m-LoRA: Adapter lora_finqa_51 loss: 0.0002183177275583148
[2025-12-23 18:00:01,605] m-LoRA: Adapter lora_finqa_61 epoch: 1/1 iteration: 68/128 step: 35
[2025-12-23 18:00:01,664] m-LoRA: Adapter lora_finqa_66 loss: 0.0013456152519211173
[2025-12-23 18:00:01,941] m-LoRA: Adapter lora_finqa_42 loss: 0.00011308073590043932
[2025-12-23 18:00:01,944] m-LoRA: Adapter lora_finqa_86 epoch: 1/1 iteration: 8/128 step: 3
[2025-12-23 18:00:02,199] m-LoRA: Adapter lora_finqa_81 loss: 2.262840986251831
[2025-12-23 18:00:02,202] m-LoRA: Adapter lora_finqa_48 epoch: 1/1 iteration: 100/128 step: 51
[2025-12-23 18:00:04,519] m-LoRA: Adapter lora_finqa_87 epoch: 1/1 iteration: 16/128 step: 3
[2025-12-23 18:00:04,743] m-LoRA: Adapter lora_finqa_82 loss: 2.249234914779663
[2025-12-23 18:00:07,105] m-LoRA: Adapter lora_finqa_88 epoch: 1/1 iteration: 8/128 step: 3
[2025-12-23 18:00:07,355] m-LoRA: Adapter lora_finqa_83 loss: 1.9116703271865845
[2025-12-23 18:00:08,359] m-LoRA: Adapter lora_finqa_76 loss: 0.2623427212238312
[2025-12-23 18:00:08,560] m-LoRA: Adapter lora_finqa_89 epoch: 1/1 iteration: 16/128 step: 3
[2025-12-23 18:00:08,761] m-LoRA: Adapter lora_finqa_57 loss: 0.01581868715584278
[2025-12-23 18:00:08,765] m-LoRA: Adapter lora_finqa_55 epoch: 1/1 iteration: 84/128 step: 43
[2025-12-23 18:00:09,403] m-LoRA: Adapter lora_finqa_40 epoch: 1/1 iteration: 116/128 step: 59
[2025-12-23 18:00:09,462] m-LoRA: Adapter lora_finqa_72 loss: 2.107375144958496
[2025-12-23 18:00:09,800] m-LoRA: Adapter lora_finqa_36 loss: 0.005487376824021339
[2025-12-23 18:00:09,955] m-LoRA: Adapter lora_finqa_78 epoch: 1/1 iteration: 48/128 step: 4
[2025-12-23 18:00:10,273] m-LoRA: Adapter lora_finqa_84 loss: 2.4559195041656494
[2025-12-23 18:00:10,277] m-LoRA: Adapter lora_finqa_79 epoch: 1/1 iteration: 6/128 step: 4
[2025-12-23 18:00:10,713] m-LoRA: Adapter lora_finqa_70 epoch: 1/1 iteration: 38/128 step: 20
[2025-12-23 18:00:10,770] m-LoRA: Adapter lora_finqa_77 loss: 1.1940433979034424
[2025-12-23 18:00:11,048] m-LoRA: Adapter lora_finqa_85 loss: 1.914914846420288
[2025-12-23 18:00:11,052] m-LoRA: Adapter lora_finqa_80 epoch: 1/1 iteration: 12/128 step: 4
[2025-12-23 18:00:11,320] m-LoRA: Adapter lora_finqa_74 loss: 0.010195653885602951
[2025-12-23 18:00:11,324] m-LoRA: Adapter lora_finqa_51 epoch: 1/1 iteration: 86/128 step: 44
[2025-12-23 18:00:12,041] m-LoRA: Adapter lora_finqa_60 loss: 0.015527368523180485
[2025-12-23 18:00:12,044] m-LoRA: Adapter lora_finqa_66 epoch: 1/1 iteration: 108/128 step: 28
[2025-12-23 18:00:12,315] m-LoRA: Adapter lora_finqa_42 epoch: 1/1 iteration: 102/128 step: 52
[2025-12-23 18:00:12,367] m-LoRA: Adapter lora_finqa_46 loss: 9.417409455636516e-05
[2025-12-23 18:00:12,654] m-LoRA: Adapter lora_finqa_37 loss: 0.005399628076702356
[2025-12-23 18:00:12,657] m-LoRA: Adapter lora_finqa_81 epoch: 1/1 iteration: 6/128 step: 4
[2025-12-23 18:00:12,913] m-LoRA: Adapter lora_finqa_47 loss: 5.534864976652898e-05
[2025-12-23 18:00:13,297] m-LoRA: Adapter lora_finqa_82 epoch: 1/1 iteration: 48/128 step: 4
[2025-12-23 18:00:13,881] m-LoRA: Adapter lora_finqa_61 loss: 0.0025032407138496637
[2025-12-23 18:00:13,884] m-LoRA: Adapter lora_finqa_83 epoch: 1/1 iteration: 48/128 step: 4
[2025-12-23 18:00:14,401] m-LoRA: Adapter lora_finqa_86 loss: 2.2521402835845947
[2025-12-23 18:00:14,406] m-LoRA: Adapter lora_finqa_76 epoch: 1/1 iteration: 88/128 step: 12
[2025-12-23 18:00:14,711] m-LoRA: Adapter lora_finqa_48 loss: 0.00010396481957286596
[2025-12-23 18:00:14,715] m-LoRA: Adapter lora_finqa_57 epoch: 1/1 iteration: 70/128 step: 36
[2025-12-23 18:00:15,774] m-LoRA: Adapter lora_finqa_72 epoch: 1/1 iteration: 76/128 step: 20
[2025-12-23 18:00:15,920] m-LoRA: Adapter lora_finqa_87 loss: 2.2604360580444336
[2025-12-23 18:00:16,494] m-LoRA: Adapter lora_finqa_36 epoch: 1/1 iteration: 118/128 step: 60
[2025-12-23 18:00:16,526] m-LoRA: Adapter lora_finqa_88 loss: 1.9139000177383423
[2025-12-23 18:00:19,385] m-LoRA: Adapter lora_finqa_89 loss: 2.4544379711151123
[2025-12-23 18:00:19,395] m-LoRA: Adapter lora_finqa_84 epoch: 1/1 iteration: 6/128 step: 4
[2025-12-23 18:00:19,664] m-LoRA: Adapter lora_finqa_55 loss: 0.5176551342010498
[2025-12-23 18:00:19,667] m-LoRA: Adapter lora_finqa_77 epoch: 1/1 iteration: 44/128 step: 12
[2025-12-23 18:00:19,939] m-LoRA: Adapter lora_finqa_40 loss: 0.004925761371850967
[2025-12-23 18:00:19,943] m-LoRA: Adapter lora_finqa_85 epoch: 1/1 iteration: 6/128 step: 4
[2025-12-23 18:00:22,561] m-LoRA: Adapter lora_finqa_78 loss: 1.9852564334869385
[2025-12-23 18:00:22,579] m-LoRA: Adapter lora_finqa_74 epoch: 1/1 iteration: 38/128 step: 20
[2025-12-23 18:00:22,722] m-LoRA: Adapter lora_finqa_79 loss: 1.4946978092193604
[2025-12-23 18:00:22,725] m-LoRA: Adapter lora_finqa_60 epoch: 1/1 iteration: 70/128 step: 36
[2025-12-23 18:00:23,066] m-LoRA: Adapter lora_finqa_70 loss: 0.01780020259320736
[2025-12-23 18:00:23,069] m-LoRA: Adapter lora_finqa_46 epoch: 1/1 iteration: 102/128 step: 52
[2025-12-23 18:00:23,678] m-LoRA: Adapter lora_finqa_37 epoch: 1/1 iteration: 118/128 step: 60
[2025-12-23 18:00:23,734] m-LoRA: Adapter lora_finqa_80 loss: 1.985946774482727
[2025-12-23 18:00:24,246] m-LoRA: Adapter lora_finqa_51 loss: 0.00020437657076399773
[2025-12-23 18:00:24,249] m-LoRA: Adapter lora_finqa_47 epoch: 1/1 iteration: 102/128 step: 52
[2025-12-23 18:00:25,266] m-LoRA: Adapter lora_finqa_61 epoch: 1/1 iteration: 70/128 step: 36
[2025-12-23 18:00:25,326] m-LoRA: Adapter lora_finqa_66 loss: 0.0009526538196951151
[2025-12-23 18:00:26,121] m-LoRA: Adapter lora_finqa_42 loss: 8.563120354665443e-05
[2025-12-23 18:00:26,124] m-LoRA: Adapter lora_finqa_86 epoch: 1/1 iteration: 12/128 step: 4
[2025-12-23 18:00:26,814] m-LoRA: Adapter lora_finqa_81 loss: 2.0016348361968994
[2025-12-23 18:00:26,817] m-LoRA: Adapter lora_finqa_48 epoch: 1/1 iteration: 102/128 step: 52
[2025-12-23 18:00:29,207] m-LoRA: Adapter lora_finqa_82 loss: 1.981895923614502
[2025-12-23 18:00:29,318] m-LoRA: Adapter lora_finqa_87 epoch: 1/1 iteration: 24/128 step: 4
[2025-12-23 18:00:31,156] m-LoRA: Adapter lora_finqa_88 epoch: 1/1 iteration: 12/128 step: 4
[2025-12-23 18:00:31,362] m-LoRA: Adapter lora_finqa_83 loss: 1.474503755569458
[2025-12-23 18:00:32,523] m-LoRA: Adapter lora_finqa_89 epoch: 1/1 iteration: 24/128 step: 4
[2025-12-23 18:00:32,652] m-LoRA: Adapter lora_finqa_76 loss: 0.18748688697814941
[2025-12-23 18:00:32,889] m-LoRA: Adapter lora_finqa_57 loss: 0.014794840477406979
[2025-12-23 18:00:32,892] m-LoRA: Adapter lora_finqa_55 epoch: 1/1 iteration: 86/128 step: 44
[2025-12-23 18:00:33,441] m-LoRA: Adapter lora_finqa_40 epoch: 1/1 iteration: 118/128 step: 60
[2025-12-23 18:00:33,498] m-LoRA: Adapter lora_finqa_72 loss: 2.0614428520202637
[2025-12-23 18:00:34,000] m-LoRA: Adapter lora_finqa_36 loss: 0.00555488932877779
[2025-12-23 18:00:34,158] m-LoRA: Adapter lora_finqa_78 epoch: 1/1 iteration: 64/128 step: 5
[2025-12-23 18:00:34,738] m-LoRA: Adapter lora_finqa_84 loss: 2.339648962020874
[2025-12-23 18:00:34,741] m-LoRA: Adapter lora_finqa_79 epoch: 1/1 iteration: 8/128 step: 5
[2025-12-23 18:00:35,374] m-LoRA: Adapter lora_finqa_70 epoch: 1/1 iteration: 40/128 step: 21
[2025-12-23 18:00:35,411] m-LoRA: Adapter lora_finqa_77 loss: 1.000031590461731
[2025-12-23 18:00:35,916] m-LoRA: Adapter lora_finqa_85 loss: 1.481027364730835
[2025-12-23 18:00:35,919] m-LoRA: Adapter lora_finqa_80 epoch: 1/1 iteration: 16/128 step: 5
[2025-12-23 18:00:36,612] m-LoRA: Adapter lora_finqa_74 loss: 0.008022255264222622
[2025-12-23 18:00:36,615] m-LoRA: Adapter lora_finqa_51 epoch: 1/1 iteration: 88/128 step: 45
[2025-12-23 18:00:36,962] m-LoRA: Adapter lora_finqa_60 loss: 0.014573207125067711
[2025-12-23 18:00:36,965] m-LoRA: Adapter lora_finqa_66 epoch: 1/1 iteration: 112/128 step: 29
[2025-12-23 18:00:37,323] m-LoRA: Adapter lora_finqa_46 loss: 8.972408977570012e-05
[2025-12-23 18:00:37,327] m-LoRA: Adapter lora_finqa_42 epoch: 1/1 iteration: 104/128 step: 53
[2025-12-23 18:00:37,679] m-LoRA: Adapter lora_finqa_37 loss: 0.004998755641281605
[2025-12-23 18:00:37,682] m-LoRA: Adapter lora_finqa_81 epoch: 1/1 iteration: 8/128 step: 5
[2025-12-23 18:00:38,032] m-LoRA: Adapter lora_finqa_47 loss: 5.2405121095944196e-05
[2025-12-23 18:00:38,183] m-LoRA: Adapter lora_finqa_82 epoch: 1/1 iteration: 64/128 step: 5
[2025-12-23 18:00:38,436] m-LoRA: Adapter lora_finqa_61 loss: 0.0017729912651702762
[2025-12-23 18:00:38,612] m-LoRA: Adapter lora_finqa_83 epoch: 1/1 iteration: 64/128 step: 5
[2025-12-23 18:00:39,224] m-LoRA: Adapter lora_finqa_86 loss: 1.988866925239563
[2025-12-23 18:00:39,230] m-LoRA: Adapter lora_finqa_76 epoch: 1/1 iteration: 96/128 step: 13
[2025-12-23 18:00:39,476] m-LoRA: Adapter lora_finqa_48 loss: 9.421015420230106e-05
[2025-12-23 18:00:39,480] m-LoRA: Adapter lora_finqa_57 epoch: 1/1 iteration: 72/128 step: 37
[2025-12-23 18:00:40,614] m-LoRA: Adapter lora_finqa_72 epoch: 1/1 iteration: 80/128 step: 21
[2025-12-23 18:00:40,736] m-LoRA: Adapter lora_finqa_87 loss: 1.9968611001968384
[2025-12-23 18:00:41,326] m-LoRA: Adapter lora_finqa_88 loss: 1.4728690385818481
[2025-12-23 18:00:41,331] m-LoRA: Adapter lora_finqa_36 epoch: 1/1 iteration: 120/128 step: 61
[2025-12-23 18:00:42,663] m-LoRA: Adapter lora_finqa_84 epoch: 1/1 iteration: 8/128 step: 5
[2025-12-23 18:00:42,739] m-LoRA: Adapter lora_finqa_89 loss: 2.336935520172119
[2025-12-23 18:00:43,020] m-LoRA: Adapter lora_finqa_55 loss: 0.4695371389389038
[2025-12-23 18:00:43,023] m-LoRA: Adapter lora_finqa_77 epoch: 1/1 iteration: 48/128 step: 13
[2025-12-23 18:00:43,271] m-LoRA: Adapter lora_finqa_40 loss: 0.005167470313608646
[2025-12-23 18:00:43,274] m-LoRA: Adapter lora_finqa_85 epoch: 1/1 iteration: 8/128 step: 5
[2025-12-23 18:00:45,549] m-LoRA: Adapter lora_finqa_74 epoch: 1/1 iteration: 40/128 step: 21
[2025-12-23 18:00:45,755] m-LoRA: Adapter lora_finqa_78 loss: 1.7019654512405396
[2025-12-23 18:00:46,192] m-LoRA: Adapter lora_finqa_79 loss: 1.1958351135253906
[2025-12-23 18:00:46,195] m-LoRA: Adapter lora_finqa_60 epoch: 1/1 iteration: 72/128 step: 37
[2025-12-23 18:00:46,409] m-LoRA: Adapter lora_finqa_46 epoch: 1/1 iteration: 104/128 step: 53
[2025-12-23 18:00:46,467] m-LoRA: Adapter lora_finqa_70 loss: 0.015518453903496265
[2025-12-23 18:00:47,080] m-LoRA: Adapter lora_finqa_37 epoch: 1/1 iteration: 120/128 step: 61
[2025-12-23 18:00:47,119] m-LoRA: Adapter lora_finqa_80 loss: 1.702839732170105
[2025-12-23 18:00:47,461] m-LoRA: Adapter lora_finqa_51 loss: 0.00016408371448051184
[2025-12-23 18:00:47,464] m-LoRA: Adapter lora_finqa_47 epoch: 1/1 iteration: 104/128 step: 53
[2025-12-23 18:00:48,025] m-LoRA: Adapter lora_finqa_61 epoch: 1/1 iteration: 72/128 step: 37
[2025-12-23 18:00:48,086] m-LoRA: Adapter lora_finqa_66 loss: 0.0006678836653009057
[2025-12-23 18:00:48,327] m-LoRA: Adapter lora_finqa_42 loss: 8.846434502629563e-05
[2025-12-23 18:00:48,330] m-LoRA: Adapter lora_finqa_86 epoch: 1/1 iteration: 16/128 step: 5
[2025-12-23 18:00:48,589] m-LoRA: Adapter lora_finqa_81 loss: 1.7218623161315918
[2025-12-23 18:00:48,593] m-LoRA: Adapter lora_finqa_48 epoch: 1/1 iteration: 104/128 step: 53
[2025-12-23 18:00:51,243] m-LoRA: Adapter lora_finqa_82 loss: 1.6989428997039795
[2025-12-23 18:00:51,414] m-LoRA: Adapter lora_finqa_87 epoch: 1/1 iteration: 32/128 step: 5
[2025-12-23 18:00:53,534] m-LoRA: Adapter lora_finqa_88 epoch: 1/1 iteration: 16/128 step: 5
[2025-12-23 18:00:53,773] m-LoRA: Adapter lora_finqa_83 loss: 1.1873128414154053
[2025-12-23 18:00:54,729] m-LoRA: Adapter lora_finqa_76 loss: 0.12027481943368912
[2025-12-23 18:00:54,814] m-LoRA: Adapter lora_finqa_89 epoch: 1/1 iteration: 32/128 step: 5
[2025-12-23 18:00:55,041] m-LoRA: Adapter lora_finqa_57 loss: 0.01438326295465231
[2025-12-23 18:00:55,044] m-LoRA: Adapter lora_finqa_55 epoch: 1/1 iteration: 88/128 step: 45
[2025-12-23 18:00:55,623] m-LoRA: Adapter lora_finqa_40 epoch: 1/1 iteration: 120/128 step: 61
[2025-12-23 18:00:55,679] m-LoRA: Adapter lora_finqa_72 loss: 2.011284828186035
[2025-12-23 18:00:55,936] m-LoRA: Adapter lora_finqa_36 loss: 0.005724935792386532
[2025-12-23 18:00:56,093] m-LoRA: Adapter lora_finqa_78 epoch: 1/1 iteration: 80/128 step: 6
[2025-12-23 18:00:56,514] m-LoRA: Adapter lora_finqa_79 epoch: 1/1 iteration: 10/128 step: 6
[2025-12-23 18:00:56,568] m-LoRA: Adapter lora_finqa_84 loss: 2.2010719776153564
[2025-12-23 18:00:57,223] m-LoRA: Adapter lora_finqa_77 loss: 0.8221979141235352
[2025-12-23 18:00:57,229] m-LoRA: Adapter lora_finqa_70 epoch: 1/1 iteration: 42/128 step: 22
[2025-12-23 18:00:57,499] m-LoRA: Adapter lora_finqa_85 loss: 1.1993632316589355
[2025-12-23 18:00:57,502] m-LoRA: Adapter lora_finqa_80 epoch: 1/1 iteration: 20/128 step: 6
[2025-12-23 18:00:58,006] m-LoRA: Adapter lora_finqa_51 epoch: 1/1 iteration: 90/128 step: 46
[2025-12-23 18:00:58,063] m-LoRA: Adapter lora_finqa_74 loss: 0.006743341684341431
[2025-12-23 18:00:58,513] m-LoRA: Adapter lora_finqa_66 epoch: 1/1 iteration: 116/128 step: 30
[2025-12-23 18:00:58,592] m-LoRA: Adapter lora_finqa_60 loss: 0.013926957733929157
[2025-12-23 18:00:58,836] m-LoRA: Adapter lora_finqa_46 loss: 9.150114783551544e-05
[2025-12-23 18:00:58,840] m-LoRA: Adapter lora_finqa_42 epoch: 1/1 iteration: 106/128 step: 54
[2025-12-23 18:00:59,241] m-LoRA: Adapter lora_finqa_37 loss: 0.004689482506364584
[2025-12-23 18:00:59,245] m-LoRA: Adapter lora_finqa_81 epoch: 1/1 iteration: 10/128 step: 6
[2025-12-23 18:00:59,647] m-LoRA: Adapter lora_finqa_47 loss: 5.32030280737672e-05
[2025-12-23 18:00:59,806] m-LoRA: Adapter lora_finqa_82 epoch: 1/1 iteration: 80/128 step: 6
[2025-12-23 18:01:00,455] m-LoRA: Adapter lora_finqa_61 loss: 0.0012938325526192784
[2025-12-23 18:01:00,459] m-LoRA: Adapter lora_finqa_83 epoch: 1/1 iteration: 80/128 step: 6
[2025-12-23 18:01:00,784] m-LoRA: Adapter lora_finqa_86 loss: 1.7070013284683228
[2025-12-23 18:01:00,927] m-LoRA: Adapter lora_finqa_76 epoch: 1/1 iteration: 104/128 step: 14
[2025-12-23 18:01:01,206] m-LoRA: Adapter lora_finqa_48 loss: 9.057013812707737e-05
[2025-12-23 18:01:01,210] m-LoRA: Adapter lora_finqa_57 epoch: 1/1 iteration: 74/128 step: 38
[2025-12-23 18:01:03,533] m-LoRA: Adapter lora_finqa_72 epoch: 1/1 iteration: 84/128 step: 22
[2025-12-23 18:01:03,645] m-LoRA: Adapter lora_finqa_87 loss: 1.7147194147109985
[2025-12-23 18:01:04,941] m-LoRA: Adapter lora_finqa_36 epoch: 1/1 iteration: 122/128 step: 62
[2025-12-23 18:01:05,029] m-LoRA: Adapter lora_finqa_88 loss: 1.1869698762893677
[2025-12-23 18:01:06,186] m-LoRA: Adapter lora_finqa_84 epoch: 1/1 iteration: 10/128 step: 6
[2025-12-23 18:01:06,252] m-LoRA: Adapter lora_finqa_89 loss: 2.1978087425231934
[2025-12-23 18:01:06,906] m-LoRA: Adapter lora_finqa_77 epoch: 1/1 iteration: 52/128 step: 14
[2025-12-23 18:01:06,978] m-LoRA: Adapter lora_finqa_55 loss: 0.4236984848976135
[2025-12-23 18:01:07,593] m-LoRA: Adapter lora_finqa_40 loss: 0.006290394812822342
[2025-12-23 18:01:07,596] m-LoRA: Adapter lora_finqa_85 epoch: 1/1 iteration: 10/128 step: 6
[2025-12-23 18:01:09,731] m-LoRA: Adapter lora_finqa_74 epoch: 1/1 iteration: 42/128 step: 22
[2025-12-23 18:01:09,951] m-LoRA: Adapter lora_finqa_78 loss: 1.3902724981307983
[2025-12-23 18:01:10,441] m-LoRA: Adapter lora_finqa_60 epoch: 1/1 iteration: 74/128 step: 38
[2025-12-23 18:01:10,472] m-LoRA: Adapter lora_finqa_79 loss: 0.7831826210021973
[2025-12-23 18:01:11,012] m-LoRA: Adapter lora_finqa_70 loss: 0.014194585382938385
[2025-12-23 18:01:11,015] m-LoRA: Adapter lora_finqa_46 epoch: 1/1 iteration: 106/128 step: 54
[2025-12-23 18:01:12,065] m-LoRA: Adapter lora_finqa_37 epoch: 1/1 iteration: 122/128 step: 62
[2025-12-23 18:01:12,126] m-LoRA: Adapter lora_finqa_80 loss: 1.3908237218856812
[2025-12-23 18:01:12,329] m-LoRA: Adapter lora_finqa_51 loss: 0.00018694512255024165
[2025-12-23 18:01:12,332] m-LoRA: Adapter lora_finqa_47 epoch: 1/1 iteration: 106/128 step: 54
[2025-12-23 18:01:13,176] m-LoRA: Adapter lora_finqa_66 loss: 0.0003830427012871951
[2025-12-23 18:01:13,181] m-LoRA: Adapter lora_finqa_61 epoch: 1/1 iteration: 74/128 step: 38
[2025-12-23 18:01:13,477] m-LoRA: Adapter lora_finqa_42 loss: 7.969796570250764e-05
[2025-12-23 18:01:13,480] m-LoRA: Adapter lora_finqa_86 epoch: 1/1 iteration: 20/128 step: 6
[2025-12-23 18:01:13,815] m-LoRA: Adapter lora_finqa_81 loss: 1.406651258468628
[2025-12-23 18:01:13,818] m-LoRA: Adapter lora_finqa_48 epoch: 1/1 iteration: 106/128 step: 54
[2025-12-23 18:01:16,200] m-LoRA: Adapter lora_finqa_82 loss: 1.3848217725753784
[2025-12-23 18:01:16,312] m-LoRA: Adapter lora_finqa_87 epoch: 1/1 iteration: 40/128 step: 6
[2025-12-23 18:01:18,227] m-LoRA: Adapter lora_finqa_88 epoch: 1/1 iteration: 20/128 step: 6
[2025-12-23 18:01:18,450] m-LoRA: Adapter lora_finqa_83 loss: 0.7796604037284851
[2025-12-23 18:01:19,663] m-LoRA: Adapter lora_finqa_76 loss: 0.06965384632349014
[2025-12-23 18:01:19,875] m-LoRA: Adapter lora_finqa_89 epoch: 1/1 iteration: 40/128 step: 6
[2025-12-23 18:01:20,101] m-LoRA: Adapter lora_finqa_57 loss: 0.013891737908124924
[2025-12-23 18:01:20,104] m-LoRA: Adapter lora_finqa_55 epoch: 1/1 iteration: 90/128 step: 46
[2025-12-23 18:01:20,560] m-LoRA: Adapter lora_finqa_40 epoch: 1/1 iteration: 122/128 step: 62
[2025-12-23 18:01:20,622] m-LoRA: Adapter lora_finqa_72 loss: 1.9624741077423096
[2025-12-23 18:01:20,857] m-LoRA: Adapter lora_finqa_36 loss: 0.003943411633372307
[2025-12-23 18:01:21,012] m-LoRA: Adapter lora_finqa_78 epoch: 1/1 iteration: 96/128 step: 7
[2025-12-23 18:01:21,365] m-LoRA: Adapter lora_finqa_84 loss: 2.0548388957977295
[2025-12-23 18:01:21,368] m-LoRA: Adapter lora_finqa_79 epoch: 1/1 iteration: 12/128 step: 7
[2025-12-23 18:01:22,060] m-LoRA: Adapter lora_finqa_70 epoch: 1/1 iteration: 44/128 step: 23
[2025-12-23 18:01:22,117] m-LoRA: Adapter lora_finqa_77 loss: 0.6560627222061157
[2025-12-23 18:01:22,375] m-LoRA: Adapter lora_finqa_85 loss: 0.7773109078407288
[2025-12-23 18:01:22,378] m-LoRA: Adapter lora_finqa_80 epoch: 1/1 iteration: 24/128 step: 7
[2025-12-23 18:01:22,664] m-LoRA: Adapter lora_finqa_74 loss: 0.00669068144634366
[2025-12-23 18:01:22,667] m-LoRA: Adapter lora_finqa_51 epoch: 1/1 iteration: 92/128 step: 47
[2025-12-23 18:01:23,134] m-LoRA: Adapter lora_finqa_60 loss: 0.01343755517154932
[2025-12-23 18:01:23,138] m-LoRA: Adapter lora_finqa_66 epoch: 1/1 iteration: 120/128 step: 31
[2025-12-23 18:01:23,540] m-LoRA: Adapter lora_finqa_46 loss: 8.503624849254265e-05
[2025-12-23 18:01:23,543] m-LoRA: Adapter lora_finqa_42 epoch: 1/1 iteration: 108/128 step: 55
[2025-12-23 18:01:23,804] m-LoRA: Adapter lora_finqa_37 loss: 0.005637641996145248
[2025-12-23 18:01:23,807] m-LoRA: Adapter lora_finqa_81 epoch: 1/1 iteration: 12/128 step: 7
[2025-12-23 18:01:24,162] m-LoRA: Adapter lora_finqa_47 loss: 4.785729470313527e-05
[2025-12-23 18:01:24,313] m-LoRA: Adapter lora_finqa_82 epoch: 1/1 iteration: 96/128 step: 7
[2025-12-23 18:01:24,595] m-LoRA: Adapter lora_finqa_61 loss: 0.0014825476100668311
[2025-12-23 18:01:24,767] m-LoRA: Adapter lora_finqa_83 epoch: 1/1 iteration: 96/128 step: 7
[2025-12-23 18:01:25,347] m-LoRA: Adapter lora_finqa_86 loss: 1.395188331604004
[2025-12-23 18:01:25,352] m-LoRA: Adapter lora_finqa_76 epoch: 1/1 iteration: 112/128 step: 15
[2025-12-23 18:01:25,587] m-LoRA: Adapter lora_finqa_48 loss: 8.664591587148607e-05
[2025-12-23 18:01:25,590] m-LoRA: Adapter lora_finqa_57 epoch: 1/1 iteration: 76/128 step: 39
[2025-12-23 18:01:26,741] m-LoRA: Adapter lora_finqa_72 epoch: 1/1 iteration: 88/128 step: 23
[2025-12-23 18:01:26,849] m-LoRA: Adapter lora_finqa_87 loss: 1.4002166986465454
[2025-12-23 18:01:27,515] m-LoRA: Adapter lora_finqa_36 epoch: 1/1 iteration: 124/128 step: 63
[2025-12-23 18:01:27,573] m-LoRA: Adapter lora_finqa_88 loss: 0.7684619426727295
[2025-12-23 18:01:28,805] m-LoRA: Adapter lora_finqa_84 epoch: 1/1 iteration: 12/128 step: 7
[2025-12-23 18:01:28,924] m-LoRA: Adapter lora_finqa_89 loss: 2.049642324447632
[2025-12-23 18:01:29,213] m-LoRA: Adapter lora_finqa_55 loss: 0.3824397623538971
[2025-12-23 18:01:29,216] m-LoRA: Adapter lora_finqa_77 epoch: 1/1 iteration: 56/128 step: 15
[2025-12-23 18:01:29,481] m-LoRA: Adapter lora_finqa_40 loss: 0.0033055583480745554
[2025-12-23 18:01:29,485] m-LoRA: Adapter lora_finqa_85 epoch: 1/1 iteration: 12/128 step: 7
[2025-12-23 18:01:31,658] m-LoRA: Adapter lora_finqa_74 epoch: 1/1 iteration: 44/128 step: 23
[2025-12-23 18:01:32,173] m-LoRA: Adapter lora_finqa_78 loss: 1.082544207572937
[2025-12-23 18:01:32,191] m-LoRA: Adapter lora_finqa_60 epoch: 1/1 iteration: 76/128 step: 39
[2025-12-23 18:01:32,248] m-LoRA: Adapter lora_finqa_79 loss: 0.5278739929199219
[2025-12-23 18:01:32,686] m-LoRA: Adapter lora_finqa_70 loss: 0.013274159282445908
[2025-12-23 18:01:32,689] m-LoRA: Adapter lora_finqa_46 epoch: 1/1 iteration: 108/128 step: 55
[2025-12-23 18:01:33,180] m-LoRA: Adapter lora_finqa_37 epoch: 1/1 iteration: 124/128 step: 63
[2025-12-23 18:01:33,236] m-LoRA: Adapter lora_finqa_80 loss: 1.0874947309494019
[2025-12-23 18:01:33,449] m-LoRA: Adapter lora_finqa_51 loss: 0.00012853155203629285
[2025-12-23 18:01:33,453] m-LoRA: Adapter lora_finqa_47 epoch: 1/1 iteration: 108/128 step: 55
[2025-12-23 18:01:33,959] m-LoRA: Adapter lora_finqa_61 epoch: 1/1 iteration: 76/128 step: 39
[2025-12-23 18:01:33,997] m-LoRA: Adapter lora_finqa_66 loss: 0.00027863887953571975
[2025-12-23 18:01:34,265] m-LoRA: Adapter lora_finqa_42 loss: 7.895981252659112e-05
[2025-12-23 18:01:34,268] m-LoRA: Adapter lora_finqa_86 epoch: 1/1 iteration: 24/128 step: 7
[2025-12-23 18:01:34,536] m-LoRA: Adapter lora_finqa_81 loss: 1.1346462965011597
[2025-12-23 18:01:34,539] m-LoRA: Adapter lora_finqa_48 epoch: 1/1 iteration: 108/128 step: 55
[2025-12-23 18:01:37,191] m-LoRA: Adapter lora_finqa_82 loss: 1.077541708946228
[2025-12-23 18:01:37,298] m-LoRA: Adapter lora_finqa_87 epoch: 1/1 iteration: 48/128 step: 7
[2025-12-23 18:01:41,545] m-LoRA: Adapter lora_finqa_88 epoch: 1/1 iteration: 24/128 step: 7
[2025-12-23 18:01:41,767] m-LoRA: Adapter lora_finqa_83 loss: 0.527498722076416
[2025-12-23 18:01:43,698] m-LoRA: Adapter lora_finqa_76 loss: 0.046787213534116745
[2025-12-23 18:01:43,780] m-LoRA: Adapter lora_finqa_89 epoch: 1/1 iteration: 48/128 step: 7
[2025-12-23 18:01:44,025] m-LoRA: Adapter lora_finqa_57 loss: 0.013216648250818253
[2025-12-23 18:01:44,028] m-LoRA: Adapter lora_finqa_55 epoch: 1/1 iteration: 92/128 step: 47
[2025-12-23 18:01:44,687] m-LoRA: Adapter lora_finqa_72 loss: 1.9068591594696045
[2025-12-23 18:01:44,693] m-LoRA: Adapter lora_finqa_40 epoch: 1/1 iteration: 124/128 step: 63
[2025-12-23 18:01:45,247] m-LoRA: Adapter lora_finqa_36 loss: 0.003948945552110672
[2025-12-23 18:01:45,404] m-LoRA: Adapter lora_finqa_78 epoch: 1/1 iteration: 112/128 step: 8
[2025-12-23 18:01:45,711] m-LoRA: Adapter lora_finqa_84 loss: 1.9023704528808594
[2025-12-23 18:01:45,714] m-LoRA: Adapter lora_finqa_79 epoch: 1/1 iteration: 14/128 step: 8
[2025-12-23 18:01:47,042] m-LoRA: Adapter lora_finqa_70 epoch: 1/1 iteration: 46/128 step: 24
[2025-12-23 18:01:47,108] m-LoRA: Adapter lora_finqa_77 loss: 0.5242810845375061
[2025-12-23 18:01:47,718] m-LoRA: Adapter lora_finqa_85 loss: 0.5352057814598083
[2025-12-23 18:01:47,722] m-LoRA: Adapter lora_finqa_80 epoch: 1/1 iteration: 28/128 step: 8
[2025-12-23 18:01:48,076] m-LoRA: Adapter lora_finqa_74 loss: 0.004443654324859381
[2025-12-23 18:01:48,079] m-LoRA: Adapter lora_finqa_51 epoch: 1/1 iteration: 94/128 step: 48
[2025-12-23 18:01:48,553] m-LoRA: Adapter lora_finqa_66 epoch: 1/1 iteration: 124/128 step: 32
[2025-12-23 18:01:48,633] m-LoRA: Adapter lora_finqa_60 loss: 0.013041135855019093
[2025-12-23 18:01:48,934] m-LoRA: Adapter lora_finqa_46 loss: 8.22733563836664e-05
[2025-12-23 18:01:48,937] m-LoRA: Adapter lora_finqa_42 epoch: 1/1 iteration: 110/128 step: 56
[2025-12-23 18:01:49,298] m-LoRA: Adapter lora_finqa_37 loss: 0.0033939590211957693
[2025-12-23 18:01:49,301] m-LoRA: Adapter lora_finqa_81 epoch: 1/1 iteration: 14/128 step: 8
[2025-12-23 18:01:49,691] m-LoRA: Adapter lora_finqa_47 loss: 4.836937296204269e-05
[2025-12-23 18:01:49,855] m-LoRA: Adapter lora_finqa_82 epoch: 1/1 iteration: 112/128 step: 8
[2025-12-23 18:01:50,275] m-LoRA: Adapter lora_finqa_61 loss: 0.0013436272274702787
[2025-12-23 18:01:50,454] m-LoRA: Adapter lora_finqa_83 epoch: 1/1 iteration: 112/128 step: 8
[2025-12-23 18:01:51,651] m-LoRA: Adapter lora_finqa_86 loss: 1.0998679399490356
[2025-12-23 18:01:51,846] m-LoRA: Adapter lora_finqa_76 epoch: 1/1 iteration: 120/128 step: 16
[2025-12-23 18:01:52,398] m-LoRA: Adapter lora_finqa_48 loss: 8.626461203675717e-05
[2025-12-23 18:01:52,402] m-LoRA: Adapter lora_finqa_57 epoch: 1/1 iteration: 78/128 step: 40
[2025-12-23 18:01:53,617] m-LoRA: Adapter lora_finqa_72 epoch: 1/1 iteration: 92/128 step: 24
[2025-12-23 18:01:53,705] m-LoRA: Adapter lora_finqa_87 loss: 1.1152715682983398
[2025-12-23 18:01:54,362] m-LoRA: Adapter lora_finqa_88 loss: 0.5209333300590515
[2025-12-23 18:01:54,367] m-LoRA: Adapter lora_finqa_36 epoch: 1/1 iteration: 126/128 step: 64
[2025-12-23 18:01:55,495] m-LoRA: Adapter lora_finqa_84 epoch: 1/1 iteration: 14/128 step: 8
[2025-12-23 18:01:55,559] m-LoRA: Adapter lora_finqa_89 loss: 1.896602988243103
[2025-12-23 18:01:55,899] m-LoRA: Adapter lora_finqa_55 loss: 0.34540271759033203
[2025-12-23 18:01:55,902] m-LoRA: Adapter lora_finqa_77 epoch: 1/1 iteration: 60/128 step: 16
[2025-12-23 18:01:56,591] m-LoRA: Adapter lora_finqa_85 epoch: 1/1 iteration: 14/128 step: 8
[2025-12-23 18:01:56,645] m-LoRA: Adapter lora_finqa_40 loss: 0.0028476431034505367
[2025-12-23 18:01:58,815] m-LoRA: Adapter lora_finqa_74 epoch: 1/1 iteration: 46/128 step: 24
[2025-12-23 18:01:59,008] m-LoRA: Adapter lora_finqa_78 loss: 0.7872166037559509
[2025-12-23 18:01:59,495] m-LoRA: Adapter lora_finqa_60 epoch: 1/1 iteration: 78/128 step: 40
[2025-12-23 18:01:59,526] m-LoRA: Adapter lora_finqa_79 loss: 0.3349607288837433
[2025-12-23 18:02:00,096] m-LoRA: Adapter lora_finqa_70 loss: 0.012458491139113903
[2025-12-23 18:02:00,099] m-LoRA: Adapter lora_finqa_46 epoch: 1/1 iteration: 110/128 step: 56
[2025-12-23 18:02:00,598] m-LoRA: Adapter lora_finqa_37 epoch: 1/1 iteration: 126/128 step: 64
[2025-12-23 18:02:00,659] m-LoRA: Adapter lora_finqa_80 loss: 0.7960472702980042
[2025-12-23 18:02:00,914] m-LoRA: Adapter lora_finqa_51 loss: 0.00011162440932821482
[2025-12-23 18:02:00,918] m-LoRA: Adapter lora_finqa_47 epoch: 1/1 iteration: 110/128 step: 56
[2025-12-23 18:02:01,489] m-LoRA: Adapter lora_finqa_66 loss: 0.0002622749889269471
[2025-12-23 18:02:01,495] m-LoRA: Adapter lora_finqa_61 epoch: 1/1 iteration: 78/128 step: 40
[2025-12-23 18:02:01,967] m-LoRA: Adapter lora_finqa_42 loss: 8.030908065848053e-05
[2025-12-23 18:02:01,970] m-LoRA: Adapter lora_finqa_86 epoch: 1/1 iteration: 28/128 step: 8
[2025-12-23 18:02:02,364] m-LoRA: Adapter lora_finqa_81 loss: 0.8333640098571777
[2025-12-23 18:02:02,367] m-LoRA: Adapter lora_finqa_48 epoch: 1/1 iteration: 110/128 step: 56
[2025-12-23 18:02:04,887] m-LoRA: Adapter lora_finqa_82 loss: 0.7855250239372253
[2025-12-23 18:02:04,994] m-LoRA: Adapter lora_finqa_87 epoch: 1/1 iteration: 56/128 step: 8
[2025-12-23 18:02:06,947] m-LoRA: Adapter lora_finqa_88 epoch: 1/1 iteration: 28/128 step: 8
[2025-12-23 18:02:07,145] m-LoRA: Adapter lora_finqa_83 loss: 0.33439522981643677
[2025-12-23 18:02:08,385] m-LoRA: Adapter lora_finqa_76 loss: 0.035948388278484344
[2025-12-23 18:02:08,468] m-LoRA: Adapter lora_finqa_89 epoch: 1/1 iteration: 56/128 step: 8
[2025-12-23 18:02:08,800] m-LoRA: Adapter lora_finqa_55 epoch: 1/1 iteration: 94/128 step: 48
[2025-12-23 18:02:08,855] m-LoRA: Adapter lora_finqa_57 loss: 0.013945051468908787
[2025-12-23 18:02:09,330] m-LoRA: Adapter lora_finqa_72 loss: 1.849367380142212
[2025-12-23 18:02:09,335] m-LoRA: Adapter lora_finqa_40 epoch: 1/1 iteration: 126/128 step: 64
[2025-12-23 18:02:09,563] m-LoRA: Adapter lora_finqa_36 loss: 0.0027686255052685738
[2025-12-23 18:02:09,758] m-LoRA: Finish and base model offload adapter - ['lora_finqa_78']
[2025-12-23 18:02:10,246] m-LoRA: Adapter lora_finqa_84 loss: 1.7430042028427124
[2025-12-23 18:02:10,556] m-LoRA: Adapter lora_finqa_79 epoch: 1/1 iteration: 16/128 step: 9
[2025-12-23 18:02:10,868] m-LoRA: Adapter lora_finqa_77 loss: 0.41529399156570435
[2025-12-23 18:02:10,996] m-LoRA: Adapter lora_finqa_70 epoch: 1/1 iteration: 48/128 step: 25
[2025-12-23 18:02:11,281] m-LoRA: Adapter lora_finqa_85 loss: 0.33964043855667114
[2025-12-23 18:02:11,284] m-LoRA: Adapter lora_finqa_80 epoch: 1/1 iteration: 32/128 step: 9
[2025-12-23 18:02:11,541] m-LoRA: Adapter lora_finqa_74 loss: 0.0032760959584265947
[2025-12-23 18:02:11,544] m-LoRA: Adapter lora_finqa_51 epoch: 1/1 iteration: 96/128 step: 49
[2025-12-23 18:02:11,984] m-LoRA: Finish and base model offload adapter - ['lora_finqa_66']
[2025-12-23 18:02:12,804] m-LoRA: Adapter lora_finqa_60 loss: 0.012510325759649277
[2025-12-23 18:02:12,899] m-LoRA: Adapter lora_finqa_46 loss: 7.426569209201261e-05
[2025-12-23 18:02:12,902] m-LoRA: Adapter lora_finqa_42 epoch: 1/1 iteration: 112/128 step: 57
[2025-12-23 18:02:13,150] m-LoRA: Adapter lora_finqa_37 loss: 0.0036127998027950525
[2025-12-23 18:02:13,153] m-LoRA: Adapter lora_finqa_81 epoch: 1/1 iteration: 16/128 step: 9
[2025-12-23 18:02:13,399] m-LoRA: Finish and base model offload adapter - ['lora_finqa_82']
[2025-12-23 18:02:13,843] m-LoRA: Adapter lora_finqa_47 loss: 4.671572969527915e-05
[2025-12-23 18:02:14,012] m-LoRA: Finish and base model offload adapter - ['lora_finqa_83']
[2025-12-23 18:02:14,789] m-LoRA: Adapter lora_finqa_61 loss: 0.000498538778629154
[2025-12-23 18:02:14,927] m-LoRA: Finish and base model offload adapter - ['lora_finqa_76']
[2025-12-23 18:02:15,221] m-LoRA: Adapter lora_finqa_86 loss: 0.8105641007423401
[2025-12-23 18:02:15,283] m-LoRA: Adapter lora_finqa_48 loss: 0.00012445426546037197
[2025-12-23 18:02:15,285] m-LoRA: Adapter lora_finqa_57 epoch: 1/1 iteration: 80/128 step: 41
[2025-12-23 18:02:15,809] m-LoRA: Adapter lora_finqa_72 epoch: 1/1 iteration: 96/128 step: 25
[2025-12-23 18:02:15,953] m-LoRA: Adapter lora_finqa_87 loss: 0.8203762173652649
[2025-12-23 18:02:16,410] m-LoRA: Finish and base model offload adapter - ['lora_finqa_36']
[2025-12-23 18:02:16,617] m-LoRA: Adapter lora_finqa_88 loss: 0.3307305574417114
[2025-12-23 18:02:17,601] m-LoRA: Adapter lora_finqa_84 epoch: 1/1 iteration: 16/128 step: 9
[2025-12-23 18:02:17,669] m-LoRA: Adapter lora_finqa_89 loss: 1.7330384254455566
[2025-12-23 18:02:17,961] m-LoRA: Adapter lora_finqa_55 loss: 0.3106713593006134
[2025-12-23 18:02:17,965] m-LoRA: Adapter lora_finqa_77 epoch: 1/1 iteration: 64/128 step: 17
[2025-12-23 18:02:18,182] m-LoRA: Adapter lora_finqa_40 loss: 0.002395742805674672
[2025-12-23 18:02:18,186] m-LoRA: Adapter lora_finqa_85 epoch: 1/1 iteration: 16/128 step: 9
[2025-12-23 18:02:18,459] m-LoRA: Adapter lora_finqa_79 loss: 0.21691714227199554
[2025-12-23 18:02:18,462] m-LoRA: Adapter lora_finqa_74 epoch: 1/1 iteration: 48/128 step: 25
[2025-12-23 18:02:18,865] m-LoRA: Adapter lora_finqa_60 epoch: 1/1 iteration: 80/128 step: 41
[2025-12-23 18:02:18,923] m-LoRA: Adapter lora_finqa_70 loss: 0.012503569945693016
[2025-12-23 18:02:19,545] m-LoRA: Adapter lora_finqa_46 epoch: 1/1 iteration: 112/128 step: 57
[2025-12-23 18:02:19,579] m-LoRA: Adapter lora_finqa_80 loss: 0.5469404458999634
[2025-12-23 18:02:19,883] m-LoRA: Finish and base model offload adapter - ['lora_finqa_37']
[2025-12-23 18:02:20,025] m-LoRA: Adapter lora_finqa_51 loss: 0.0001047155456035398
[2025-12-23 18:02:20,194] m-LoRA: Adapter lora_finqa_42 loss: 7.402901974273846e-05
[2025-12-23 18:02:20,197] m-LoRA: Adapter lora_finqa_47 epoch: 1/1 iteration: 112/128 step: 57
[2025-12-23 18:02:20,464] m-LoRA: Adapter lora_finqa_81 loss: 0.5899768471717834
[2025-12-23 18:02:20,467] m-LoRA: Adapter lora_finqa_61 epoch: 1/1 iteration: 80/128 step: 41
[2025-12-23 18:02:20,932] m-LoRA: Adapter lora_finqa_57 loss: 0.012394063174724579
[2025-12-23 18:02:20,935] m-LoRA: Adapter lora_finqa_86 epoch: 1/1 iteration: 32/128 step: 9
[2025-12-23 18:02:21,574] m-LoRA: Adapter lora_finqa_72 loss: 1.79080331325531
[2025-12-23 18:02:21,760] m-LoRA: Adapter lora_finqa_48 epoch: 1/1 iteration: 112/128 step: 57
[2025-12-23 18:02:21,969] m-LoRA: Adapter lora_finqa_84 loss: 1.5602948665618896
[2025-12-23 18:02:22,086] m-LoRA: Adapter lora_finqa_87 epoch: 1/1 iteration: 64/128 step: 9
[2025-12-23 18:02:22,717] m-LoRA: Adapter lora_finqa_77 loss: 0.32802167534828186
[2025-12-23 18:02:22,723] m-LoRA: Adapter lora_finqa_88 epoch: 1/1 iteration: 32/128 step: 9
[2025-12-23 18:02:23,006] m-LoRA: Adapter lora_finqa_85 loss: 0.22162528336048126
[2025-12-23 18:02:23,114] m-LoRA: Adapter lora_finqa_89 epoch: 1/1 iteration: 64/128 step: 9
[2025-12-23 18:02:23,422] m-LoRA: Adapter lora_finqa_74 loss: 0.0021055336110293865
[2025-12-23 18:02:23,426] m-LoRA: Adapter lora_finqa_55 epoch: 1/1 iteration: 96/128 step: 49
[2025-12-23 18:02:23,717] m-LoRA: Finish and base model offload adapter - ['lora_finqa_40']
[2025-12-23 18:02:23,864] m-LoRA: Adapter lora_finqa_60 loss: 0.011945988051593304
[2025-12-23 18:02:24,061] m-LoRA: Adapter lora_finqa_46 loss: 6.634450983256102e-05
[2025-12-23 18:02:24,064] m-LoRA: Adapter lora_finqa_79 epoch: 1/1 iteration: 18/128 step: 10
[2025-12-23 18:02:24,400] m-LoRA: Adapter lora_finqa_47 loss: 4.383763007353991e-05
[2025-12-23 18:02:24,404] m-LoRA: Adapter lora_finqa_70 epoch: 1/1 iteration: 50/128 step: 26
[2025-12-23 18:02:24,698] m-LoRA: Adapter lora_finqa_61 loss: 0.00047480518696829677
[2025-12-23 18:02:24,701] m-LoRA: Adapter lora_finqa_80 epoch: 1/1 iteration: 36/128 step: 10
[2025-12-23 18:02:25,366] m-LoRA: Adapter lora_finqa_51 epoch: 1/1 iteration: 98/128 step: 50
[2025-12-23 18:02:25,401] m-LoRA: Adapter lora_finqa_86 loss: 0.5608546733856201
[2025-12-23 18:02:25,627] m-LoRA: Adapter lora_finqa_42 epoch: 1/1 iteration: 114/128 step: 58
[2025-12-23 18:02:25,680] m-LoRA: Adapter lora_finqa_48 loss: 7.500855281250551e-05
[2025-12-23 18:02:26,901] m-LoRA: Adapter lora_finqa_81 epoch: 1/1 iteration: 18/128 step: 10
[2025-12-23 18:02:26,970] m-LoRA: Adapter lora_finqa_87 loss: 0.57185959815979
[2025-12-23 18:02:27,511] m-LoRA: Adapter lora_finqa_57 epoch: 1/1 iteration: 82/128 step: 42
[2025-12-23 18:02:27,568] m-LoRA: Adapter lora_finqa_88 loss: 0.21571795642375946
[2025-12-23 18:02:29,855] m-LoRA: Adapter lora_finqa_89 loss: 1.5491957664489746
[2025-12-23 18:02:29,865] m-LoRA: Adapter lora_finqa_72 epoch: 1/1 iteration: 100/128 step: 26
[2025-12-23 18:02:30,271] m-LoRA: Adapter lora_finqa_55 loss: 0.2767481207847595
[2025-12-23 18:02:30,275] m-LoRA: Adapter lora_finqa_84 epoch: 1/1 iteration: 18/128 step: 10
[2025-12-23 18:02:30,571] m-LoRA: Adapter lora_finqa_77 epoch: 1/1 iteration: 68/128 step: 18
[2025-12-23 18:02:30,645] m-LoRA: Adapter lora_finqa_79 loss: 0.11365304887294769
[2025-12-23 18:02:30,971] m-LoRA: Adapter lora_finqa_70 loss: 0.010895570740103722
[2025-12-23 18:02:30,974] m-LoRA: Adapter lora_finqa_85 epoch: 1/1 iteration: 18/128 step: 10
[2025-12-23 18:02:32,161] m-LoRA: Adapter lora_finqa_74 epoch: 1/1 iteration: 50/128 step: 26
[2025-12-23 18:02:32,218] m-LoRA: Adapter lora_finqa_80 loss: 0.3919304609298706
[2025-12-23 18:02:32,572] m-LoRA: Adapter lora_finqa_60 epoch: 1/1 iteration: 82/128 step: 42
[2025-12-23 18:02:32,603] m-LoRA: Adapter lora_finqa_51 loss: 9.790761396288872e-05
[2025-12-23 18:02:32,915] m-LoRA: Adapter lora_finqa_42 loss: 8.472759509459138e-05
[2025-12-23 18:02:32,918] m-LoRA: Adapter lora_finqa_46 epoch: 1/1 iteration: 114/128 step: 58
[2025-12-23 18:02:33,232] m-LoRA: Adapter lora_finqa_81 loss: 0.42808017134666443
[2025-12-23 18:02:33,235] m-LoRA: Adapter lora_finqa_47 epoch: 1/1 iteration: 114/128 step: 58
[2025-12-23 18:02:33,806] m-LoRA: Adapter lora_finqa_57 loss: 0.011980907991528511
[2025-12-23 18:02:33,809] m-LoRA: Adapter lora_finqa_61 epoch: 1/1 iteration: 82/128 step: 42
[2025-12-23 18:02:35,067] m-LoRA: Adapter lora_finqa_72 loss: 1.7257733345031738
[2025-12-23 18:02:35,073] m-LoRA: Adapter lora_finqa_86 epoch: 1/1 iteration: 36/128 step: 10
[2025-12-23 18:02:35,413] m-LoRA: Adapter lora_finqa_84 loss: 1.3967382907867432
[2025-12-23 18:02:35,417] m-LoRA: Adapter lora_finqa_48 epoch: 1/1 iteration: 114/128 step: 58
[2025-12-23 18:02:35,992] m-LoRA: Adapter lora_finqa_77 loss: 0.25906792283058167
[2025-12-23 18:02:36,116] m-LoRA: Adapter lora_finqa_87 epoch: 1/1 iteration: 72/128 step: 10
[2025-12-23 18:02:36,645] m-LoRA: Adapter lora_finqa_85 loss: 0.11732751876115799
[2025-12-23 18:02:36,649] m-LoRA: Adapter lora_finqa_88 epoch: 1/1 iteration: 36/128 step: 10
[2025-12-23 18:02:36,865] m-LoRA: Adapter lora_finqa_74 loss: 0.0014807889237999916
[2025-12-23 18:02:36,954] m-LoRA: Adapter lora_finqa_89 epoch: 1/1 iteration: 72/128 step: 10
[2025-12-23 18:02:37,720] m-LoRA: Adapter lora_finqa_60 loss: 0.011301497928798199
[2025-12-23 18:02:37,723] m-LoRA: Adapter lora_finqa_55 epoch: 1/1 iteration: 98/128 step: 50
[2025-12-23 18:02:38,220] m-LoRA: Adapter lora_finqa_46 loss: 6.684336403850466e-05
[2025-12-23 18:02:38,223] m-LoRA: Adapter lora_finqa_79 epoch: 1/1 iteration: 20/128 step: 11
[2025-12-23 18:02:38,526] m-LoRA: Adapter lora_finqa_47 loss: 4.2365030822111294e-05
[2025-12-23 18:02:38,529] m-LoRA: Adapter lora_finqa_70 epoch: 1/1 iteration: 52/128 step: 27
[2025-12-23 18:02:38,839] m-LoRA: Adapter lora_finqa_61 loss: 0.0003795204684138298
[2025-12-23 18:02:38,843] m-LoRA: Adapter lora_finqa_80 epoch: 1/1 iteration: 40/128 step: 11
[2025-12-23 18:02:39,495] m-LoRA: Adapter lora_finqa_51 epoch: 1/1 iteration: 100/128 step: 51
[2025-12-23 18:02:39,554] m-LoRA: Adapter lora_finqa_86 loss: 0.4103424549102783
[2025-12-23 18:02:40,084] m-LoRA: Adapter lora_finqa_48 loss: 7.380164606729522e-05
[2025-12-23 18:02:40,087] m-LoRA: Adapter lora_finqa_42 epoch: 1/1 iteration: 116/128 step: 59
[2025-12-23 18:02:41,215] m-LoRA: Adapter lora_finqa_81 epoch: 1/1 iteration: 20/128 step: 11
[2025-12-23 18:02:41,298] m-LoRA: Adapter lora_finqa_87 loss: 0.41941091418266296
[2025-12-23 18:02:41,768] m-LoRA: Adapter lora_finqa_57 epoch: 1/1 iteration: 84/128 step: 43
[2025-12-23 18:02:41,799] m-LoRA: Adapter lora_finqa_88 loss: 0.11904790252447128
[2025-12-23 18:02:42,866] m-LoRA: Adapter lora_finqa_72 epoch: 1/1 iteration: 104/128 step: 27
[2025-12-23 18:02:42,950] m-LoRA: Adapter lora_finqa_89 loss: 1.3856173753738403
[2025-12-23 18:02:43,194] m-LoRA: Adapter lora_finqa_84 epoch: 1/1 iteration: 20/128 step: 11
[2025-12-23 18:02:43,250] m-LoRA: Adapter lora_finqa_55 loss: 0.24804776906967163
[2025-12-23 18:02:43,619] m-LoRA: Adapter lora_finqa_79 loss: 0.053965818136930466
[2025-12-23 18:02:43,622] m-LoRA: Adapter lora_finqa_77 epoch: 1/1 iteration: 72/128 step: 19
[2025-12-23 18:02:43,912] m-LoRA: Adapter lora_finqa_70 loss: 0.010316313244402409
[2025-12-23 18:02:43,915] m-LoRA: Adapter lora_finqa_85 epoch: 1/1 iteration: 20/128 step: 11
[2025-12-23 18:02:44,472] m-LoRA: Adapter lora_finqa_80 loss: 0.2611754238605499
[2025-12-23 18:02:44,477] m-LoRA: Adapter lora_finqa_74 epoch: 1/1 iteration: 52/128 step: 27
[2025-12-23 18:02:44,925] m-LoRA: Adapter lora_finqa_51 loss: 9.266728739021346e-05
[2025-12-23 18:02:44,928] m-LoRA: Adapter lora_finqa_60 epoch: 1/1 iteration: 84/128 step: 43
[2025-12-23 18:02:45,298] m-LoRA: Adapter lora_finqa_42 loss: 6.585018854821101e-05
[2025-12-23 18:02:45,302] m-LoRA: Adapter lora_finqa_46 epoch: 1/1 iteration: 116/128 step: 59
[2025-12-23 18:02:45,616] m-LoRA: Adapter lora_finqa_81 loss: 0.2867881655693054
[2025-12-23 18:02:45,619] m-LoRA: Adapter lora_finqa_47 epoch: 1/1 iteration: 116/128 step: 59
[2025-12-23 18:02:45,930] m-LoRA: Adapter lora_finqa_61 epoch: 1/1 iteration: 84/128 step: 43
[2025-12-23 18:02:45,989] m-LoRA: Adapter lora_finqa_57 loss: 0.011472789570689201
[2025-12-23 18:02:46,659] m-LoRA: Adapter lora_finqa_72 loss: 1.660369634628296
[2025-12-23 18:02:46,686] m-LoRA: Adapter lora_finqa_86 epoch: 1/1 iteration: 40/128 step: 11
[2025-12-23 18:02:46,964] m-LoRA: Adapter lora_finqa_84 loss: 1.2141443490982056
[2025-12-23 18:02:46,967] m-LoRA: Adapter lora_finqa_48 epoch: 1/1 iteration: 116/128 step: 59
[2025-12-23 18:02:47,617] m-LoRA: Adapter lora_finqa_77 loss: 0.20516327023506165
[2025-12-23 18:02:47,778] m-LoRA: Adapter lora_finqa_87 epoch: 1/1 iteration: 80/128 step: 11
[2025-12-23 18:02:48,058] m-LoRA: Adapter lora_finqa_85 loss: 0.06142067164182663
[2025-12-23 18:02:48,062] m-LoRA: Adapter lora_finqa_88 epoch: 1/1 iteration: 40/128 step: 11
[2025-12-23 18:02:48,302] m-LoRA: Adapter lora_finqa_74 loss: 0.000938106793910265
[2025-12-23 18:02:48,404] m-LoRA: Adapter lora_finqa_89 epoch: 1/1 iteration: 80/128 step: 11
[2025-12-23 18:02:48,752] m-LoRA: Adapter lora_finqa_60 loss: 0.011329494416713715
[2025-12-23 18:02:48,755] m-LoRA: Adapter lora_finqa_55 epoch: 1/1 iteration: 100/128 step: 51
[2025-12-23 18:02:49,135] m-LoRA: Adapter lora_finqa_46 loss: 6.402195140253752e-05
[2025-12-23 18:02:49,138] m-LoRA: Adapter lora_finqa_79 epoch: 1/1 iteration: 22/128 step: 12
[2025-12-23 18:02:49,428] m-LoRA: Adapter lora_finqa_47 loss: 4.305805123294704e-05
[2025-12-23 18:02:49,432] m-LoRA: Adapter lora_finqa_70 epoch: 1/1 iteration: 54/128 step: 28
[2025-12-23 18:02:49,885] m-LoRA: Adapter lora_finqa_61 loss: 0.000332675757817924
[2025-12-23 18:02:49,888] m-LoRA: Adapter lora_finqa_80 epoch: 1/1 iteration: 44/128 step: 12
[2025-12-23 18:02:50,634] m-LoRA: Adapter lora_finqa_86 loss: 0.2713511884212494
[2025-12-23 18:02:50,639] m-LoRA: Adapter lora_finqa_51 epoch: 1/1 iteration: 102/128 step: 52
[2025-12-23 18:02:50,969] m-LoRA: Adapter lora_finqa_48 loss: 7.434759754687548e-05
[2025-12-23 18:02:50,972] m-LoRA: Adapter lora_finqa_42 epoch: 1/1 iteration: 118/128 step: 60
[2025-12-23 18:02:52,223] m-LoRA: Adapter lora_finqa_87 loss: 0.27618730068206787
[2025-12-23 18:02:52,279] m-LoRA: Adapter lora_finqa_81 epoch: 1/1 iteration: 22/128 step: 12
[2025-12-23 18:02:52,843] m-LoRA: Adapter lora_finqa_88 loss: 0.06103920564055443
[2025-12-23 18:02:52,848] m-LoRA: Adapter lora_finqa_57 epoch: 1/1 iteration: 86/128 step: 44
[2025-12-23 18:02:53,959] m-LoRA: Adapter lora_finqa_72 epoch: 1/1 iteration: 108/128 step: 28
[2025-12-23 18:02:54,044] m-LoRA: Adapter lora_finqa_89 loss: 1.1971313953399658
[2025-12-23 18:02:54,286] m-LoRA: Adapter lora_finqa_55 loss: 0.22101391851902008
[2025-12-23 18:02:54,290] m-LoRA: Adapter lora_finqa_84 epoch: 1/1 iteration: 22/128 step: 12
[2025-12-23 18:02:54,569] m-LoRA: Adapter lora_finqa_77 epoch: 1/1 iteration: 76/128 step: 20
[2025-12-23 18:02:54,645] m-LoRA: Adapter lora_finqa_79 loss: 0.035331953316926956
[2025-12-23 18:02:54,912] m-LoRA: Adapter lora_finqa_70 loss: 0.009434579871594906
[2025-12-23 18:02:54,916] m-LoRA: Adapter lora_finqa_85 epoch: 1/1 iteration: 22/128 step: 12
[2025-12-23 18:02:55,525] m-LoRA: Adapter lora_finqa_80 loss: 0.18717047572135925
[2025-12-23 18:02:55,531] m-LoRA: Adapter lora_finqa_74 epoch: 1/1 iteration: 54/128 step: 28
[2025-12-23 18:02:55,959] m-LoRA: Adapter lora_finqa_51 loss: 8.525430894223973e-05
[2025-12-23 18:02:55,962] m-LoRA: Adapter lora_finqa_60 epoch: 1/1 iteration: 86/128 step: 44
[2025-12-23 18:02:56,230] m-LoRA: Adapter lora_finqa_46 epoch: 1/1 iteration: 118/128 step: 60
[2025-12-23 18:02:56,290] m-LoRA: Adapter lora_finqa_42 loss: 6.02201180299744e-05
[2025-12-23 18:02:56,589] m-LoRA: Adapter lora_finqa_81 loss: 0.1954212486743927
[2025-12-23 18:02:56,593] m-LoRA: Adapter lora_finqa_47 epoch: 1/1 iteration: 118/128 step: 60
[2025-12-23 18:02:56,910] m-LoRA: Adapter lora_finqa_57 loss: 0.011907689273357391
[2025-12-23 18:02:56,913] m-LoRA: Adapter lora_finqa_61 epoch: 1/1 iteration: 86/128 step: 44
[2025-12-23 18:02:57,576] m-LoRA: Adapter lora_finqa_72 loss: 1.5967841148376465
[2025-12-23 18:02:57,581] m-LoRA: Adapter lora_finqa_86 epoch: 1/1 iteration: 44/128 step: 12
[2025-12-23 18:02:57,885] m-LoRA: Adapter lora_finqa_84 loss: 1.0161521434783936
[2025-12-23 18:02:57,888] m-LoRA: Adapter lora_finqa_48 epoch: 1/1 iteration: 118/128 step: 60
[2025-12-23 18:02:58,499] m-LoRA: Adapter lora_finqa_77 loss: 0.15544867515563965
[2025-12-23 18:02:58,627] m-LoRA: Adapter lora_finqa_87 epoch: 1/1 iteration: 88/128 step: 12
[2025-12-23 18:02:58,918] m-LoRA: Adapter lora_finqa_85 loss: 0.03595350310206413
[2025-12-23 18:02:58,921] m-LoRA: Adapter lora_finqa_88 epoch: 1/1 iteration: 44/128 step: 12
[2025-12-23 18:02:59,188] m-LoRA: Adapter lora_finqa_74 loss: 0.0006337683880701661
[2025-12-23 18:02:59,290] m-LoRA: Adapter lora_finqa_89 epoch: 1/1 iteration: 88/128 step: 12
[2025-12-23 18:02:59,640] m-LoRA: Adapter lora_finqa_60 loss: 0.010316495783627033
[2025-12-23 18:02:59,643] m-LoRA: Adapter lora_finqa_55 epoch: 1/1 iteration: 102/128 step: 52
[2025-12-23 18:03:00,011] m-LoRA: Adapter lora_finqa_46 loss: 5.939619222772308e-05
[2025-12-23 18:03:00,015] m-LoRA: Adapter lora_finqa_79 epoch: 1/1 iteration: 24/128 step: 13
[2025-12-23 18:03:00,268] m-LoRA: Adapter lora_finqa_70 epoch: 1/1 iteration: 56/128 step: 29
[2025-12-23 18:03:00,325] m-LoRA: Adapter lora_finqa_47 loss: 4.066577457706444e-05
[2025-12-23 18:03:00,727] m-LoRA: Adapter lora_finqa_61 loss: 0.0002170201187254861
[2025-12-23 18:03:00,730] m-LoRA: Adapter lora_finqa_80 epoch: 1/1 iteration: 48/128 step: 13
[2025-12-23 18:03:01,377] m-LoRA: Adapter lora_finqa_51 epoch: 1/1 iteration: 104/128 step: 53
[2025-12-23 18:03:01,413] m-LoRA: Adapter lora_finqa_86 loss: 0.19254018366336823
[2025-12-23 18:03:01,779] m-LoRA: Adapter lora_finqa_48 loss: 6.836887769168243e-05
[2025-12-23 18:03:01,782] m-LoRA: Adapter lora_finqa_42 epoch: 1/1 iteration: 120/128 step: 61
[2025-12-23 18:03:02,963] m-LoRA: Adapter lora_finqa_81 epoch: 1/1 iteration: 24/128 step: 13
[2025-12-23 18:03:03,100] m-LoRA: Adapter lora_finqa_87 loss: 0.19156181812286377
[2025-12-23 18:03:03,733] m-LoRA: Adapter lora_finqa_57 epoch: 1/1 iteration: 88/128 step: 45
[2025-12-23 18:03:03,794] m-LoRA: Adapter lora_finqa_88 loss: 0.03822467476129532
[2025-12-23 18:03:04,874] m-LoRA: Adapter lora_finqa_72 epoch: 1/1 iteration: 112/128 step: 29
[2025-12-23 18:03:04,952] m-LoRA: Adapter lora_finqa_89 loss: 1.0012626647949219
[2025-12-23 18:03:05,186] m-LoRA: Adapter lora_finqa_55 loss: 0.1963609755039215
[2025-12-23 18:03:05,189] m-LoRA: Adapter lora_finqa_84 epoch: 1/1 iteration: 24/128 step: 13
[2025-12-23 18:03:05,524] m-LoRA: Adapter lora_finqa_77 epoch: 1/1 iteration: 80/128 step: 21
[2025-12-23 18:03:05,596] m-LoRA: Adapter lora_finqa_79 loss: 0.025971639901399612
[2025-12-23 18:03:05,815] m-LoRA: Adapter lora_finqa_85 epoch: 1/1 iteration: 24/128 step: 13
[2025-12-23 18:03:05,872] m-LoRA: Adapter lora_finqa_70 loss: 0.008855879306793213
[2025-12-23 18:03:06,436] m-LoRA: Adapter lora_finqa_80 loss: 0.12097188085317612
[2025-12-23 18:03:06,441] m-LoRA: Adapter lora_finqa_74 epoch: 1/1 iteration: 56/128 step: 29
[2025-12-23 18:03:06,844] m-LoRA: Adapter lora_finqa_51 loss: 8.183967293007299e-05
[2025-12-23 18:03:06,847] m-LoRA: Adapter lora_finqa_60 epoch: 1/1 iteration: 88/128 step: 45
[2025-12-23 18:03:07,237] m-LoRA: Adapter lora_finqa_42 loss: 6.255447078729048e-05
[2025-12-23 18:03:07,241] m-LoRA: Adapter lora_finqa_46 epoch: 1/1 iteration: 120/128 step: 61
[2025-12-23 18:03:07,565] m-LoRA: Adapter lora_finqa_81 loss: 0.1307762712240219
[2025-12-23 18:03:07,568] m-LoRA: Adapter lora_finqa_47 epoch: 1/1 iteration: 120/128 step: 61
[2025-12-23 18:03:07,895] m-LoRA: Adapter lora_finqa_57 loss: 0.011105719953775406
[2025-12-23 18:03:07,898] m-LoRA: Adapter lora_finqa_61 epoch: 1/1 iteration: 88/128 step: 45
[2025-12-23 18:03:08,576] m-LoRA: Adapter lora_finqa_72 loss: 1.5331380367279053
[2025-12-23 18:03:08,581] m-LoRA: Adapter lora_finqa_86 epoch: 1/1 iteration: 48/128 step: 13
[2025-12-23 18:03:08,856] m-LoRA: Adapter lora_finqa_48 epoch: 1/1 iteration: 120/128 step: 61
[2025-12-23 18:03:08,911] m-LoRA: Adapter lora_finqa_84 loss: 0.8391563296318054
[2025-12-23 18:03:09,610] m-LoRA: Adapter lora_finqa_77 loss: 0.11050332337617874
[2025-12-23 18:03:09,616] m-LoRA: Adapter lora_finqa_87 epoch: 1/1 iteration: 96/128 step: 13
[2025-12-23 18:03:09,914] m-LoRA: Adapter lora_finqa_85 loss: 0.027687199413776398
[2025-12-23 18:03:09,918] m-LoRA: Adapter lora_finqa_88 epoch: 1/1 iteration: 48/128 step: 13
[2025-12-23 18:03:10,163] m-LoRA: Adapter lora_finqa_74 loss: 0.0004615966754499823
[2025-12-23 18:03:10,242] m-LoRA: Adapter lora_finqa_89 epoch: 1/1 iteration: 96/128 step: 13
[2025-12-23 18:03:10,624] m-LoRA: Adapter lora_finqa_60 loss: 0.010441347025334835
[2025-12-23 18:03:10,627] m-LoRA: Adapter lora_finqa_55 epoch: 1/1 iteration: 104/128 step: 53
[2025-12-23 18:03:10,997] m-LoRA: Adapter lora_finqa_46 loss: 6.271076563280076e-05
[2025-12-23 18:03:11,000] m-LoRA: Adapter lora_finqa_79 epoch: 1/1 iteration: 26/128 step: 14
[2025-12-23 18:03:11,307] m-LoRA: Adapter lora_finqa_47 loss: 4.17181036027614e-05
[2025-12-23 18:03:11,311] m-LoRA: Adapter lora_finqa_70 epoch: 1/1 iteration: 58/128 step: 30
[2025-12-23 18:03:11,696] m-LoRA: Adapter lora_finqa_61 loss: 0.0001479413767810911
[2025-12-23 18:03:11,699] m-LoRA: Adapter lora_finqa_80 epoch: 1/1 iteration: 52/128 step: 14
[2025-12-23 18:03:12,352] m-LoRA: Adapter lora_finqa_51 epoch: 1/1 iteration: 106/128 step: 54
[2025-12-23 18:03:12,407] m-LoRA: Adapter lora_finqa_86 loss: 0.13093338906764984
[2025-12-23 18:03:12,736] m-LoRA: Adapter lora_finqa_48 loss: 6.783279968658462e-05
[2025-12-23 18:03:12,740] m-LoRA: Adapter lora_finqa_42 epoch: 1/1 iteration: 122/128 step: 62
[2025-12-23 18:03:15,174] m-LoRA: Adapter lora_finqa_81 epoch: 1/1 iteration: 26/128 step: 14
[2025-12-23 18:03:15,261] m-LoRA: Adapter lora_finqa_87 loss: 0.12833172082901
[2025-12-23 18:03:15,713] m-LoRA: Adapter lora_finqa_57 epoch: 1/1 iteration: 90/128 step: 46
[2025-12-23 18:03:15,772] m-LoRA: Adapter lora_finqa_88 loss: 0.02706247568130493
[2025-12-23 18:03:16,775] m-LoRA: Adapter lora_finqa_72 epoch: 1/1 iteration: 116/128 step: 30
[2025-12-23 18:03:16,883] m-LoRA: Adapter lora_finqa_89 loss: 0.8236562609672546
[2025-12-23 18:03:17,173] m-LoRA: Adapter lora_finqa_84 epoch: 1/1 iteration: 26/128 step: 14
[2025-12-23 18:03:17,227] m-LoRA: Adapter lora_finqa_55 loss: 0.1674937754869461
[2025-12-23 18:03:17,910] m-LoRA: Adapter lora_finqa_77 epoch: 1/1 iteration: 84/128 step: 22
[2025-12-23 18:03:17,987] m-LoRA: Adapter lora_finqa_79 loss: 0.020097339525818825
[2025-12-23 18:03:18,347] m-LoRA: Adapter lora_finqa_70 loss: 0.0077741327695548534
[2025-12-23 18:03:18,350] m-LoRA: Adapter lora_finqa_85 epoch: 1/1 iteration: 26/128 step: 14
[2025-12-23 18:03:19,083] m-LoRA: Adapter lora_finqa_74 epoch: 1/1 iteration: 58/128 step: 30
[2025-12-23 18:03:19,141] m-LoRA: Adapter lora_finqa_80 loss: 0.06896677613258362
[2025-12-23 18:03:19,848] m-LoRA: Adapter lora_finqa_51 loss: 7.772896788083017e-05
[2025-12-23 18:03:19,852] m-LoRA: Adapter lora_finqa_60 epoch: 1/1 iteration: 90/128 step: 46
[2025-12-23 18:03:20,569] m-LoRA: Adapter lora_finqa_42 loss: 5.964494630461559e-05
[2025-12-23 18:03:20,572] m-LoRA: Adapter lora_finqa_46 epoch: 1/1 iteration: 122/128 step: 62
[2025-12-23 18:03:20,928] m-LoRA: Adapter lora_finqa_81 loss: 0.07888849824666977
[2025-12-23 18:03:20,932] m-LoRA: Adapter lora_finqa_47 epoch: 1/1 iteration: 122/128 step: 62
[2025-12-23 18:03:21,260] m-LoRA: Adapter lora_finqa_57 loss: 0.010289928875863552
[2025-12-23 18:03:21,263] m-LoRA: Adapter lora_finqa_61 epoch: 1/1 iteration: 90/128 step: 46
[2025-12-23 18:03:21,868] m-LoRA: Adapter lora_finqa_86 epoch: 1/1 iteration: 52/128 step: 14
[2025-12-23 18:03:21,947] m-LoRA: Adapter lora_finqa_72 loss: 1.4684475660324097
[2025-12-23 18:03:22,325] m-LoRA: Adapter lora_finqa_84 loss: 0.6744132041931152
[2025-12-23 18:03:22,328] m-LoRA: Adapter lora_finqa_48 epoch: 1/1 iteration: 122/128 step: 62
[2025-12-23 18:03:22,999] m-LoRA: Adapter lora_finqa_77 loss: 0.0825733095407486
[2025-12-23 18:03:23,005] m-LoRA: Adapter lora_finqa_87 epoch: 1/1 iteration: 104/128 step: 14
[2025-12-23 18:03:23,355] m-LoRA: Adapter lora_finqa_85 loss: 0.021000629290938377
[2025-12-23 18:03:23,359] m-LoRA: Adapter lora_finqa_88 epoch: 1/1 iteration: 52/128 step: 14
[2025-12-23 18:03:23,607] m-LoRA: Adapter lora_finqa_74 loss: 0.00036320131039246917
[2025-12-23 18:03:23,737] m-LoRA: Adapter lora_finqa_89 epoch: 1/1 iteration: 104/128 step: 14
[2025-12-23 18:03:23,978] m-LoRA: Adapter lora_finqa_60 loss: 0.010639895685017109
[2025-12-23 18:03:23,981] m-LoRA: Adapter lora_finqa_55 epoch: 1/1 iteration: 106/128 step: 54
[2025-12-23 18:03:24,376] m-LoRA: Adapter lora_finqa_79 epoch: 1/1 iteration: 28/128 step: 15
[2025-12-23 18:03:24,413] m-LoRA: Adapter lora_finqa_46 loss: 5.5690314184175804e-05
[2025-12-23 18:03:24,707] m-LoRA: Adapter lora_finqa_47 loss: 3.841260331682861e-05
[2025-12-23 18:03:24,710] m-LoRA: Adapter lora_finqa_70 epoch: 1/1 iteration: 60/128 step: 31
[2025-12-23 18:03:25,106] m-LoRA: Adapter lora_finqa_61 loss: 0.00013658811803907156
[2025-12-23 18:03:25,109] m-LoRA: Adapter lora_finqa_80 epoch: 1/1 iteration: 56/128 step: 15
[2025-12-23 18:03:25,689] m-LoRA: Adapter lora_finqa_51 epoch: 1/1 iteration: 108/128 step: 55
[2025-12-23 18:03:25,755] m-LoRA: Adapter lora_finqa_86 loss: 0.0769268274307251
[2025-12-23 18:03:26,097] m-LoRA: Adapter lora_finqa_42 epoch: 1/1 iteration: 124/128 step: 63
[2025-12-23 18:03:26,145] m-LoRA: Adapter lora_finqa_48 loss: 6.654709432041273e-05
[2025-12-23 18:03:27,316] m-LoRA: Adapter lora_finqa_81 epoch: 1/1 iteration: 28/128 step: 15
[2025-12-23 18:03:27,379] m-LoRA: Adapter lora_finqa_87 loss: 0.07543302327394485
[2025-12-23 18:03:27,831] m-LoRA: Adapter lora_finqa_57 epoch: 1/1 iteration: 92/128 step: 47
[2025-12-23 18:03:27,889] m-LoRA: Adapter lora_finqa_88 loss: 0.02088303305208683
[2025-12-23 18:03:28,967] m-LoRA: Adapter lora_finqa_72 epoch: 1/1 iteration: 120/128 step: 31
[2025-12-23 18:03:29,049] m-LoRA: Adapter lora_finqa_89 loss: 0.6585593223571777
[2025-12-23 18:03:29,322] m-LoRA: Adapter lora_finqa_84 epoch: 1/1 iteration: 28/128 step: 15
[2025-12-23 18:03:29,353] m-LoRA: Adapter lora_finqa_55 loss: 0.14289483428001404
[2025-12-23 18:03:29,726] m-LoRA: Adapter lora_finqa_79 loss: 0.01631307043135166
[2025-12-23 18:03:29,729] m-LoRA: Adapter lora_finqa_77 epoch: 1/1 iteration: 88/128 step: 23
[2025-12-23 18:03:30,013] m-LoRA: Adapter lora_finqa_70 loss: 0.008341033011674881
[2025-12-23 18:03:30,016] m-LoRA: Adapter lora_finqa_85 epoch: 1/1 iteration: 28/128 step: 15
[2025-12-23 18:03:30,611] m-LoRA: Adapter lora_finqa_80 loss: 0.0464961975812912
[2025-12-23 18:03:30,617] m-LoRA: Adapter lora_finqa_74 epoch: 1/1 iteration: 60/128 step: 31
[2025-12-23 18:03:31,106] m-LoRA: Adapter lora_finqa_51 loss: 8.585844625486061e-05
[2025-12-23 18:03:31,110] m-LoRA: Adapter lora_finqa_60 epoch: 1/1 iteration: 92/128 step: 47
[2025-12-23 18:03:31,467] m-LoRA: Adapter lora_finqa_42 loss: 6.0692142142215744e-05
[2025-12-23 18:03:31,471] m-LoRA: Adapter lora_finqa_46 epoch: 1/1 iteration: 124/128 step: 63
[2025-12-23 18:03:31,811] m-LoRA: Adapter lora_finqa_81 loss: 0.05510782450437546
[2025-12-23 18:03:31,814] m-LoRA: Adapter lora_finqa_47 epoch: 1/1 iteration: 124/128 step: 63
[2025-12-23 18:03:32,140] m-LoRA: Adapter lora_finqa_57 loss: 0.009716810658574104
[2025-12-23 18:03:32,144] m-LoRA: Adapter lora_finqa_61 epoch: 1/1 iteration: 92/128 step: 47
[2025-12-23 18:03:32,748] m-LoRA: Adapter lora_finqa_86 epoch: 1/1 iteration: 56/128 step: 15
[2025-12-23 18:03:32,832] m-LoRA: Adapter lora_finqa_72 loss: 1.3951815366744995
[2025-12-23 18:03:33,163] m-LoRA: Adapter lora_finqa_84 loss: 0.5393725037574768
[2025-12-23 18:03:33,167] m-LoRA: Adapter lora_finqa_48 epoch: 1/1 iteration: 124/128 step: 63
[2025-12-23 18:03:33,823] m-LoRA: Adapter lora_finqa_77 loss: 0.064365454018116
[2025-12-23 18:03:33,965] m-LoRA: Adapter lora_finqa_87 epoch: 1/1 iteration: 112/128 step: 15
[2025-12-23 18:03:34,324] m-LoRA: Adapter lora_finqa_85 loss: 0.016681615263223648
[2025-12-23 18:03:34,327] m-LoRA: Adapter lora_finqa_88 epoch: 1/1 iteration: 56/128 step: 15
[2025-12-23 18:03:34,529] m-LoRA: Adapter lora_finqa_74 loss: 0.00032465168624185026
[2025-12-23 18:03:35,015] m-LoRA: Adapter lora_finqa_60 loss: 0.00894543994218111
[2025-12-23 18:03:35,019] m-LoRA: Adapter lora_finqa_89 epoch: 1/1 iteration: 112/128 step: 15
[2025-12-23 18:03:35,229] m-LoRA: Adapter lora_finqa_55 epoch: 1/1 iteration: 108/128 step: 55
[2025-12-23 18:03:35,433] m-LoRA: Adapter lora_finqa_46 loss: 5.5599884944967926e-05
[2025-12-23 18:03:35,437] m-LoRA: Adapter lora_finqa_79 epoch: 1/1 iteration: 30/128 step: 16
[2025-12-23 18:03:35,784] m-LoRA: Adapter lora_finqa_47 loss: 3.757690137717873e-05
[2025-12-23 18:03:35,788] m-LoRA: Adapter lora_finqa_70 epoch: 1/1 iteration: 62/128 step: 32
[2025-12-23 18:03:36,110] m-LoRA: Adapter lora_finqa_61 loss: 0.00011829540017060935
[2025-12-23 18:03:36,113] m-LoRA: Adapter lora_finqa_80 epoch: 1/1 iteration: 60/128 step: 16
[2025-12-23 18:03:36,288] m-LoRA: Adapter lora_finqa_51 epoch: 1/1 iteration: 110/128 step: 56
[2025-12-23 18:03:36,382] m-LoRA: Adapter lora_finqa_42 epoch: 1/1 iteration: 126/128 step: 64
[2025-12-23 18:03:36,469] m-LoRA: Adapter lora_finqa_81 epoch: 1/1 iteration: 30/128 step: 16
[2025-12-23 18:03:36,539] m-LoRA: Adapter lora_finqa_57 epoch: 1/1 iteration: 94/128 step: 48
[2025-12-23 18:03:36,916] m-LoRA: Adapter lora_finqa_72 epoch: 1/1 iteration: 124/128 step: 32
[2025-12-23 18:03:37,001] m-LoRA: Adapter lora_finqa_86 loss: 0.049961186945438385
[2025-12-23 18:03:37,387] m-LoRA: Adapter lora_finqa_48 loss: 6.371211929945275e-05
[2025-12-23 18:03:37,390] m-LoRA: Adapter lora_finqa_84 epoch: 1/1 iteration: 30/128 step: 16
[2025-12-23 18:03:38,881] m-LoRA: Adapter lora_finqa_87 loss: 0.04985731095075607
[2025-12-23 18:03:38,891] m-LoRA: Adapter lora_finqa_77 epoch: 1/1 iteration: 92/128 step: 24
[2025-12-23 18:03:39,472] m-LoRA: Adapter lora_finqa_85 epoch: 1/1 iteration: 30/128 step: 16
[2025-12-23 18:03:39,529] m-LoRA: Adapter lora_finqa_88 loss: 0.01706206426024437
[2025-12-23 18:03:40,602] m-LoRA: Adapter lora_finqa_74 epoch: 1/1 iteration: 62/128 step: 32
[2025-12-23 18:03:40,710] m-LoRA: Adapter lora_finqa_89 loss: 0.5270934104919434
[2025-12-23 18:03:40,988] m-LoRA: Adapter lora_finqa_55 loss: 0.1258011758327484
[2025-12-23 18:03:40,991] m-LoRA: Adapter lora_finqa_60 epoch: 1/1 iteration: 94/128 step: 48
[2025-12-23 18:03:41,212] m-LoRA: Adapter lora_finqa_79 loss: 0.01359377708286047
[2025-12-23 18:03:41,216] m-LoRA: Adapter lora_finqa_46 epoch: 1/1 iteration: 126/128 step: 64
[2025-12-23 18:03:41,584] m-LoRA: Adapter lora_finqa_70 loss: 0.006195510737597942
[2025-12-23 18:03:41,587] m-LoRA: Adapter lora_finqa_47 epoch: 1/1 iteration: 126/128 step: 64
[2025-12-23 18:03:42,274] m-LoRA: Adapter lora_finqa_61 epoch: 1/1 iteration: 94/128 step: 48
[2025-12-23 18:03:42,331] m-LoRA: Adapter lora_finqa_80 loss: 0.035511668771505356
[2025-12-23 18:03:42,601] m-LoRA: Adapter lora_finqa_51 loss: 6.98444782756269e-05
[2025-12-23 18:03:42,605] m-LoRA: Adapter lora_finqa_86 epoch: 1/1 iteration: 60/128 step: 16
[2025-12-23 18:03:42,883] m-LoRA: Adapter lora_finqa_42 loss: 5.4508975154021755e-05
[2025-12-23 18:03:42,886] m-LoRA: Adapter lora_finqa_48 epoch: 1/1 iteration: 126/128 step: 64
[2025-12-23 18:03:43,268] m-LoRA: Adapter lora_finqa_81 loss: 0.04017684981226921
[2025-12-23 18:03:43,272] m-LoRA: Adapter lora_finqa_87 epoch: 1/1 iteration: 120/128 step: 16
[2025-12-23 18:03:43,667] m-LoRA: Adapter lora_finqa_57 loss: 0.0093791913241148
[2025-12-23 18:03:43,670] m-LoRA: Adapter lora_finqa_88 epoch: 1/1 iteration: 60/128 step: 16
[2025-12-23 18:03:44,399] m-LoRA: Adapter lora_finqa_72 loss: 1.3154047727584839
[2025-12-23 18:03:44,589] m-LoRA: Adapter lora_finqa_89 epoch: 1/1 iteration: 120/128 step: 16
[2025-12-23 18:03:44,843] m-LoRA: Adapter lora_finqa_84 loss: 0.4296187460422516
[2025-12-23 18:03:44,846] m-LoRA: Adapter lora_finqa_55 epoch: 1/1 iteration: 110/128 step: 56
[2025-12-23 18:03:45,506] m-LoRA: Adapter lora_finqa_77 loss: 0.0530317947268486
[2025-12-23 18:03:45,511] m-LoRA: Adapter lora_finqa_79 epoch: 1/1 iteration: 32/128 step: 17
[2025-12-23 18:03:45,864] m-LoRA: Adapter lora_finqa_85 loss: 0.01406303234398365
[2025-12-23 18:03:45,867] m-LoRA: Adapter lora_finqa_70 epoch: 1/1 iteration: 64/128 step: 33
[2025-12-23 18:03:46,194] m-LoRA: Adapter lora_finqa_74 loss: 0.00027112106909044087
[2025-12-23 18:03:46,197] m-LoRA: Adapter lora_finqa_80 epoch: 1/1 iteration: 64/128 step: 17
[2025-12-23 18:03:46,500] m-LoRA: Adapter lora_finqa_60 loss: 0.00899495743215084
[2025-12-23 18:03:46,504] m-LoRA: Adapter lora_finqa_51 epoch: 1/1 iteration: 112/128 step: 57
[2025-12-23 18:03:46,825] m-LoRA: Finish and base model offload adapter - ['lora_finqa_42']
[2025-12-23 18:03:47,567] m-LoRA: Adapter lora_finqa_46 loss: 5.4829455621074885e-05
[2025-12-23 18:03:47,713] m-LoRA: Adapter lora_finqa_47 loss: 4.043714579893276e-05
[2025-12-23 18:03:47,716] m-LoRA: Adapter lora_finqa_81 epoch: 1/1 iteration: 32/128 step: 17
[2025-12-23 18:03:47,869] m-LoRA: Adapter lora_finqa_61 loss: 0.0001234610244864598
[2025-12-23 18:03:47,872] m-LoRA: Adapter lora_finqa_57 epoch: 1/1 iteration: 96/128 step: 49
[2025-12-23 18:03:48,301] m-LoRA: Finish and base model offload adapter - ['lora_finqa_72']
[2025-12-23 18:03:48,665] m-LoRA: Adapter lora_finqa_86 loss: 0.037706781178712845
[2025-12-23 18:03:48,863] m-LoRA: Adapter lora_finqa_48 loss: 6.0486516304081306e-05
[2025-12-23 18:03:48,866] m-LoRA: Adapter lora_finqa_84 epoch: 1/1 iteration: 32/128 step: 17
[2025-12-23 18:03:50,210] m-LoRA: Adapter lora_finqa_87 loss: 0.03680524230003357
[2025-12-23 18:03:50,220] m-LoRA: Adapter lora_finqa_77 epoch: 1/1 iteration: 96/128 step: 25
[2025-12-23 18:03:50,766] m-LoRA: Adapter lora_finqa_88 loss: 0.014195455238223076
[2025-12-23 18:03:50,771] m-LoRA: Adapter lora_finqa_85 epoch: 1/1 iteration: 32/128 step: 17
[2025-12-23 18:03:53,300] m-LoRA: Adapter lora_finqa_89 loss: 0.4148280620574951
[2025-12-23 18:03:53,311] m-LoRA: Adapter lora_finqa_74 epoch: 1/1 iteration: 64/128 step: 33
[2025-12-23 18:03:53,722] m-LoRA: Adapter lora_finqa_55 loss: 0.1114128902554512
[2025-12-23 18:03:53,725] m-LoRA: Adapter lora_finqa_60 epoch: 1/1 iteration: 96/128 step: 49
[2025-12-23 18:03:54,078] m-LoRA: Finish and base model offload adapter - ['lora_finqa_46']
[2025-12-23 18:03:54,376] m-LoRA: Adapter lora_finqa_79 loss: 0.012005542404949665
[2025-12-23 18:03:54,470] m-LoRA: Finish and base model offload adapter - ['lora_finqa_47']
[2025-12-23 18:03:55,045] m-LoRA: Adapter lora_finqa_70 loss: 0.005100128706544638
[2025-12-23 18:03:55,210] m-LoRA: Adapter lora_finqa_80 loss: 0.02933819591999054
[2025-12-23 18:03:55,215] m-LoRA: Adapter lora_finqa_61 epoch: 1/1 iteration: 96/128 step: 49
[2025-12-23 18:03:55,474] m-LoRA: Adapter lora_finqa_51 loss: 7.319961878238246e-05
[2025-12-23 18:03:55,477] m-LoRA: Adapter lora_finqa_86 epoch: 1/1 iteration: 64/128 step: 17
[2025-12-23 18:03:55,795] m-LoRA: Finish and base model offload adapter - ['lora_finqa_48']
[2025-12-23 18:03:56,240] m-LoRA: Adapter lora_finqa_81 loss: 0.032874200493097305
[2025-12-23 18:03:56,429] m-LoRA: Adapter lora_finqa_57 loss: 0.009402989409863949
[2025-12-23 18:03:56,555] m-LoRA: Finish and base model offload adapter - ['lora_finqa_87']
[2025-12-23 18:03:57,140] m-LoRA: Adapter lora_finqa_84 loss: 0.3405549228191376
[2025-12-23 18:03:57,143] m-LoRA: Adapter lora_finqa_88 epoch: 1/1 iteration: 64/128 step: 17
[2025-12-23 18:03:57,690] m-LoRA: Adapter lora_finqa_77 loss: 0.04461066797375679
[2025-12-23 18:03:57,829] m-LoRA: Finish and base model offload adapter - ['lora_finqa_89']
[2025-12-23 18:03:58,417] m-LoRA: Adapter lora_finqa_85 loss: 0.012242406606674194
[2025-12-23 18:03:58,420] m-LoRA: Adapter lora_finqa_55 epoch: 1/1 iteration: 112/128 step: 57
[2025-12-23 18:03:58,723] m-LoRA: Adapter lora_finqa_74 loss: 0.00020123261492699385
[2025-12-23 18:03:58,726] m-LoRA: Adapter lora_finqa_79 epoch: 1/1 iteration: 34/128 step: 18
[2025-12-23 18:03:59,335] m-LoRA: Adapter lora_finqa_60 loss: 0.007888677529990673
[2025-12-23 18:03:59,338] m-LoRA: Adapter lora_finqa_70 epoch: 1/1 iteration: 66/128 step: 34
[2025-12-23 18:03:59,976] m-LoRA: Adapter lora_finqa_80 epoch: 1/1 iteration: 68/128 step: 18
[2025-12-23 18:04:00,054] m-LoRA: Adapter lora_finqa_61 loss: 0.00010096249752677977
[2025-12-23 18:04:00,565] m-LoRA: Adapter lora_finqa_86 loss: 0.031122976914048195
[2025-12-23 18:04:00,571] m-LoRA: Adapter lora_finqa_51 epoch: 1/1 iteration: 114/128 step: 58
[2025-12-23 18:04:01,253] m-LoRA: Adapter lora_finqa_81 epoch: 1/1 iteration: 34/128 step: 18
[2025-12-23 18:04:01,310] m-LoRA: Adapter lora_finqa_88 loss: 0.01277910452336073
[2025-12-23 18:04:01,617] m-LoRA: Adapter lora_finqa_55 loss: 0.09940506517887115
[2025-12-23 18:04:01,620] m-LoRA: Adapter lora_finqa_57 epoch: 1/1 iteration: 98/128 step: 50
[2025-12-23 18:04:01,912] m-LoRA: Adapter lora_finqa_79 loss: 0.01073093619197607
[2025-12-23 18:04:01,915] m-LoRA: Adapter lora_finqa_84 epoch: 1/1 iteration: 34/128 step: 18
[2025-12-23 18:04:02,269] m-LoRA: Adapter lora_finqa_70 loss: 0.004284851253032684
[2025-12-23 18:04:02,273] m-LoRA: Adapter lora_finqa_77 epoch: 1/1 iteration: 100/128 step: 26
[2025-12-23 18:04:02,939] m-LoRA: Adapter lora_finqa_85 epoch: 1/1 iteration: 34/128 step: 18
[2025-12-23 18:04:02,999] m-LoRA: Adapter lora_finqa_80 loss: 0.024116676300764084
[2025-12-23 18:04:03,351] m-LoRA: Adapter lora_finqa_51 loss: 7.936868496472016e-05
[2025-12-23 18:04:03,354] m-LoRA: Adapter lora_finqa_74 epoch: 1/1 iteration: 66/128 step: 34
[2025-12-23 18:04:03,690] m-LoRA: Adapter lora_finqa_81 loss: 0.026835864409804344
[2025-12-23 18:04:03,693] m-LoRA: Adapter lora_finqa_60 epoch: 1/1 iteration: 98/128 step: 50
[2025-12-23 18:04:04,035] m-LoRA: Adapter lora_finqa_57 loss: 0.008362334221601486
[2025-12-23 18:04:04,039] m-LoRA: Adapter lora_finqa_61 epoch: 1/1 iteration: 98/128 step: 50
[2025-12-23 18:04:04,387] m-LoRA: Adapter lora_finqa_84 loss: 0.269973486661911
[2025-12-23 18:04:04,391] m-LoRA: Adapter lora_finqa_86 epoch: 1/1 iteration: 68/128 step: 18
[2025-12-23 18:04:04,997] m-LoRA: Adapter lora_finqa_88 epoch: 1/1 iteration: 68/128 step: 18
[2025-12-23 18:04:05,083] m-LoRA: Adapter lora_finqa_77 loss: 0.038729630410671234
[2025-12-23 18:04:05,354] m-LoRA: Adapter lora_finqa_85 loss: 0.011325682513415813
[2025-12-23 18:04:05,358] m-LoRA: Adapter lora_finqa_55 epoch: 1/1 iteration: 114/128 step: 58
[2025-12-23 18:04:05,630] m-LoRA: Adapter lora_finqa_74 loss: 0.00026692505343817174
[2025-12-23 18:04:05,633] m-LoRA: Adapter lora_finqa_79 epoch: 1/1 iteration: 36/128 step: 19
[2025-12-23 18:04:06,004] m-LoRA: Adapter lora_finqa_60 loss: 0.007514569908380508
[2025-12-23 18:04:06,008] m-LoRA: Adapter lora_finqa_70 epoch: 1/1 iteration: 68/128 step: 35
[2025-12-23 18:04:06,373] m-LoRA: Adapter lora_finqa_80 epoch: 1/1 iteration: 72/128 step: 19
[2025-12-23 18:04:06,451] m-LoRA: Adapter lora_finqa_61 loss: 9.355320798931643e-05
[2025-12-23 18:04:06,972] m-LoRA: Adapter lora_finqa_51 epoch: 1/1 iteration: 116/128 step: 59
[2025-12-23 18:04:07,021] m-LoRA: Adapter lora_finqa_86 loss: 0.026176664978265762
[2025-12-23 18:04:07,687] m-LoRA: Adapter lora_finqa_88 loss: 0.01149615366011858
[2025-12-23 18:04:07,692] m-LoRA: Adapter lora_finqa_81 epoch: 1/1 iteration: 36/128 step: 19
[2025-12-23 18:04:07,973] m-LoRA: Adapter lora_finqa_57 epoch: 1/1 iteration: 100/128 step: 51
[2025-12-23 18:04:08,027] m-LoRA: Adapter lora_finqa_55 loss: 0.0912589281797409
[2025-12-23 18:04:08,343] m-LoRA: Adapter lora_finqa_79 loss: 0.010179809294641018
[2025-12-23 18:04:08,347] m-LoRA: Adapter lora_finqa_84 epoch: 1/1 iteration: 36/128 step: 19
[2025-12-23 18:04:08,712] m-LoRA: Adapter lora_finqa_70 loss: 0.004288166761398315
[2025-12-23 18:04:08,716] m-LoRA: Adapter lora_finqa_77 epoch: 1/1 iteration: 104/128 step: 27
[2025-12-23 18:04:09,359] m-LoRA: Adapter lora_finqa_80 loss: 0.02003207430243492
[2025-12-23 18:04:09,365] m-LoRA: Adapter lora_finqa_85 epoch: 1/1 iteration: 36/128 step: 19
[2025-12-23 18:04:09,755] m-LoRA: Adapter lora_finqa_51 loss: 6.840985588496551e-05
[2025-12-23 18:04:09,758] m-LoRA: Adapter lora_finqa_74 epoch: 1/1 iteration: 68/128 step: 35
[2025-12-23 18:04:10,041] m-LoRA: Adapter lora_finqa_81 loss: 0.02142811380326748
[2025-12-23 18:04:10,045] m-LoRA: Adapter lora_finqa_60 epoch: 1/1 iteration: 100/128 step: 51
[2025-12-23 18:04:10,366] m-LoRA: Adapter lora_finqa_61 epoch: 1/1 iteration: 100/128 step: 51
[2025-12-23 18:04:10,423] m-LoRA: Adapter lora_finqa_57 loss: 0.00849888939410448
[2025-12-23 18:04:10,695] m-LoRA: Adapter lora_finqa_84 loss: 0.21369537711143494
[2025-12-23 18:04:10,767] m-LoRA: Adapter lora_finqa_86 epoch: 1/1 iteration: 72/128 step: 19
[2025-12-23 18:04:11,357] m-LoRA: Adapter lora_finqa_88 epoch: 1/1 iteration: 72/128 step: 19
[2025-12-23 18:04:11,441] m-LoRA: Adapter lora_finqa_77 loss: 0.035053860396146774
[2025-12-23 18:04:11,710] m-LoRA: Adapter lora_finqa_55 epoch: 1/1 iteration: 116/128 step: 59
[2025-12-23 18:04:11,765] m-LoRA: Adapter lora_finqa_85 loss: 0.010096181184053421
[2025-12-23 18:04:12,063] m-LoRA: Adapter lora_finqa_74 loss: 0.0001739980943966657
[2025-12-23 18:04:12,067] m-LoRA: Adapter lora_finqa_79 epoch: 1/1 iteration: 38/128 step: 20
[2025-12-23 18:04:12,348] m-LoRA: Adapter lora_finqa_60 loss: 0.007957891561090946
[2025-12-23 18:04:12,351] m-LoRA: Adapter lora_finqa_70 epoch: 1/1 iteration: 70/128 step: 36
[2025-12-23 18:04:12,844] m-LoRA: Adapter lora_finqa_61 loss: 8.759841148275882e-05
[2025-12-23 18:04:12,848] m-LoRA: Adapter lora_finqa_80 epoch: 1/1 iteration: 76/128 step: 20
[2025-12-23 18:04:13,610] m-LoRA: Adapter lora_finqa_86 loss: 0.02150939404964447
[2025-12-23 18:04:13,616] m-LoRA: Adapter lora_finqa_51 epoch: 1/1 iteration: 118/128 step: 60
[2025-12-23 18:04:13,945] m-LoRA: Adapter lora_finqa_81 epoch: 1/1 iteration: 38/128 step: 20
[2025-12-23 18:04:14,002] m-LoRA: Adapter lora_finqa_88 loss: 0.010442241095006466
[2025-12-23 18:04:14,355] m-LoRA: Adapter lora_finqa_55 loss: 0.08449527621269226
[2025-12-23 18:04:14,358] m-LoRA: Adapter lora_finqa_57 epoch: 1/1 iteration: 102/128 step: 52
[2025-12-23 18:04:14,655] m-LoRA: Adapter lora_finqa_79 loss: 0.008495607413351536
[2025-12-23 18:04:14,659] m-LoRA: Adapter lora_finqa_84 epoch: 1/1 iteration: 38/128 step: 20
[2025-12-23 18:04:15,021] m-LoRA: Adapter lora_finqa_70 loss: 0.002800464630126953
[2025-12-23 18:04:15,025] m-LoRA: Adapter lora_finqa_77 epoch: 1/1 iteration: 108/128 step: 28
[2025-12-23 18:04:15,723] m-LoRA: Adapter lora_finqa_80 loss: 0.017173806205391884
[2025-12-23 18:04:15,729] m-LoRA: Adapter lora_finqa_85 epoch: 1/1 iteration: 38/128 step: 20
[2025-12-23 18:04:16,072] m-LoRA: Adapter lora_finqa_51 loss: 6.415058305719867e-05
[2025-12-23 18:04:16,075] m-LoRA: Adapter lora_finqa_74 epoch: 1/1 iteration: 70/128 step: 36
[2025-12-23 18:04:16,391] m-LoRA: Adapter lora_finqa_81 loss: 0.017816130071878433
[2025-12-23 18:04:16,394] m-LoRA: Adapter lora_finqa_60 epoch: 1/1 iteration: 102/128 step: 52
[2025-12-23 18:04:16,700] m-LoRA: Adapter lora_finqa_61 epoch: 1/1 iteration: 102/128 step: 52
[2025-12-23 18:04:16,753] m-LoRA: Adapter lora_finqa_57 loss: 0.007450931239873171
[2025-12-23 18:04:17,094] m-LoRA: Adapter lora_finqa_84 loss: 0.16480286419391632
[2025-12-23 18:04:17,098] m-LoRA: Adapter lora_finqa_86 epoch: 1/1 iteration: 76/128 step: 20
[2025-12-23 18:04:17,758] m-LoRA: Adapter lora_finqa_88 epoch: 1/1 iteration: 76/128 step: 20
[2025-12-23 18:04:17,842] m-LoRA: Adapter lora_finqa_77 loss: 0.03191161900758743
[2025-12-23 18:04:18,164] m-LoRA: Adapter lora_finqa_85 loss: 0.00904699508100748
[2025-12-23 18:04:18,167] m-LoRA: Adapter lora_finqa_55 epoch: 1/1 iteration: 118/128 step: 60
[2025-12-23 18:04:18,562] m-LoRA: Adapter lora_finqa_79 epoch: 1/1 iteration: 40/128 step: 21
[2025-12-23 18:04:18,620] m-LoRA: Adapter lora_finqa_74 loss: 0.0001400655892211944
[2025-12-23 18:04:18,898] m-LoRA: Adapter lora_finqa_60 loss: 0.00694610457867384
[2025-12-23 18:04:18,901] m-LoRA: Adapter lora_finqa_70 epoch: 1/1 iteration: 72/128 step: 37
[2025-12-23 18:04:19,198] m-LoRA: Adapter lora_finqa_61 loss: 8.384802640648559e-05
[2025-12-23 18:04:19,201] m-LoRA: Adapter lora_finqa_80 epoch: 1/1 iteration: 80/128 step: 21
[2025-12-23 18:04:19,884] m-LoRA: Adapter lora_finqa_51 epoch: 1/1 iteration: 120/128 step: 61
[2025-12-23 18:04:19,943] m-LoRA: Adapter lora_finqa_86 loss: 0.018222380429506302
[2025-12-23 18:04:20,528] m-LoRA: Adapter lora_finqa_81 epoch: 1/1 iteration: 40/128 step: 21
[2025-12-23 18:04:20,584] m-LoRA: Adapter lora_finqa_88 loss: 0.009074906818568707
[2025-12-23 18:04:20,844] m-LoRA: Adapter lora_finqa_55 loss: 0.07889766991138458
[2025-12-23 18:04:20,847] m-LoRA: Adapter lora_finqa_57 epoch: 1/1 iteration: 104/128 step: 53
[2025-12-23 18:04:21,159] m-LoRA: Adapter lora_finqa_84 epoch: 1/1 iteration: 40/128 step: 21
[2025-12-23 18:04:21,213] m-LoRA: Adapter lora_finqa_79 loss: 0.008015022613108158
[2025-12-23 18:04:21,474] m-LoRA: Adapter lora_finqa_70 loss: 0.0017533391946926713
[2025-12-23 18:04:21,477] m-LoRA: Adapter lora_finqa_77 epoch: 1/1 iteration: 112/128 step: 29
[2025-12-23 18:04:22,090] m-LoRA: Adapter lora_finqa_85 epoch: 1/1 iteration: 40/128 step: 21
[2025-12-23 18:04:22,146] m-LoRA: Adapter lora_finqa_80 loss: 0.015156729146838188
[2025-12-23 18:04:22,422] m-LoRA: Adapter lora_finqa_74 epoch: 1/1 iteration: 72/128 step: 37
[2025-12-23 18:04:22,476] m-LoRA: Adapter lora_finqa_51 loss: 5.861163299414329e-05
[2025-12-23 18:04:22,809] m-LoRA: Adapter lora_finqa_81 loss: 0.015542576089501381
[2025-12-23 18:04:22,813] m-LoRA: Adapter lora_finqa_60 epoch: 1/1 iteration: 104/128 step: 53
[2025-12-23 18:04:23,093] m-LoRA: Adapter lora_finqa_57 loss: 0.006881979759782553
[2025-12-23 18:04:23,097] m-LoRA: Adapter lora_finqa_61 epoch: 1/1 iteration: 104/128 step: 53
[2025-12-23 18:04:23,517] m-LoRA: Adapter lora_finqa_84 loss: 0.11655701696872711
[2025-12-23 18:04:23,520] m-LoRA: Adapter lora_finqa_86 epoch: 1/1 iteration: 80/128 step: 21
[2025-12-23 18:04:24,156] m-LoRA: Adapter lora_finqa_77 loss: 0.02923681028187275
[2025-12-23 18:04:24,162] m-LoRA: Adapter lora_finqa_88 epoch: 1/1 iteration: 80/128 step: 21
[2025-12-23 18:04:24,437] m-LoRA: Adapter lora_finqa_55 epoch: 1/1 iteration: 120/128 step: 61
[2025-12-23 18:04:24,492] m-LoRA: Adapter lora_finqa_85 loss: 0.008508003316819668
[2025-12-23 18:04:24,810] m-LoRA: Adapter lora_finqa_74 loss: 0.00012675330799538642
[2025-12-23 18:04:24,814] m-LoRA: Adapter lora_finqa_79 epoch: 1/1 iteration: 42/128 step: 22
[2025-12-23 18:04:25,108] m-LoRA: Adapter lora_finqa_60 loss: 0.00628080777823925
[2025-12-23 18:04:25,158] m-LoRA: Adapter lora_finqa_70 epoch: 1/1 iteration: 74/128 step: 38
[2025-12-23 18:04:25,468] m-LoRA: Adapter lora_finqa_61 loss: 8.0573619925417e-05
[2025-12-23 18:04:25,471] m-LoRA: Adapter lora_finqa_80 epoch: 1/1 iteration: 84/128 step: 22
[2025-12-23 18:04:26,043] m-LoRA: Adapter lora_finqa_51 epoch: 1/1 iteration: 122/128 step: 62
[2025-12-23 18:04:26,084] m-LoRA: Adapter lora_finqa_86 loss: 0.01595538668334484
[2025-12-23 18:04:26,653] m-LoRA: Adapter lora_finqa_81 epoch: 1/1 iteration: 42/128 step: 22
[2025-12-23 18:04:26,701] m-LoRA: Adapter lora_finqa_88 loss: 0.008003908209502697
[2025-12-23 18:04:26,972] m-LoRA: Adapter lora_finqa_55 loss: 0.0734575167298317
[2025-12-23 18:04:26,975] m-LoRA: Adapter lora_finqa_57 epoch: 1/1 iteration: 106/128 step: 54
[2025-12-23 18:04:27,256] m-LoRA: Adapter lora_finqa_84 epoch: 1/1 iteration: 42/128 step: 22
[2025-12-23 18:04:27,305] m-LoRA: Adapter lora_finqa_79 loss: 0.007357100956141949
[2025-12-23 18:04:27,590] m-LoRA: Adapter lora_finqa_70 loss: 0.0012965990463271737
[2025-12-23 18:04:27,594] m-LoRA: Adapter lora_finqa_77 epoch: 1/1 iteration: 116/128 step: 30
[2025-12-23 18:04:28,173] m-LoRA: Adapter lora_finqa_85 epoch: 1/1 iteration: 42/128 step: 22
[2025-12-23 18:04:28,230] m-LoRA: Adapter lora_finqa_80 loss: 0.014081374742090702
[2025-12-23 18:04:28,499] m-LoRA: Adapter lora_finqa_51 loss: 5.80477571929805e-05
[2025-12-23 18:04:28,569] m-LoRA: Adapter lora_finqa_74 epoch: 1/1 iteration: 74/128 step: 38
[2025-12-23 18:04:28,844] m-LoRA: Adapter lora_finqa_60 epoch: 1/1 iteration: 106/128 step: 54
[2025-12-23 18:04:28,897] m-LoRA: Adapter lora_finqa_81 loss: 0.013948517851531506
[2025-12-23 18:04:29,192] m-LoRA: Adapter lora_finqa_57 loss: 0.006325951311737299
[2025-12-23 18:04:29,195] m-LoRA: Adapter lora_finqa_61 epoch: 1/1 iteration: 106/128 step: 54
[2025-12-23 18:04:29,532] m-LoRA: Adapter lora_finqa_84 loss: 0.0845300629734993
[2025-12-23 18:04:29,536] m-LoRA: Adapter lora_finqa_86 epoch: 1/1 iteration: 84/128 step: 22
[2025-12-23 18:04:30,122] m-LoRA: Adapter lora_finqa_88 epoch: 1/1 iteration: 84/128 step: 22
[2025-12-23 18:04:30,204] m-LoRA: Adapter lora_finqa_77 loss: 0.026830829679965973
[2025-12-23 18:04:30,467] m-LoRA: Adapter lora_finqa_85 loss: 0.006533406209200621
[2025-12-23 18:04:30,470] m-LoRA: Adapter lora_finqa_55 epoch: 1/1 iteration: 122/128 step: 62
[2025-12-23 18:04:30,767] m-LoRA: Adapter lora_finqa_79 epoch: 1/1 iteration: 44/128 step: 23
[2025-12-23 18:04:30,800] m-LoRA: Adapter lora_finqa_74 loss: 0.00012329156743362546
[2025-12-23 18:04:31,085] m-LoRA: Adapter lora_finqa_60 loss: 0.005251405760645866
[2025-12-23 18:04:31,088] m-LoRA: Adapter lora_finqa_70 epoch: 1/1 iteration: 76/128 step: 39
[2025-12-23 18:04:31,404] m-LoRA: Adapter lora_finqa_80 epoch: 1/1 iteration: 88/128 step: 23
[2025-12-23 18:04:31,496] m-LoRA: Adapter lora_finqa_61 loss: 7.629538595210761e-05
[2025-12-23 18:04:32,009] m-LoRA: Adapter lora_finqa_51 epoch: 1/1 iteration: 124/128 step: 63
[2025-12-23 18:04:32,054] m-LoRA: Adapter lora_finqa_86 loss: 0.014541215263307095
[2025-12-23 18:04:32,630] m-LoRA: Adapter lora_finqa_81 epoch: 1/1 iteration: 44/128 step: 23
[2025-12-23 18:04:32,665] m-LoRA: Adapter lora_finqa_88 loss: 0.006517515052109957
[2025-12-23 18:04:32,922] m-LoRA: Adapter lora_finqa_55 loss: 0.06828619539737701
[2025-12-23 18:04:32,926] m-LoRA: Adapter lora_finqa_57 epoch: 1/1 iteration: 108/128 step: 55
[2025-12-23 18:04:33,245] m-LoRA: Adapter lora_finqa_79 loss: 0.006189823150634766
[2025-12-23 18:04:33,248] m-LoRA: Adapter lora_finqa_84 epoch: 1/1 iteration: 44/128 step: 23
[2025-12-23 18:04:33,526] m-LoRA: Adapter lora_finqa_77 epoch: 1/1 iteration: 120/128 step: 31
[2025-12-23 18:04:33,595] m-LoRA: Adapter lora_finqa_70 loss: 0.0008852242026478052
[2025-12-23 18:04:34,229] m-LoRA: Adapter lora_finqa_85 epoch: 1/1 iteration: 44/128 step: 23
[2025-12-23 18:04:34,290] m-LoRA: Adapter lora_finqa_80 loss: 0.013626386411488056
[2025-12-23 18:04:34,603] m-LoRA: Adapter lora_finqa_51 loss: 6.01315769017674e-05
[2025-12-23 18:04:34,607] m-LoRA: Adapter lora_finqa_74 epoch: 1/1 iteration: 76/128 step: 39
[2025-12-23 18:04:34,920] m-LoRA: Adapter lora_finqa_81 loss: 0.01328240055590868
[2025-12-23 18:04:34,923] m-LoRA: Adapter lora_finqa_60 epoch: 1/1 iteration: 108/128 step: 55
[2025-12-23 18:04:35,191] m-LoRA: Adapter lora_finqa_57 loss: 0.006085721775889397
[2025-12-23 18:04:35,194] m-LoRA: Adapter lora_finqa_61 epoch: 1/1 iteration: 108/128 step: 55
[2025-12-23 18:04:35,506] m-LoRA: Adapter lora_finqa_84 loss: 0.06535216420888901
[2025-12-23 18:04:35,510] m-LoRA: Adapter lora_finqa_86 epoch: 1/1 iteration: 88/128 step: 23
[2025-12-23 18:04:36,144] m-LoRA: Adapter lora_finqa_88 epoch: 1/1 iteration: 88/128 step: 23
[2025-12-23 18:04:36,232] m-LoRA: Adapter lora_finqa_77 loss: 0.024196702986955643
[2025-12-23 18:04:36,569] m-LoRA: Adapter lora_finqa_85 loss: 0.005040892865508795
[2025-12-23 18:04:36,573] m-LoRA: Adapter lora_finqa_55 epoch: 1/1 iteration: 124/128 step: 63
[2025-12-23 18:04:36,939] m-LoRA: Adapter lora_finqa_74 loss: 0.00010719776764744893
[2025-12-23 18:04:36,942] m-LoRA: Adapter lora_finqa_79 epoch: 1/1 iteration: 46/128 step: 24
[2025-12-23 18:04:37,251] m-LoRA: Adapter lora_finqa_60 loss: 0.0074996668845415115
[2025-12-23 18:04:37,255] m-LoRA: Adapter lora_finqa_70 epoch: 1/1 iteration: 78/128 step: 40
[2025-12-23 18:04:37,582] m-LoRA: Adapter lora_finqa_61 loss: 8.075812365859747e-05
[2025-12-23 18:04:37,585] m-LoRA: Adapter lora_finqa_80 epoch: 1/1 iteration: 92/128 step: 24
[2025-12-23 18:04:38,221] m-LoRA: Adapter lora_finqa_51 epoch: 1/1 iteration: 126/128 step: 64
[2025-12-23 18:04:38,279] m-LoRA: Adapter lora_finqa_86 loss: 0.013835015706717968
[2025-12-23 18:04:39,139] m-LoRA: Adapter lora_finqa_88 loss: 0.005217433907091618
[2025-12-23 18:04:39,145] m-LoRA: Adapter lora_finqa_81 epoch: 1/1 iteration: 46/128 step: 24
[2025-12-23 18:04:39,584] m-LoRA: Adapter lora_finqa_55 loss: 0.063626728951931
[2025-12-23 18:04:39,587] m-LoRA: Adapter lora_finqa_57 epoch: 1/1 iteration: 110/128 step: 56
[2025-12-23 18:04:39,964] m-LoRA: Adapter lora_finqa_79 loss: 0.0046288189478218555
[2025-12-23 18:04:39,968] m-LoRA: Adapter lora_finqa_84 epoch: 1/1 iteration: 46/128 step: 24
[2025-12-23 18:04:40,688] m-LoRA: Adapter lora_finqa_70 loss: 0.0005988958291709423
[2025-12-23 18:04:40,805] m-LoRA: Adapter lora_finqa_77 epoch: 1/1 iteration: 124/128 step: 32
[2025-12-23 18:04:41,319] m-LoRA: Adapter lora_finqa_85 epoch: 1/1 iteration: 46/128 step: 24
[2025-12-23 18:04:41,375] m-LoRA: Adapter lora_finqa_80 loss: 0.012183161452412605
[2025-12-23 18:04:41,658] m-LoRA: Adapter lora_finqa_51 loss: 5.697231608792208e-05
[2025-12-23 18:04:41,661] m-LoRA: Adapter lora_finqa_74 epoch: 1/1 iteration: 78/128 step: 40
[2025-12-23 18:04:42,057] m-LoRA: Adapter lora_finqa_81 loss: 0.013115494512021542
[2025-12-23 18:04:42,060] m-LoRA: Adapter lora_finqa_60 epoch: 1/1 iteration: 110/128 step: 56
[2025-12-23 18:04:42,375] m-LoRA: Adapter lora_finqa_61 epoch: 1/1 iteration: 110/128 step: 56
[2025-12-23 18:04:42,427] m-LoRA: Adapter lora_finqa_57 loss: 0.006674719043076038
[2025-12-23 18:04:43,115] m-LoRA: Adapter lora_finqa_84 loss: 0.053304266184568405
[2025-12-23 18:04:43,118] m-LoRA: Adapter lora_finqa_86 epoch: 1/1 iteration: 92/128 step: 24
[2025-12-23 18:04:43,654] m-LoRA: Adapter lora_finqa_88 epoch: 1/1 iteration: 92/128 step: 24
[2025-12-23 18:04:43,735] m-LoRA: Adapter lora_finqa_77 loss: 0.021652191877365112
[2025-12-23 18:04:44,063] m-LoRA: Adapter lora_finqa_55 epoch: 1/1 iteration: 126/128 step: 64
[2025-12-23 18:04:44,094] m-LoRA: Adapter lora_finqa_85 loss: 0.003963591065257788
[2025-12-23 18:04:44,399] m-LoRA: Adapter lora_finqa_74 loss: 9.969215170713142e-05
[2025-12-23 18:04:44,402] m-LoRA: Adapter lora_finqa_79 epoch: 1/1 iteration: 48/128 step: 25
[2025-12-23 18:04:44,719] m-LoRA: Adapter lora_finqa_60 loss: 0.005268910899758339
[2025-12-23 18:04:44,722] m-LoRA: Adapter lora_finqa_70 epoch: 1/1 iteration: 80/128 step: 41
[2025-12-23 18:04:45,050] m-LoRA: Adapter lora_finqa_61 loss: 7.418040331685916e-05
[2025-12-23 18:04:45,054] m-LoRA: Adapter lora_finqa_80 epoch: 1/1 iteration: 96/128 step: 25
[2025-12-23 18:04:45,683] m-LoRA: Finish and base model offload adapter - ['lora_finqa_51']
[2025-12-23 18:04:46,365] m-LoRA: Adapter lora_finqa_86 loss: 0.012848413549363613
[2025-12-23 18:04:46,516] m-LoRA: Adapter lora_finqa_88 loss: 0.0038665439933538437
[2025-12-23 18:04:46,522] m-LoRA: Adapter lora_finqa_81 epoch: 1/1 iteration: 48/128 step: 25
[2025-12-23 18:04:46,689] m-LoRA: Adapter lora_finqa_55 loss: 0.060126204043626785
[2025-12-23 18:04:46,692] m-LoRA: Adapter lora_finqa_57 epoch: 1/1 iteration: 112/128 step: 57
[2025-12-23 18:04:46,843] m-LoRA: Adapter lora_finqa_84 epoch: 1/1 iteration: 48/128 step: 25
[2025-12-23 18:04:46,876] m-LoRA: Adapter lora_finqa_79 loss: 0.0028494347352534533
[2025-12-23 18:04:47,138] m-LoRA: Finish and base model offload adapter - ['lora_finqa_77']
[2025-12-23 18:04:47,332] m-LoRA: Adapter lora_finqa_70 loss: 0.0006288056611083448
[2025-12-23 18:04:47,831] m-LoRA: Adapter lora_finqa_80 loss: 0.011553037911653519
[2025-12-23 18:04:47,837] m-LoRA: Adapter lora_finqa_85 epoch: 1/1 iteration: 48/128 step: 25
[2025-12-23 18:04:48,151] m-LoRA: Adapter lora_finqa_81 loss: 0.011345173232257366
[2025-12-23 18:04:48,154] m-LoRA: Adapter lora_finqa_74 epoch: 1/1 iteration: 80/128 step: 41
[2025-12-23 18:04:48,524] m-LoRA: Adapter lora_finqa_57 loss: 0.004900965839624405
[2025-12-23 18:04:48,528] m-LoRA: Adapter lora_finqa_60 epoch: 1/1 iteration: 112/128 step: 57
[2025-12-23 18:04:48,664] m-LoRA: Adapter lora_finqa_61 epoch: 1/1 iteration: 112/128 step: 57
[2025-12-23 18:04:48,756] m-LoRA: Adapter lora_finqa_86 epoch: 1/1 iteration: 96/128 step: 25
[2025-12-23 18:04:48,878] m-LoRA: Adapter lora_finqa_88 epoch: 1/1 iteration: 96/128 step: 25
[2025-12-23 18:04:48,994] m-LoRA: Finish and base model offload adapter - ['lora_finqa_55']
[2025-12-23 18:04:49,333] m-LoRA: Adapter lora_finqa_84 loss: 0.0452139712870121
[2025-12-23 18:04:49,493] m-LoRA: Adapter lora_finqa_85 loss: 0.0028581665828824043
[2025-12-23 18:04:49,496] m-LoRA: Adapter lora_finqa_79 epoch: 1/1 iteration: 50/128 step: 26
[2025-12-23 18:04:49,643] m-LoRA: Adapter lora_finqa_74 loss: 9.44558487390168e-05
[2025-12-23 18:04:49,646] m-LoRA: Adapter lora_finqa_70 epoch: 1/1 iteration: 82/128 step: 42
[2025-12-23 18:04:49,955] m-LoRA: Adapter lora_finqa_60 loss: 0.0043989503756165504
[2025-12-23 18:04:49,958] m-LoRA: Adapter lora_finqa_80 epoch: 1/1 iteration: 100/128 step: 26
[2025-12-23 18:04:50,235] m-LoRA: Adapter lora_finqa_61 loss: 6.698453216813505e-05
[2025-12-23 18:04:50,238] m-LoRA: Adapter lora_finqa_81 epoch: 1/1 iteration: 50/128 step: 26
[2025-12-23 18:04:50,679] m-LoRA: Adapter lora_finqa_57 epoch: 1/1 iteration: 114/128 step: 58
[2025-12-23 18:04:51,351] m-LoRA: Adapter lora_finqa_86 loss: 0.013135586865246296
[2025-12-23 18:04:51,357] m-LoRA: Adapter lora_finqa_84 epoch: 1/1 iteration: 50/128 step: 26
[2025-12-23 18:04:51,933] m-LoRA: Adapter lora_finqa_88 loss: 0.0038418322801589966
[2025-12-23 18:04:51,938] m-LoRA: Adapter lora_finqa_85 epoch: 1/1 iteration: 50/128 step: 26
[2025-12-23 18:04:52,179] m-LoRA: Adapter lora_finqa_79 loss: 0.0018356875516474247
[2025-12-23 18:04:52,182] m-LoRA: Adapter lora_finqa_74 epoch: 1/1 iteration: 82/128 step: 42
[2025-12-23 18:04:52,527] m-LoRA: Adapter lora_finqa_70 loss: 0.00036639333120547235
[2025-12-23 18:04:52,531] m-LoRA: Adapter lora_finqa_60 epoch: 1/1 iteration: 114/128 step: 58
[2025-12-23 18:04:53,171] m-LoRA: Adapter lora_finqa_80 loss: 0.010787226259708405
[2025-12-23 18:04:53,177] m-LoRA: Adapter lora_finqa_61 epoch: 1/1 iteration: 114/128 step: 58
[2025-12-23 18:04:53,459] m-LoRA: Adapter lora_finqa_81 loss: 0.010651368647813797
[2025-12-23 18:04:53,462] m-LoRA: Adapter lora_finqa_86 epoch: 1/1 iteration: 100/128 step: 26
[2025-12-23 18:04:53,790] m-LoRA: Adapter lora_finqa_57 loss: 0.004540454130619764
[2025-12-23 18:04:53,794] m-LoRA: Adapter lora_finqa_88 epoch: 1/1 iteration: 100/128 step: 26
[2025-12-23 18:04:54,054] m-LoRA: Adapter lora_finqa_84 loss: 0.039752595126628876
[2025-12-23 18:04:54,057] m-LoRA: Adapter lora_finqa_79 epoch: 1/1 iteration: 52/128 step: 27
[2025-12-23 18:04:54,419] m-LoRA: Adapter lora_finqa_85 loss: 0.0020823113154619932
[2025-12-23 18:04:54,422] m-LoRA: Adapter lora_finqa_70 epoch: 1/1 iteration: 84/128 step: 43
[2025-12-23 18:04:54,806] m-LoRA: Adapter lora_finqa_74 loss: 8.918742969399318e-05
[2025-12-23 18:04:54,810] m-LoRA: Adapter lora_finqa_80 epoch: 1/1 iteration: 104/128 step: 27
[2025-12-23 18:04:55,073] m-LoRA: Adapter lora_finqa_60 loss: 0.0030667632818222046
[2025-12-23 18:04:55,216] m-LoRA: Adapter lora_finqa_81 epoch: 1/1 iteration: 52/128 step: 27
[2025-12-23 18:04:55,444] m-LoRA: Adapter lora_finqa_61 loss: 6.915382255101576e-05
[2025-12-23 18:04:55,447] m-LoRA: Adapter lora_finqa_57 epoch: 1/1 iteration: 116/128 step: 59
[2025-12-23 18:04:56,070] m-LoRA: Adapter lora_finqa_86 loss: 0.01148981973528862
[2025-12-23 18:04:56,075] m-LoRA: Adapter lora_finqa_84 epoch: 1/1 iteration: 52/128 step: 27
[2025-12-23 18:04:56,653] m-LoRA: Adapter lora_finqa_88 loss: 0.0018450075294822454
[2025-12-23 18:04:56,658] m-LoRA: Adapter lora_finqa_85 epoch: 1/1 iteration: 52/128 step: 27
[2025-12-23 18:04:56,910] m-LoRA: Adapter lora_finqa_79 loss: 0.0013861872721463442
[2025-12-23 18:04:56,913] m-LoRA: Adapter lora_finqa_74 epoch: 1/1 iteration: 84/128 step: 43
[2025-12-23 18:04:57,324] m-LoRA: Adapter lora_finqa_70 loss: 0.002015992533415556
[2025-12-23 18:04:57,327] m-LoRA: Adapter lora_finqa_60 epoch: 1/1 iteration: 116/128 step: 59
[2025-12-23 18:04:57,943] m-LoRA: Adapter lora_finqa_80 loss: 0.010119495913386345
[2025-12-23 18:04:57,949] m-LoRA: Adapter lora_finqa_61 epoch: 1/1 iteration: 116/128 step: 59
[2025-12-23 18:04:58,268] m-LoRA: Adapter lora_finqa_81 loss: 0.00963413156569004
[2025-12-23 18:04:58,271] m-LoRA: Adapter lora_finqa_86 epoch: 1/1 iteration: 104/128 step: 27
[2025-12-23 18:04:58,599] m-LoRA: Adapter lora_finqa_57 loss: 0.003575423266738653
[2025-12-23 18:04:58,603] m-LoRA: Adapter lora_finqa_88 epoch: 1/1 iteration: 104/128 step: 27
[2025-12-23 18:04:58,894] m-LoRA: Adapter lora_finqa_84 loss: 0.03615236654877663
[2025-12-23 18:04:58,898] m-LoRA: Adapter lora_finqa_79 epoch: 1/1 iteration: 54/128 step: 28
[2025-12-23 18:04:59,432] m-LoRA: Adapter lora_finqa_85 loss: 0.0016058806795626879
[2025-12-23 18:04:59,435] m-LoRA: Adapter lora_finqa_70 epoch: 1/1 iteration: 86/128 step: 44
[2025-12-23 18:04:59,782] m-LoRA: Adapter lora_finqa_74 loss: 8.323971269419417e-05
[2025-12-23 18:04:59,785] m-LoRA: Adapter lora_finqa_80 epoch: 1/1 iteration: 108/128 step: 28
[2025-12-23 18:04:59,996] m-LoRA: Adapter lora_finqa_60 loss: 0.002659835619851947
[2025-12-23 18:04:59,999] m-LoRA: Adapter lora_finqa_81 epoch: 1/1 iteration: 54/128 step: 28
[2025-12-23 18:05:00,268] m-LoRA: Adapter lora_finqa_57 epoch: 1/1 iteration: 118/128 step: 60
[2025-12-23 18:05:00,299] m-LoRA: Adapter lora_finqa_61 loss: 7.536401972174644e-05
[2025-12-23 18:05:00,872] m-LoRA: Adapter lora_finqa_84 epoch: 1/1 iteration: 54/128 step: 28
[2025-12-23 18:05:00,926] m-LoRA: Adapter lora_finqa_86 loss: 0.011312083341181278
[2025-12-23 18:05:01,571] m-LoRA: Adapter lora_finqa_88 loss: 0.0015434914967045188
[2025-12-23 18:05:01,577] m-LoRA: Adapter lora_finqa_85 epoch: 1/1 iteration: 54/128 step: 28
[2025-12-23 18:05:01,911] m-LoRA: Adapter lora_finqa_79 loss: 0.0008031085599213839
[2025-12-23 18:05:01,915] m-LoRA: Adapter lora_finqa_74 epoch: 1/1 iteration: 86/128 step: 44
[2025-12-23 18:05:02,198] m-LoRA: Adapter lora_finqa_70 loss: 0.0002806105185300112
[2025-12-23 18:05:02,201] m-LoRA: Adapter lora_finqa_60 epoch: 1/1 iteration: 118/128 step: 60
[2025-12-23 18:05:02,807] m-LoRA: Adapter lora_finqa_61 epoch: 1/1 iteration: 118/128 step: 60
[2025-12-23 18:05:02,873] m-LoRA: Adapter lora_finqa_80 loss: 0.00918696541339159
[2025-12-23 18:05:03,198] m-LoRA: Adapter lora_finqa_86 epoch: 1/1 iteration: 108/128 step: 28
[2025-12-23 18:05:03,270] m-LoRA: Adapter lora_finqa_81 loss: 0.00884372927248478
[2025-12-23 18:05:03,564] m-LoRA: Adapter lora_finqa_57 loss: 0.003141793655231595
[2025-12-23 18:05:03,568] m-LoRA: Adapter lora_finqa_88 epoch: 1/1 iteration: 108/128 step: 28
[2025-12-23 18:05:03,829] m-LoRA: Adapter lora_finqa_84 loss: 0.03315524756908417
[2025-12-23 18:05:03,832] m-LoRA: Adapter lora_finqa_79 epoch: 1/1 iteration: 56/128 step: 29
[2025-12-23 18:05:04,203] m-LoRA: Adapter lora_finqa_85 loss: 0.0008627246133983135
[2025-12-23 18:05:04,206] m-LoRA: Adapter lora_finqa_70 epoch: 1/1 iteration: 88/128 step: 45
[2025-12-23 18:05:04,482] m-LoRA: Adapter lora_finqa_74 loss: 7.562211976619437e-05
[2025-12-23 18:05:04,858] m-LoRA: Adapter lora_finqa_60 loss: 0.0022025855723768473
[2025-12-23 18:05:04,861] m-LoRA: Adapter lora_finqa_80 epoch: 1/1 iteration: 112/128 step: 29
[2025-12-23 18:05:05,216] m-LoRA: Adapter lora_finqa_61 loss: 5.9832684200955555e-05
[2025-12-23 18:05:05,220] m-LoRA: Adapter lora_finqa_81 epoch: 1/1 iteration: 56/128 step: 29
[2025-12-23 18:05:05,810] m-LoRA: Adapter lora_finqa_57 epoch: 1/1 iteration: 120/128 step: 61
[2025-12-23 18:05:05,865] m-LoRA: Adapter lora_finqa_86 loss: 0.010051497258245945
[2025-12-23 18:05:06,365] m-LoRA: Adapter lora_finqa_84 epoch: 1/1 iteration: 56/128 step: 29
[2025-12-23 18:05:06,421] m-LoRA: Adapter lora_finqa_88 loss: 0.0008447871077805758
[2025-12-23 18:05:06,685] m-LoRA: Adapter lora_finqa_79 loss: 0.0007280026911757886
[2025-12-23 18:05:06,688] m-LoRA: Adapter lora_finqa_85 epoch: 1/1 iteration: 56/128 step: 29
[2025-12-23 18:05:06,989] m-LoRA: Adapter lora_finqa_70 loss: 0.0001755434350343421
[2025-12-23 18:05:06,992] m-LoRA: Adapter lora_finqa_74 epoch: 1/1 iteration: 88/128 step: 45
[2025-12-23 18:05:07,547] m-LoRA: Adapter lora_finqa_60 epoch: 1/1 iteration: 120/128 step: 61
[2025-12-23 18:05:07,606] m-LoRA: Adapter lora_finqa_80 loss: 0.008653581142425537
[2025-12-23 18:05:07,890] m-LoRA: Adapter lora_finqa_81 loss: 0.007970551960170269
[2025-12-23 18:05:07,893] m-LoRA: Adapter lora_finqa_61 epoch: 1/1 iteration: 120/128 step: 61
[2025-12-23 18:05:08,207] m-LoRA: Adapter lora_finqa_57 loss: 0.002893347991630435
[2025-12-23 18:05:08,211] m-LoRA: Adapter lora_finqa_86 epoch: 1/1 iteration: 112/128 step: 29
[2025-12-23 18:05:08,504] m-LoRA: Adapter lora_finqa_84 loss: 0.030754802748560905
[2025-12-23 18:05:08,507] m-LoRA: Adapter lora_finqa_88 epoch: 1/1 iteration: 112/128 step: 29
[2025-12-23 18:05:08,869] m-LoRA: Adapter lora_finqa_85 loss: 0.001036378089338541
[2025-12-23 18:05:08,873] m-LoRA: Adapter lora_finqa_79 epoch: 1/1 iteration: 58/128 step: 30
[2025-12-23 18:05:09,148] m-LoRA: Adapter lora_finqa_70 epoch: 1/1 iteration: 90/128 step: 46
[2025-12-23 18:05:09,201] m-LoRA: Adapter lora_finqa_74 loss: 7.02388133504428e-05
[2025-12-23 18:05:09,551] m-LoRA: Adapter lora_finqa_60 loss: 0.002728738822042942
[2025-12-23 18:05:09,554] m-LoRA: Adapter lora_finqa_80 epoch: 1/1 iteration: 116/128 step: 30
[2025-12-23 18:05:09,814] m-LoRA: Adapter lora_finqa_81 epoch: 1/1 iteration: 58/128 step: 30
[2025-12-23 18:05:09,868] m-LoRA: Adapter lora_finqa_61 loss: 5.8071564126294106e-05
[2025-12-23 18:05:10,425] m-LoRA: Adapter lora_finqa_57 epoch: 1/1 iteration: 122/128 step: 62
[2025-12-23 18:05:10,482] m-LoRA: Adapter lora_finqa_86 loss: 0.009505635127425194
[2025-12-23 18:05:11,025] m-LoRA: Adapter lora_finqa_84 epoch: 1/1 iteration: 58/128 step: 30
[2025-12-23 18:05:11,081] m-LoRA: Adapter lora_finqa_88 loss: 0.0006196181057021022
[2025-12-23 18:05:11,352] m-LoRA: Adapter lora_finqa_79 loss: 0.0005546394968405366
[2025-12-23 18:05:11,355] m-LoRA: Adapter lora_finqa_85 epoch: 1/1 iteration: 58/128 step: 30
[2025-12-23 18:05:11,666] m-LoRA: Adapter lora_finqa_74 epoch: 1/1 iteration: 90/128 step: 46
[2025-12-23 18:05:11,723] m-LoRA: Adapter lora_finqa_70 loss: 0.00014914113853592426
[2025-12-23 18:05:12,283] m-LoRA: Adapter lora_finqa_60 epoch: 1/1 iteration: 122/128 step: 62
[2025-12-23 18:05:12,316] m-LoRA: Adapter lora_finqa_80 loss: 0.008127552457153797
[2025-12-23 18:05:12,577] m-LoRA: Adapter lora_finqa_81 loss: 0.0076677524484694
[2025-12-23 18:05:12,580] m-LoRA: Adapter lora_finqa_61 epoch: 1/1 iteration: 122/128 step: 62
[2025-12-23 18:05:12,884] m-LoRA: Adapter lora_finqa_57 loss: 0.002688645850867033
[2025-12-23 18:05:12,888] m-LoRA: Adapter lora_finqa_86 epoch: 1/1 iteration: 116/128 step: 30
[2025-12-23 18:05:13,179] m-LoRA: Adapter lora_finqa_84 loss: 0.02743537537753582
[2025-12-23 18:05:13,183] m-LoRA: Adapter lora_finqa_88 epoch: 1/1 iteration: 116/128 step: 30
[2025-12-23 18:05:13,530] m-LoRA: Adapter lora_finqa_85 loss: 0.0004107999848201871
[2025-12-23 18:05:13,533] m-LoRA: Adapter lora_finqa_79 epoch: 1/1 iteration: 60/128 step: 31
[2025-12-23 18:05:14,209] m-LoRA: Adapter lora_finqa_74 loss: 6.750092143192887e-05
[2025-12-23 18:05:14,213] m-LoRA: Adapter lora_finqa_70 epoch: 1/1 iteration: 92/128 step: 47
[2025-12-23 18:05:14,757] m-LoRA: Adapter lora_finqa_80 epoch: 1/1 iteration: 120/128 step: 31
[2025-12-23 18:05:14,834] m-LoRA: Adapter lora_finqa_60 loss: 0.0020955128129571676
[2025-12-23 18:05:15,157] m-LoRA: Adapter lora_finqa_61 loss: 5.6251330533996224e-05
[2025-12-23 18:05:15,160] m-LoRA: Adapter lora_finqa_81 epoch: 1/1 iteration: 60/128 step: 31
[2025-12-23 18:05:15,827] m-LoRA: Adapter lora_finqa_86 loss: 0.009427419863641262
[2025-12-23 18:05:15,833] m-LoRA: Adapter lora_finqa_57 epoch: 1/1 iteration: 124/128 step: 63
[2025-12-23 18:05:16,383] m-LoRA: Adapter lora_finqa_88 loss: 0.0005824355175718665
[2025-12-23 18:05:16,388] m-LoRA: Adapter lora_finqa_84 epoch: 1/1 iteration: 60/128 step: 31
[2025-12-23 18:05:16,990] m-LoRA: Adapter lora_finqa_79 loss: 0.0003454348770901561
[2025-12-23 18:05:16,993] m-LoRA: Adapter lora_finqa_85 epoch: 1/1 iteration: 60/128 step: 31
[2025-12-23 18:05:17,631] m-LoRA: Adapter lora_finqa_74 epoch: 1/1 iteration: 92/128 step: 47
[2025-12-23 18:05:17,691] m-LoRA: Adapter lora_finqa_70 loss: 0.00012833041546400636
[2025-12-23 18:05:18,226] m-LoRA: Adapter lora_finqa_80 loss: 0.0066801076754927635
[2025-12-23 18:05:18,231] m-LoRA: Adapter lora_finqa_60 epoch: 1/1 iteration: 124/128 step: 63
[2025-12-23 18:05:18,516] m-LoRA: Adapter lora_finqa_81 loss: 0.006362872198224068
[2025-12-23 18:05:18,645] m-LoRA: Adapter lora_finqa_61 epoch: 1/1 iteration: 124/128 step: 63
[2025-12-23 18:05:18,867] m-LoRA: Adapter lora_finqa_57 loss: 0.0017613518284633756
[2025-12-23 18:05:18,871] m-LoRA: Adapter lora_finqa_86 epoch: 1/1 iteration: 120/128 step: 31
[2025-12-23 18:05:19,195] m-LoRA: Adapter lora_finqa_84 loss: 0.024948161095380783
[2025-12-23 18:05:19,198] m-LoRA: Adapter lora_finqa_88 epoch: 1/1 iteration: 120/128 step: 31
[2025-12-23 18:05:19,528] m-LoRA: Adapter lora_finqa_85 loss: 0.00030825170688331127
[2025-12-23 18:05:19,532] m-LoRA: Adapter lora_finqa_79 epoch: 1/1 iteration: 62/128 step: 32
[2025-12-23 18:05:19,813] m-LoRA: Adapter lora_finqa_74 loss: 6.800124538131058e-05
[2025-12-23 18:05:19,817] m-LoRA: Adapter lora_finqa_70 epoch: 1/1 iteration: 94/128 step: 48
[2025-12-23 18:05:20,122] m-LoRA: Adapter lora_finqa_80 epoch: 1/1 iteration: 124/128 step: 32
[2025-12-23 18:05:20,199] m-LoRA: Adapter lora_finqa_60 loss: 0.0015398012474179268
[2025-12-23 18:05:20,449] m-LoRA: Adapter lora_finqa_61 loss: 5.9012003475800157e-05
[2025-12-23 18:05:20,452] m-LoRA: Adapter lora_finqa_81 epoch: 1/1 iteration: 62/128 step: 32
[2025-12-23 18:05:21,033] m-LoRA: Adapter lora_finqa_86 loss: 0.007721335627138615
[2025-12-23 18:05:21,039] m-LoRA: Adapter lora_finqa_57 epoch: 1/1 iteration: 126/128 step: 64
[2025-12-23 18:05:21,626] m-LoRA: Adapter lora_finqa_84 epoch: 1/1 iteration: 62/128 step: 32
[2025-12-23 18:05:21,692] m-LoRA: Adapter lora_finqa_88 loss: 0.00042800657683983445
[2025-12-23 18:05:22,024] m-LoRA: Adapter lora_finqa_79 loss: 0.0006534259300678968
[2025-12-23 18:05:22,027] m-LoRA: Adapter lora_finqa_85 epoch: 1/1 iteration: 62/128 step: 32
[2025-12-23 18:05:22,291] m-LoRA: Adapter lora_finqa_70 loss: 0.00016010670515242964
[2025-12-23 18:05:22,294] m-LoRA: Adapter lora_finqa_74 epoch: 1/1 iteration: 94/128 step: 48
[2025-12-23 18:05:22,950] m-LoRA: Adapter lora_finqa_80 loss: 0.006441178731620312
[2025-12-23 18:05:22,956] m-LoRA: Adapter lora_finqa_60 epoch: 1/1 iteration: 126/128 step: 64
[2025-12-23 18:05:23,256] m-LoRA: Adapter lora_finqa_81 loss: 0.006719924043864012
[2025-12-23 18:05:23,259] m-LoRA: Adapter lora_finqa_61 epoch: 1/1 iteration: 126/128 step: 64
[2025-12-23 18:05:23,545] m-LoRA: Adapter lora_finqa_57 loss: 0.0014178643468767405
[2025-12-23 18:05:23,549] m-LoRA: Adapter lora_finqa_86 epoch: 1/1 iteration: 124/128 step: 32
[2025-12-23 18:05:23,859] m-LoRA: Adapter lora_finqa_84 loss: 0.022270044311881065
[2025-12-23 18:05:23,862] m-LoRA: Adapter lora_finqa_88 epoch: 1/1 iteration: 124/128 step: 32
[2025-12-23 18:05:24,198] m-LoRA: Adapter lora_finqa_85 loss: 0.0002566152543295175
[2025-12-23 18:05:24,202] m-LoRA: Adapter lora_finqa_79 epoch: 1/1 iteration: 64/128 step: 33
[2025-12-23 18:05:24,548] m-LoRA: Adapter lora_finqa_74 loss: 6.354337529046461e-05
[2025-12-23 18:05:24,552] m-LoRA: Adapter lora_finqa_70 epoch: 1/1 iteration: 96/128 step: 49
[2025-12-23 18:05:24,829] m-LoRA: Finish and base model offload adapter - ['lora_finqa_80']
[2025-12-23 18:05:25,195] m-LoRA: Adapter lora_finqa_60 loss: 0.0012481448939070106
[2025-12-23 18:05:25,318] m-LoRA: Adapter lora_finqa_61 loss: 5.7053643104154617e-05
[2025-12-23 18:05:25,321] m-LoRA: Adapter lora_finqa_81 epoch: 1/1 iteration: 64/128 step: 33
[2025-12-23 18:05:25,699] m-LoRA: Finish and base model offload adapter - ['lora_finqa_57']
[2025-12-23 18:05:25,921] m-LoRA: Adapter lora_finqa_86 loss: 0.007300727069377899
[2025-12-23 18:05:26,348] m-LoRA: Adapter lora_finqa_88 loss: 0.00028209463926032186
[2025-12-23 18:05:26,354] m-LoRA: Adapter lora_finqa_84 epoch: 1/1 iteration: 64/128 step: 33
[2025-12-23 18:05:26,609] m-LoRA: Adapter lora_finqa_79 loss: 0.0003087935328949243
[2025-12-23 18:05:26,612] m-LoRA: Adapter lora_finqa_85 epoch: 1/1 iteration: 64/128 step: 33
[2025-12-23 18:05:26,920] m-LoRA: Adapter lora_finqa_74 epoch: 1/1 iteration: 96/128 step: 49
[2025-12-23 18:05:26,976] m-LoRA: Adapter lora_finqa_70 loss: 0.00010627294250298291
[2025-12-23 18:05:27,246] m-LoRA: Finish and base model offload adapter - ['lora_finqa_60']
[2025-12-23 18:05:27,385] m-LoRA: Adapter lora_finqa_81 loss: 0.004360428545624018
[2025-12-23 18:05:27,532] m-LoRA: Finish and base model offload adapter - ['lora_finqa_61']
[2025-12-23 18:05:28,229] m-LoRA: Adapter lora_finqa_84 loss: 0.019727153703570366
[2025-12-23 18:05:28,407] m-LoRA: Finish and base model offload adapter - ['lora_finqa_86']
[2025-12-23 18:05:28,645] m-LoRA: Adapter lora_finqa_85 loss: 0.00021526467753574252
[2025-12-23 18:05:28,650] m-LoRA: Adapter lora_finqa_74 loss: 6.114906136645004e-05
[2025-12-23 18:05:28,908] m-LoRA: Finish and base model offload adapter - ['lora_finqa_88']
[2025-12-23 18:05:29,427] m-LoRA: Adapter lora_finqa_79 epoch: 1/1 iteration: 66/128 step: 34
[2025-12-23 18:05:29,513] m-LoRA: Adapter lora_finqa_70 epoch: 1/1 iteration: 98/128 step: 50
[2025-12-23 18:05:29,709] m-LoRA: Adapter lora_finqa_81 epoch: 1/1 iteration: 66/128 step: 34
[2025-12-23 18:05:29,793] m-LoRA: Adapter lora_finqa_84 epoch: 1/1 iteration: 66/128 step: 34
[2025-12-23 18:05:30,172] m-LoRA: Adapter lora_finqa_79 loss: 0.00018777974764816463
[2025-12-23 18:05:30,175] m-LoRA: Adapter lora_finqa_85 epoch: 1/1 iteration: 66/128 step: 34
[2025-12-23 18:05:30,436] m-LoRA: Adapter lora_finqa_70 loss: 9.737360960571095e-05
[2025-12-23 18:05:30,439] m-LoRA: Adapter lora_finqa_74 epoch: 1/1 iteration: 98/128 step: 50
[2025-12-23 18:05:30,694] m-LoRA: Adapter lora_finqa_81 loss: 0.003404945367947221
[2025-12-23 18:05:31,009] m-LoRA: Adapter lora_finqa_84 loss: 0.01800021342933178
[2025-12-23 18:05:31,357] m-LoRA: Adapter lora_finqa_85 loss: 0.0001837065356085077
[2025-12-23 18:05:31,360] m-LoRA: Adapter lora_finqa_79 epoch: 1/1 iteration: 68/128 step: 35
[2025-12-23 18:05:31,631] m-LoRA: Adapter lora_finqa_74 loss: 5.690176840289496e-05
[2025-12-23 18:05:31,635] m-LoRA: Adapter lora_finqa_70 epoch: 1/1 iteration: 100/128 step: 51
[2025-12-23 18:05:31,797] m-LoRA: Adapter lora_finqa_81 epoch: 1/1 iteration: 68/128 step: 35
[2025-12-23 18:05:31,901] m-LoRA: Adapter lora_finqa_84 epoch: 1/1 iteration: 68/128 step: 35
[2025-12-23 18:05:32,308] m-LoRA: Adapter lora_finqa_85 epoch: 1/1 iteration: 68/128 step: 35
[2025-12-23 18:05:32,345] m-LoRA: Adapter lora_finqa_79 loss: 0.00018357412773184478
[2025-12-23 18:05:32,625] m-LoRA: Adapter lora_finqa_70 loss: 9.150908590527251e-05
[2025-12-23 18:05:32,628] m-LoRA: Adapter lora_finqa_74 epoch: 1/1 iteration: 100/128 step: 51
[2025-12-23 18:05:32,856] m-LoRA: Adapter lora_finqa_81 loss: 0.0027759158983826637
[2025-12-23 18:05:33,214] m-LoRA: Adapter lora_finqa_84 loss: 0.016798578202724457
[2025-12-23 18:05:33,217] m-LoRA: Adapter lora_finqa_79 epoch: 1/1 iteration: 70/128 step: 36
[2025-12-23 18:05:33,513] m-LoRA: Adapter lora_finqa_85 loss: 0.00016216687799897045
[2025-12-23 18:05:33,881] m-LoRA: Adapter lora_finqa_74 loss: 5.453160702018067e-05
[2025-12-23 18:05:33,884] m-LoRA: Adapter lora_finqa_70 epoch: 1/1 iteration: 102/128 step: 52
[2025-12-23 18:05:34,061] m-LoRA: Adapter lora_finqa_81 epoch: 1/1 iteration: 70/128 step: 36
[2025-12-23 18:05:34,211] m-LoRA: Adapter lora_finqa_84 epoch: 1/1 iteration: 70/128 step: 36
[2025-12-23 18:05:34,265] m-LoRA: Adapter lora_finqa_79 loss: 0.00014103311696089804
[2025-12-23 18:05:34,389] m-LoRA: Adapter lora_finqa_85 epoch: 1/1 iteration: 70/128 step: 36
[2025-12-23 18:05:34,818] m-LoRA: Adapter lora_finqa_70 loss: 8.732351125217974e-05
[2025-12-23 18:05:34,821] m-LoRA: Adapter lora_finqa_74 epoch: 1/1 iteration: 102/128 step: 52
[2025-12-23 18:05:35,212] m-LoRA: Adapter lora_finqa_81 loss: 0.0020279623568058014
[2025-12-23 18:05:35,216] m-LoRA: Adapter lora_finqa_79 epoch: 1/1 iteration: 72/128 step: 37
[2025-12-23 18:05:35,514] m-LoRA: Adapter lora_finqa_84 loss: 0.015430714003741741
[2025-12-23 18:05:35,846] m-LoRA: Adapter lora_finqa_85 loss: 0.0001438448525732383
[2025-12-23 18:05:35,849] m-LoRA: Adapter lora_finqa_70 epoch: 1/1 iteration: 104/128 step: 53
[2025-12-23 18:05:36,148] m-LoRA: Adapter lora_finqa_81 epoch: 1/1 iteration: 72/128 step: 37
[2025-12-23 18:05:36,200] m-LoRA: Adapter lora_finqa_74 loss: 5.331714783096686e-05
[2025-12-23 18:05:36,527] m-LoRA: Adapter lora_finqa_79 loss: 0.00012925275950692594
[2025-12-23 18:05:36,531] m-LoRA: Adapter lora_finqa_84 epoch: 1/1 iteration: 72/128 step: 37
[2025-12-23 18:05:36,925] m-LoRA: Adapter lora_finqa_70 loss: 8.155336399795488e-05
[2025-12-23 18:05:36,928] m-LoRA: Adapter lora_finqa_85 epoch: 1/1 iteration: 72/128 step: 37
[2025-12-23 18:05:37,292] m-LoRA: Adapter lora_finqa_74 epoch: 1/1 iteration: 104/128 step: 53
[2025-12-23 18:05:37,349] m-LoRA: Adapter lora_finqa_81 loss: 0.0012824770528823137
[2025-12-23 18:05:37,642] m-LoRA: Adapter lora_finqa_84 loss: 0.015277115628123283
[2025-12-23 18:05:37,646] m-LoRA: Adapter lora_finqa_79 epoch: 1/1 iteration: 74/128 step: 38
[2025-12-23 18:05:37,901] m-LoRA: Adapter lora_finqa_85 loss: 0.00014722485502716154
[2025-12-23 18:05:37,904] m-LoRA: Adapter lora_finqa_70 epoch: 1/1 iteration: 106/128 step: 54
[2025-12-23 18:05:38,352] m-LoRA: Adapter lora_finqa_74 loss: 5.0240840209880844e-05
[2025-12-23 18:05:38,355] m-LoRA: Adapter lora_finqa_81 epoch: 1/1 iteration: 74/128 step: 38
[2025-12-23 18:05:38,685] m-LoRA: Adapter lora_finqa_79 loss: 0.00011767393152695149
[2025-12-23 18:05:38,688] m-LoRA: Adapter lora_finqa_84 epoch: 1/1 iteration: 74/128 step: 38
[2025-12-23 18:05:39,011] m-LoRA: Adapter lora_finqa_70 loss: 7.94681764091365e-05
[2025-12-23 18:05:39,015] m-LoRA: Adapter lora_finqa_85 epoch: 1/1 iteration: 74/128 step: 38
[2025-12-23 18:05:39,309] m-LoRA: Adapter lora_finqa_81 loss: 0.0016524754464626312
[2025-12-23 18:05:39,313] m-LoRA: Adapter lora_finqa_74 epoch: 1/1 iteration: 106/128 step: 54
[2025-12-23 18:05:39,707] m-LoRA: Adapter lora_finqa_84 loss: 0.014108910225331783
[2025-12-23 18:05:39,710] m-LoRA: Adapter lora_finqa_79 epoch: 1/1 iteration: 76/128 step: 39
[2025-12-23 18:05:40,041] m-LoRA: Adapter lora_finqa_85 loss: 0.00012146117660449818
[2025-12-23 18:05:40,045] m-LoRA: Adapter lora_finqa_70 epoch: 1/1 iteration: 108/128 step: 55
[2025-12-23 18:05:40,372] m-LoRA: Adapter lora_finqa_74 loss: 4.9273468903265893e-05
[2025-12-23 18:05:40,376] m-LoRA: Adapter lora_finqa_81 epoch: 1/1 iteration: 76/128 step: 39
[2025-12-23 18:05:40,712] m-LoRA: Adapter lora_finqa_79 loss: 0.00010733926319517195
[2025-12-23 18:05:40,716] m-LoRA: Adapter lora_finqa_84 epoch: 1/1 iteration: 76/128 step: 39
[2025-12-23 18:05:41,134] m-LoRA: Adapter lora_finqa_70 loss: 7.328008359763771e-05
[2025-12-23 18:05:41,137] m-LoRA: Adapter lora_finqa_85 epoch: 1/1 iteration: 76/128 step: 39
[2025-12-23 18:05:41,418] m-LoRA: Adapter lora_finqa_74 epoch: 1/1 iteration: 108/128 step: 55
[2025-12-23 18:05:41,478] m-LoRA: Adapter lora_finqa_81 loss: 0.0006421760190278292
[2025-12-23 18:05:41,784] m-LoRA: Adapter lora_finqa_84 loss: 0.013669056817889214
[2025-12-23 18:05:41,787] m-LoRA: Adapter lora_finqa_79 epoch: 1/1 iteration: 78/128 step: 40
[2025-12-23 18:05:42,159] m-LoRA: Adapter lora_finqa_85 loss: 0.00012025934120174497
[2025-12-23 18:05:42,163] m-LoRA: Adapter lora_finqa_70 epoch: 1/1 iteration: 110/128 step: 56
[2025-12-23 18:05:42,532] m-LoRA: Adapter lora_finqa_74 loss: 4.9139482143800706e-05
[2025-12-23 18:05:42,535] m-LoRA: Adapter lora_finqa_81 epoch: 1/1 iteration: 78/128 step: 40
[2025-12-23 18:05:42,846] m-LoRA: Adapter lora_finqa_79 loss: 0.0001017913527903147
[2025-12-23 18:05:42,849] m-LoRA: Adapter lora_finqa_84 epoch: 1/1 iteration: 78/128 step: 40
[2025-12-23 18:05:43,165] m-LoRA: Adapter lora_finqa_70 loss: 8.0233505286742e-05
[2025-12-23 18:05:43,169] m-LoRA: Adapter lora_finqa_85 epoch: 1/1 iteration: 78/128 step: 40
[2025-12-23 18:05:43,546] m-LoRA: Adapter lora_finqa_81 loss: 0.0004402182239573449
[2025-12-23 18:05:43,549] m-LoRA: Adapter lora_finqa_74 epoch: 1/1 iteration: 110/128 step: 56
[2025-12-23 18:05:43,854] m-LoRA: Adapter lora_finqa_84 loss: 0.01343852374702692
[2025-12-23 18:05:43,857] m-LoRA: Adapter lora_finqa_79 epoch: 1/1 iteration: 80/128 step: 41
[2025-12-23 18:05:44,157] m-LoRA: Adapter lora_finqa_85 loss: 0.00011395219917176291
[2025-12-23 18:05:44,161] m-LoRA: Adapter lora_finqa_70 epoch: 1/1 iteration: 112/128 step: 57
[2025-12-23 18:05:44,557] m-LoRA: Adapter lora_finqa_74 loss: 4.615395300788805e-05
[2025-12-23 18:05:44,561] m-LoRA: Adapter lora_finqa_81 epoch: 1/1 iteration: 80/128 step: 41
[2025-12-23 18:05:44,975] m-LoRA: Adapter lora_finqa_79 loss: 9.537782898405567e-05
[2025-12-23 18:05:44,978] m-LoRA: Adapter lora_finqa_84 epoch: 1/1 iteration: 80/128 step: 41
[2025-12-23 18:05:45,211] m-LoRA: Adapter lora_finqa_70 loss: 6.774534995201975e-05
[2025-12-23 18:05:45,215] m-LoRA: Adapter lora_finqa_85 epoch: 1/1 iteration: 80/128 step: 41
[2025-12-23 18:05:45,528] m-LoRA: Adapter lora_finqa_81 loss: 0.0003535533032845706
[2025-12-23 18:05:45,532] m-LoRA: Adapter lora_finqa_74 epoch: 1/1 iteration: 112/128 step: 57
[2025-12-23 18:05:46,017] m-LoRA: Adapter lora_finqa_84 loss: 0.012742279097437859
[2025-12-23 18:05:46,021] m-LoRA: Adapter lora_finqa_79 epoch: 1/1 iteration: 82/128 step: 42
[2025-12-23 18:05:46,360] m-LoRA: Adapter lora_finqa_85 loss: 9.975681314244866e-05
[2025-12-23 18:05:46,363] m-LoRA: Adapter lora_finqa_70 epoch: 1/1 iteration: 114/128 step: 58
[2025-12-23 18:05:46,769] m-LoRA: Adapter lora_finqa_74 loss: 4.777475260198116e-05
[2025-12-23 18:05:46,772] m-LoRA: Adapter lora_finqa_81 epoch: 1/1 iteration: 82/128 step: 42
[2025-12-23 18:05:47,102] m-LoRA: Adapter lora_finqa_79 loss: 9.386414603795856e-05
[2025-12-23 18:05:47,105] m-LoRA: Adapter lora_finqa_84 epoch: 1/1 iteration: 82/128 step: 42
[2025-12-23 18:05:47,400] m-LoRA: Adapter lora_finqa_70 loss: 7.135202031349763e-05
[2025-12-23 18:05:47,403] m-LoRA: Adapter lora_finqa_85 epoch: 1/1 iteration: 82/128 step: 42
[2025-12-23 18:05:47,684] m-LoRA: Adapter lora_finqa_74 epoch: 1/1 iteration: 114/128 step: 58
[2025-12-23 18:05:47,736] m-LoRA: Adapter lora_finqa_81 loss: 0.0002677498559933156
[2025-12-23 18:05:48,078] m-LoRA: Adapter lora_finqa_79 epoch: 1/1 iteration: 84/128 step: 43
[2025-12-23 18:05:48,132] m-LoRA: Adapter lora_finqa_84 loss: 0.012242471799254417
[2025-12-23 18:05:48,375] m-LoRA: Adapter lora_finqa_70 epoch: 1/1 iteration: 116/128 step: 59
[2025-12-23 18:05:48,429] m-LoRA: Adapter lora_finqa_85 loss: 9.191910066874698e-05
[2025-12-23 18:05:48,710] m-LoRA: Adapter lora_finqa_74 loss: 4.315138721722178e-05
[2025-12-23 18:05:48,713] m-LoRA: Adapter lora_finqa_81 epoch: 1/1 iteration: 84/128 step: 43
[2025-12-23 18:05:49,110] m-LoRA: Adapter lora_finqa_79 loss: 8.192024688469246e-05
[2025-12-23 18:05:49,114] m-LoRA: Adapter lora_finqa_84 epoch: 1/1 iteration: 84/128 step: 43
[2025-12-23 18:05:49,452] m-LoRA: Adapter lora_finqa_70 loss: 6.622604269068688e-05
[2025-12-23 18:05:49,455] m-LoRA: Adapter lora_finqa_85 epoch: 1/1 iteration: 84/128 step: 43
[2025-12-23 18:05:49,779] m-LoRA: Adapter lora_finqa_81 loss: 0.0007412403356283903
[2025-12-23 18:05:49,782] m-LoRA: Adapter lora_finqa_74 epoch: 1/1 iteration: 116/128 step: 59
[2025-12-23 18:05:50,085] m-LoRA: Adapter lora_finqa_84 loss: 0.011743063107132912
[2025-12-23 18:05:50,088] m-LoRA: Adapter lora_finqa_79 epoch: 1/1 iteration: 86/128 step: 44
[2025-12-23 18:05:50,487] m-LoRA: Adapter lora_finqa_85 loss: 9.064647747436538e-05
[2025-12-23 18:05:50,491] m-LoRA: Adapter lora_finqa_70 epoch: 1/1 iteration: 118/128 step: 60
[2025-12-23 18:05:50,809] m-LoRA: Adapter lora_finqa_74 loss: 4.243889270583168e-05
[2025-12-23 18:05:50,813] m-LoRA: Adapter lora_finqa_81 epoch: 1/1 iteration: 86/128 step: 44
[2025-12-23 18:05:51,125] m-LoRA: Adapter lora_finqa_79 loss: 7.854549767216668e-05
[2025-12-23 18:05:51,128] m-LoRA: Adapter lora_finqa_84 epoch: 1/1 iteration: 86/128 step: 44
[2025-12-23 18:05:51,513] m-LoRA: Adapter lora_finqa_70 loss: 6.195891910465434e-05
[2025-12-23 18:05:51,516] m-LoRA: Adapter lora_finqa_85 epoch: 1/1 iteration: 86/128 step: 44
[2025-12-23 18:05:51,848] m-LoRA: Adapter lora_finqa_81 loss: 0.0001918146008392796
[2025-12-23 18:05:51,851] m-LoRA: Adapter lora_finqa_74 epoch: 1/1 iteration: 118/128 step: 60
[2025-12-23 18:05:52,187] m-LoRA: Adapter lora_finqa_84 loss: 0.011312849819660187
[2025-12-23 18:05:52,191] m-LoRA: Adapter lora_finqa_79 epoch: 1/1 iteration: 88/128 step: 45
[2025-12-23 18:05:52,502] m-LoRA: Adapter lora_finqa_85 loss: 8.090120536508039e-05
[2025-12-23 18:05:52,505] m-LoRA: Adapter lora_finqa_70 epoch: 1/1 iteration: 120/128 step: 61
[2025-12-23 18:05:52,895] m-LoRA: Adapter lora_finqa_74 loss: 4.10359280067496e-05
[2025-12-23 18:05:52,898] m-LoRA: Adapter lora_finqa_81 epoch: 1/1 iteration: 88/128 step: 45
[2025-12-23 18:05:53,228] m-LoRA: Adapter lora_finqa_79 loss: 8.103218715405092e-05
[2025-12-23 18:05:53,231] m-LoRA: Adapter lora_finqa_84 epoch: 1/1 iteration: 88/128 step: 45
[2025-12-23 18:05:53,543] m-LoRA: Adapter lora_finqa_70 loss: 7.099895447026938e-05
[2025-12-23 18:05:53,547] m-LoRA: Adapter lora_finqa_85 epoch: 1/1 iteration: 88/128 step: 45
[2025-12-23 18:05:53,861] m-LoRA: Adapter lora_finqa_81 loss: 0.00019897191668860614
[2025-12-23 18:05:53,864] m-LoRA: Adapter lora_finqa_74 epoch: 1/1 iteration: 120/128 step: 61
[2025-12-23 18:05:54,273] m-LoRA: Adapter lora_finqa_84 loss: 0.011230949312448502
[2025-12-23 18:05:54,277] m-LoRA: Adapter lora_finqa_79 epoch: 1/1 iteration: 90/128 step: 46
[2025-12-23 18:05:54,571] m-LoRA: Adapter lora_finqa_85 loss: 7.947687117848545e-05
[2025-12-23 18:05:54,574] m-LoRA: Adapter lora_finqa_70 epoch: 1/1 iteration: 122/128 step: 62
[2025-12-23 18:05:54,870] m-LoRA: Adapter lora_finqa_74 loss: 3.989634205936454e-05
[2025-12-23 18:05:54,873] m-LoRA: Adapter lora_finqa_81 epoch: 1/1 iteration: 90/128 step: 46
[2025-12-23 18:05:55,258] m-LoRA: Adapter lora_finqa_84 epoch: 1/1 iteration: 90/128 step: 46
[2025-12-23 18:05:55,288] m-LoRA: Adapter lora_finqa_79 loss: 7.006534724496305e-05
[2025-12-23 18:05:55,588] m-LoRA: Adapter lora_finqa_70 loss: 5.70094161957968e-05
[2025-12-23 18:05:55,592] m-LoRA: Adapter lora_finqa_85 epoch: 1/1 iteration: 90/128 step: 46
[2025-12-23 18:05:55,895] m-LoRA: Adapter lora_finqa_81 loss: 0.00013908883556723595
[2025-12-23 18:05:55,899] m-LoRA: Adapter lora_finqa_74 epoch: 1/1 iteration: 122/128 step: 62
[2025-12-23 18:05:56,208] m-LoRA: Adapter lora_finqa_84 loss: 0.010445180349051952
[2025-12-23 18:05:56,211] m-LoRA: Adapter lora_finqa_79 epoch: 1/1 iteration: 92/128 step: 47
[2025-12-23 18:05:56,594] m-LoRA: Adapter lora_finqa_85 loss: 7.271738286362961e-05
[2025-12-23 18:05:56,598] m-LoRA: Adapter lora_finqa_70 epoch: 1/1 iteration: 124/128 step: 63
[2025-12-23 18:05:56,939] m-LoRA: Adapter lora_finqa_74 loss: 3.974702849518508e-05
[2025-12-23 18:05:56,942] m-LoRA: Adapter lora_finqa_81 epoch: 1/1 iteration: 92/128 step: 47
[2025-12-23 18:05:57,264] m-LoRA: Adapter lora_finqa_79 loss: 6.847553595434874e-05
[2025-12-23 18:05:57,267] m-LoRA: Adapter lora_finqa_84 epoch: 1/1 iteration: 92/128 step: 47
[2025-12-23 18:05:57,560] m-LoRA: Adapter lora_finqa_85 epoch: 1/1 iteration: 92/128 step: 47
[2025-12-23 18:05:57,619] m-LoRA: Adapter lora_finqa_70 loss: 6.362791464198381e-05
[2025-12-23 18:05:57,989] m-LoRA: Adapter lora_finqa_81 loss: 0.00012376323866192251
[2025-12-23 18:05:57,992] m-LoRA: Adapter lora_finqa_74 epoch: 1/1 iteration: 124/128 step: 63
[2025-12-23 18:05:58,290] m-LoRA: Adapter lora_finqa_84 loss: 0.01045443955808878
[2025-12-23 18:05:58,294] m-LoRA: Adapter lora_finqa_79 epoch: 1/1 iteration: 94/128 step: 48
[2025-12-23 18:05:58,614] m-LoRA: Adapter lora_finqa_85 loss: 7.218859536806121e-05
[2025-12-23 18:05:58,617] m-LoRA: Adapter lora_finqa_70 epoch: 1/1 iteration: 126/128 step: 64
[2025-12-23 18:05:58,930] m-LoRA: Adapter lora_finqa_74 loss: 3.84102895623073e-05
[2025-12-23 18:05:58,933] m-LoRA: Adapter lora_finqa_81 epoch: 1/1 iteration: 94/128 step: 48
[2025-12-23 18:05:59,243] m-LoRA: Adapter lora_finqa_84 epoch: 1/1 iteration: 94/128 step: 48
[2025-12-23 18:05:59,302] m-LoRA: Adapter lora_finqa_79 loss: 6.367029709508643e-05
[2025-12-23 18:05:59,703] m-LoRA: Adapter lora_finqa_70 loss: 5.591771696344949e-05
[2025-12-23 18:05:59,706] m-LoRA: Adapter lora_finqa_85 epoch: 1/1 iteration: 94/128 step: 48
[2025-12-23 18:05:59,994] m-LoRA: Adapter lora_finqa_81 loss: 0.00011522274144226685
[2025-12-23 18:05:59,997] m-LoRA: Adapter lora_finqa_74 epoch: 1/1 iteration: 126/128 step: 64
[2025-12-23 18:06:00,323] m-LoRA: Adapter lora_finqa_84 loss: 0.009939124807715416
[2025-12-23 18:06:00,326] m-LoRA: Adapter lora_finqa_79 epoch: 1/1 iteration: 96/128 step: 49
[2025-12-23 18:06:00,639] m-LoRA: Finish and base model offload adapter - ['lora_finqa_70']
[2025-12-23 18:06:00,907] m-LoRA: Adapter lora_finqa_85 loss: 6.716197094647214e-05
[2025-12-23 18:06:00,941] m-LoRA: Adapter lora_finqa_74 loss: 3.737253064173274e-05
[2025-12-23 18:06:01,159] m-LoRA: Adapter lora_finqa_81 epoch: 1/1 iteration: 96/128 step: 49
[2025-12-23 18:06:01,578] m-LoRA: Adapter lora_finqa_79 loss: 6.095546268625185e-05
[2025-12-23 18:06:01,581] m-LoRA: Adapter lora_finqa_84 epoch: 1/1 iteration: 96/128 step: 49
[2025-12-23 18:06:01,735] m-LoRA: Adapter lora_finqa_85 epoch: 1/1 iteration: 96/128 step: 49
[2025-12-23 18:06:02,035] m-LoRA: Finish and base model offload adapter - ['lora_finqa_74']
[2025-12-23 18:06:02,553] m-LoRA: Adapter lora_finqa_81 loss: 0.00010910646960837767
[2025-12-23 18:06:02,558] m-LoRA: Adapter lora_finqa_84 loss: 0.00935574434697628
[2025-12-23 18:06:02,763] m-LoRA: Adapter lora_finqa_85 loss: 6.339276296785101e-05
[2025-12-23 18:06:03,094] m-LoRA: Adapter lora_finqa_79 epoch: 1/1 iteration: 98/128 step: 50
[2025-12-23 18:06:03,248] m-LoRA: Adapter lora_finqa_81 epoch: 1/1 iteration: 98/128 step: 50
[2025-12-23 18:06:03,492] m-LoRA: Adapter lora_finqa_84 epoch: 1/1 iteration: 98/128 step: 50
[2025-12-23 18:06:03,906] m-LoRA: Adapter lora_finqa_85 epoch: 1/1 iteration: 98/128 step: 50
[2025-12-23 18:06:03,950] m-LoRA: Adapter lora_finqa_79 loss: 6.16611068835482e-05
[2025-12-23 18:06:04,202] m-LoRA: Adapter lora_finqa_81 loss: 0.00012281935778446496
[2025-12-23 18:06:04,463] m-LoRA: Adapter lora_finqa_84 loss: 0.008490564301609993
[2025-12-23 18:06:04,785] m-LoRA: Adapter lora_finqa_85 loss: 6.550865509780124e-05
[2025-12-23 18:06:04,788] m-LoRA: Adapter lora_finqa_79 epoch: 1/1 iteration: 100/128 step: 51
[2025-12-23 18:06:04,992] m-LoRA: Adapter lora_finqa_81 epoch: 1/1 iteration: 100/128 step: 51
[2025-12-23 18:06:05,206] m-LoRA: Adapter lora_finqa_84 epoch: 1/1 iteration: 100/128 step: 51
[2025-12-23 18:06:05,678] m-LoRA: Adapter lora_finqa_85 epoch: 1/1 iteration: 100/128 step: 51
[2025-12-23 18:06:05,735] m-LoRA: Adapter lora_finqa_79 loss: 5.75609301449731e-05
[2025-12-23 18:06:05,942] m-LoRA: Adapter lora_finqa_81 loss: 9.489190415479243e-05
[2025-12-23 18:06:06,251] m-LoRA: Adapter lora_finqa_84 loss: 0.007981248199939728
[2025-12-23 18:06:06,682] m-LoRA: Adapter lora_finqa_85 loss: 6.0160557040944695e-05
[2025-12-23 18:06:06,686] m-LoRA: Adapter lora_finqa_79 epoch: 1/1 iteration: 102/128 step: 52
[2025-12-23 18:06:06,868] m-LoRA: Adapter lora_finqa_81 epoch: 1/1 iteration: 102/128 step: 52
[2025-12-23 18:06:07,116] m-LoRA: Adapter lora_finqa_84 epoch: 1/1 iteration: 102/128 step: 52
[2025-12-23 18:06:07,588] m-LoRA: Adapter lora_finqa_85 epoch: 1/1 iteration: 102/128 step: 52
[2025-12-23 18:06:07,647] m-LoRA: Adapter lora_finqa_79 loss: 5.565453102462925e-05
[2025-12-23 18:06:07,879] m-LoRA: Adapter lora_finqa_81 loss: 8.580520079704002e-05
[2025-12-23 18:06:08,176] m-LoRA: Adapter lora_finqa_84 loss: 0.007515511009842157
[2025-12-23 18:06:08,497] m-LoRA: Adapter lora_finqa_85 loss: 5.6781900639180094e-05
[2025-12-23 18:06:08,501] m-LoRA: Adapter lora_finqa_79 epoch: 1/1 iteration: 104/128 step: 53
[2025-12-23 18:06:08,673] m-LoRA: Adapter lora_finqa_81 epoch: 1/1 iteration: 104/128 step: 53
[2025-12-23 18:06:08,899] m-LoRA: Adapter lora_finqa_84 epoch: 1/1 iteration: 104/128 step: 53
[2025-12-23 18:06:09,377] m-LoRA: Adapter lora_finqa_85 epoch: 1/1 iteration: 104/128 step: 53
[2025-12-23 18:06:09,431] m-LoRA: Adapter lora_finqa_79 loss: 5.271867848932743e-05
[2025-12-23 18:06:09,659] m-LoRA: Adapter lora_finqa_81 loss: 8.061421976890415e-05
[2025-12-23 18:06:09,974] m-LoRA: Adapter lora_finqa_84 loss: 0.0071147531270980835
[2025-12-23 18:06:10,335] m-LoRA: Adapter lora_finqa_85 loss: 5.6100547226378694e-05
[2025-12-23 18:06:10,338] m-LoRA: Adapter lora_finqa_79 epoch: 1/1 iteration: 106/128 step: 54
[2025-12-23 18:06:10,534] m-LoRA: Adapter lora_finqa_81 epoch: 1/1 iteration: 106/128 step: 54
[2025-12-23 18:06:10,768] m-LoRA: Adapter lora_finqa_84 epoch: 1/1 iteration: 106/128 step: 54
[2025-12-23 18:06:11,271] m-LoRA: Adapter lora_finqa_79 loss: 5.263405182631686e-05
[2025-12-23 18:06:11,274] m-LoRA: Adapter lora_finqa_85 epoch: 1/1 iteration: 106/128 step: 54
[2025-12-23 18:06:11,538] m-LoRA: Adapter lora_finqa_81 loss: 8.673865522723645e-05
[2025-12-23 18:06:11,831] m-LoRA: Adapter lora_finqa_84 loss: 0.006553545594215393
[2025-12-23 18:06:12,214] m-LoRA: Adapter lora_finqa_85 loss: 5.337800394045189e-05
[2025-12-23 18:06:12,217] m-LoRA: Adapter lora_finqa_79 epoch: 1/1 iteration: 108/128 step: 55
[2025-12-23 18:06:12,406] m-LoRA: Adapter lora_finqa_81 epoch: 1/1 iteration: 108/128 step: 55
[2025-12-23 18:06:12,649] m-LoRA: Adapter lora_finqa_84 epoch: 1/1 iteration: 108/128 step: 55
[2025-12-23 18:06:13,092] m-LoRA: Adapter lora_finqa_85 epoch: 1/1 iteration: 108/128 step: 55
[2025-12-23 18:06:13,147] m-LoRA: Adapter lora_finqa_79 loss: 4.890659329248592e-05
[2025-12-23 18:06:13,388] m-LoRA: Adapter lora_finqa_81 loss: 0.00011165996693307534
[2025-12-23 18:06:13,663] m-LoRA: Adapter lora_finqa_84 loss: 0.005911358166486025
[2025-12-23 18:06:14,015] m-LoRA: Adapter lora_finqa_85 loss: 5.489840259542689e-05
[2025-12-23 18:06:14,018] m-LoRA: Adapter lora_finqa_79 epoch: 1/1 iteration: 110/128 step: 56
[2025-12-23 18:06:14,266] m-LoRA: Adapter lora_finqa_81 epoch: 1/1 iteration: 110/128 step: 56
[2025-12-23 18:06:14,472] m-LoRA: Adapter lora_finqa_84 epoch: 1/1 iteration: 110/128 step: 56
[2025-12-23 18:06:14,989] m-LoRA: Adapter lora_finqa_85 epoch: 1/1 iteration: 110/128 step: 56
[2025-12-23 18:06:15,036] m-LoRA: Adapter lora_finqa_79 loss: 4.757312126457691e-05
[2025-12-23 18:06:15,295] m-LoRA: Adapter lora_finqa_81 loss: 8.826991688692942e-05
[2025-12-23 18:06:15,571] m-LoRA: Adapter lora_finqa_84 loss: 0.00531794922426343
[2025-12-23 18:06:15,915] m-LoRA: Adapter lora_finqa_85 loss: 5.0420516345184296e-05
[2025-12-23 18:06:15,918] m-LoRA: Adapter lora_finqa_79 epoch: 1/1 iteration: 112/128 step: 57
[2025-12-23 18:06:16,093] m-LoRA: Adapter lora_finqa_81 epoch: 1/1 iteration: 112/128 step: 57
[2025-12-23 18:06:16,396] m-LoRA: Adapter lora_finqa_84 epoch: 1/1 iteration: 112/128 step: 57
[2025-12-23 18:06:16,858] m-LoRA: Adapter lora_finqa_85 epoch: 1/1 iteration: 112/128 step: 57
[2025-12-23 18:06:16,915] m-LoRA: Adapter lora_finqa_79 loss: 4.6555222070310265e-05
[2025-12-23 18:06:17,143] m-LoRA: Adapter lora_finqa_81 loss: 7.851192640373483e-05
[2025-12-23 18:06:17,425] m-LoRA: Adapter lora_finqa_84 loss: 0.005590722430497408
[2025-12-23 18:06:17,872] m-LoRA: Adapter lora_finqa_85 loss: 4.9040812882594764e-05
[2025-12-23 18:06:17,875] m-LoRA: Adapter lora_finqa_79 epoch: 1/1 iteration: 114/128 step: 58
[2025-12-23 18:06:18,045] m-LoRA: Adapter lora_finqa_81 epoch: 1/1 iteration: 114/128 step: 58
[2025-12-23 18:06:18,352] m-LoRA: Adapter lora_finqa_84 epoch: 1/1 iteration: 114/128 step: 58
[2025-12-23 18:06:18,797] m-LoRA: Adapter lora_finqa_85 epoch: 1/1 iteration: 114/128 step: 58
[2025-12-23 18:06:18,854] m-LoRA: Adapter lora_finqa_79 loss: 5.587226041825488e-05
[2025-12-23 18:06:19,089] m-LoRA: Adapter lora_finqa_81 loss: 7.156976062105969e-05
[2025-12-23 18:06:19,427] m-LoRA: Adapter lora_finqa_84 loss: 0.004679536446928978
[2025-12-23 18:06:19,826] m-LoRA: Adapter lora_finqa_85 loss: 4.76719178550411e-05
[2025-12-23 18:06:19,829] m-LoRA: Adapter lora_finqa_79 epoch: 1/1 iteration: 116/128 step: 59
[2025-12-23 18:06:20,001] m-LoRA: Adapter lora_finqa_81 epoch: 1/1 iteration: 116/128 step: 59
[2025-12-23 18:06:20,360] m-LoRA: Adapter lora_finqa_84 epoch: 1/1 iteration: 116/128 step: 59
[2025-12-23 18:06:20,740] m-LoRA: Adapter lora_finqa_85 epoch: 1/1 iteration: 116/128 step: 59
[2025-12-23 18:06:20,793] m-LoRA: Adapter lora_finqa_79 loss: 4.4596174120670184e-05
[2025-12-23 18:06:21,007] m-LoRA: Adapter lora_finqa_81 loss: 6.656330515397713e-05
[2025-12-23 18:06:21,358] m-LoRA: Adapter lora_finqa_84 loss: 0.004195395857095718
[2025-12-23 18:06:21,700] m-LoRA: Adapter lora_finqa_85 loss: 4.607983282767236e-05
[2025-12-23 18:06:21,703] m-LoRA: Adapter lora_finqa_79 epoch: 1/1 iteration: 118/128 step: 60
[2025-12-23 18:06:21,917] m-LoRA: Adapter lora_finqa_81 epoch: 1/1 iteration: 118/128 step: 60
[2025-12-23 18:06:22,123] m-LoRA: Adapter lora_finqa_84 epoch: 1/1 iteration: 118/128 step: 60
[2025-12-23 18:06:22,591] m-LoRA: Adapter lora_finqa_85 epoch: 1/1 iteration: 118/128 step: 60
[2025-12-23 18:06:22,628] m-LoRA: Adapter lora_finqa_79 loss: 4.367390283732675e-05
[2025-12-23 18:06:22,892] m-LoRA: Adapter lora_finqa_81 loss: 7.475185702787712e-05
[2025-12-23 18:06:23,167] m-LoRA: Adapter lora_finqa_84 loss: 0.0036284541711211205
[2025-12-23 18:06:23,497] m-LoRA: Adapter lora_finqa_85 loss: 4.493347660172731e-05
[2025-12-23 18:06:23,501] m-LoRA: Adapter lora_finqa_79 epoch: 1/1 iteration: 120/128 step: 61
[2025-12-23 18:06:23,714] m-LoRA: Adapter lora_finqa_81 epoch: 1/1 iteration: 120/128 step: 61
[2025-12-23 18:06:24,012] m-LoRA: Adapter lora_finqa_84 epoch: 1/1 iteration: 120/128 step: 61
[2025-12-23 18:06:24,558] m-LoRA: Adapter lora_finqa_85 epoch: 1/1 iteration: 120/128 step: 61
[2025-12-23 18:06:24,603] m-LoRA: Adapter lora_finqa_79 loss: 4.2595384002197534e-05
[2025-12-23 18:06:24,836] m-LoRA: Adapter lora_finqa_81 loss: 5.9694495575968176e-05
[2025-12-23 18:06:25,147] m-LoRA: Adapter lora_finqa_84 loss: 0.0031276841182261705
[2025-12-23 18:06:25,488] m-LoRA: Adapter lora_finqa_85 loss: 4.527718556346372e-05
[2025-12-23 18:06:25,491] m-LoRA: Adapter lora_finqa_79 epoch: 1/1 iteration: 122/128 step: 62
[2025-12-23 18:06:25,637] m-LoRA: Adapter lora_finqa_81 epoch: 1/1 iteration: 122/128 step: 62
[2025-12-23 18:06:25,879] m-LoRA: Adapter lora_finqa_84 epoch: 1/1 iteration: 122/128 step: 62
[2025-12-23 18:06:26,349] m-LoRA: Adapter lora_finqa_85 epoch: 1/1 iteration: 122/128 step: 62
[2025-12-23 18:06:26,402] m-LoRA: Adapter lora_finqa_79 loss: 4.211763371131383e-05
[2025-12-23 18:06:26,651] m-LoRA: Adapter lora_finqa_81 loss: 8.751040877541527e-05
[2025-12-23 18:06:26,926] m-LoRA: Adapter lora_finqa_84 loss: 0.0026328370440751314
[2025-12-23 18:06:27,237] m-LoRA: Adapter lora_finqa_85 loss: 4.2906056478386745e-05
[2025-12-23 18:06:27,240] m-LoRA: Adapter lora_finqa_79 epoch: 1/1 iteration: 124/128 step: 63
[2025-12-23 18:06:27,480] m-LoRA: Adapter lora_finqa_81 epoch: 1/1 iteration: 124/128 step: 63
[2025-12-23 18:06:27,705] m-LoRA: Adapter lora_finqa_84 epoch: 1/1 iteration: 124/128 step: 63
[2025-12-23 18:06:28,153] m-LoRA: Adapter lora_finqa_85 epoch: 1/1 iteration: 124/128 step: 63
[2025-12-23 18:06:28,207] m-LoRA: Adapter lora_finqa_79 loss: 4.046143658342771e-05
[2025-12-23 18:06:28,435] m-LoRA: Adapter lora_finqa_81 loss: 5.7486919104121625e-05
[2025-12-23 18:06:28,736] m-LoRA: Adapter lora_finqa_84 loss: 0.001688396674580872
[2025-12-23 18:06:29,073] m-LoRA: Adapter lora_finqa_85 loss: 4.586700742947869e-05
[2025-12-23 18:06:29,076] m-LoRA: Adapter lora_finqa_79 epoch: 1/1 iteration: 126/128 step: 64
[2025-12-23 18:06:29,282] m-LoRA: Adapter lora_finqa_81 epoch: 1/1 iteration: 126/128 step: 64
[2025-12-23 18:06:29,536] m-LoRA: Adapter lora_finqa_84 epoch: 1/1 iteration: 126/128 step: 64
[2025-12-23 18:06:29,955] m-LoRA: Adapter lora_finqa_85 epoch: 1/1 iteration: 126/128 step: 64
[2025-12-23 18:06:30,007] m-LoRA: Adapter lora_finqa_79 loss: 4.040691419504583e-05
[2025-12-23 18:06:30,248] m-LoRA: Adapter lora_finqa_81 loss: 5.407816934166476e-05
[2025-12-23 18:06:30,514] m-LoRA: Adapter lora_finqa_84 loss: 0.0013061559293419123
[2025-12-23 18:06:30,852] m-LoRA: Finish and base model offload adapter - ['lora_finqa_79']
[2025-12-23 18:06:31,442] m-LoRA: Adapter lora_finqa_85 loss: 4.0878130675992e-05
[2025-12-23 18:06:31,880] m-LoRA: Finish and base model offload adapter - ['lora_finqa_81']
[2025-12-23 18:06:32,374] m-LoRA: Finish and base model offload adapter - ['lora_finqa_84']
[2025-12-23 18:06:32,777] m-LoRA: Finish and base model offload adapter - ['lora_finqa_85']
